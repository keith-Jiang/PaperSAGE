# Multi-view Granular-ball Contrastive Clustering

Peng $\mathbf { S u } ^ { 1 , 2 }$ , Shudong Huang1,2\*, Weihong $\mathbf { M } \mathbf { a } ^ { 3 }$ , Deng Xiong4, Jiancheng Lv1,2

1College of Computer Science, Sichuan University, Chengdu 610065, China 2Engineering Research Center of Machine Learning and Industry Intelligence, Ministry of Education, China 3Information Technology Research Center, Beijing Academy of Agriculture and Forestry Sciences, Beijing 100097, China 4Stevens Institute of Technology, 1 Castle Point Terrace, Hoboken, NJ 07030, USA supeng $@$ stu.scu.edu.cn, huangsd $@$ scu.edu.cn, mawh $@$ nercita.org.cn, dxiong $@$ stevens.edu, lvjiancheng@scu.edu.cn

# Abstract

Previous multi-view contrastive learning methods typically operate at two scales: instance-level and cluster-level. Instance-level approaches construct positive and negative pairs based on sample correspondences, aiming to bring positive pairs closer and push negative pairs further apart in the latent space. Cluster-level methods focus on calculating cluster assignments for samples under each view and maximize view consensus by reducing distribution discrepancies, e.g., minimizing KL divergence or maximizing mutual information. However, these two types of methods either introduce false negatives, leading to reduced model discriminability, or overlook local structures and cannot measure relationships between clusters across views explicitly. To this end, we propose a method named Multi-view Granularball Contrastive Clustering (MGBCC). MGBCC segments the sample set into coarse-grained granular balls, and establishes associations between intra-view and cross-view granular balls. These associations are reinforced in a shared latent space, thereby achieving multi-granularity contrastive learning. Granular balls lie between instances and clusters, naturally preserving the local topological structure of the sample set. We conduct extensive experiments to validate the effectiveness of the proposed method.

Code — https://github.com/Duo-laimi/mgbcc main

# Introduction

Multi-view data refers to data collected from different sensors or obtained by different feature extractors, often exhibiting heterogeneity (Fang et al. 2023). For example, a web page typically contains images, text, and videos, each of which can be considered a view, reflecting the same sample from different perspectives. Multi-view clustering has received continuous attention in recent years, aiming to partition multi-view data into different clusters in an unsupervised manner (Huang et al. 2019, 2022; Liu 2023; Deng et al. 2024). The key challenge in multi-view clustering is balancing the consistency and diversity between different views to learn the most comprehensive shared representation. Traditional multi-view learning methods mainly include subspace learning, graph learning, and multi-kernel learning. These methods often involve matrix decomposition and fusion, resulting in high computational complexity, making them difficult to apply to large-scale datasets, which severely hinders their practical application.

In recent years, deep-based multi-view learning methods have gained significant attention due to their excellent representation capabilities. These methods extend deep singleview clustering and typically select appropriate feature extractors based on the properties of the views. DCCA (Andrew et al. 2013) projects data from two views into a common space using deep neural networks, where the representations of the two views are highly linearly correlated, making it a nonlinear extension of canonical correlation analysis. PARTY (Peng et al. 2016) is a deep subspace clustering method with sparse priors that projects input data into a latent space, maintaining local structure by minimizing reconstruction loss while introducing sparse prior information into the latent representation learning to preserve sparse reconstruction relationships across the entire dataset. DIMC (Wen et al. 2020) extracts high-level features of multiple views through view-specific autoencoders and introduces fusion graph-based constraints to preserve the local geometric structure of the data. DMCE (Zhao, Yang, and Nie 2023) applies ensemble clustering to fuse similarity graphs from different views, using graph autoencoders to learn a common spectral embedding. These methods combine deep learning with traditional multi-view learning ideas by introducing constraints from traditional methods such as neighbor graph constraints or self-expression constraints into the latent space projected by deep modules. This allows the models to learn concise but comprehensive representations that maximally preserve the structural information of the input data.

Multi-view contrastive learning is another important branch of deep multi-view clustering. It can generally be divided into two categories: instance-level contrastive learning and cluster-level contrastive learning. The basic idea of the former is that instances of the same sample from different views should be as close as possible in the latent space, typically forming positive pairs. In these methods (Liu et al. 2023; Su et al. 2024; Yang et al. 2023b; Xu et al. 2023a), the construction and handling of negative pairs is a key focus due to the unknown instance labels in unsupervised paradigms. Improper negative pairs can degrade the model’s discriminative ability. Cluster-level methods (Xu et al. 2022; Jin et al. 2023; Chen et al. 2023), on the other hand, align the clustering assignments of different views. They typically establish one-to-one correspondences between clusters across views and aim to make the distributions of corresponding clusters as consistent as possible. However, clusters are macro structures and do not effectively utilize the local structural information within views.

We propose a multi-granularity multi-view learning method. This method models the local structure of the sample set using granular balls and establishes intra-view and inter-view granular-ball connections based on overlap and intersection size, respectively. By bringing connected granular balls closer in the latent space, our model learns highly discriminative features. To the best of our knowledge, this is the pioneering work utilizing granular-ball methodology for multiview contrastive learning. Specifically, our contributions are summarized as follows:

• We propose a novel deep multi-view clustering method that performs contrastive learning at the granular-ball level. This method avoids directly using neighboring samples to construct negative pairs while preserving the local structural information of the sample set, addressing the shortcomings of instance-level and cluster-level methods.   
• We introduce a simple yet effective granular-ball construction method. Unlike classical methods that continuously bisect the dataset until reaching the smallest granularity, our method directly partitions the sample set into multiple granular balls based on the granularity parameter, avoiding the drawback of non-adjacent samples being grouped into the same granular ball in boundary regions.   
• Extensive experiments on seven typical multi-view datasets demonstrate that our method achieves comparable or superior performance compared to state-of-the-art methods.

# Related Work

In this section, we briefly review the latest advancements in related topics, including multi-view contrastive learning and granular-ball computing.

# Multi-view Contrastive Learning

Contrastive learning (He et al. 2020; Chen et al. 2020; Zhang and Wang 2024) aims to learn a feature space with good discriminative properties, where positive pairs are pulled closer together, and negative pairs are pushed further apart. In a single-view setting, positive pairs are typically constructed through augmentations of the same sample, while negative pairs come from other samples within the same batch or dynamically constructed feature queues. This idea naturally extends to multi-view learning, as multi-view instances can be seen as natural augmentations of a sample: they are unique yet collectively describe the same sample, giving rise to multi-view contrastive learning.

Completer (Lin et al. 2021) uses conditional entropy and mutual information to measure the differences and consensus between different views. By maximizing the mutual information between views, they aims to learn rich and consistent representations. To resolve the conflict between maintaining multi-view semantic consistency and the reconstruction process that tends to preserve view-specific information, MFLVC (Xu et al. 2022) proposes a multi-level feature multi-view contrastive framework. This model learns lowlevel features, high-level features, and semantic labels from raw features in a fusion-free manner. Reconstruction is performed on low-level features, while consensus is explored through contrastive learning on high-level features. SURE (Yang et al. 2023a) addresses the issue of false negatives in multi-view contrastive learning, where two instances used to construct a negative pair might actually belong to the same cluster. It divides negative pairs into three intervals based on distance, treating those with distances below a certain threshold as potential positives for optimization.

# Granular-ball Computing

Expanding on the theoretical foundations of traditional granularity computation and integrating the human cognitive mechanism of ’macro-first’ (Chen 1982), Wang (Wang 2017) introduced the innovative concept of multi-granularity cognitive computation. Building on Wang’s framework, Xia (Xia et al. 2019) developed an efficient, robust, and interpretable computational method known as granular-ball computing. Unlike traditional methods that process data at the most granular level of individual points, granular-ball computing encapsulates and represents data using granular-balls, thereby enhancing efficiency and robustness. Notable applications of granular-ball computing include granular-ball clustering (Cheng et al. 2024; Xie et al. 2024a,b,c), granularball classifiers (Xia et al. 2024b; Quadir and Tanveer 2024), granular-ball sampling methods (Xia et al. 2023b), granularball rough sets (Xia et al. 2022, 2023a; Zhang et al. 2023), granular-ball three-way decisions (Yang et al. 2024; Xia et al. 2024a), and advancements such as granular-ball reinforcement learning (Liu et al. 2024).

![](images/daea4edfa8a343ee54e4bbc126b38c163d2b9870f107d370f30a88972b749c04.jpg)  
Figure 1: Examples of granular balls

Given a dataset $\{ x _ { i } \} _ { i = 1 } ^ { n }$ , let $\{ G B _ { i } \} _ { i = 1 } ^ { k }$ denote the set of granular balls generated based on it, where $k$ represents the total number of balls. As illustrated in Figure 1, one ball contains multiple neighboring samples or feature points, e.g., $G B _ { i } = \{ \bar { x _ { j } } \} _ { j = 1 } ^ { n _ { i } }$ , which essentially reflects the local topological relationships among samples. The center $c _ { i }$ and the radius $r _ { i }$ of $G B _ { i }$ are defined as

$$
c _ { i } = \frac { 1 } { n _ { i } } \sum _ { j = 1 } ^ { n _ { i } } x _ { j } , \quad r _ { i } = \frac { 1 } { n _ { i } } \sum _ { j = 1 } ^ { n _ { i } } \| c _ { i } - x _ { i } \| _ { 2 } .
$$

In granular-ball computation, the key lies in how to generate the granular-ball set, which involves two critical steps: partitioning and merging. Partitioning refers to the recursive process of dividing a large ball into two smaller ones. Initially, the entire dataset is initialized as a single granular ball. Granular balls that meet the split conditions will continue to split. The split conditions typically vary depending on the task. In clustering tasks, if the average radius of the original ball is greater than the weighted average radius of the two sub-ball combined, the ball will split. Otherwise, it will stop. This condition can lead to over-partitioning, such as having one ball per sample. To prevent this, a minimum capacity threshold $\eta$ is introduced. If the number of samples in a ball is less than $\eta$ , it will also stop splitting.

Merging refers to the process of combining two significantly overlapping ball into a single ball and recalculating the ball center and radius. Two balls are considered overlapping if they satisfy following conditions

$$
\| c _ { i } - c _ { j } \| _ { 2 } - ( r _ { i } + r _ { j } ) < \omega , \omega = \frac { m i n ( r _ { i } , r _ { j } ) } { m i n ( p _ { i } , p _ { j } ) } .
$$

where $p _ { i }$ and $p _ { j }$ denote the total number of overlaps with adjacent granular balls for $G B _ { i }$ and $G B _ { j }$ . The merging process continues until the ball set no longer changes.

# Methodology

In this section, we introduce a deep multi-view clustering method called Multi-view Granular-ball Contrastive Clustering (MGBCC). MGBCC encompasses four crucial processes: within-view reconstruction, within-view granularball generation, and cross-view granular-ball asociation and granular-ball contrastive learning. The framework is shown in Figure 2.

# Within-view Reconstruction

Given a multi-view dataset Xv V with $N$ samples, each sample has instances from $V$ different views. Let $d _ { v }$ represent the feature dimension of the $\boldsymbol { v }$ -th view, which typically varies across different views. To standardize the dimensions across views for subsequent comparison and fusion, we project the features of different views into a common dimension $d$ .

Deep autoencoders are employed as the representation learning framework to effectively extract essential lowdimensional embeddings from raw features. We assign an autoencoder to each view. Specifically, for the $v$ -th view, $E _ { v } ( \cdot ; \theta ^ { v } )$ and $D _ { v } ( \cdot ; \phi ^ { v } )$ denote its encoder and decoder, with $\theta ^ { v }$ and $\phi ^ { v }$ being their learnable parameters. As mentioned earlier, we set the output feature dimension of all encoders $\{ E _ { v } \} _ { v = 1 } ^ { V }$ to $d$ . After projection through encoders $\{ E _ { v } \} ^ { V }$ , we obtain the high-level features $\left\{ \mathbf { H } ^ { v } \right\} _ { v = 1 } ^ { V }$ of instances from the $\boldsymbol { v }$ -th view by minimizing

$$
\mathcal { L } _ { r e c } = \sum _ { v = 1 } ^ { V } \sum _ { i = 1 } ^ { N } \| \mathbf { x } _ { i } ^ { v } - D _ { v } \big ( E _ { v } ( \mathbf { x } _ { i } ^ { v } ; \boldsymbol { \theta } ^ { v } ) ; \boldsymbol { \phi } ^ { v } \big ) \| _ { 2 } ^ { 2 } ,
$$

where $\mathbf { x } _ { i } ^ { v }$ denotes the $i$ -th sample of $\mathbf { X } ^ { v }$ . The representation of $i$ -th sample in $\boldsymbol { v }$ -th view is given by

$$
\begin{array} { r } { \mathbf h _ { i } ^ { v } = E _ { v } ( \mathbf x _ { i } ^ { v } ; \theta ^ { v } ) . } \end{array}
$$

In the subsequent computations, we will use these instance representations for constructing granular balls instead of the original features.

# Within-view Granular-ball Generation

In clustering tasks, the classic granular ball partitioning method controls the granularity of division using a minimum capacity threshold (e.g., $\eta$ ). Granular balls are recursively split until the number of samples in a granular ball is less than this threshold. The issue with this method arises when it reaches the edge regions of the sample space, where the number of samples within a granular ball may be below the threshold, but the samples are dispersed (e.g., outliers). In such cases, the ball center may experience significant deviation, and the radius may be overestimated, resulting in inappropriate overlapping relationships.

To address this, we designed an alternative granular ball generation method. First, we introduce a granularity control parameter $p$ , which roughly reflects the granularity of granular ball generation. Let $k$ denote the total number of granular balls to be generated. We set $N$ and $k$ to satisfy the following relationship

$$
k = \operatorname* { m a x } \left( \left\lfloor { \frac { N } { p } } \right\rfloor , 1 \right) .
$$

We then directly apply the $k$ -means (Lloyd 1982) to the entire dataset, dividing it into $k$ clusters, with each cluster considered a granular ball. For each ball, we compute its center and radius. Intuitively, outliers in the sample space, being far from most samples, tend to form their own clusters. Non-outliers will cluster together approximately according to the granularity parameter $p$ .

We construct granular balls for each view individually. For the $\boldsymbol { v }$ -th view, $H ^ { v }$ denotes latent representations obtained through the projection by the encoding layer $E ^ { v }$ . Using the aforementioned method, we obtain $\begin{array} { r } { \begin{array} { r l } { S ^ { v } } & { { } = } \end{array} } \end{array}$ $\{ G B _ { i } ^ { v } \} _ { i = 1 } ^ { k _ { v } }$ , where $k _ { v }$ represents the number of granular balls in the $v$ -th view. If we set the granularity parameter $p _ { v }$ to the same value $p$ for each view, the numbers $\{ k _ { v } \} _ { v = 1 } ^ { V }$ across all views will be the same. For simplicity, we adopt this setting in the subsequent analysis and experiments.

Let $\boldsymbol { S } \doteq \{ S ^ { v } \} _ { v = 1 } ^ { V }$ denote granular ball sets constructed for all views, $\mathbf { C } ^ { v }$ be the center matrix of the $v$ -th view, and $\mathbf { r } ^ { v }$ be the radius matrix. For a granular ball $G B _ { i } ^ { v }$ , its center is $\mathbf { c } _ { i } ^ { v }$ and its radius is $r _ { i } ^ { v }$ . Note that the calculations of the centers and radii are gradient-preserving. In our granularball generation process, there is no merging process as in classical methods. However, we still need to consider the overlapping relationships of balls within each view.

![](images/6b8c85beb721ebfd0496a3d6ff7dce00286301f0787aa144e3f55233d9908edc.jpg)  
Figure 2: The framework of MGBCC. As shown, the overall loss function consists of two parts, e.g., reconstruction loss and granular-ball contrastive loss. We construct granular-ball sets $\{ S ^ { v } \} _ { v = 1 } ^ { V }$ for different views in the latent space and establish intraview and cross-view associations based on overlap and intersection size respectively. Granular balls model the local structure of the dataset, and associated granular balls should be close to each other in the latent space.

Let $\mathbf { D } ^ { v }$ represent the center distance matrix of the $\boldsymbol { v }$ -th view. The distance between the $i$ -th ball and the $j$ -th ball is calculated as $\mathbf { d } _ { i j } ^ { v } = \| \mathbf { c } _ { i } ^ { v } - \mathbf { c } _ { j } ^ { v } \| _ { 2 }$ . Based on $\mathbf { D } ^ { v }$ , we compute the granular balls overlapping matrix $\mathbf { A } ^ { v }$ , which satisfies

$$
a _ { i j } ^ { v } = \left\{ \begin{array} { l l } { 1 , } & { \mathrm { i f ~ } \mathrm { E q } ( 2 ) \mathrm { ~ i s ~ s a t i s f i e d } } \\ { 0 , } & { \mathrm { o t h e r w i s e } } \end{array} \right. .
$$

Note that $\mathbf { A } ^ { v }$ will serve as part of the mask matrix for contrastive learning.

# Cross-view Granular-ball Association

Through matrices $\{ \mathbf { A } ^ { v } \} _ { v = 1 } ^ { V }$ , we have established the intraview relationships between granular balls. Then we need to consider how to establish connections between cross-view granular balls. An intuitive approach is to consider two balls from different views as neighbors in the latent space if they each contain instances of the same sample from their respective views. However, this method lacks robustness. When $p$ is relatively large, granular balls also become larger, and two cross-view balls might contain a very small number of common samples due to randomness.

To address this, we modified the method. Let $G B _ { i } ^ { m }$ and $G B _ { j } ^ { n }$ be two granular balls from views $m$ and $n$ , respectively, containing $t _ { i }$ and $t _ { j }$ samples. First, we identify the common sample set between the two balls based on the stored sample indices:

$$
\operatorname { I d } _ { \mathrm { b o t h } } = \operatorname { I d } ( G B _ { i } ^ { m } ) \cap \operatorname { I d } ( G B _ { j } ^ { n } )
$$

where $\operatorname { I d } ( \cdot )$ represents the sample indices contained in a granular ball. Next, we count the number of samples in $\mathrm { I d } _ { \mathrm { b o t h } }$ :

$$
t _ { \mathrm { b o t h } } = \mathrm { l e n g t h } ( \mathrm { I d } _ { \mathrm { b o t h } } )
$$

Let $\mathbf { P } ^ { ( m , n ) }$ be the cross-view granular ball association matrix, which satisfies the following condition

$$
\mathsf { p } _ { i j } ^ { ( m , n ) } = \left\{ { 1 , \quad \mathrm { i f } \ t _ { \mathrm { b o t h } } / \operatorname* { m i n } ( t _ { i } , t _ { j } ) \geq \tau } \right.
$$

Here, $\tau$ is a threshold parameter that determines the minimum proportion of common samples required to consider two cross-view granular balls as associated.

# Granular-ball Contrastive Learning

Matrices $\{ \mathbf { A } ^ { v } \} _ { v = 1 } ^ { V }$ reflects whether any two granular balls within a view overlap, while matrices $\{ \mathbf { P } ^ { ( m , n ) } \} _ { \forall m \neq n }$ indicates whether any two balls across views have sufficient intersection. We aim for these associated granular ball pairs to be as close as possible in the latent space, while unrelated pairs should be far apart.

We use the granular-ball centers to represent the entire granular balls during the calculations. To facilitate computation, for any two views $m$ and $n$ , we define the combined center matrix as

$$
\mathbf { C } = \left[ \mathbf { C } ^ { m } \right]
$$

then concatenate $\{ \mathbf { A } ^ { m } , \mathbf { A } ^ { n } \}$ and $\{ \mathbf { P } ^ { ( m , n ) } , \mathbf { P } ^ { ( n , m ) } \}$ into a unified mask matrix

$$
\mathbf { M } = \left[ \begin{array} { c c } { \mathbf { A } ^ { m } } & { \mathbf { P } ^ { ( m , n ) } } \\ { \mathbf { P } ^ { ( n , m ) } } & { \mathbf { A } ^ { n } } \end{array} \right]
$$

where matrix $\mathbf { P } ^ { ( n , m ) }$ is the transpose of $\mathbf { P } ^ { ( m , n ) }$ . This unified mask matrix $\mathbf { M }$ ensures that granular balls within the

Table 1: Description of the seven multi-view datasets.   

<html><body><table><tr><td>Dataset</td><td>Samples</td><td>Clusters</td><td></td><td>Views Dimensionality</td></tr><tr><td>BBCSport</td><td>544</td><td>5</td><td>2</td><td>3183/3203</td></tr><tr><td>Caltech101-20</td><td>2386</td><td>20</td><td>2</td><td>1984/512</td></tr><tr><td>Cora</td><td>2708</td><td>7</td><td>2</td><td>2708/1433</td></tr><tr><td>Scene-15</td><td>4485</td><td>15</td><td>3</td><td>20/59/40</td></tr><tr><td>MNIST-USPS</td><td>5000</td><td>10</td><td>2</td><td>784/784</td></tr><tr><td>ALOI-100</td><td>10800</td><td>100</td><td>4</td><td>77/13/64/125</td></tr><tr><td>NoisyMNIST</td><td>50000</td><td>10</td><td>2</td><td>784/784</td></tr></table></body></html>

same view and across different views are appropriately considered in the contrastive learning process. we calculate the contrastive loss at the granular-ball level

$$
\mathcal { L } ^ { ( m , n ) } = \frac { 1 } { k } \sum _ { i } ^ { k } \sum _ { j \in \Omega _ { i } } \frac { e x p ( c o s ( \mathbf { c } _ { i } , \mathbf { c } _ { j } ) ) } { \sum _ { z \in \Phi _ { i } } e x p ( c o s ( \mathbf { c } _ { i } , \mathbf { c } _ { z } ) ) }
$$

where $\boldsymbol { \Omega } _ { i } = \{ j | \mathbf { M } _ { i j } = 1 , \forall j \}$ and $\boldsymbol { \Phi } _ { i } = \{ z | \mathbf { M } _ { i z } = 0 , \forall z \}$ . $k$ represents the total number of granular balls and $c o s ( \cdot , \cdot )$ denotes the cosine similarity between two vectors.

$$
\mathcal { L } _ { c o n } = \frac { 2 } { V ( V - 1 ) } \sum _ { \forall m \neq n } \mathcal { L } ^ { ( m , n ) }
$$

We perform the same calculation process between any two views and take the average of all the losses as the final contrastive loss.

# Overall Loss And Optimization

Combining the above two loss functions with a regularization parameter $\lambda$ , the overall loss is formulated as

$$
\begin{array} { r } { \mathcal { L } = \mathcal { L } _ { c o n } + \lambda \mathcal { L } _ { r e c } . } \end{array}
$$

Any gradient-based optimization method can be used to minimize this objective function. We will further discuss the implementation details later.

# Experiments

In this section, we analyze the experimental results of the proposed method on seven widely used multi-view datasets and compare it with several state-of-the-art methods to demonstrate its effectiveness.

# Experimental Settings

Datasets. Seven multi-view benchmark datasets are employed in this work. BBCSport (Greene and Cunningham 2006) includes 544 sports news articles in 5 subject areas, with 3183-dimensional MTX features and 3203-dimensional TERMS features, forming 2 views. Caltech101-20 (Li et al. 2015) contains 101 classes in total. We select 20 widely used classes with 2 views and 2386 samples for our experiments. Cora (Bisson and Grimal 2012) contains 4 views, including content, inbound, outbound, and citations, extracted from the documents. Scene15 (Fei-Fei and Perona 2005) consists of 4568 natural scenes categorized into 15 groups. Each scene is described by three types of features: GIST, SIFT, and LBP. MNIST-USPS (Peng et al. 2019) is a popular handwritten digit dataset containing 5000 samples with two different styles of digital images. ALOI-100 (Schubert and Zimek 2010) consists of 10800 object images, with each image described by 4 different features. NoisyMNIST (Wang et al. 2015) uses the original images as view 1 and randomly selects within-class images with white Gaussian noise as view 2. Table 1 lists the important information of all datasets.

Compared Methods. We compared the proposed method with seven classical or state-of-the-art methods including Completer (Lin et al. 2021), MFLVC (Xu et al. 2022), DealMVC (Yang et al. 2023b), DMCE (Zhao, Yang, and Nie 2023), CSPAN (Jin et al. 2023), ADPAC (Xu et al. 2023b), SURE (Yang et al. 2023a). All compared methods are implemented according to the source codes released by the authors, and the hyper parameters are set according to the suggestion in the corresponding paper.

Evaluation Metrics. To perform a fair comparison, we adopt the commonly used metrics, e.g., clustering accuracy (ACC), normalized mutual information (NMI), and purity (PUR).

# Implementation Details

The network structure follows a standard autoencoder architecture. For each view, the encoder consists of several linear layers with ReLU activation functions between each pair of layers. Except for the BBCSport and Cora datasets, all other datasets use the same encoder structure with dimensions set as $\{ d _ { v } , 2 0 0 0 , 5 0 0 , 5 0 0 , d \}$ , where $d _ { v }$ is the input feature dimension of each view. $d$ is the projection feature dimension, which is the same for all views. After encoding, inputs undergo standardization. The decoder mirrors the encoder structure. For the Cora dataset, we use the same dimensions but without activation functions between layers, resulting in a linear projection. For BBCSport, given its small sample size of 544, we use a single-layer linear projection with the encoder dimensions set to $\{ d _ { v } , d \}$ .

Our implementation of MGBCC is carried out using PyTorch 2.3 (Paszke et al. 2019) on a Windows 10 operating system, powered by an NVIDIA GeForce GTX 1660 Ti GPU. We employ the Adam optimizer with learning rate of 0.0001 and weight decay of 0. The batch size is typically set to either 256 or 1024, depending on the dataset size. The regularization parameter $\lambda$ is generally set to 1 across most datasets, except for BBCSport and Cora, where it is adjusted to 0 due to differences in the projection approach (e.g., linear or nonlinear). The threshold parameter $\tau$ is uniformly set to 0.1 across all datasets. The granularity parameter $p$ significantly impacts the experimental results, which will be analyzed later.

During the clustering phase, we equally weight and fuse the projected features $\left\{ \mathbf { H } ^ { v } \right\} _ { v = 1 } ^ { V }$ from each view and then apply the $k$ -means algorithm to obtain clustering labels.

# Experimental Results

In Table 2, we present the experimental results of the proposed method in comparison with other methods, leading to the following conclusions: (1) Across the three given metrics, the proposed method achieves the best or second-best results for most case. Even on the NoisyMNIST datasets, the proposed method ranks approximately third, with only slight differences from the top two methods. Using Cora dataset as an example, our proposed method achieves an accuracy of $6 5 . 4 4 \%$ , significantly surpassing the best comparative result of $4 9 . 0 7 \%$ . This demonstrates the effectiveness and competitiveness of our method. (2) Compared with classical multi-view constrastive learning methods (e.g., Completer, DealMVC, SURE), the proposed method consistently achieves more favorable clustering results across the majority of datasets. As a representative, SURE is an instancelevel contrastive learning method that focuses on the issue of false negatives, achieving the best or second-best results on the Scene-15, MNIST-USPS, ALOI-100, and NoisyMNIST datasets. It’s noteworthy that the proposed method does not show significant performance degradation on these four datasets and clearly outperforms other methods. Moreover, on the remaining three datasets, the proposed method significantly outperforms SURE, highlighting the effectiveness of contrastive learning at the granular-ball level. (3) We visualize the clustering results of the proposed method on the MNIST-USPS dataset using t-SNE. As shown in Figure 3, the clustering structure becomes progressively clearer with the increase of the optimization epoch. This suggests that the proposed method is effective at revealing the underlying cluster structure.

Table 2: The clustering results on seven datasets $( \% )$ . The best results are bolded, and the second-best results are underline Results marked with a dot are directly quoted from the original papers. - indicates unavailable results due to out of memory.   

<html><body><table><tr><td>Dataset\Method</td><td>Completer</td><td>MFLVC</td><td>DealMVC</td><td>DMCE</td><td>CSPAN</td><td>ADPAC</td><td>SURE</td><td>MGBCC</td></tr><tr><td colspan="9">ACC(%)</td></tr><tr><td>BBCSport</td><td>35.11</td><td>60.11</td><td>80.70.</td><td>37.13</td><td>58.27</td><td>35.29</td><td>55.33</td><td>95.77</td></tr><tr><td>Caltech101-20</td><td>71.42</td><td>36.92</td><td>40.36</td><td>61.48</td><td>44.72</td><td>77.16</td><td>50.21</td><td>72.63</td></tr><tr><td>Cora</td><td>22.12</td><td>41.84</td><td>49.07.</td><td>26.48</td><td>42.54</td><td>30.87</td><td>42.76</td><td>65.44</td></tr><tr><td>Scene-15</td><td>39.29</td><td>32.87</td><td>32.71</td><td>34.85</td><td>33.73</td><td>41.49</td><td>42.01</td><td>43.72</td></tr><tr><td>MNIST-USPS</td><td>67.02</td><td>99.50.</td><td>80.92</td><td>62.18</td><td>80.14</td><td>98.16</td><td>99.56</td><td>99.60</td></tr><tr><td>ALOI-100</td><td>62.70</td><td>47.26</td><td>15.80</td><td>75.39</td><td>14.86</td><td>26.24</td><td>90.37</td><td>88.39</td></tr><tr><td>NoisyMNIST</td><td>87.45</td><td>98.91</td><td>99.42</td><td></td><td>55.68</td><td>97.27</td><td>99.14</td><td>98.48</td></tr><tr><td colspan="9">NMI(%)</td></tr><tr><td>BBCSport</td><td>2.62</td><td>43.04</td><td>65.59.</td><td>4.39</td><td>48.27</td><td>3.94</td><td>38.78</td><td>87.21</td></tr><tr><td>Caltech101-20</td><td>70.96</td><td>52.68</td><td>59.41</td><td>57.93</td><td>63.04</td><td>73.85</td><td>60.92</td><td>71.57</td></tr><tr><td>Cora</td><td>1.42</td><td>30.41</td><td>37.75.</td><td>1.19</td><td>22.21</td><td>7.65</td><td>22.49</td><td>46.86</td></tr><tr><td>Scene-15</td><td>43.46</td><td>33.93</td><td>32.46</td><td>32.09</td><td>31.23</td><td>44.21</td><td>42.87</td><td>41.62</td></tr><tr><td>MNIST-USPS</td><td>81.83</td><td>98.50.</td><td>90.24</td><td>72.90</td><td>78.27</td><td>95.61</td><td>98.68</td><td>98.96</td></tr><tr><td>ALOI-100</td><td>84.00</td><td>75.72</td><td>56.12</td><td>83.67</td><td>39.88</td><td>51.59</td><td>94.04</td><td>94.78</td></tr><tr><td>NoisyMNIST</td><td>86.70</td><td>96.79</td><td>98.15</td><td>1</td><td>60.07</td><td>93.34</td><td>97.30</td><td>96.17</td></tr><tr><td colspan="9">PUR(%)</td></tr><tr><td>BBCSport</td><td>35.85</td><td>69.12</td><td>80.70.</td><td>37.13</td><td>69.30</td><td>38.62</td><td>63.60</td><td>95.77</td></tr><tr><td>Caltech101-20</td><td>78.58</td><td>69.74</td><td>70.12</td><td>71.12</td><td>76.19</td><td>80.68</td><td>73.60</td><td>81.89</td></tr><tr><td>Cora</td><td>30.28</td><td>51.51</td><td>60.67.</td><td>30.32</td><td>49.89</td><td>36.74</td><td>48.15</td><td>68.02</td></tr><tr><td>Scene-15</td><td>42.88</td><td>34.02</td><td>34.34</td><td>36.77</td><td>36.39</td><td>45.08</td><td>44.93</td><td>47.07</td></tr><tr><td>MNIST-USPS</td><td>73.00</td><td>99.50.</td><td>80.92</td><td>66.80</td><td>81.70</td><td>98.16</td><td>99.56</td><td>99.60</td></tr><tr><td>ALOI-100</td><td>66.74</td><td>48.58</td><td>15.80</td><td>76.97</td><td>18.53</td><td>30.74</td><td>90.67</td><td>89.31</td></tr><tr><td>NoisyMNIST</td><td>87.45</td><td>98.91</td><td>99.42</td><td>1</td><td>60.69</td><td>97.27</td><td>99.14</td><td>98.48</td></tr></table></body></html>

# Ablation Studies

To accurately validate the effectiveness of contrastive learning at the granular-ball level, we conduct an ablation study on the Caltech101-20 dataset. The feature dimension $d$ is set to 128. Based on this, we adopted three experimental settings. The first setting trains the model solely based on reconstruction loss. The second setting includes both the reconstruction loss and instance-level contrastive loss (i.e., $p = 1 \AA ,$ ). The third setting incorporates reconstruction loss and granular-ball contrastive loss, with the granularity parameter set to 2. It is important to emphasize that the parameter $p$ reflects the average granularity rather than the absolute granularity.

Table 3 presents the corresponding experimental results. As can be seen, the instance-level contrastive method performed poorly on this dataset, whereas the granular-ball contrastive method achieved significant improvements. This further demonstrates the feasibility and effectiveness of contrastive learning at the granular-ball level.

![](images/361fbb8a104d5acf24e8579a8fc87d223084d53e595dfa3c12fbe79e84b0ed13.jpg)  
Figure 3: The t-SNE visualization of the clustering results on MNIST-USPS dataset.

Table 3: Ablation studies on Caltech101-20.   

<html><body><table><tr><td>Setting</td><td>ACC (%)</td><td>NMI (%)</td><td>PUR (%)</td></tr><tr><td>Lrec</td><td>40.28</td><td>60.03</td><td>75.40</td></tr><tr><td>Lrec +Lcon ~ p=1</td><td>44.47</td><td>62.38</td><td>78.54</td></tr><tr><td>Lrec + Lcon ~ p=2</td><td>72.63</td><td>71.57</td><td>81.89</td></tr></table></body></html>

# Parameter Analysis

The model has two important hyperparameters: the granularity parameter $p$ and the dimension $d$ of the projection features. The former essentially reflects the average size of the granular balls. When $p$ is set to 1, it is equivalent to instancelevel contrastive learning. The latter affects the amount of original feature information contained in the latent representation. If $d$ is too small, important information might be lost, whereas if $d$ is too large, it increases the complexity of optimization and memory requirements. To explore the optimal parameter settings, we conduct experiments on Caltech101- 20 and Cora. We varied the parameter $p$ within the range [1, 2, 4, 8, 16], and the parameter $d$ within the range [8, 16, 32, 64, 128, 256].

![](images/5740eec34cf8e04c85031eea59a15b72aa1076f3574410e1d77e21cd778d5c1f.jpg)  
Figure 4: The clustering accuracy $( \% )$ with different parameters $p$ and $d$ on Caltech101-20 and Cora.   
Figure 5: Loss vs. Metrics on Cora.

Figure 4 illustrates the experimental results on the aforementioned datasets. When $p$ is set to 2, the proposed method performs well. However, as $p$ increases, performance gradually declines. This may be because larger granular balls can no longer be effectively associated based solely on overlap and intersection size. When $p$ becomes too large, the method essentially degrades into a cluster-level contrastive approach, where reducing cluster assignment differences might be a more reasonable strategy. In experiments, we typically set the parameter $p$ to 1, 2, or 4. The parameter $d$ has a relatively minor impact on the experimental results and is generally set to 64.

6.8 6.6 0.6 6.4 0.5 N 0 Loss ACC 5.6 NMI 0.2 5.4 PUR 0.1 5.2 0.0 0 10 20 30 40 50 60 Number of epochs

# Convergence Analysis

We evaluated the convergence of the proposed method on Cora dataset by tracking the loss values and corresponding clustering performance over increasing epochs. As shown in Figure 5, the total loss values gradually decrease and converge within 100 epochs. These results demonstrate the strong convergence performance of the proposed method.

# Conclusion

In this paper, we propose a multi-view granular-ball contrastive clustering method. Specifically, we model the local structure of the sample set using granular balls in the latent space, resulting in respective granular-ball sets for each view. We establish intra-view and cross-view associations between granular balls based on their overlap and intersection size, encouraging associated granular balls to be close to each other in the latent space. Extensive experiments have been conducted to validate the effectiveness of the proposed method. In the future, we will extend the proposed method to handle incomplete multi-view data.