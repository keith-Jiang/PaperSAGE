# Enhancing Entertainment Translation for Indian Languages Using Adaptive Context, Style and LLMs

Pratik Rakesh Singh, Mohammadi Zaki and Pankaj Wasnik

Media Analysis Group, Sony Research India, Bangalore {pratik.singh, mohammadi.zaki, pankaj.wasnik} $@$ sony.com

# Abstract

We address the challenging task of neural machine translation (NMT) in the entertainment domain, where the objective is to automatically translate a given dialogue from a source language content to a target language. This task has various applications, particularly in automatic dubbing, subtitling, and other content localization tasks, enabling source content to reach a wider audience. Traditional NMT systems typically translate individual sentences in isolation, without facilitating knowledge transfer of crucial elements such as the context and style from previously encountered sentences. In this work, we emphasize the significance of these fundamental aspects in producing pertinent and captivating translations. We demonstrate their significance through several examples and propose a novel framework for entertainment translation, which, to our knowledge, is the first of its kind. Furthermore, we introduce an algorithm to estimate the context and style of the current session and use these estimations to generate a prompt that guides a Large Language Model (LLM) to generate high-quality translations. Our method is both language and LLM-agnostic, making it a general-purpose tool. We demonstrate the effectiveness of our algorithm through various numerical studies and observe significant improvement in the COMET scores over various state-of-the-art LLMs. Moreover, our proposed method consistently outperforms baseline LLMs in terms of win-ratio.

# Introduction

Recent advancements in neural machine translation (NMT) have become increasingly important in the entertainment industry for automatic content localization. These advancements have addressed some limitations of entertainment translation by incorporating contextual understanding and cultural nuances into translations (Yao et al. 2024; Matusov, Wilken, and Georgakopoulou 2019; Vincent et al. 2024a).

In entertainment content, where dialogues often depend on prior interactions to convey a scene’s meaning and emotion effectively, context-aware translation plays a vital role (Vu, Kamigaito, and Watanabe 2024; Maruf, Saleh, and Haffari 2021; Vincent et al. 2024b; Agrawal et al. 2023). Incorporating the broader dialogue or narrative context, rather than translating sentences in isolation, is crucial to ensure accurate and emotionally relevant translations (McClarty 2014).

Table 1: Example Translations and Errors   

<html><body><table><tr><td>Examples</td></tr><tr><td>Source: bro fruits belong to the one who has got the gun Desired ranslation: Hcd Chat GT: Error:Simile and Contextual Source: will do it from your roof top I will shout in front of everyone.</td></tr><tr><td>DesiredTranslation:可！ Chat GT: Error:Contextual, Literal Translation Source: okay okay.alright get ready.cat behind the mouse. mouse in</td></tr><tr><td>front of the cat too much fan man too much fun. DesiredTranslatin: Chat GT:ff Error:Literal Translation, Idiomatic</td></tr></table></body></html>

On the other hand, entertainment translation also needs a culturally adaptable system to address the challenge of cultural unawareness (Etchegoyhen et al. 2014; Yao et al. 2024). Such systems should integrate cultural context for localization to ensure translations are suitable for the intended audience. They should go beyond literal translations, modifying idiomatic expressions, jokes, and cultural references to align with the audience’s customs and values, thereby enhancing the relevance of the translated content(Gupta et al. 2019; Li et al. 2024). In Table 1 we show some examples of common mistakes made by NMT systems when translating entertainment content. In Example 1, ’fruits’ idiomatically refers to ’reward,’ but ChatGPT’s literal translation misses this. In Example 2, the desired translation is culturally more creative, aligning with native Hindi speakers by conveying “I will badmouth you by knocking door to door.” In Example 3, the desired translation uses idiomatic language effectively, unlike ChatGPT’s literal approach.

In this paper, we address the challenging task of entertainment translation, where we are given a sequence of source sentences from the entertainment domain without any additional information about the timestamp, speaker ID, or context, and our task is to translate these sentences into dialogues in the target language. The challenge lies in preserving the context, mood, and style of the original content while also incorporating creativity and considering regional dialects, idioms, and other linguistic nuances (Gupta et al. 2019). The importance of our study is underscored by the need to produce translations that are not only accurate but also engaging for the target audience.

In particular, we treat the entertainment translation task as a sequential process to extract time-dependent contextual information by dividing the input text into a series of sessions. We primarily employ context-retrieval and domain adaptation to facilitate in-context learning of Large Language Models to extract both the style, representing the cultural nuances and temporal context from these sessions. We can then use this characteristic information to generate culturally enriched translations. In addition, our proposed methodology does not need auxiliary information such as speaker information, timestamps, and conversation mood, making it generalized and applicable in a wide range of applications. Our key contributions can be summarized as follows:

• We proposed an algorithm (Alg. 2), which we call Context And Style Aware Translation (CASAT). It incorporates context and style awareness, enhancing the input prompt and enabling LLM to produce culturally relevant translations. • Proposed methodology is language and LLM-agnostic. further, it does not rely on dialogue timestamps, speaker identification, etc., making it a versatile approach. • We proposed Context retrieval–Advanced RAG module to extract a precise and relevant context from entertainment content such as a movie or series episode. • We proposed a Domain Adaptation Module to provide a cultural understanding of input to LLMs.

# Background and Motivation

In this section, we provide a review of some of the major research works in the field of machine translation as well as applications of LLMs in NMT.

NMT was introduced in the seminal works of (Bahdanau, Cho, and Bengio 2015; Cho et al. 2014), who used basic encoder-decoder architectures and RNNs, respectively, for the NMT task. These techniques were superseded by attention-based mechanisms introduced in (Luong, Pham, and Manning 2015; Wu et al. 2016). With the advent of Transformers in (Vaswani et al. 2017), the attention computation became massively parallelized, increasing the speed and efficiency of modern NMT systems.

LLMs for NMT: In the last couple of years, LLMs have caused a major shift in the way AI research is carried out (Brown et al. 2020). The translation task has become a goto application of the LLMs since their advent (Lyu et al. 2024). A comprehensive review of machine translation using LLMs can be found in (Cai et al. 2024).

Entertainment Translation: Most of the previously presented research on entertainment domain translation focuses primarily on subtitling and segmentation (Vincent et al. 2024b; Karakanta et al. 2022; Vincent et al. 2024a; Matusov, Wilken, and Georgakopoulou 2019; Etchegoyhen et al. 2014). These works depend on additional information like timestamps and speaker details from the input text. However, timestamp information may not always be present or could be incorrect, leading to ambiguity or distortions in the temporal context, making entertainment translation more challenging (Gaido et al. 2024).

Use of contextual information for NMT: In recent years, the importance of (correct) context in the translation task has been studied and highlighted (Voita, Sennrich, and Titov 2019) for document-level translations (Maruf, Saleh, and Haffari 2021). However, these approaches do not perform consistently while dealing with overly large contexts or complicated scenarios (Vu, Kamigaito, and Watanabe 2024), as is usually the case in the entertainment domain.

LLMs for Creative Translations and Style Transfer: Use of LLMs to induce creativity can be accomplished to a certain extent using prompt engineering techniques (Zhang, Haddow, and Birch 2023). In addition, advanced retrieval-based techniques (Agrawal et al. 2023; Reheman et al. 2023; Glass et al. 2022) can be used to generate context from a given text and be used to provide necessary information for the desired translations. On the other hand, recent work on style transfer (Tao et al. 2024) introduces a Domain Adaptation Module to copy the style of the input text to be used for modifying the LLM-based translations. However, all these methods are static; that is, they do not change with respect to the variation in the mood, genre, or context, which is an inherent property of the entertainment content. Similarly, Li et al. (2024) tries to induce cultural nuances of the target language by introducing a knowledge base (KB) for idioms, which are difficult to translate in general. However, these models do not cover Indian languages, which have their own structural and lexical nuances (Leong et al. 2023).

LLMs for Entertainment Translation: Machine Translation using LLMs has started to gain popularity in recent times (Brown et al. 2020; Zhang, Haddow, and Birch 2023; Tao et al. 2024). Broadly, this can be classified into two categories: (i) prompt-based guiding and (ii) translation memory/RAG-based translation aiding. Below, we point out the issues with these techniques when applied to entertainment translation.

(i) Prompt-based Guiding: Prompt-based guiding of LLMs to perform translation can be treated as providing a conditioning parameter $p , \nu i z .$ ., the prompt, to the translation model:

$$
P _ { \theta } \left( y | x , p \right) = \prod _ { i = 1 } ^ { L } P _ { \theta } \left( y _ { i } | p , x , y _ { 1 } , . . . , y _ { i - 1 } \right) .
$$

where $L$ is the length of the output sentence $y$ . However, when working in the automatic dubbing application for movies and OTT content, the prompt needs to be timedependent, i.e. $p  p _ { t }$ , in order to deal with the dynamic context $c _ { t }$ . In particular, the prompt can be formulated

The narrator, a wise and aged SAGE, stands before a majestic statue of Lord Ram, surrounded by diyas and flowers. The sage's eyes sparkle with devotion as he begins to speak.. . \*\*SAGE\*\* Output Translation: (voiceover). This film is a screen versi over) . This film is a screen version of "यह कथा, यह ŵी राम का sess the greatest Indian epic, Valmiki Ramayan have been made to ensure it stays true वैभव,  इतना िवशाल, to the original version, it is possible th cter and events may vary.. . As the इतना गहन, िक शɨों मŐ sage be factually or historically accurate. epic with respect and sensitivity.. बयां करना नामुमिकन है, The camera cuts to a montage of Indian history, showcasing the country's rich cultural heritage and भी।" achievements. The narrator's voice continues sess2 Ct Context Retrieval Module 1 Source sentence: x Prompt Generation LLM sessk "This story and the grandeur of Shri Ram Domain Adaptation 人 cannot be expressed" Module $\tilde { p } _ { t } \big ( \tilde { c } _ { t } , \tilde { s } _ { x } \big )$ S Youarea BotwhichCreativelyTranslatesFrom The desired Hindi translation should reflect the style of the EnglishSentencesfrom Movie to Hindi language conversation, which typically has an average sentence length of basedonplotinformationofmoviesceneandStyle 37 and features long, detailed, and emotionally rich sentences. InformationabouttheDesired Translation The tone is mainly one of excitement, conveying eagerness, Input Movie M in source language broken up into conversation uses many function words, with a higher frequency of verbs and adjectives for content words, and prepositions and conjunctions for function words. Modal particles like 'भी, हो, ही, anticipation, and high energy. In terms of word choice, the Context Information: Style Information: EnglishSentence:x $\tilde { s } _ { x }$ $\tilde { c } _ { t }$ genre-wise त' are commonly used, along with monosyllabic words such as HindiSentence:" sessions 'व', while polysyllabic words are used less frequently.

as $p _ { t } = h ( p , c _ { t } )$ , where $h$ is a linking and weight function in a latent space. The adaptive nature of the prompt $p _ { t }$ induced by the time-varying context $c _ { t }$ is vital in generating context-relevant translations for dubbing applications. However, it has received limited attention from researchers (Gao et al. 2023).

(ii) Translation memory-based approach: Traditional retrieval-aided translation systems have two primary components: (i) a retriever $\dot { p _ { \eta } } ( . | x )$ which gives a probability distribution over a set of hidden context vectors stored in a vector database, and (ii) a generator $p _ { w } ( . | x , z )$ which gives a probability distribution over the output tokens given the source sentence $x$ and context $z$ . The retriever aims at providing additional information to the generator, which is an LLM performing translation, by retrieving context $z$ by Maximum Inner-Product Search (MIPS) (Lewis et al. 2021). However, the retrieved context vectors $z$ are semantically similar to the query sentence $x$ and do not take into account the style $s _ { x }$ of the source sentence, for example, politeness, (in-)formality, regional dialect, etc. (Tao et al. 2024)

# Potential Resolution

The above-mentioned limitations reflect the need for a machine translation system that takes into account the context $c _ { t }$ and preserves the style $s _ { x }$ of a given source input sentence $x$ . To this extent, a potential solution is to segment the (sequential) text into sessions, where the ‘genre’ of the sentences in a session remains constant. These ‘constant mood’ sessions can be used to estimate the context and style, i.e., $\tilde { c } _ { t }$ and $\tilde { s } _ { x }$ . By incorporating this additional information, a time-varying prompt $p _ { t } ( \tilde { c } _ { t } , \tilde { s } _ { x } )$ can be obtained to leverage LLM’s reasoning and understanding capabilities for generating context and style-aware translations.

# Algorithm 1: Genre Classification and Segmentation

1: Input: $\mathcal { M }$ , clusters of the three classes, minimum number of sentences for a new session $( \alpha )$ , maximum number of sentences in a session $( \beta )$ 2: Extract embeddings for each $x \in \mathcal { M }$ and use $k$ -NN to assign its class label and store in a array $g$ . 3: current-session $ \{ g [ 0 ] \}$ 4: session-list $ \emptyset$ 5: while $i <$ length $( g )$ do 6: if length(current-session) $\scriptstyle = = { \beta }$ then 7: session-list $$ current-session 8: current-session $ \emptyset$ 9: end if   
10: if $g [ i ] \ \neq$ current-session[0] $\wedge$ length(currentsession) $\geqslant \alpha$ then   
11: majority-label $ \mathrm { M A J O R I T Y } ( g [ i ] : g [ i + \alpha ] )$   
12: if majority-label $\neq$ current-session[0] then   
13: session-list $$ current-session   
14: current-session $ \emptyset$   
15: end if   
16: end if   
17: current-session g[i]   
18: i i + 1   
19: end while   
20: Output: session-list

# Methodology

In this section, we describe our methodology beginning with stating the problem statement formally. Next, we explain the necessity of segmenting the input text and how to obtain it. We then describe the method for extracting the $\tilde { c } _ { t }$ and $\tilde { s } _ { x }$ for a particular dialogue $x$ to generate the context and styleaware prompt $p _ { t }$ .

# Problem Formulation

We consider the entertainment translation as an extension of neural machine translation task, where we primarily try to translate sentences from a source language $( S )$ to a target language $( \mathcal { T } )$ . These sentences can be dialogues from movies, web series, novels, etc. Formally, let $\mathcal { D } ^ { s }$ be defined as the set of all sentences in a $s$ and $\mathcal { D } ^ { \dot { \tau } }$ the corresponding set in $\tau$ . The goal of a translation system is to find a mapping $g : D ^ { S } \mapsto \mathcal { D } ^ { T }$ . However, translating movie dialogues from one language to another requires additional knowledge of the running context $c _ { t }$ as well as the style $s _ { x }$ of the source sentence $x$ . Hence, we define a mapping $g _ { E }$ , which is specific to translation in the entertainment domain, as a function that outputs the translated text $y$ as $y = g _ { E } ( x ; c _ { t } , s _ { x } )$ . In other words, the aim of an entertainment translation system is to find a mapping $g _ { E }$ which not only translates any $\boldsymbol { x } \in \mathcal { D } ^ { s }$ , into a sentence $\bar { y \in \mathcal { D } ^ { T } }$ but also preserves the context $c _ { t }$ and the style $s _ { x }$ of the input source sentence. Further, the mapping learned should be such that it induces creativity in the translation, which can increase the target audience’s interest and engagement. These additional factors make the task of entertainment translation unique and challenging.

# Adaptive Session Classification and Segmentation

For this section, we will take a concrete example of a movie $\mathcal { M }$ to explain the key concepts (note: we only consider the sequence of text dialogues as $\mathcal { M }$ ). In entertainment content, each movie or web series is characterized by a sequence of scenes, each belonging to a specific genre or tone, such as action, horror, comedy, and so forth. Therefore, a movie $\mathcal { M }$ can be represented as $\mathcal { M } = ( s e s s _ { 1 } , s e s s _ { 2 } , \ldots , s e s s _ { M } )$ , where $M$ is the total number of scenes/sessions in the movie. Suppose a dialogue $x \in s e s s _ { k }$ , the style of translation of $x$ is expected to be more likely dependent on the current and $K$ neighboring sessions than much older sessions, which necessitates the segmentation of the text to ensure translation quality.

We provide an offline algorithm for achieving adaptive segmentation of $\mathcal { M }$ in Alg. 1, which classifies each session into one of the three three primary tonal categories: Serious (Intense genres: action, mystery, thriller, horror), Casual (Light genres: comedy, romance, fantasy) and Neutral (Dialogues with low emotional intensity). While not all the input texts may fit perfectly into these three categories, this approach provides a foundation for simple yet consistent classification by grouping genres with similar tones. We pretrain a $k$ -NN classifier and generate clusters using example dialogues from the three categories. We refer the reader to the Appendix for details on the segmentation process. We also remark that Alg. 1 only provides a rough estimate of the session boundaries of $\mathcal { M }$ . Next, we demonstrate how we extract the context and style information from the available sessions.

# Session Information Generation

This section provides a thorough insight to the crux of our method. Let the current input dialogue be $x$ . As depicted in Figure 1, $x$ passes through two separate pipelines for $\tilde { c } _ { t }$ and $\tilde { s } _ { x }$ extraction. Subsequent paragraphs provide detailed description of these blocks.

![](images/18dfdbf3ad3485eafd29a2cec7359fe0c6528cd1ad7ad9ad3c2a94c981726775.jpg)  
Figure 2: A block diagram of the Context retriever block.

Context retrieval–Advanced RAG: Using Large Language Models (LLMs) to translate dialogues from one language to another without any prior context can lead to disconnected translations, especially in a conversation. In order to induce interest among the target audience, LLMs can generate creative translations, which may lead to hallucinations (Zhang et al. 2023). Hence, providing the current session information can guide the LLM in translating the source sentence creatively with respect to the context of the movie, reducing hallucinations.

As depicted in Figure 2, we consider an offline process to extract the plots, i.e., a summary of movie scenes, from $K$ consecutive sessions via an LLM. This extracted context is then subdivided into small chunks and stored in a vector database. This chunking helps our methodology two-fold. Firstly, the generated prompt might be too large for the LLM to comprehend. Secondly, the most relevant chunk/scene for the source sentence could well be from a different session (in the past or in the future). During the translation phase, a retriever uses the source sentence $x$ to retrieve $M$ most relevant chunks from the vector database (Lewis et al. 2021). This is then passed through a re-ranker (Glass et al. 2022), to generate $N$ most relevant chunks in a ranked fashion, which we denote as $\tilde { c } _ { t }$ for sentence $x$ .

Style extraction-Domain Adaptation Module: By using the above pipeline for context information extraction, we can generate creative translation that aligns with the current context and mood of the scene. However, this does not help in extracting the style or tone of the dialogue. In particular, $\tilde { c } _ { t }$ does not include the most used words, idioms, and emotional state of the current scene, which define the overall language register. To tackle this, we designed a Domain Adaptation Module (DAM), which is a collection of various information-extracting NLP subroutines. These subroutines help in constructing $\tilde { s } _ { x }$ , which acts as a clear and comprehensive style-determining prompt to be fed to the LLM. We note that we get inspired from (Tao et al. 2024) with changes in the DAM module owing to our specific application and the change in language family. In particular, we pay special attention to dialogue and session-level information, respectively, which is in contrast with their approach, which dealt with style transfer as a one-shot method for the entire text at once. Subsequently, we explain these modules in detail.

Dialogue Level Module: This module provides the structural information of the dialogues, giving us the overall conversational style of speakers. It consists of three parts as described in brief below.

• Content and Function words: Here, we take the output translations of the past $K$ sessions as input and pass it through a PoS Tagger trained on Indic languages. We categorize these tagged words into content words and function words(Carnap 1967), which we then convert to the respective prompts $f _ { c }$ and $f _ { f }$ . For the explicit prompts, we refer the reader to the Appendix.

• Frequent Syllabic Words: Every speaker may have a different style of speaking for instance, depending on the regional dialect, pronouns like "I" or "myself" can be termed in Hindi as “apun", (spoken in Mumbai region) or “hum", (spoken in northern India), etc. Identifying this will provide the model with information on the frequent use of monosyllabic and polysyllabic words. Similar to the above case, we convert them into prompts as $f _ { m }$ and $f _ { p }$ respectively.

• Modal Words and Idioms: Modal words and idioms contribute to the tone, politeness, and effectiveness of the conversation $f _ { m o d a l }$ , $f _ { i d i o m s }$ respectively).

# Algorithm 2: Context and Style Aware Translation (CASAT)

1: Input: Source Sentences $( \mathcal { M } )$ , $M$ , $N$ , session-list (See Alg. 1)   
2: for $x \in \mathcal { M }$ do   
3: $\tilde { c } _ { t } \gets$ Extract $M$ relevant scenes from the vector DB and choose $N$ best through the Context Retriever Module.   
4: $\tilde { s } _ { x } \gets$ Extract dialogue level and session level information through DAM.   
5: $p _ { t } \gets$ Generate prompt using $\tilde { c } _ { t }$ and $\tilde { s } _ { x }$   
6: Translation $y _ { x } \gets \mathrm { L L M } ( p _ { t } , x )$   
7: end for

Session Level Module: In contrast with the dialogue-level information extraction, the session-level module allows an understanding of the global intent of the ongoing and past sessions.

• Sentence Intent and Emotion: Intent of a session can be derived from the use of punctuation marks. For instance, excessive use of question marks in a particular scene can indicate the scene to be interrogatory. Hence, we count all the punctuation in session, then define intent based on thresholds $( f _ { i n t e n t } )$ . Further, to extract the emotion, we pass the current session through an LLM to generate $f _ { e m o t i o n }$ . Furthermore, we provide a concrete example of the DAM in the Appendix.

![](images/259987812fdff7dbf57991eab97e2b0e452f5a2bf4697cc222dc41e827c0a70c.jpg)  
Figure 3: Visualization of embedding projections

![](images/6611be4718802e546bb3ad618ae42450b25b920456c63a7a023f9970d2fc0370.jpg)  
Figure 4: Embedding distances from the reference output

Finally, we obtain the Context and Style Aware prompt $p _ { t }$ , by concatenating the outputs from the context retrieval module $( \tilde { c } _ { t } )$ and the DAM module $( \tilde { s } _ { x } )$ . We refer the reader to the Appendix, where we illustrate detailed examples of prompt $p _ { t }$ for enhanced clarity.

# Experiments

In this section, we present the experimental evaluation of our proposed approach. We will also describe the effect caused by the individual components of CASAT through ablation studies. All experiments were carried out on 1x1H100 80 GB GPU.

# Experimental Settings

Evaluation Dataset: This section provides details of the datasets used to evaluate our approach, focusing on the data employed for testing Alg. 2 since our method does not have an explicit training phase. In addition, due to the unavailability of Indian language entertainment domain public datasets, we use web-scraped data for our simulations, which will be explained later.

We scrapped parallel text data of popular movies from the popular subtitle website OpenSubtitles.org. To see the effect on text data, which requires even more human-induced creativity, we further used parallel text data from a popular children ’s cartoon series. All our experiments are conducted on the set of three language directions, viz., Englishto-Hindi (en-hi), English-to-Bengali (en-bn) and English-toTelugu (en-te). Next, we mention the specific details of the text content used for our numerical studies. We label our text data into three categories: (i) literal, (ii) semi-creative, and (iii) creative, owing to the increasing levels of creativity in the reference gold data.

Table 2: Performance comparison of CASAT with various SOTA LLMs fed with prompts to generate creative translations. Here B.:BLEU, C.:COMET score in range [0,1] and $\Delta$ is the win-ratio of CASAT-assisted models vs. base models.   

<html><body><table><tr><td rowspan="2">LLMs Sizes</td><td rowspan="2">Models</td><td colspan="4">en-hi</td><td colspan="6">en-bn</td><td colspan="4">en-te</td></tr><tr><td>Base</td><td></td><td>CASAT</td><td></td><td></td><td>Base</td><td></td><td></td><td>CASAT</td><td></td><td>Base</td><td></td><td>CASAT</td><td></td></tr><tr><td rowspan="4">Small-Sized LLMs</td><td></td><td>B.</td><td>C.</td><td>B. C.</td><td></td><td>A</td><td>B.</td><td>C. B.</td><td></td><td>C.</td><td>△ B.</td><td>C.</td><td>B.</td><td>C.</td><td>A</td></tr><tr><td>Mistral7B</td><td>1.33</td><td>0.41</td><td>1.55</td><td>0.42</td><td>0.56 0.2</td><td>0.43</td><td>0.38</td><td>0.48</td><td>0.62</td><td>0.1</td><td>0.42</td><td>0.07</td><td>0.41</td><td>0.8</td></tr><tr><td>LLaMa-38B</td><td>3.42</td><td>0.51</td><td>4.51</td><td>0.56</td><td>0.56</td><td>0.75</td><td>0.61</td><td>1.12 0.67</td><td>0.52</td><td>0.85</td><td>0.51</td><td>0.60</td><td>0.58</td><td>0.69</td></tr><tr><td>Aya238B</td><td>6.67</td><td>0.61</td><td>7.21</td><td>0.64</td><td>0.67</td><td>0.30</td><td>0.48</td><td>0.4</td><td>0.53</td><td>0.56 0.16</td><td>0.42</td><td>0.3</td><td>0.46</td><td>0.76</td></tr><tr><td rowspan="3">Mid-Sized LLMs</td><td>Gemma29B</td><td>6.68</td><td>0.56</td><td>6.88</td><td>0.62</td><td>0.62</td><td>1.55 0.68</td><td>2.53</td><td>0.75</td><td>0.62</td><td>1.43</td><td>0.65</td><td>1.75</td><td>0.69</td><td>0.79</td></tr><tr><td>Gemma2 27B</td><td>4.71</td><td>0.62</td><td>8.07</td><td>0.67</td><td>0.69</td><td>1.49 0.70</td><td>3.08</td><td>0.77</td><td>0.67</td><td>1.7</td><td>0.67</td><td>2.07</td><td>0.71</td><td>0.77</td></tr><tr><td>Aya2335B</td><td>9.25</td><td>0.63</td><td>9.59 0.68</td><td>0.70</td><td>0.80</td><td>0.62</td><td>0.82</td><td>0.65</td><td>0.59</td><td>0.17</td><td>0.44</td><td>0.23</td><td>0.48</td><td>0.8</td></tr><tr><td rowspan="2">Large-Sized LLMs</td><td>GP1-33T70b</td><td>7.964</td><td>0.63</td><td>944</td><td>0.70</td><td>0.73</td><td>2468</td><td>0.66</td><td>149</td><td>0.75</td><td>0.74 0.92</td><td>0.66</td><td>10.9</td><td></td><td>0.85</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.68</td><td></td></tr></table></body></html>

• English-to-Hindi: We choose subtitles scrapped from the opensubtitles website for the following movies: (i) Adipurush (creative), (ii) Pushpa (semi-creative), and (iii) Interstellar (literal). In addition, we use episodes from a popular cartoon series (creative) for evaluation. The total number of sentence pairs for en-hi was 5238. • English-to-Bengali: Similarly, we scrapped subtitles of two movies, namely Wolves and Maharaja from opensubtitles website was used for evaluation for this language pair, amounting to a total of 3259 sentence pairs. • English-to-Telugu: For English to Telugu translation, we scrapped subtitles of two movies, namely Without Remorse and Bumblebee from opensubtitles for evaluation, comprising of 1698 sentence/dialogue pairs.

LLMs used for comparison: We randomly select 800 data samples from each language source and translate them to the target language utilizing 5 distinct Large Language Models with varying sizes, categorizing them into three sections:

• Small Sized LLMs: We focused on three multi-lingual small sized models which perform well in Indic Languages i.e Mistral 7B (Jiang et al. 2023), Gemma2 9B (Gemma-Team 2024), Aya23 8B (Aryabumi et al. 2024), Llama3 8B (Meta-Team 2024).   
• Mid-sized LLMs: We consider two LLMs, namely, Gemma2 27B (Gemma-Team 2024) and Aya23 35B (Aryabumi et al. 2024), for mid-sized category. Both of these LLMs have performed consistently well in Indic languages.   
• Large-sized LLMs: Likewise we considered two largesized LLMs that are Llama3 70B (Meta-Team 2024) and GPT-3.5 Turbo, both having excellent reasoning and translation qualities.

Evaluation Metrics: We adopt three metrics for the evaluation task. SacreBLEU (Post 2018) represents $n$ -gram matching while COMET (wmt22-cometkiwi-da) (Rei et al. 2022)

represents the reference-free neural-based evaluation. Third, we use GPT-4o for evaluation of the translated text, which is well-known to replicate human-level judgment (Fu et al. 2023) by calculating the win-ratio $( \Delta )$ of our approach over the baseline models as follows:

$$
\Delta = \frac { \left( { \begin{array} { l } { \# } \mathrm { t i m e s ~ G P T - 4 o ~ c h o o s e s ~ C A S A T ~ b a s e d } } \\ { \mathrm { t r a n s l a t i o n ~ o v e r ~ b a s e l i n e ~ L L M ~ t r a n s l a t i o n } } \end{array} \right)}   { \# \mathrm { t o t a l ~ t r a n s l a t i o n s } } .
$$

# Can CASAT provide audience-engaging translations?

Main Result and Analysis: The outcomes presented in Table 2 illustrate that our method demonstrates superior performance by consistently incorporating plot and style information compared to directly prompting creativity in LLMs (see the exact prompt used for baseline LLMs in the Appendix). For the en-hi direction, we observe an increase of 21. $9 5 \%$ in the BLEU score and 7. $4 \%$ in the COMET score across all models. In en-bn direction, BLEU score improved by $4 3 . 2 \%$ , while COMET by $9 . 3 \%$ . For the en-te direction, the improvements were 21. $9 \%$ in BLEU and $8 . 5 7 \%$ in COMET, further demonstrating the effectiveness of CASAT. Secondly, irrespective of the LLM chosen to produce the translation, CASAT significantly improves its quality across the evaluation metrics. Interestingly, Mistral 7B shows minimal enhancement for the en-hi and en-te directions, yet exhibits a commendable win ratio for en-bn and en-te directions. Third, both performance in win ratio and COMET scores improve with larger model sizes, suggesting that increasing the model size enhances LLM’s capability of plot development and comprehension of the in-context information. However, surprisingly, we observe that the 9B and 27B versions of Gemma2 either perform similarly to or even outperform models such as Aya23 35B and Llama3 70B for enbn and en-te language directions in terms of COMET scores. How does the inclusion of context and style impact the resulting output? We plot the multi-dimensional scaling (MDS) representation of the generated text from Llama 3- 8B, with varying prompts in Figure 3. We observe that prompting the LLM differently affects the output translation in a significant manner, as also reported in (Salinas and Morstatter 2024). The plot indicates that solely incorporating the style has minimal impact on the translation quality, whereas solely providing the plot information (context) enhances the quality, evident by the reduced distance between the context and reference in comparison to style alone. CASAT, i.e., the simultaneous provision of context and style, significantly enhances the quality of the translation. Figure 4 plots the average Euclidean distance of the generated text from the reference translations for a range of prompts. The plot shows that CASAT is closest to the reference translation.

Table 3: Analysis of the effect of the individual components of CASAT.   

<html><body><table><tr><td rowspan="2">Model Size</td><td rowspan="2">Models</td><td colspan="2">BLEUCOMET</td><td colspan="3">BLEUonceoMErly</td><td colspan="3">BLEUPAMMmIy</td><td colspan="3"></td></tr><tr><td></td><td></td><td></td><td></td><td>A</td><td></td><td></td><td>A</td><td>BLEU</td><td>CASMEr</td><td>A</td></tr><tr><td rowspan="4">Small-SizedLLMs</td><td>Mistral 7B</td><td>1.33</td><td>0.41</td><td>1.16</td><td>0.41</td><td>0.67</td><td>1.89</td><td>0.41</td><td>0.67</td><td>1.55</td><td>0.42</td><td>0.56</td></tr><tr><td></td><td></td><td>0.50</td><td></td><td></td><td>0.58</td><td></td><td>0.521</td><td></td><td>4.51</td><td></td><td></td></tr><tr><td>LAyaM38B</td><td>3.42</td><td></td><td>3.82</td><td>0.54</td><td></td><td>3.03</td><td></td><td>0.54</td><td></td><td>0.56</td><td>0.69</td></tr><tr><td>Gemma2 9B</td><td>6.68</td><td>0.56</td><td>7.80</td><td>0.67</td><td>0.61</td><td>7.14</td><td>0.59</td><td>0.60</td><td>6.88</td><td>0.62</td><td>0.62</td></tr><tr><td rowspan="2">Mid-SizedLLMs</td><td>Gemma227B</td><td>4.71</td><td>0.62</td><td>7.46</td><td>0.66</td><td>0.62</td><td>5.17</td><td>0.64</td><td>0.66</td><td>8.07</td><td>0.67</td><td>0.69</td></tr><tr><td>Aya23 35B</td><td>9.25</td><td>0.63</td><td>6.95</td><td>0.67</td><td>0.67</td><td>8.32</td><td>0.66</td><td>0.70</td><td>9.59</td><td>0.68</td><td>0.70</td></tr><tr><td>Large-Sized LLMs</td><td>LLaMa370B</td><td>7.96</td><td>0.62</td><td>7.12</td><td>0.66</td><td>0.71</td><td>8.99</td><td>0.67</td><td>0.64</td><td>9.84</td><td>0.70</td><td>0.73</td></tr></table></body></html>

Table 4: COMET scores showing the effect of varying the value of number of sessions $K$ .   

<html><body><table><tr><td>Models</td><td>K=1</td><td>K=2</td><td>K=3</td><td>K=4</td></tr><tr><td>Mistral 7B</td><td>0.367</td><td>0.424</td><td>0.402</td><td>0.371</td></tr><tr><td>Llama3 8B</td><td>0.487</td><td>0.562</td><td>0.534</td><td>0.507</td></tr><tr><td>Gemma2 9B</td><td>0.644</td><td>0.62</td><td>0.647</td><td>0.658</td></tr><tr><td>Aya23 8B</td><td>0.637</td><td>0.64</td><td>0.65</td><td>0.644</td></tr><tr><td>Gemma227B</td><td>0.66</td><td>0.67</td><td>0.64</td><td>0.63</td></tr><tr><td>Aya2335B</td><td>0.67</td><td>0.68</td><td>0.69</td><td>0.66</td></tr><tr><td>Llama3 70B</td><td>0.68</td><td>0.70</td><td>0.67</td><td>0.66</td></tr></table></body></html>

# How does CASAT fare against traditional MT Systems?

We evaluate the Win-Ratio $( \Delta )$ of CASAT-augmented models against traditional machine translation (MT) systems across en-hi, en-bn, and en-tl translation directions. Specifically, we compare the performance of Gemma2 9B (CG9) and Gemma2 27B (CG27) models, enhanced with the CASAT approach, against traditional systems such as IndicTrans2 (ITv2) (Gala et al. 2023) and NLLB (Team et al. 2022). The results, summarized in Table 5, demonstrate that CASAT-augmented models are consistently preferred in the entertainment domain, underscoring the effectiveness of the CASAT approach in improving translation quality, particularly in domain-specific contexts.

How many sessions $K$ to consider? The performance of all models on en-hi language pair datasets are compared for various values of $K$ in Table 4. Since $K$ is utilized in plot design and DAM, it is a crucial parameter to consider. Generally, it has been observed that $K = 2$ and $K = 3$ exhibit good performance. The results indicate that using $K = 1$ yields insufficient contextual information, while $\scriptstyle \mathrm { K = 4 }$ results in less specificity.

Table 5: CASAT vs. traditional MT systems win-ratio $\Delta$ .   

<html><body><table><tr><td>Models</td><td>en-hi</td><td>en-bn</td><td>en-te</td></tr><tr><td>CG9 vs ITv2</td><td>58%</td><td>51%</td><td>53%</td></tr><tr><td>CG27vsITv2</td><td>65%</td><td>58%</td><td>53%</td></tr><tr><td>CG9 vs NLLB</td><td>66%</td><td>51%</td><td>54%</td></tr><tr><td>CG27 vsNLLB</td><td>64%</td><td>61%</td><td>68%</td></tr></table></body></html>

# Ablation Studies

We conduct ablation studies on the effect of the domain adaptation module for style transfer and the context retriever block and compare the results with the respective baseline LLMs. Table 3 presents BLEU scores, COMET scores and win-ratios for all the considered open-source LLMs. In the Table, the highlighted numbers represent the best performing model in the corresponding model category as per the model size. We observe that providing ‘context only’ improves the relevancy of output translation, which is reflected in COMET and win ratio scores. On the other hand, ‘DAM only’ helps to navigate the output to copy the style of text and hence a larger value for the metric BLEU. Finally, combining the two, i.e., for CASAT, we obtain better BLEU score, COMET, and win-ratios across LLMs, which we conjecture that the LLM is able to gain complementary information from each of the two blocks.

# Conclusion

We explored the challenging task of entertainment translation, where we identified two key aspects, context, and style, which make this problem unique. We proposed a methodology to estimate these factors and use them to generate context and style-aware translations from an LLM. We showcased the efficacy of our algorithm via numerous experiments using three Indian language entertainment text datasets and various LLMs. Further, our approach has an offline component for partitioning of sessions and generation of contextual information, which we intend to eliminate to develop a completely online algorithm.