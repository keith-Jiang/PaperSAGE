# Adversity-aware Few-shot Named Entity Recognition via Augmentation Learning

Li Huang1,2, Haowen Liu1, Qiang $\mathbf { G a 0 } ^ { 1 , 2 * }$ , Jiajing $\mathbf { Y } \mathbf { u } ^ { 1 }$ , Guisong $\mathbf { L i u } ^ { 1 , 2 , 3 }$ , Xueqin Chen3

1School of Computing and Artificial Intelligence, Southwestern University of Finance and Economics, Chengdu, China 2Engineering Research Center of Intelligent Finance, Ministry of Education, Chengdu, China 3Kash Institute of Electronics and Information Industry, Kashgar, China lihuang@swufe.edu.cn, 223081200021@smail.swufe.edu.cn, qianggao $@$ swufe.edu.cn, 223081200001@smail.swufe.edu.cn, gliu@swufe.edu.cn, nedchen $1 0 7 2 8 @$ gmail.com

# Abstract

Few-shot Named Entity Recognition (NER) spotlights the tag of novel entity types in data-limited scenarios or lowerresource settings. Advances with Pre-trained Language Models (PLMs), including BERT, GPT, and their variants, have driven tremendous strategies to leverage context-dependent representations and exploit predefined relational cues, yielding significant gains in witnessing unseen entities. Nevertheless, a fundamental issue exists in prior efforts regarding their susceptibility to adversarial attacks in the intricate semantic environment. This vulnerability undermines the robustness of semantic representations, exacerbating the challenge of accurate entity identification, especially when transitioning across domains. To this end, we propose an Adversityaware Augment Learning (AAL) solution for the few-shot NER task, dedicated to retrieving and reinforcing entity prototypes resilient to adversarial inference, thereby enhancing cross-domain semantic coherence. In particular, AAL employs a two-stage paradigm consisting of training and finetuning. The process initiates with augmentation learning by leveraging two kinds of prompt learning schemes, then identifies prototypes under the guidance of a variational manner. Furthermore, we devise a domain-oriented prototype refinement to optimize prototype learning under conditions of uncertainty attack, facilitating the effective transfer of common knowledge from source to target domains. The experimental results, encompassing the few-shot NER datasets under both certainty and uncertainty conditions, affirm the superiority of the proposed AAL over several representative baselines, particularly its capability against adversarial attacks.

# 1 Introduction

Named Entity Recognition (NER) constitutes a fundamental task in natural language processing (NLP), which aims at identifying named entities, such as personal names, organizations, and geographical locations, from unstructured texts (Lample et al. 2016; Ma and Hovy 2016). Despite the significant advances achieved by existing NER efforts, their reliance on extensively annotated datasets poses a significant constraint when encountering scenarios with scarce manually tagged samples and the emergence of knowledge from diverse domains, as well as new entity types (Chiu

Source Domain Target Domain   
The best way to control these The battle for customer loyalty   
pets [animal] is to pick them is evident along the confedrate   
[animal] off the plants [plant] parkway [fac] strip.   
by hand. F Attack Training The battle for customer loyalty is evident along the confedrate Model government [ORG] strip.

and Nichols 2016; Devlin et al. 2018). This drawback has inspired interest in the realm of few-shot learning (FSL), which empowers NER models with the capacity to transfer knowledge from existing examples to scarcity like humans (Ding et al. 2021; Huang et al. 2021; Ma et al. 2022).

The dominant solutions with deep neural architectures, e.g., convolutional networks, recurrent networks, and attention mechanisms, have emerged as the preferred alternatives in handling few-shot NER tasks. In contrast to traditional NER efforts, they adaptively seek the diverse dependencies and interactive relations underlying knowledge correlations, facilitating the discovery of potentially foundational but contextual collaborations across various domains.

To uncover knowledge correlations in a few-shot manner, the majority of previous studies attempted to consider tokenlevel dependencies, predominantly striving to discover new entities by measuring the distance between tokens in the target domain corresponding to the source. For example, (Lin et al. 2021) used a pre-trained language model to replace the target entity with other entities that have the same semantic type. (Wang et al. 2022b) proposed two mutual informationbased training goals to prevent the model from over-relying on entity-mention information. More recently, (Fang et al. 2023) acknowledged the strength of prototype representations in generalized effectiveness to the few-shot conditions. Besides, (Wang et al. 2022a) utilized prototype classification to capture the semantic representation of each label. In a nutshell, the current few-shot NER solutions usually concentrate on similarity-based methods (Fritzler, Logacheva, and

Kretov 2019; Huisman, Van Rijn, and Plaat 2021), which are straight-forward to conduct the classification in the target domain according to its similarity with the representation of each class in the source domain, yielding promising results under lower-resource settings.

Despite the remarkable achievements in deep learningbased paradigms, previous arts endeavor to understand semantic dependencies, particularly through token-level distance measurements. More importantly, there are still two significant challenges: scarce examples is one of the inherent issues that hinder models from generalizing effectively beyond very limited tagged datasets, resulting in unsatisfactory outcomes when encountering new or unseen entities. Another is resilience against adversarial attacks particularly those leveraging synonyms to create ambiguity. In the realworld scenario, language is context-dependent, with many words or phrases that can be used interchangeably and subjectively. Adversaries, objective or subjective, exploit synonyms or other subtle variations to deliberately obscure entities, leading to potential misclassification or failure of the model to recognize the entity altogether, as illustrated in Fig. 1. Therefore, a robust few-shot NER should not only handle the constraints of limited annotated data but effectively counteract adversarial strategies that aim to introduce ambiguity and undermine its performance.

To address the aforementioned concerns, this study introduces an Adversity-aware Augmentation Learning (or AAL) solution for handling the few-shot NER task. Specifically, AAL is designed as a two-stage paradigm consisting of training and fine-tuning, which thoroughly comprises three primary steps: (1) We first implement augmentation learning using two different prompt templates, context-enhancing prompt and oriented-inducing prompt, to enrich the source domain dataset and introduce variations that broaden the exposure of AAL to diverse scenarios. (2) To mitigate the influence of irrelevant knowledge, we employ prototype learning on the source domain to capture the common knowledge of entities, thereby facilitating the identification of tokens in the target domain. (3) To effectively harness pertinent knowledge from a novel domain, we introduce a domain-oriented prototype to optimize prototype learning within the context of uncertain noise injection, thereby augmenting the adaptability and stability of AAL. In the end, we adapt concepts from NER to jointly optimize position tags and entity types, thereby reducing the computational complexity caused by category combination explosion. In sum, our main contributions can be outlined as follows:

• We present AAL, a novel adversity-aware augmentation learning solution for the adversarial challenge of few-shot NER. In particular, it capitalizes on inter-domain knowledge transfer to reinforce common dependencies and interactive relation learning by augmenting pivotal prototypes from a source domain to the target. • To enhance the resilience of prototypes across diverse entities, we employ a domain-oriented adaption prototype learning and further enhance with uncertainty-guided adversarial training, thereby enabling AAL to yield efficacious yet adversity-awareness prototype representations.

• Experimental results on both certain and uncertain datasets, including few-shot and cross-domain conditions, demonstrate the superiority and robustness of the proposed AAL compared to state-of-the-art baselines.

# 2 Preliminaries

Few-shot NER on Episode Learning. Given the source domain $\mathcal { D } _ { s } = \{ ( S _ { s } , \bar { \mathcal { Q } _ { s } } ) \}$ , the task of few-shot NER should adapt to the target domain of $\mathcal { D } _ { t } ~ = ~ \{ ( \boldsymbol { S } _ { t } , \boldsymbol { \mathcal { Q } } _ { t } ) \}$ . Under episode learning, each episode consists of a support set $S _ { s / t } ~ = ~ \{ ( x _ { s / t } ^ { ( i ) } , y _ { s / t } ^ { ( i ) } ) \} _ { i = 1 } ^ { N \times K }$ for adaption, and a query set $\mathcal { Q } _ { s / t } = \{ ( x _ { s / t } ^ { ( j ) } , y _ { s / t } ^ { ( j ) } ) \} _ { j = 1 } ^ { N \times K ^ { \prime } }$ for evaluation. Here, $N$ denotes the number of entity types in an episode, $K$ and $K ^ { \prime }$ denote the number of examples per entity type in support set and query set, respectively, commonly referred to $N$ -way $K$ - shot setting (Ding et al. 2021). Typically, $K$ is very small, often $K = 1$ or 5. The goal is to learn a model parameterized by $\Theta$ , such that it can accurately predict the named entities for a novel query instance $\boldsymbol { x } _ { t }$ under a new semantic situation, as $\Theta ( x _ { t } ) = y _ { t }$ , where $( x _ { t } , y _ { t } ) \notin \mathcal { D } _ { s }$ .

Adversarial Attack. We utilize the widely used ambiguous situation of synonym institution as our adversarial attack setting (Li et al. 2020), where a word in the original text is randomly replaced by its synonyms (Ren et al. 2019). This substituted operation is imperceptible to humans but sensitive to the model. In detail, adversarial example $\mathcal { A } _ { p } = ( x _ { p } , x _ { p } ^ { \prime } )$ are constructed by selecting out entities in the sentence that may mislead the target model and then replacing them using synonyms in the synonym set, where $x _ { p }$ is the specifical entity, $x _ { p } ^ { \prime }$ is the corresponding attack sample. In this work, we randomly selected adversarial examples to “fool” the few-shot NER to simulate the adversarial attack scenarios.

Fine-tuning of PLMs. Fine-tuning, inspired by PLMs, is a widely used practice to address the discrepancy between pre-training objectives and downstream task requirements. In a nutshell, the process commences with an initialized PLM $\mathcal { M }$ , where an input sequence $X \ = \ \{ x _ { 1 } , \ldots , x _ { n } \}$ is transformed into $\hat { X } = ( X , T )$ , $T$ is a task-oriented template. Subsequently, $\mathcal { M }$ along with extra fine-tuning layers (OPT) encodes $\hat { X }$ to comprehend semantic dependencies associated with the guidance of template $T$ .

# 3 Methodology

Drawing upon prior arts, the reason for model performance decline for cross-domain learning in few-shot NER is manifested in two aspects: 1) imprecise classification of unseen entity types within limited training data; 2) inaccuracies in entity classification owing to ambiguous entity descriptions or intended attacking. In our proposed AAL, we introduce a novel two-stage training and fine-tuning framework for fewshot NER, incorporating augmented learning with respect to data augment and prototype augment to enhance robustness understanding. The overview of the proposed model is illustrated in Fig. 2. Now we turn to elaborate on the design of each module.

![](images/c86ea05507e4daf45122bf5c5cfa98bca2b81a1aed28919d856bf687af684837.jpg)  
Figure 2: The illustration of the inference phase via our proposed AAL, where the distance is calculated between prototype $\mathcal { P }$ and entity representation ${ \bar { H } } ^ { q }$ . During training, distances are computed based on prototype $\mathcal { P }$ and augmentation set entities ${ \bar { H } } ^ { a }$   
Figure 3: Illustration of prompt schemes for support set.

Source sentence On wednesday Mohamed is to travel to  the United Nations. Time Person Organization   
Oriented-inducing prompt $\textcircled{!}$ 5'2 wednesday is time  5'2 Isabel is person 5'2 alliance is organization   
Context-enhancing prompt $\textcircled { A B }$ On wednesday Mohamed is to travel to the United Nations. TGRNCEG TGRNCEG Isabel institution On wednesday Mohamed is to travel to the United : Nations 5'2 wednesday is time $\textcircled{1}$ On wednesday Isabel is to travel to institution 5'2 wednesday is time $\textcircled{!}$ On the month Mohamed is to travel to alliance 5'2 Mohamed is person $\textcircled{!}$ On wednesday Isabel is to travel to the United Nations 5'2 United Nations is organization $\textcircled{1}$

# 3.1 Augmentation Learning

Motivated by existing augmentation efforts and advancements in prompt-based techniques (Lee et al. 2021), we integrate prompt learning into data augmentation, thereby establishing a dynamic mechanism incorporating task-specific prompts for enhancing support set. We propose two distinct types of prompts: context-enhancing prompt and orientedinducing prompt, as depicted in Fig. 3. These prompts are designed to introduce controlled variations that maintain consistency with the original entity types while allowing for diverse semantics context and broadening the exposure of AAL to diverse scenarios, thereby improving performance in low-resource settings.

Context-enhancing Prompt $( E _ { c } )$ . To enhance the diversity of entity examples, we employ a context-enhancing prompting scheme that entails substituting a particular entity within a sentence attribute consistency, generating new, diverse examples while preserving the original sentence structure and context. Formally, this procedure involves a binomial distribution to determine the replacement of each entity probabilistically. During replacement, we choose to replace a word from the top- $N$ word sets corresponding to this entity type. The employment of context-enhancing prompt directs the model towards the specific labels to anticipate, facilitating semantic comprehension by metric learning in diverse contexts. Notably, augmented sentences retain an unchanged entity, such as words with gray underlining in Fig. 3, and we give a template to describe it. For instance, the entity “Mohamed” vs. “Mohamed is person”.

Oriented-inducing Prompt $( E _ { o } )$ . Subsequently, to mitigate the influence of entity token replacement, we devise an oriented-inducing prompt strategy for our augmentation learning. This strategy extends the concept of entity replacement by explicitly linking the most prevalent entity tokens with their corresponding positional tags, i.e., $\{ B , I , O , E , S \}$ , thereby contextualizing replacements. The entities and their tags are subsequently concatenated using the special token “[SEP]” to maintain semantic coherence. For each sentence in the support set, we sequentially select each entity and append it to the end of the sentence using a tailored prompt template. This strategy enhances dataset diversity, ensuring that AAL generalizes to unseen entities and refines its recognition efficacy under uncertain scenarios.

# 3.2 Semantic Encoding

We initially leverage the pre-trained Language Model (PLM), such as BERT, to encode the input text into contextualized tensors. To comprehend semantic dependency, we feed the concatenate inputs of text associated with its prompt template to PLM to acquire the contextualized intermediate representation. Specifically, AAL employs two semantic encoding schemes, $H ^ { a } = \bar { P } L M ( X , \bar { E _ { c } } , \bar { E _ { o } } )$ denotes the support set fed to PLM are augmented, while $H = P L M ( X )$ refers to the inputs are come from the original support set, where $\{ H ^ { a } , H \} \in \mathbb { R } ^ { | X | \times d _ { m } }$ . Particularly, the remains where symbols with a superscript $a$ denote AAL utilized the augmentation support set.

# 3.3 Prototype Learning

Inspired by MANNER (Fang et al. 2023), we employ prototype learning for entities, which encapsulates the essential representation of entities of the same type. Compared with MANNER which relies on a key-value pairs memory to form prototypes, AAL leverages dynamic representations that adapt to their semantic conditions and emphasizes capturing common knowledge in uncertain semantic contexts.

We introduce $\mathcal { P } = \{ \bar { P _ { 1 } } , \cdot \cdot \cdot , P _ { \epsilon } \} \in \mathbb { R } ^ { \epsilon \times d _ { m } }$ to encapsulate the prototypical representations of the entity types from source domain $\mathcal { D } _ { s }$ , where $\epsilon$ refers to the number of entity types and $P _ { i }$ denotes the prototype of $i$ -th entity type. In particular, we categorize non-typing as an entity type, indicating that tokens are not considered entities. Each prototype $P _ { i }$ represents a specific entity type $i$ and can be expressed as:

$$
\begin{array} { r } { P _ { i } = \frac { 1 } { n _ { j } } \sum _ { j = 1 } ^ { n _ { j } } ( \bar { h } _ { i } ) _ { j } , } \end{array}
$$

where $\bar { h } _ { i } \in \mathbb { R } ^ { d _ { m } }$ signifies the representative token for the $i$ -th entity type, extracted from the tensor $\bar { H } = P L M _ { 4 } ( S _ { s } )$ , which is computed as the average outcomes from the last four layers of PLM, applied to $\mathcal { S } _ { s } \subset \mathcal { D } _ { s }$ , without augmentations. $n _ { j }$ quantifies the number of tokens classified to the $i$ -th entity type within $\mathcal { D } _ { s }$ . Notably, we only created prototypes on the support set.

Whereafter obtaining the prototypical representation $\mathcal { P }$ , we operate the metric learning on the augmentation support set and query set. Specifically, we conduct prototype learning under the guidance of Jenson-Shannon divergence (Fuglede and Topsoe 2004) between prototypes $P _ { i }$ and tokens $\bar { h } _ { j } ^ { a }$ which is retrieved from $\bar { H } ^ { a } = P L M _ { 4 } ( S _ { s } ^ { a } , \mathcal { Q } _ { s } )$ as:

$$
\begin{array} { l } { \displaystyle \pi ( P _ { i } , \bar { h } _ { j } ^ { a } ) = D _ { J S } ( \mathcal { N } _ { P _ { i } } , \mathcal { N } _ { \bar { h } _ { j } ^ { a } } ) , } \\ { \displaystyle = \frac { 1 } { 2 } \big ( D _ { K L } ( \mathcal { N } _ { ( \mu _ { P _ { i } } , \sigma _ { P _ { i } } ) } | | \mathcal { N } _ { ( \mu _ { \bar { h } _ { j } ^ { a } } , \sigma _ { \bar { h } _ { j } ^ { a } } ) } ) } \\ { \displaystyle ~ + D _ { K L } ( \mathcal { N } _ { ( \mu _ { \bar { h } _ { j } ^ { a } } , \sigma _ { \bar { h } _ { j } ^ { a } } ) } | | \mathcal { N } _ { ( \mu _ { P _ { i } } , \sigma _ { P _ { i } } ) } ) \big ) , } \end{array}
$$

where $\mathcal { N } _ { ( \mu _ { * } , \sigma _ { * } ) }$ denotes a $d$ -dimensional Gaussian distribution projected by a linear layer, $D _ { K L }$ refers to the KullbackLeibler divergence, thereby $\pi ( \cdot )$ measures the distance between tokens and prototypes. For all tokens in $\{ \cal { S } _ { s } ^ { a } , \mathcal { Q } _ { s } \}$ , the prototype learning can be conducted as:

$$
\begin{array} { r } { \mathcal { L } _ { p } = \frac { 1 } { m } \sum _ { j } ^ { m } \big ( - \log \frac { \frac { 1 } { | \psi ( i ) | } \sum _ { ( P _ { i } , \bar { h } _ { j } ^ { a } ) \in \psi ( i ) } \exp { \left( - \pi ( P _ { i } , \bar { h } _ { j } ^ { a } ) \right) } } { \sum _ { i } ^ { \epsilon } \exp { \left( - \pi ( P _ { i } , \bar { h } _ { j } ^ { a } ) \right) } } \big ) , } \end{array}
$$

where $m \ = \ | \{ { \cal S } _ { s } ^ { a } , { \mathcal Q } _ { s } \} |$ denotes the amount of tokens in $\{ \cal { S } _ { s } ^ { a } , \mathcal { Q } _ { s } \}$ , $( P _ { i } , h _ { j } ^ { a } ) \in \psi ( i )$ refers to token $\bar { h } _ { j } ^ { a }$ and prototype $P _ { i }$ are attributes the same entity type, i.e., $\psi ( i )$ .

Span Detection. We follow the NER task to formulate span detection as a sequence labeling task, i.e., to predict the position tag $\{ B , O , I , E , S \}$ of tokens. Based on the semantic

encoding of PLM, we employ a feed-forward network associated with a gated linear layer to obtain the prediction of the position tag as:

$$
\mathbb { P } _ { \theta } \left( \hat { \pmb { c } } | X , \mathcal { P } \right) = a ^ { T } ( H ^ { a } ) \odot g ( \beta W _ { c } + b _ { c } ) ,
$$

where $\odot$ is the element-wise product, $a ^ { T } ( \cdot )$ represents a two-layer feed-forward neural network with residual connection, $g ( \cdot )$ refers to the sigmoid operation, $H ^ { a }$ is the output of PLM with augmentation dataset as input, β ∈ R|X|×2 is a 2-d vector, where one dimension records the top metric between each token and its corresponding prototype, while the other dimension captures the metric with a specific prototype representing non-entity. $W _ { c } \in \mathbb { R } ^ { 2 \times d _ { c } } , b _ { c } \in \mathbb { R } ^ { d _ { c } }$ are learnable parameters. Finally, span detection loss is calculated by prediction $\hat { c }$ associated with its golden label $c$ :

$$
\begin{array} { r } { \mathcal { L } _ { c } = \sum c ( \log \mathbb { P } _ { \theta } ( \hat { c } | X , \mathcal { P } ) ) . } \end{array}
$$

Entity Typing. We follow the principle of prototypical networks (Snell, Swersky, and Zemel 2017; Fang et al. 2023) to conduct the entity type prediction. Initially, we calculate domain-oriented entity representation associated with augmented support set $ { \boldsymbol { S } } _ { s } ^ { a }$ and query set $\mathcal { Q } _ { s }$ :

$$
\begin{array} { r l } & { \mathtt { P } _ { \theta } \big ( Z _ { s } | (  { S _ { s } ^ { a } } ,  { \mathcal { Q } _ { s } } ) \big ) = \rVert _ { i \in \varepsilon } \big [ \mathtt { P } _ { \theta } \big ( Z _ { s } ^ { \psi ( i ) } |  { S ^ { ( a , \psi ( i ) ) } } ,  { Q ^ { \psi ( i ) } } \big ) \big ] } \\ & { \qquad = \rVert _ { i \in \varepsilon } \big [  { N } \big ( P _ { i } ^ { a } | f _ { \theta } \big (  { S ^ { ( a , \psi ( i ) ) } } ,  { Q ^ { \psi ( i ) } } \big ) , \sigma ^ { 2 } \pmb { I } \big ) \big ] , } \end{array}
$$

where $| |$ refers to group augmentation prototypes, and the updated prototype distribution, resulting from the function $f _ { \theta }$ , is calculated by:

$$
\begin{array} { r l r } { f _ { \theta } ( S ^ { \psi ( i ) } , Q ^ { \psi ( i ) } ) = \gamma \cdot F F N ( r _ { i } ^ { \{ s ; q \} } ) + ( 1 - \gamma ) \cdot r _ { i } ^ { s } , } & { } & \\ { r _ { i } ^ { * } = \displaystyle \frac { 1 } { | \psi ( i ) | } \sum _ { j } \hat { h } _ { j } ^ { ( * , \psi ( i ) ) } , \mathrm { ~ w h e r e ~ } \hat { h } _ { j } \in \psi ( i ) } & { } & \end{array}
$$

where $\hat { h } ^ { * } ~ \in ~ \mathbb { R } ^ { d _ { z } }$ denotes semantic encoding with corresponding input datasets with a linear layer to transform as $\hat { h } ^ { ( s ; q ) } = P L M ( S _ { s } ^ { a } ; \mathcal { Q } _ { s } ) W _ { s } + b _ { s }$ , learnable parameters $W _ { s } \in \mathbb R ^ { d _ { m } \times d _ { z } } , b _ { s } \in \mathbb R ^ { d _ { z } }$ , $r _ { i } ^ { * }$ is the mean value of the token representations within $i$ -th entity type in the corresponding set, and $\mathrm { F F N } ( \cdot )$ is the feed-forward neural network with the ReLU activation function. The hyperparameter $\gamma$ modulates entity information with support and query sets. Thus, we will obtain domain-oriented prototype $\boldsymbol { Z _ { s } } \in \mathbb { R } ^ { \epsilon \times d _ { z } }$ .

Consequently, given a sentence $X = \{ x _ { 1 } , \cdot \cdot \cdot , x _ { n } \}$ , the probability of entity types of $X$ can be expressed as follows:

$$
\begin{array} { r } { \mathbb { P } _ { \theta } \big ( \tilde { e } | X , Z _ { s } \big ) = \sum _ { d } \mathopen { } \mathclose \bgroup \left( [ H ] W _ { e } + b _ { e } \aftergroup \egroup \right) \odot \big ( Z _ { s } ^ { a } \big ) ^ { T } , } \end{array}
$$

herein, we employ an uncertainty-augmentation strategy through the random injection of diverse noise to $Z _ { s }$ , yielding a modified entity representation to $Z _ { s } ^ { a } \in \mathbb { R } ^ { n _ { e } \times \epsilon \times d _ { z } }$ , $n _ { e }$ denotes the sample size for augmentation, thereby $[ H ] \in$ Rne×|X|×dz refers to the expanding output of PLM, e˜ $\mathbb { R } ^ { n _ { e } \times | X | \times \epsilon }$ is the prediction of entity types of sequence $X$ , $W _ { e } \in \mathbb { R } ^ { d _ { m } \times d _ { z } } , b _ { e } \in \mathbb { R } ^ { d _ { z } }$ are learnable parameters, $\textstyle \sum _ { d }$ denotes the addition performed along the last dimension.

Specifically, we further augment prototypes to calibrate entity typing, which can be expressed as:

$$
e ^ { a } = [ \tilde { e } ; \pi ( \mathcal { P } , \bar { H } ^ { a } ) ] ,
$$

where $\pmb { e } ^ { a } \in \mathbb { R } ^ { n _ { e } \times | X | \times 2 \epsilon }$ , and the prediction is defined as:

$$
\begin{array} { r l } & { \mathrm { P } _ { \theta } ( \hat { e } | X , \mathcal { P } , Z _ { s } ) = \big ( ( A \odot g ( B ) ) W _ { \hat { e } } + b _ { \hat { e } } \big ) + \tilde { e } , } \\ & { \qquad \mathrm { w h e r e ~ } A = e ^ { a } W _ { a 1 } + b _ { a 1 } , B = e ^ { a } W _ { a 2 } + b _ { a 2 } . } \end{array}
$$

Herein, $\{ W _ { a 1 } , W _ { a 2 } \} \in \mathbb { R } ^ { 2 \epsilon \times 2 \epsilon }$ , $W _ { \hat { e } } \in \mathbb { R } ^ { 2 \epsilon \times \epsilon }$ are learnable parameters, $\hat { e } \in \mathbb { R } ^ { n _ { e } \times | X | \times \epsilon }$ is the finally prediction of entity types. Thereby, the entity type loss can be calculated by:

$$
\begin{array} { r } { \mathcal { L } _ { e } = \sum [ e ] \log \mathbb { P } _ { \theta } \big ( \hat { e } \big | ( X , \mathcal { P } , Z _ { s } ) \big ) , } \end{array}
$$

where $[ e ] \in \mathbb { R } ^ { n _ { e } \times | X | \times \epsilon }$ denotes expanding golden label for matching the shape of prediction $\hat { e }$ .

Training Criterion. Given source domain datasets $D _ { s } \ = \ $ $\{ S _ { s } , Q _ { s } \}$ , the corresponding sample as $\textbf { \em o } = \left( X , y , c , e \right)$ , where $\dot { \mathbf { c } } = \{ B , O , I , E , S \}$ refers to namely position tags, $e ~ = ~ \{ e _ { 1 } , \cdot \cdot \cdot , e _ { \epsilon } \}$ represents entity types, and $_ y$ is the ground-truth of jointy-label, such as $^ { \mathrm { 6 6 } } \mathrm { { B - p e r s o n } ^ { \mathrm { 3 } } }$ . We combine the results of span detection and entity classification of our model as the joint probability distribution of $\mathbb { P } _ { \theta } \big ( \hat { \pmb { y } } , \hat { \pmb { c } } , \hat { \pmb { e } } \big ) = \mathbb { P } _ { \theta } \big ( \hat { \pmb { c } } | \boldsymbol { X } , \mathcal { P } \big ) \cdot \mathbb { P } _ { \theta } \big ( \hat { \pmb { e } } | \boldsymbol { X } , \mathcal { P } , Z _ { s } \big )$ . Thus the loss function of joint prediction can be computed as follows:

$$
\begin{array} { r } { \mathcal { L } _ { J } = \sum _ { o \in D _ { s } } \mathbb { E } [ - \log \mathbb { P } _ { \theta } ( \pmb { \hat { y } } , \hat { c } , \hat { e } , | X , Z _ { s } , \mathcal { P } ) ] . } \end{array}
$$

Ultimately, the overall loss can be linearly combined as:

$$
\begin{array} { r } { \mathcal { L } = \mathcal { L } _ { s } + \mathcal { L } _ { e } + \mathcal { L } _ { J } + \alpha \mathcal { L } _ { p } . } \end{array}
$$

# 3.4 Target Domain Adapting.

Since we do not have access to the query set when the model is adapted to the target domain, we follow the previous work (Ma et al. 2022) to fine-tune the model with a few examples ( $K$ -shot) in the target domain. After adapting AAL to the target domain by fine-tuning, we use $\mathrm { P } _ { \theta } \mathbf { \bar { ( } } \hat { \pmb { y } } , \hat { \hat { c } } , \hat { e } | X , \mathcal { P } , Z _ { t } )$ to predict the sentence $X$ in the query set of the target domain. Notably, we directly employ $\mathrm { P } _ { \theta } \big ( Z _ { t } | S _ { t } ^ { a } \big )$ (cf. Eq.(6)) as the entity representation that is conducted on the support set of the target domain.

# 4 Experiments

# 4.1 Experimental Setup

Datasets. To align with previous studies, we conduct experiments on the following datasets: (1) SNIPS (Coucke et al. 2018): It has 7 domains with different label sets and a small number of samples, with a relatively even number of samples per domain per label set, which makes it easy to simulate a small number of samples. (2) Cross-Dataset (Hou et al. 2020): It is constructed from datasets from four different domains: CoNLL-2003 (Tjong Kim Sang 2002), GUM (Zeldes 2017), WNUT-2017 (Derczynski et al. 2017), and Ontonotes (Pradhan et al. 2013). We take two of the datasets as the training set, one as the validation set, and one as the test set. (3) Adversarial examples. Following (Xue et al. 2024), we use the textual adversarial attack algorithm BertAttack (Li et al. 2020) to perform textual adversarial attacks on samples in the support set $\boldsymbol { \mathcal { S } } _ { t }$ and query set $\mathcal { Q } _ { t }$ of the target domain. The cross-domain migration learning capability is demonstrated by the performance of the Few-shot NER model in the query set $\mathcal { Q } _ { t }$ of the target domain.

Baselines. Our baselines include TransferBERT, MNetwork, and L-TapNet+CDT used in (Hou et al. 2020), ProtoBERT (Fritzler, Logacheva, and Kretov 2019), ESD (Wang et al. 2021), MANNER (Fang et al. 2023). Recently related studies SimBERT (Hou et al. 2020), CONTaiNER (Das et al. 2022), Decp-MetaNER (Ma et al. 2022), SpanProto (Wang et al. 2022a), MSDP (Dong et al. 2023), and BDCP (Xue et al. 2024) as additional baselines for cross-dataset validation. We also evaluate five strong baselines, including BDCP and MANNER, under the uncertainty condition using the authors’ original code.

Evaluation. To align with previous efforts such as (Hou et al. 2020), we evaluate all methods using $F l$ -score with the test episode and average all scores as results. Notably, we used five different random seeds in each experiment and reported the mean and standard deviation of these results.

Implementation Details. We exploit the Uncased-Bert base model as the PLM. $\{ d _ { m } , d _ { z } , n _ { e } , \alpha , \gamma \}$ and dropout are set to $\{ 7 6 8 , 1 2 8 , 5 , 0 . 5 , 0 . 5 , 0 . 1 \}$ . We employ the AdamW optimizer for AAL, accelerated on an NVIDIA A100 GPU. For reproduction, the source code is released at https://github. com/swufe-NiceLab-GeoText/AAL.git.

# 4.2 Performance Evaluation

Table 1 - Table 4 report the performance of various methods under certain and uncertain conditions. The best gain is highlighted in bold while the second best is underline. The findings are summarized as follows.

Performance on Certainty Condition. Table 1 and Table 2 present the performance comparison of our AAL against baselines on SNIPS and Cross-Dataset under certain conditions. AAL achieves an average enhancement of $6 . 2 7 \%$ and $3 . 0 4 \%$ in overall results for the 1-shot and 5-shot scenarios, outperforming the robust baseline MANNER. Specifically, significant F1-score improvements of $1 2 . 6 8 \%$ and $8 . 0 5 \%$ are noted on SNIPS (Se, 1-shot) and Cross-Dataset (Wiki, 1- shot), respectively, indicating the efficacy of AAL in adapting to novel domains with minimal labeled data. This underscores AAL’s strength in leveraging target domain support samples, particularly in low-resource scenarios, affirming its adaptive and resource-efficient nature.

Performance on Uncertainty Condition. Table 3 and Table 4 report the performance of our AAL alongside baselines on SNIPS and Cross-Dataset following the application of Bert-Attack adversarial algorithm to the target domain data. The findings reveal a substantial decline in the performance of baseline models under adversarial conditions, highlighting the vulnerability of existing few-shot NER. Specifically, MANNER, a leading model, experiences an average F1 score reduction of $7 . { \bar { 9 } } 4 \%$ and $9 . 0 \hat { 7 } \%$ on SNIPS and CrossDataset, respectively. This susceptibility stems from their reliance on specific word features, making them prone to interference from adversarially crafted words. In contrast, our AAL, leveraging oriented-inducing prompt learning, enhances resilience by associating entity types with words vulnerable to such attacks, thereby reducing adversarial interference. Moreover, we augment model robustness by incorporating unaltered support set prototypes, further contributing to defense against adversarial attacks.

Table 1: Overall performance on the SNIPS.   

<html><body><table><tr><td></td><td>Models</td><td>We</td><td>Mu</td><td>Pl</td><td>Bo</td><td>Se</td><td>Re</td><td>Cr</td></tr><tr><td></td><td>TransferBERT</td><td>55.82±2.75</td><td>38.01±1.74</td><td>45.65±2.02</td><td>31.63±5.32</td><td>21.96±3.98</td><td>41.79±3.81</td><td>38.53±7.42</td></tr><tr><td>LOHS-I</td><td>M-Network</td><td>21.74±4.60</td><td>10.68±1.07</td><td>39.71±1.81</td><td>58.15±0.68</td><td>24.21±1.20</td><td>32.88±0.64</td><td>69.66±1.68</td></tr><tr><td></td><td>L-TapNet+CDT</td><td>71.53±4.04</td><td>60.56±0.77</td><td>66.27±2.71</td><td>84.54±1.08</td><td>76.27±1.72</td><td>70.79±1.60</td><td>62.89±1.88</td></tr><tr><td></td><td>ProtoBERT</td><td>46.72±1.03</td><td>40.07±0.48</td><td>50.78±2.09</td><td>68.73±1.87</td><td>60.81±1.70</td><td>55.58±3.56</td><td>67.67±1.16</td></tr><tr><td></td><td>ESD</td><td>78.25±1.50</td><td>54.74±1.02</td><td>71.15±1.55</td><td>71.45±1.38</td><td>67.85±0.75</td><td>71.52±0.98</td><td>78.14±1.46</td></tr><tr><td></td><td>MANNER</td><td>75.41±0.52</td><td>60.93±0.14</td><td>66.65±0.70</td><td>72.80±0.32</td><td>68.35±1.00</td><td>74.99±0.11</td><td>59.20±2.64</td></tr><tr><td></td><td>Ours</td><td>80.87±0.35</td><td>65.50±0.97</td><td>78.06±0.77</td><td>88.41±0.35</td><td>81.03±0.12</td><td>81.02±0.24</td><td>79.04±0.75</td></tr><tr><td></td><td>TransferBERT</td><td>59.41±0.30</td><td>42.00±2.83</td><td>46.07±4.32</td><td>20.74±3.36</td><td>28.20±0.29</td><td>67.75±1.28</td><td>58.61±3.67</td></tr><tr><td></td><td>Matching Network</td><td>36.67±3.64</td><td>33.67±6.12</td><td>52.62±2.84</td><td>69.09±2.36</td><td>38.42±4.06</td><td>33.28±2.99</td><td>72.10±1.48</td></tr><tr><td></td><td>L-TapNet+CDT</td><td>71.64±3.62</td><td>67.16±2.97</td><td>75.88±1.51</td><td>84.38±2.81</td><td>82.58±2.12</td><td>70.05±1.61</td><td>73.41±2.61</td></tr><tr><td></td><td>ProtoBERT</td><td>67.82±4.11</td><td>55.99±2.24</td><td>46.02±3.19</td><td>72.17±1.75</td><td>73.59±1.60</td><td>60.18±6.96</td><td>66.89±2.88</td></tr><tr><td>JOHS-S</td><td>ESD</td><td>84.50±1.06</td><td>66.61±2.00</td><td>79.69±1.35</td><td>82.57±1.37</td><td>82.22±0.81</td><td>80.44±0.80</td><td>81.13±1.84</td></tr><tr><td></td><td>MANNER</td><td>86.53±0.21</td><td>74.93±0.55</td><td>80.24±0.22</td><td>83.91±0.57</td><td>83.78±0.56</td><td>84.72±0.48</td><td>72.07±0.34</td></tr><tr><td></td><td>Ours</td><td>87.00±1.06</td><td>75.36±0.11</td><td>85.88±0.32</td><td>90.22±0.57</td><td>87.12±0.21</td><td>85.09±0.37</td><td>80.24±0.39</td></tr></table></body></html>

Table 2: Overall performance on the Cross-Dataset.   

<html><body><table><tr><td rowspan="2">Models</td><td colspan="4">1-shot</td><td colspan="4">5-shot</td></tr><tr><td>News</td><td>Wiki</td><td>Social</td><td>Mixed</td><td>News</td><td>Wiki</td><td>Social</td><td>Mixed</td></tr><tr><td>TransferBERT</td><td>4.75±1.42</td><td>0.57±0.32</td><td>2.71±0.72</td><td>3.46±0.54</td><td>15.36±2.81</td><td>3.62±0.57</td><td>11.08±0.57</td><td>35.49±7.60</td></tr><tr><td>M-Network</td><td>19.50±0.35</td><td>4.73±0.16</td><td>17.23±2.75</td><td>15.06±1.61</td><td>19.85±0.74</td><td>5.58±0.23</td><td>6.61±1.75</td><td>8.08±0.47</td></tr><tr><td>L-TapNet+CDT</td><td>44.30±3.15</td><td>12.04±0.65</td><td>20.80±1.06</td><td>15.17±1.25</td><td>45.35±2.67</td><td>11.65±2.34</td><td>23.30±2.80</td><td>20.95±2.81</td></tr><tr><td>ProtoBERT</td><td>32.49±2.01</td><td>3.89±0.24</td><td>10.68±1.40</td><td>6.67±0.46</td><td>50.06±1.57</td><td>9.54±0.44</td><td>17.26±2.65</td><td>13.59±1.61</td></tr><tr><td>SimBERT</td><td>19.22±0.00</td><td>6.91±0.00</td><td>5.18±0.00</td><td>13.99±0.00</td><td>32.01±0.00</td><td>10.63±0.00</td><td>8.20±0.00</td><td>21.12±0.00</td></tr><tr><td>CONTaiNER</td><td>34.09±0.94</td><td>10.81±0.45</td><td>16.45±0.92</td><td>32.96±0.91</td><td>58.63±1.56</td><td>24.31±0.66</td><td>27.50±0.58</td><td>48.62±2.81</td></tr><tr><td>Decp-MetaNER</td><td>46.09±0.44</td><td>17.54±0.98</td><td>25.14±0.24</td><td>34.13±0.92</td><td>58.18±0.87</td><td>31.36±0.91</td><td>31.02±1.28</td><td>45.55±0.90</td></tr><tr><td>SpanProto</td><td>47.71±0.51</td><td>20.16±0.80</td><td>30.19±0.94</td><td>37.91±0.79</td><td>61.61±1.03</td><td>43.75±0.50</td><td>31.37±0.94</td><td>49.04±0.93</td></tr><tr><td>MSDP</td><td>49.14±0.52</td><td>21.88±0.29</td><td>30.10±0.56</td><td>38.05±0.88</td><td>63.98±0.80</td><td>36.53±0.81</td><td>35.61±0.72</td><td>49.99±0.95</td></tr><tr><td>MANNER</td><td>49.06±0.48</td><td>23.17±0.20</td><td>28.54±0.69</td><td>43.61±0.48</td><td>64.84±0.51</td><td>40.86±0.96</td><td>35.86±1.28</td><td>58.37±0.62</td></tr><tr><td>BDCP</td><td>43.88±0.00</td><td>11.85±0.00</td><td>25.90±0.00</td><td>28.16±0.00</td><td>58.76±0.00</td><td>32.17±0.00</td><td>31.84±0.00</td><td>46.29±0.00</td></tr><tr><td>Ours</td><td>49.21±0.89</td><td>31.22±0.94</td><td>32.05±1.04</td><td>46.51±0.35</td><td>66.18±0.97</td><td>44.19±0.45</td><td>39.91±0.24</td><td>59.06±0.28</td></tr></table></body></html>

Decoupling Study. We explore the effectiveness of different components of AAL by comparing with its four decoupling variants on Cross-Dataset: AAL w/o DO proto removes the domain-oriented prototype residual connections; AAL w/o base proto removes the prototype module; AAL w/o aug removes the context-enhancing prompt in augmentation learning; AAL w/o T & aug removes the whole augmentation learning. The results of the decoupling experiments are shown in Fig. 4. Overall, AAL outperforms its variant models, validating the positive contribution of various components. A significant performance decline is evident in AAL w/o DO proto, underscoring the efficacy of domainoriented prototypes and showcasing that incorporating uncertainty injection enhances AAL’s stability. The superiority of AAL over AAL w/o proto confirms the efficacy of capturing prototypes representing common knowledge among entities. Moreover, the degradation in performance when the AAL removes data augmentation (AAL w/o aug and AAL w/o T & aug) further validates our statement, emphasizing the crucial role of data enhancement.

Entity Representation Visualization. To illustrate the efficacy of AAL on entity representation, we employ the test set in the 1-shot scenario from SNIPS Bo and utilize the tSNE (Van der Maaten and Hinton 2008) toolkit to visualize them. As depicted in Fig. 5, these embeddings demonstrate clustering around type prototype regions for distinct entity classes. Notably, even after exposure to textual adversarial attacks, the majority of span representations maintain this clustering pattern, indicating the robustness of our proposed

![](images/4ff7c560f8c41f04717982d0a317861f77c7e8a22e457bd42d8501fbfb290957.jpg)  
Figure 4: Decopling study.

AAL in discerning and assigning entity types accurately in both original and adversarial conditions.

Interpretability of Dependency Learning. We randomly sampled instances from the query set of SNIPS Bo under a 1-shot learning scenario, alongside its adversarial counterparts, to depict semantic dependencies in Fig. 6. The alignment of AAL’s correct entity type prediction for both original and attack tokens highlights its adversarial awareness. Examining attention heatmaps reveals that despite substituting the entity “book” with “title”, the token dependencies exhibit minimal shifts in semantic correlation, highlighting the cooperation of augmentation and prototype learning. Notably, the similarity in heatmap color distribution underscores AAL’s robustness in capturing token semantics, further emphasizing its resilience to adversarial attacks.

Table 3: Overall performance on the attacked SNIPS.   

<html><body><table><tr><td></td><td>Models</td><td>We</td><td>Mu</td><td>PI</td><td>B0</td><td>Se</td><td>Re</td><td>Cr</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>LOHS-I</td><td>L-TapNet+CDT</td><td>61.13±0.94</td><td>53.37±0.59</td><td>60.81±4.18</td><td>78.15±0.98</td><td>41.32±2.03</td><td>66.76±9.75</td><td>55.92±2.00</td></tr><tr><td></td><td>Decp-MetaNER</td><td>29.74±0.13</td><td>24.54±0.08</td><td>47.48±0.70</td><td>51.37±0.32</td><td>28.17±0.29</td><td>42.37±0.75</td><td>17.71±0.79</td></tr><tr><td></td><td>MANNER</td><td>62.11±1.85</td><td>50.45±0.19</td><td>62.17±0.23</td><td>72.62±0.21</td><td>53.32±0.18</td><td>62.17±0.14</td><td>52.32±0.35</td></tr><tr><td></td><td>BDCP</td><td>29.13±0.14</td><td>23.88±0.92</td><td>51.34±0.23</td><td>51.05±0.81</td><td>29.06±0.48</td><td>41.87±0.11</td><td>18.00±0.15</td></tr><tr><td></td><td>Ours</td><td>67.37±0.16</td><td>52.52±0.74</td><td>69.69±1.14</td><td>79.21±0.19</td><td>66.47±1.41</td><td>69.25±0.43</td><td>57.32±1.50</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>LOHS-S</td><td>L-TapNet+CDT</td><td>65.33±3.4</td><td>65.37±0.16</td><td>63.05±1.08</td><td>77.49±2.66</td><td>70.78±2.64</td><td>63.92±2.14</td><td>58.61±1.34</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>Decp-MetaNER MANNER</td><td>37.56±0.40</td><td>32.21±0.24</td><td>61.60±0.43</td><td>56.07±0.24</td><td>40.48±0.32</td><td>50.99±0.35</td><td>22.20±0.14</td></tr><tr><td></td><td></td><td>75.51±0.15 37.62±0.26</td><td>62.31±0.53 31.64±0.21</td><td>75.18±0.33 62.31±0.14</td><td>79.42±0.81 55.46±0.21</td><td>74.87±0.28 40.48±0.66</td><td>74.05±0.58 51.28±0.69</td><td>60.95±0.52</td></tr><tr><td></td><td>BDCP</td><td></td><td>62.76±0.55</td><td></td><td>80.47±0.53</td><td>75.32±0.78</td><td>75.17±0.40</td><td>22.33±0.39</td></tr><tr><td></td><td>Ours</td><td>76.20±0.99</td><td></td><td>76.02±1.03</td><td></td><td></td><td></td><td>61.31±0.35</td></tr></table></body></html>

<html><body><table><tr><td rowspan="2">Models</td><td colspan="4">1-shot</td><td colspan="4">5-shot</td></tr><tr><td>News</td><td>Wiki</td><td>Social</td><td>Mixed</td><td>News</td><td>Wiki</td><td>Social</td><td>Mixed</td></tr><tr><td>L-TapNet+CDT</td><td>3.37±0.14</td><td>4.78±1.96</td><td>19.47±0.76</td><td>0.19±0.05</td><td>2.66±0.15</td><td>0.43±0.05</td><td>0.96±0.25</td><td>0.29±0.02</td></tr><tr><td>ESD</td><td>25.57±0.36</td><td>6.54±0.33</td><td>13.28±0.35</td><td>17.52±0.09</td><td>27.90±1.47</td><td>9.96±1.57</td><td>16.31±0.59</td><td>20.83±2.07</td></tr><tr><td>Decp-MetaNER</td><td>34.89±0.33</td><td>9.05±0.12</td><td>16.16±0.32</td><td>21.74±0.93</td><td>46.62±0.28</td><td>18.61±2.51</td><td>18.54±0.75</td><td>29.90±0.91</td></tr><tr><td>MANNER</td><td>38.57±0.17</td><td>20.11±0.59</td><td>18.46±0.40</td><td>35.59±0.69</td><td>53.51±0.66</td><td>36.01±0.44</td><td>22.77±0.53</td><td>46.72±1.21</td></tr><tr><td>BDCP</td><td>34.95±0.99</td><td>12.64±0.29</td><td>16.18±0.44</td><td>25.62±0.68</td><td>45.52±0.28</td><td>24.68±0.33</td><td>18.36±0.53</td><td>32.78±1.39</td></tr><tr><td>Ours</td><td>41.25±0.36</td><td>26.51±0.25</td><td>20.55±0.37</td><td>37.39±0.35</td><td>55.20±0.47</td><td>37.66±0.49</td><td>23.99±0.52</td><td>47.42±0.46</td></tr></table></body></html>

Table 4: Overall performance on the attacked Cross-Dataset.

![](images/829136b0940b531fd0d5fa577288f093e0bf80c8bc093d1e5d28c820262860e8.jpg)  
Figure 5: Visualization of entity representation.

![](images/224d0265aed5d46c4032e290ee3fb10073ae7aca7912003d7c8cc68cde3b7077.jpg)  
Figure 6: Attention heatmap for two conditions.

# 5 Related Work

Few-shot NER. Recent arts have introduced comprehensive benchmarks under the unified N-way K-shot framework (Ding et al. 2021; Hou et al. 2020). Part of these works center on developing models by common knowledge learning (Huang et al. 2021; Tong et al. 2021; Ji et al. 2022), leveraging prototype networks (Snell, Swersky, and Zemel 2017; Wang et al. 2022a) or Model-Agnostic MetaLearning (Finn, Abbeel, and Levine 2017) to adapt to lowresource scenarios via internal support set adjustments. Alternatively, transfer learning involves pre-training feature extractors on a resource-rich source domain before adapting to the target domain (Yang and Katiyar 2020). An emerging trend is two-stage models (Ziyadi et al. 2020; Ma et al. 2022), which improve localization and classification by addressing span detection and entity typing sequentially.

Adversarial Robustness on Texts. Extensive research has been dedicated to devising textual adversarial attacks, including synonym substitution, word embedding perturbation, and phrase-level manipulations that preserve sentence coherence but cause erroneous predictions (Zeng et al. 2023; Liu et al. 2022). These endeavors highlight the susceptibility of models to adversarial attacks. To evaluate few-shot NER resilience, Xue et al. employed Bert-attack, mitigating adversarial disturbances through interference minimization. Zeng et al. enhanced robustness by creating input variants through random word masking, while Lin et al. utilized Wikidata entities for contextual substitutions leveraging a pre-trained language model. Despite this progress, research on cross-domain transfer learning’s adversarial robustness remains limited, especially on cross-domain transfer in the context of few-shot NER.

# 6 Conclusion

This work presents AAL for few-shot NER task, addressing challenges through two key strategies. First, it employs prompt-based augmentation learning to enhance data diversity and semantic understanding. Second, it introduces augmented prototype learning, leveraging general entity knowledge and domain-oriented adaptations, further refined by uncertainty-guided adversarial attacks for prototype calibration. Experimental results demonstrate AAL’s superiority across conditions, highlighting its potential for advancing augmentation learning, semantic dependency modeling, and broader few-shot NLP tasks in open-world settings.