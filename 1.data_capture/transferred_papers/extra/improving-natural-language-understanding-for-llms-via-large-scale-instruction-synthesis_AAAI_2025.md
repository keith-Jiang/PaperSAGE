# Improving Natural Language Understanding for LLMs via Large-Scale Instruction Synthesis

Lin Yuan\*, Jun $\mathbf { X } \mathbf { u } ^ { * }$ , Honghao Gui\*, Mengshu Sun, Zhiqiang Zhang, Lei Liang, Jun Zhou

Ant Group, Hangzhou, China {huiwai.yl, xujun.xj, zhongjin.ghh, mengshu.sms, lingyao.zzq, leywar.liang, jun.zhoujun}@antgroup.com

# Abstract

High-quality, large-scale instructions are crucial for aligning large language models (LLMs), however, there is a severe shortage of instruction in the field of natural language understanding (NLU). Previous works on constructing NLU instructions mainly focus on information extraction (IE), neglecting tasks such as machine reading comprehension, question answering, and text classification. Furthermore, the lack of diversity in the data has led to a decreased generalization ability of trained LLMs in other NLU tasks and a noticeable decline in the fundamental model’s general capabilities. To address this issue, we propose Hum, a large-scale, highquality synthetic instruction corpus for NLU tasks, designed to enhance the NLU capabilities of LLMs. Specifically, Hum includes IE (either close IE or open IE), machine reading comprehension, text classification, and instruction generalist tasks, thereby enriching task diversity. Additionally, we introduce a human-LLMs collaborative mechanism to synthesize instructions, which enriches instruction diversity by incorporating guidelines, preference rules, and format variants. We conduct extensive experiments on 5 NLU tasks and 28 general capability evaluation datasets for LLMs. Experimental results show that Hum enhances the NLU capabilities of six LLMs by an average of $3 . 1 \%$ , with no significant decline observed in other general capabilities.

# Introduction

NLU is a subset of natural language processing in artificial intelligence, encompassing key tasks such as machine reading comprehension, text classification, question answering, and information extraction. Recently, LLMs (Dubey et al. 2024; Yang et al. 2023) have shown impressive performance in general chat, but their language understanding ability still has shortcomings (Xu et al. 2024a; Li et al. 2023a; Cheng, Huang, and Wei 2023). Supervised instruction fine-tuning is an effective method for enhancing specific capabilities of LLMs (Sainz et al. 2023; Zeng et al. 2024). Technical reports from Llama3.1 (Dubey et al. 2024) and Qwen2 (Yang et al. 2024) emphasize that high-quality instruction data is essential for effectively aligning LLMs, and producing such data is crucial for improving model performance significantly.

![](images/f6b88c7b3c6baeb902e8bc96027744e3022dfa5ee7411af947242f9fb220e788.jpg)  
Figure 1: The existing information extraction instructions significantly reduce the performance of LLMs in NLU tasks.

Recently, there have been some works on high-quality instruction synthesis. Xu et al. (2024b) generates numerous queries through various templates, allowing current LLMs to produce responses. Cheng et al. (2024) has developed an instruction synthesis framework that converts raw pre-training text into instructional formats, substantially improving the performance of pre-trained models. Additionally, Zeng et al. (2024) has introduced an end-to-end framework that utilizes LLMs to create evolving synthesis instruction datasets. However, the instructions synthesized by these methods are domain-independent. Currently, there is a significant scarcity of instruction synthesis specifically for NLU tasks. Recently, LLMs have achieved impressive performance in unified information extraction tasks by synthesizing information extraction instructions (Xu et al. $2 0 2 4 \mathrm { a }$ ; Wang et al. 2023a; Gui et al. 2024). However, these synthesized instructions have several limitations. As illustrated in Figure 1, the language understanding performance of YAYI-UIE (Xiao et al. 2023), train on the Baichuan2-13B-Chat (Yang et al. 2023) and YAYI datasets, and Llama3-iepile (Gui et al. 2024), train on Llama-3-8B-Instruct (Dubey et al. 2024) and IEPILE, has noticeably decreased compared to their respective LLMs, with OneKE experiencing a $1 4 . 5 \%$ decline. An analysis reveals two main issues with the natural language understanding instructions developed in these cases: first, they primarily concentrate on information extraction tasks while overlooking machine reading comprehension, text classification, and question answering. Second, the instruction formats are too simplistic and fixed to make LLMs easily overfit these instructions. Consequently, this has significantly reduced the capabilities of LLMs trained by these instructions in the face of non-information extraction tasks or other NLU challenges.

To tackle these challenges and improve the language understanding capabilities of LLMs, we propose an effective instruction synthesis framework. First, to address the insufficient coverage of NLU tasks in prior works (Xiao et al. 2023; Gui et al. 2024; Wang et al. 2023a; Lu et al. 2022), we construct a dataset by incorporating various tasks, including information extraction, machine reading comprehension, text classification, and instruction generalist. This increased the range of task formats from 3 to 11, significantly enhancing capabilities for non-IE tasks. Second, to overcome the limitations of previous approaches that relied on a single type of instruction, we introduced innovative instruction synthesis methods, such as guidelines synthesis, preference rules synthesis, and format variants synthesis. By utilizing a diverse array of synthesis techniques, we alleviate the issue of LLMs overfitting to a single instruction, thereby helping to maintain their proficiency in non-NLU tasks even after training on the Hum dataset.

In summary, the main contribution of this work is as follows:

• We propose a framework with innovative methods for large-scale synthesis of instruction datasets. By employing guidelines synthesis, preference rules synthesis, and format variants synthesis, we address the issues of low generalization and limited instruction diversity found in NLU datasets constructed by previous works. • We synthesize a dataset to improve the language understanding ability of LLMs and thoroughly verified that it does not significantly impact the other general capabilities of the LLMs.

# Related Work

Generative Natural Language Understanding In the field of natural language understanding, mainstream tasks encompass information extraction (NER, RE, EE, OpenIE etc.), text classification (topic classification, sentiment analysis, text similarity, natural language inference, etc.), and machine reading comprehension. For information extraction, the UIE (Lu et al. 2022) framework pioneered a generation-based unified approach, effectively addressing the challenges associated with redundant models and data construction. Building on this, InstructUIE (Wang et al. 2023a) and YAYI-UIE (Xiao et al. 2023) developed a suite of information extraction instructions, implementing an instruction-based extraction framework through fine-tuning of large language models. To further enhance generalization beyond previous extraction instructions, OneKE (Gui et al. 2024) has introduced a more comprehensive and diverse set of information extraction instructions. In the realm of text classification, Wang, Pang, and Lin (2023) and Sun et al. (2023) have innovatively utilized different prompting methods to facilitate zeroshot text classification and natural language inference, respectively. For machine reading comprehension, Cheng, Huang, and Wei (2023) achieved significant performance improvements by converting extensive amounts of raw text into QA pairs before fine-tuning.

Instruction Synthesis Recent technical reports on the opensource large language models Llama 3.1 (Dubey et al. 2024) and Qwen2 (Yang et al. 2024) highlight that generating high-quality instructions is vital for training large models during both the pre-training and alignment stages. Wang et al. (2023b) proposes a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Li et al. (2024) exclusively utilizes a pre-curated taxonomy of human knowledge and capabilities as input and generates largescale synthetic instruction data across all disciplines. Additionally, Dong et al. (2024) transforms the validation of instruction-following data quality into code verification, requiring LLMs to generate instructions. There are also efforts to argument instructions for IE tasks. By annotation guidelines, GoLLIE (Sainz et al. 2023) improves zero-shot information extraction, while ADELIE (Qi et al. 2024) constructs a high-quality alignment corpus for IE instructions.

# Methodology

The architecture of our instruction synthesis framework is illustrated in Figure 2, which mainly consists of two parts. First, the basic instruction synthesis, which employs the structured instruction style with the field of “instruction”, “schema” and “input” from existing information extraction instructions (Lu et al. 2022; Gui et al. 2024; Xiao et al. 2023; Xu et al. 2024a) and extends to other NLU tasks, such as open information extraction, machine reading comprehension, and text classification. Second, the compound instruction synthesis, which diversifies the data from the basic instruction synthesis. The main strategies for this diversification include guidelines synthesis, preference rules synthesis, and format variants synthesis.

# Guidelines Synthesis

Most of the previous methods (Xu et al. 2024a; Lu et al. 2022; Wang et al. $2 0 2 3 \mathrm { a }$ ; Xiao et al. 2023) focus solely on zero-shot learning for information extraction. The instructions they design are very rigid, leading to a significant loss of in-context learning ability in large language models trained on these instructions. To address these issues, a guidelines synthesis strategy is developed. We transform the basic instructions with multiple perspectives to synthesize instructions with guidelines, which effectively prevent LLMs from overfitting and improve their language understanding capabilities. The main perspectives are as follows:

• Description: Add semantic explanations or typical values to a schema. For example, the schema “date” can refer to a certain date as “2024-08-15” or it can also refer to a particular month or day of the week, such as “Augest”, “Thursday”. • Example: Providing the representative positive and negative examples in domain-specific tasks to help LLMs better follow and understand user instructions, thereby alleviating the issue of loss in-context learning capacity.

Instruction Synthesis Framework Kill NER EE Basic Instruction Synthesis 1 NER Output Variants   
Sweans. <coRnovbicetretdF.ofKeansnseadsys|in@atPienogp|U>..S. TC OtMhRerCNLU Transform To Output: ISncsphturetu:mctai:on: [KAensnweedry]”: (“SLirohca”:n ]Si}rhan, Peop) \n   
Type: Fiancial|Social|Political|Educational Guidelines Synthesis 2 EMxtarakct twhnatStydlef ifnoerdRiEn schema and Label1: To cause the death of someone output in the form of markdown Table. Example: | subject |predicate | object | NLU positive: --- | --- |--- Instructions Shinzpou AFboe mwera  sphaont eanPdr mkiel eMd.i sTtheer Annotator |Sirhan Sirhan|kill| Robert F.Kennedy | suspect is Tetsuya Yamagami TC Output Variants output:{"Label1":[{"subject": "Tetsuya Political {"type": "Political"} 交 niengpatuitv:eT:he bullet did not hit Trump. DeVsacriiapnttison ValuJeSsOfoNr-smtTaythle: instructionTsetyxlte-:style SIanmdpilvei-dlueavlel {"Label1": [{"subject": "Sirhan Sirhan", Representative Preference rule Null value： "object": "Robert F. Kennedy"}]} Examples generation Return empty list text M Ili ScheLmabaelD-ilcetvieolnary • RDeotnu’rtnreNtuArnN …… (entJitSyO, tNype) { entity : , BoEuntditayries Punctuation pSecrhseomn a，_prluelaes: kWeheepni ’ssutbijtelecti/foebjxeisct is a •MRueltiuprlnelvisatlue： t…yp…e: } Microsoft Numerical Nesting {"Label1": [{"subject":"Sirhan Sirhan", Sep by commas Markdown "object": "U.S.Sen. Robert F.Kennedy"}]} …… Granularity Reverse Phi-3 Preference Rules Synthesis 3 Format Variants Synthesis

• Format: Construct various structures and formats. The structures can be hierarchical or flat. The formats include JSON, text, markdown, code, etc. By specifying the output formats of an instruction and transforming the same sample into multiple corresponding structures and formats, we further reduce the overfitting of LLMs on monotonous format of instructions.

Guideline Paraphrasing To improve the generalization ability of the instructions based on the guidelines, we make additional confusion, introduce variations, and modify the guidelines. The specific strategies are as follows:

• Label Name Variants $\because$ Utilizing synonyms to enhance the diversity of label name variants, for instance, the entity type “Position” may be substituted with terms such as “Title”, “Job”, and “Occupation”. • Label Name Masking: Replacing a portion of the label names within the schema with placeholders in a randomized manner encourages the model to concentrate on and comprehend the schema guidelines more effectively. • Description Variants: Request LLM to generate explanations for a specific schema in a particular semantics using various expressions. • Representative Examples: For each schema, we generate five positive examples, five negative examples and various representative candidates, together with other guidelines (such as descriptions and name variants)

to create a comprehensive scheme dictionary. Consequently, when synthesizing an instruction, the guidelines of a certain schema, including examples, can be randomly sampled from this dictionary.

# Preference Rules Synthesis

While the synthesis of guidelines can enhance the diversity of instructions, the underlying semantics of these instructions remain almost unchanged, leading to minimal variation in model outputs. To address this limitation and synthesize samples with distinct semantics, we developed a strategy named “preference rules synthesis” as depicted in Figure 3. This approach leverages existing guidelines to implement a modification strategy that utilizes GPT-4 for generating a novel labeling rule, subsequently producing entirely new outputs based on this rule. In contrast to the direct utilization of a rule library for invoking GPT-4 to create labeled samples, this methodology yields labeled samples with greater semantic diversity, effectively mitigating the risk of overfitting in LLMs and improving their capability to understand fine-grained task requirements. The proposed modification strategy is outlined as follows:

• Entity Boundaries: Handling of modifying prefixes and suffixes, such as President of the United States Biden or simply Biden. • Numerical: Including quantities, chronological order, logical sequence, etc. For example, extracting only the most recent position, the highest degree, or the first two companies.

<html><body><table><tr><td>Input: Instruction: You are an expert of NER. In order to improve the model's compliance with instructions,please give the de- scription of the given schema,and generate the annotation rule, follow by which the original output meets.Then read the mod- ification strategy and 2 example given as follows,determine whether it is possible to make slight adjustments to the ori- gin rule to generate a new rule, and return annotated result that complies with the new rule. Modification Strategy:#Numerical (detailed content omitted)</td></tr><tr><td>Examples:#example(contentomitted) Text: Mr. John Smith, independent director, bachelor's degree, bachelor from Harvard, Ph.D. from MIT, senior engineer with professorship.</td></tr><tr><td>Schema: degree Label: ["bachelor's degree”,“bachelor","Ph.D."]</td></tr><tr><td>Output: Schema Description: The name of educational qualifications and degrees.</td></tr><tr><td>Original Rule:Extract all educational qualifications and de- grees of the individual. New Rule: Extract the highest educational qualification of the individual. If multiple degrees exist, annotate only the highest degree.</td></tr></table></body></html>

• Granularity: Different datasets may have varying definitions for the same schema, such as organizational entities being limited to companies only.   
• Punctuation: Addressing punctuation, book titles, numerical units, and so on. For example, $5 0 0 ~ \ S$ vs. 500; “War and Peace” (with quotation marks) vs. War and Peace (without quotation marks) .   
• Nesting: Resolving issues of nested entities. For instance, whether Beijing within Beijing Sport University should be considered a geographical entity.   
• Reverse: The position of subject and object of a relation can be exchanged according to the semantics definition of relation label. Such as [James Cameron, direct (is the director of), Avatar] VS. [Avatar, direct (directed by), James Cameron].

# Format Variants Synthesis

The previous instruction structure (Li et al. 2023b; Gui et al. 2024; Xu et al. 2024a) is constrained to a single output format, such as JSON, code, or plain text. However, numerous NLU tasks do not adhere to a singular representational style. For example, tasks such as machine reading comprehension and text classification do not align well with the JSON format, as they often struggle to define appropriate “keys” within the JSON structure. This restriction to a sole JSON instruction format poses considerable limitations on the language understanding capabilities of LLMs. To address this challenge, as show in Figure 2, we extend the output formats for identical samples to include JSON, text, markdown, and other styles. Additionally, we integrate prompts for various output styles within the input instructions, thereby transforming a singular sample into multiple representations. To mitigate the risk of LLMs becoming overfitted to a specific style, we generate multiple outputs for each output style. For instance, in the NER task, we define different candidates for producing empty results, such as “”, “NAN”, and []. By varying the format specification in the input instructions and selecting a diverse array of candidate outputs, we significantly enhance the variety of sample formats, ultimately alleviating the overfitting challenges faced by LLMs.

# Instruction Statistics

Based on the framework mentioned above, a synthesized dataset of 2,812,832 instructions is generated. As illustrated in Figure 4, the entire dataset encompasses the following tasks: NER $( 2 3 \% )$ , RE $( 2 9 \% )$ , SPO $( 1 1 \% )$ , EE $( 5 \% )$ , EET $( 3 \% )$ , EEA $( 2 \% )$ , OpenIE $(4 \% )$ , KGE $( 1 2 \% )$ , MRC $( 2 \% )$ , and TC $( 1 \% )$ , with an additional $8 \%$ IG (Instruction Generalist is included to prevent LLMs from losing its chat capability). All synthesis instructions are divided into two categories: basic instructions and compound instructions. Basic instructions account for $5 5 \%$ of the total. Compound instructions make up $45 \%$ and include at least one type of instruction diversity synthesis strategy (guidelines synthesis, preference rules synthesis, format variants synthesis). The total number of compound instructions is 1,261,658, in which 1,152,470 contain guidelines, 34,770 apply preference rules synthesis, and 108,091 use format variants synthesis. Due to overlaps among these strategies, the total data volume is less than the sum of the data for each individual strategy. The definitions, examples of instructions, and data source distributions for each task, along with examples of basic and compound instructions for each task, are detailed in the Appendix.

![](images/f55f7fe331cbbb3d91539d2244c63c6db36697e44343fc2a7fcf4758ed1a6ef8.jpg)  
Figure 3: Prompt template for preference rule annotation.   
Figure 4: The source of the Hum dataset and the distribution of synthesis instructions.

# Experimental Settings

# Datasets

To evaluate the effectiveness of the Hum dataset for natural language understanding, we perform zero-shot experiments on five NLU datasets: CrossNER (Liu et al. 2021) for named entity recognition, FewRel (Han et al. 2018) for relation extraction, CCF Law for event extraction, C3 (Sun et al. 2020)

Table 1: Zero-shot testing for tasks related to natural language understanding. The same colored background indicates that the base model is identical. Bold text indicates that the same base model performs best. The evaluation metric used is the F1 score. B denotes basic instructions in information extraction style, and the instruction format is the same as that of OneKE and Llama3-iepile. C refers to compound instructions, which may include guidelines, rules, or multiple formats. In the CCF Law dataset, $\mathrm { \Delta x / y }$ represent the metrics for trigger and argument, respectively.   

<html><body><table><tr><td rowspan="2"></td><td colspan="2">CrossNER</td><td colspan="2">FewRel</td><td colspan="2">CCF Law</td><td colspan="2">C3</td><td colspan="2">IMDB</td><td colspan="2">Avg</td></tr><tr><td>B</td><td>C</td><td>B</td><td>C</td><td>B</td><td>C</td><td>B</td><td>C</td><td>B</td><td>C</td><td>B</td><td>C</td></tr><tr><td>GPT-4</td><td>54.75</td><td>42.41</td><td>19.43</td><td>30.21</td><td>51.12/51.22</td><td>52.74/57.95</td><td>94.60</td><td>95.60</td><td>93.40</td><td>93.00</td><td>62.67</td><td>57.27</td></tr><tr><td>Qwen2</td><td>48.11</td><td>12.03</td><td>3.82</td><td>24.81</td><td>4.63/5.64</td><td>30.93/35.51</td><td>80.80</td><td>88.80</td><td>89.80</td><td>89.00</td><td>45.53</td><td>49.57</td></tr><tr><td>Llama2</td><td>29.78</td><td>0.07</td><td>0.34</td><td>4.56</td><td>0.00/0.00</td><td>12.88/11.78</td><td>12.00</td><td>39.00</td><td>39.60</td><td>78.20</td><td>16.34</td><td>26.83</td></tr><tr><td>Baichuan2</td><td>40.40</td><td>11.10</td><td>2.26</td><td>6.72</td><td>0.00/0.85</td><td>27.64/30.32</td><td>39.00</td><td>74.20</td><td>83.60</td><td>82.40</td><td>33.14</td><td>40.68</td></tr><tr><td>Llama3</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00/0.00</td><td>10.70/13.25</td><td>67.20</td><td>76.80</td><td>90.20</td><td>90.00</td><td>31.48</td><td>35.76</td></tr><tr><td>OneKE</td><td>52.22</td><td>59.94</td><td>33.93</td><td>39.14</td><td>62.85/62.02</td><td>61.86/63.88</td><td>68.13</td><td>67.04</td><td>82.26</td><td>90.28</td><td>59.80</td><td>63.85</td></tr><tr><td>YAYI-UIE</td><td>50.39</td><td>20.75</td><td> 36.09</td><td>16.96</td><td>12.87/59.42</td><td>38.08/40.96</td><td>35.60</td><td>76.20</td><td>49.40</td><td>92.80</td><td>41.53</td><td>45.85</td></tr><tr><td>LLama3-iepile</td><td>51.48</td><td>52.30</td><td>23.76</td><td>21.71</td><td>56.82/57.91</td><td>56.73/54.54</td><td>51.80</td><td>0.80</td><td>86.60</td><td>0.00</td><td>54.20</td><td>26.09</td></tr><tr><td>HumQwen2</td><td>50.86</td><td>58.14</td><td>26.90</td><td>45.07</td><td>64.96/61.85</td><td>61.96/67.68</td><td>90.20</td><td>91.86</td><td>89.40</td><td>89.60</td><td>64.15</td><td>69.41</td></tr><tr><td> HumLlama2</td><td>50.68</td><td>55.86</td><td>32.92</td><td>45.62</td><td>66.57/52.29</td><td>64.62/58.05</td><td>73.40</td><td>84.20</td><td>89.00</td><td>87.97</td><td>61.10</td><td>67.00</td></tr><tr><td> HumBaichuan2</td><td>50.57</td><td>56.14</td><td>20.96</td><td>31.95</td><td>65.01/64.42</td><td>55.19/56.76</td><td>24.00</td><td>73.80</td><td>91.40</td><td>90.89</td><td>50.33</td><td>61.75</td></tr><tr><td> HumLlama3</td><td>49.42</td><td>56.41</td><td>31.62</td><td>43.39</td><td>62.08/61.48</td><td>51.63/50.85</td><td>82.20</td><td>80.80</td><td>92.00</td><td>91.00</td><td>63.40</td><td>64.57</td></tr></table></body></html>

for machine reading comprehension, and IMDB (Maas et al. 2011) for text classification. The examples of the basic and compound instructions of these five tasks are detailed in the Appendix. Additionally, to determine if the Hum dataset adversely affects LLMs, we conduct zero-shot testing across seven dimensions (language understanding, tool utilization, general knowledge, professional knowledge, coding, math, and reasoning) using a total of 28 datasets. We employ the same experimental settings as in previous work.

# Comparison Methods

We categorize the comparison methods into two groups. The first group includes train-free models, such as GPT-4 (API), Qwen2 (Qwen2-7B-Instruct), Llama2 (Chinese-Alpaca-2- 13B), Baichuan2 (Baichuan2-13B-Chat), Llama3 (MetaLlama-3-8B-Instruct), Mistral (Mistral-7B-Instruct-v0.2), and Phi3 (Phi-3-medium- $\boldsymbol { \cdot } 4 \boldsymbol { \mathrm { k } }$ -instruct). The second group comprises supervised fine-tuned models like YAYI-UIE (based on Baichuan2), Llama3-iepile (based on Llama3), and OneKE (based on Llama2). YAYI-UIE builds upon InstructUIE (Wang et al. 2023a) to develop a cohesive and comprehensive framework for IE instructions. This framework is subsequently refined through supervised fine-tuning with the large language model Baichuan2-13B-Chat (Yang et al. 2023), resulting in a unified model capable of chat interactions. Meanwhile, Llama3-iepile aims to enhance the generalization capabilities of YAYI-UIE by integrating a broader variety of instructions. It has achieved better generalization on multiple datasets with Meta-Llama-3- 8B-Instruct (Dubey et al. 2024). Additionally, OneKE utilizes the constructed IEPILE dataset and conducts extensive supervised fine-tuning with Chinese-Alpaca-2-13B (Cui, Yang, and Yao 2023), leading to a LLM that demonstrates improved generalization in IE tasks. All experimental results for these models are obtained through a re-evaluation based on the officially released models and using the same instructions.

# Implementation Details

To mitigate the impact of different models utilizing various LLMs, we perform supervised fine-tuning with Hum across multiple LLMs. We consistently apply LoRA for this finetuning, with a LoRA rank and alpha both set at 64 and a dropout rate of 0.05. The batch size is established at 320, accompanied by a learning rate of 5e-5. The input length is configured to 1500 tokens, while the output length is capped at 500 tokens. We utilize an Adam optimizer with weight decay at a rate of 1e-4 for training. The learning rate warm-up proportion is set to 0.1, alongside a dropout rate of 0.1. Additionally, the temperature for adjusting next token probabilities is fixed at 0.2, with the topmost probable tokens summing to a probability of 0.95. The training is conducted using the LlamaFactory (Zheng et al. 2024) framework, leveraging $3 2 \times \mathrm { H } 1 0 0$ GPUs, 384 CPU cores, and 3.2TB of memory.

# Experimental Results

# Overall Results

We fine-tune the Hum dataset on LLMs and conducted zeroshot evaluations across five NLU tasks. As highlighted in Table 1, our model achieves superior average performance compared to other models. In the instruction tests within the basic style, it improves by $1 . 3 \%$ , $8 . 8 \%$ , and $9 . 2 \%$ over OneKE, YAYI-UIE, and Llama3-iepile, respectively. For the compound instructions, the improvements are even more significant at 3.2Moreover, the supervised fine-tuning performs with Qwen2 significantly enhance the performance of the Hum dataset on these NLU tasks, showing notable gains in both basic and compound instruction scenarios. Interestingly, while OneKE showcases a commendable generalization in IE tasks such as CrossNER, FewRel, and CCF Law, its effectiveness drops sharply in non-IE NLU tasks. This dip in performance appears to stem from OneKE’s tendency to overfit the specific instructions for IE tasks, resulting in substantially lower outcomes in various other evaluations compared to Llama3-iepile and YAYI-UIE. In contrast, models fine-tune on the Hum dataset demonstrate marked advantages over train-free LLMs across NLU tasks, regardless of whether the instructions are IE-style or compound. Among these tasks, LLMs trained on the Hum dataset (Qwen2, Llama2, Llama3) consistently surpass the performance of GPT-4.

Table 2: Analysis of instruction forms in in-context learning.   

<html><body><table><tr><td>Instruction</td><td>CrossNER</td><td>FewRel</td></tr><tr><td>basic style</td><td>50.86</td><td>26.90</td></tr><tr><td>+ example</td><td>58.09</td><td>40.53</td></tr><tr><td>+description</td><td>53.04</td><td>41.75</td></tr><tr><td>+ example & description (Hum)</td><td>58.14</td><td>45.07</td></tr></table></body></html>

LLMs have excellent in-context learning capabilities. By providing specific examples and descriptions, we can effectively engage the model’s cognitive abilities, leading to enhanced overall performance. As indicated in Tables 1 and 2, when instructions are presented in the basic style (B) during inference, the model achieves moderate results on CrossNER, FewRel, and various other NLU datasets. However, incorporating examples or descriptions of the content to be extracted leads to significant performance gains on OneKE, YAYI-UIE, and Hum. Furthermore, the combination of both examples and descriptions (C) enables the model to deliver even stronger results.

# Model Ablation Studies

We construct four datasets: one excluding guidelines synthesis instructions, one omitting preference rule synthesis instructions, one lacking format variants synthesis instructions, and one that retained all instructions. Note that, in order to maintain the same amount of instructions as Hum, for the first three datasets, we don’t simply delete the corresponding compound instructions, but instead convert them to the basic instructions. We then conduct supervised finetuning on these datasets using Qwen2. The results of our experiments are presented in Table 3. Notably, the removal of preference rules has the most substantial effect on the model, leading to a marked decrease in performance across all four NLU tasks. Additionally, the absence of format variants synthesis instruction cause a significant decline in the model’s performance in both CrossNER and FewRel. This indicates that integrating format variants synthesis instruction can help the LLM avoid overfitting to information extraction instructions. Simultaneously, it is evident that these strategies exhibit minimal fluctuations in the CrossNER and C3 datasets. This can primarily be attributed to the relatively straightforward nature of these two tasks, which diminishes the observable impact of our instruction synthesis strategy.

Table 3: Ablation experiments on various instruction data.   

<html><body><table><tr><td>Model</td><td>CrossNER</td><td>FewRel</td><td>CCFLaw</td><td>C3</td></tr><tr><td>HumQwen2</td><td>58.14</td><td>45.07</td><td>61.69/67.68</td><td>91.86</td></tr><tr><td>- Guidelines</td><td>60.50</td><td>41.20</td><td>59.76/64.65</td><td>89.65</td></tr><tr><td>- Rules</td><td>57.90</td><td>44.36</td><td>58.50/56.53</td><td>90.40</td></tr><tr><td>- Format</td><td>56.83</td><td>37.11</td><td>64.47/61.12</td><td>91.60</td></tr></table></body></html>

<html><body><table><tr><td></td><td>C3</td><td>WSC</td><td></td><td>XSum Lambda Lcsts</td><td></td><td>Race</td></tr><tr><td>GPT-4</td><td>95.10</td><td>74.00</td><td>20.10</td><td>65.50</td><td>12.30</td><td>92.35</td></tr><tr><td>Qwen2</td><td>92.27</td><td>66.35</td><td>18.68</td><td>62.39</td><td>13.07</td><td>88.37</td></tr><tr><td>Llama2</td><td>81.70</td><td>50.96</td><td>23.29</td><td>63.26</td><td>15.99</td><td>55.64</td></tr><tr><td>Baichuan2</td><td>84.44</td><td>66.35</td><td>20.81</td><td>62.43</td><td>16.54</td><td>76.85</td></tr><tr><td>Llama3</td><td>86.63</td><td>65.38</td><td>25.84</td><td>36.72</td><td>0.09</td><td>83.76</td></tr><tr><td>Mistral</td><td>67.29</td><td>30.77</td><td>21.16</td><td>59.98</td><td>0.78</td><td>73.46</td></tr><tr><td>Phi3</td><td>68.60</td><td>42.31</td><td>0.60</td><td>71.74</td><td>3.47</td><td>73.18</td></tr><tr><td>OneKE</td><td>39.29</td><td>46.15</td><td>19.99</td><td>25.69</td><td>17.91</td><td>54.59</td></tr><tr><td>YAYI-UIE</td><td>80.55</td><td>63.46</td><td>19.95</td><td>14.12</td><td>20.20</td><td>67.78</td></tr><tr><td>Llama3-iepile</td><td>80.55</td><td>45.19</td><td>24.10</td><td>34.56</td><td>13.97</td><td>76.14</td></tr><tr><td>HumQwen2</td><td>92.88</td><td>70.19</td><td>31.33</td><td>66.16</td><td>18.53</td><td>88.17</td></tr><tr><td>HumLlama2</td><td>82.36</td><td>63.46</td><td>24.51</td><td>65.22</td><td>17.51</td><td>68.48</td></tr><tr><td>HumBaichuan2</td><td>84.11</td><td>66.35</td><td>21.51</td><td>62.64</td><td>17.27</td><td>77.18</td></tr><tr><td>HumLlama3</td><td>83.40</td><td>62.50</td><td>26.72</td><td>54.07</td><td>18.45</td><td>81.16</td></tr><tr><td>HumMistral</td><td>47.29</td><td>39.42</td><td>21.54</td><td>69.09</td><td>17.14</td><td>72.42</td></tr><tr><td>Humphi3</td><td>85.21</td><td>25.94</td><td>0.36</td><td>71.24</td><td>15.49</td><td>74.00</td></tr></table></body></html>

Table 4: Enhancement of natural language understanding capabilities in different LLMs by Hum. The experimental results are based on the open-compass framework and tested using the “gen” mode. The evaluation metrics for C3, WSC, Lambda, and Race are ACC. XSum and Lcsts are measured using ROUGE-1. Race includes Race-middle and Race-high, and their average is taken.

# Hum For Natural Language Understanding

We fine-tune six different LLMs using Hum data and evaluate them across seven dimensions.

As illustrated in Table 5, models trained on the Hum dataset, such as Llama2, Llama3, Mistral, and Phi3, show an improvement in average performance across multiple dimensions. However, there is a noticeable decline in average performance for Qwen2 and Baichuan2. When comparing against models like YAYI-UIE (based on Baichuan2), Llama3-iepile (based on Llama3), and OneKE (based on Llama2), our synthesized data substantially outperformed these in multiple dimensions. Notably, tasks related to language understanding show significant improvements across all LLMs, with an average increase of $3 . 1 \%$ . The models, as shown in Table 4, improve significantly on tasks such as Lcsts, Lambada, Xsum, and WSC, which are similar to information extraction tasks as they require extracting answers from the original text. In contrast, C3 and Race are multiplechoice question-answering tasks, and the Hum dataset lacks this type of data, leading to less noticeable results. For other dimensions, results are mixed with some showing improvements and others showing declines. It is noteworthy that in evaluations across multiple dimensions, there is no comprehensive decline observed in any single dimension. This disparity is largely attributed to our synthesized data focusing solely on language understanding, coupled with secondary SFT on instruct/chat versions of the models, which affect the general capabilities of the base models. Future work will involve synthesizing a broader variety of data to address these limitations.

Table 5: Performance evaluation of Hum in multiple dimensions across different LLMs. For each dimension, the average value of different datasets is taken as the reported value. The detailed dataset for each dimension can be found in the appendix.   

<html><body><table><tr><td></td><td>Unangtanding</td><td>Tools</td><td>KGewerage</td><td>Prnowsiogal</td><td>Coding</td><td>Math</td><td>Reasoning</td><td>Avg</td></tr><tr><td>GPT-4</td><td>59.89</td><td>86.44</td><td>78.59</td><td>74.23</td><td>68.10</td><td>68.60</td><td>76.65</td><td>73.21</td></tr><tr><td>Qwen2</td><td>56.86</td><td>76.03</td><td>71.52</td><td>77.73</td><td>62.46</td><td>65.03</td><td>67.58</td><td>68.17</td></tr><tr><td>Llama2</td><td>48.47</td><td>45.68</td><td>51.72</td><td>46.98</td><td>23.37</td><td>17.85</td><td>49.65</td><td>40.53</td></tr><tr><td>Baichuan2</td><td>54.57</td><td>48.25</td><td>60.82</td><td>55.90</td><td>25.89</td><td>16.62</td><td>45.31</td><td>43.91</td></tr><tr><td> Llama3</td><td>49.74</td><td>56.17</td><td>62.85</td><td> 55.97</td><td>55.17</td><td>52.37</td><td>59.13</td><td> 55.91</td></tr><tr><td>Mistral</td><td>42.24</td><td>42.47</td><td>58.29</td><td>48.01</td><td>25.47</td><td>28.22</td><td>47.83</td><td>41.79</td></tr><tr><td>Phi3</td><td>43.32</td><td>41.05</td><td>55.50</td><td>52.09</td><td>45.23</td><td>63.10</td><td>44.21</td><td>49.21</td></tr><tr><td>OneKE</td><td>33.96</td><td>30.24</td><td>31.85</td><td>31.67</td><td>10.16</td><td>1.47</td><td>32.74</td><td>24.58</td></tr><tr><td>YAYI-UIE</td><td>44.34</td><td>33.89</td><td>55.56</td><td>50.58</td><td>23.70</td><td>10.02</td><td>50.10</td><td>38.31</td></tr><tr><td>Llama3-iepile</td><td>45.75</td><td>50.13</td><td>56.38</td><td>48.79</td><td>44.96</td><td>46.02</td><td>54.36</td><td>49.48</td></tr><tr><td>HumQwen2</td><td>61.21</td><td>71.51</td><td>71.12</td><td>77.46</td><td>60.48</td><td>59.90</td><td>67.33</td><td>67.00</td></tr><tr><td> HumLlama2</td><td>53.59</td><td>45.58</td><td> 51.90</td><td>46.68</td><td>21.56</td><td>17.96</td><td>49.13</td><td>40.91</td></tr><tr><td>HumBaichuan2</td><td>54.84</td><td>49.88</td><td>60.77</td><td>55.55</td><td>23.57</td><td>16.66</td><td>43.73</td><td>43.57</td></tr><tr><td>HumLlama3</td><td> 54.38</td><td> 59.71</td><td>64.92</td><td> 56.93</td><td> 51.55</td><td> 50.51</td><td>58.38</td><td> 56.63</td></tr><tr><td>HumMistral</td><td>44.48</td><td>55.49</td><td>60.12</td><td>47.53</td><td>33.76</td><td>30.09</td><td>52.28</td><td>46.25</td></tr><tr><td>Humphi3</td><td>45.37</td><td>38.60</td><td>57.59</td><td>55.96</td><td>42.42</td><td>61.98</td><td>51.14</td><td>50.44</td></tr></table></body></html>

# Case Study

A typical compound instruction for relation extraction is shown in Figure 5. The LLMs are asked to extract instances

Instruction: You are an expert in relationship extraction.   
Please extract relationship triples that match the schema defini  
tion from the input. Return an empty list for relationships that   
do not exist. Please respond in the format of a JSON string.You   
can refer to the example for extraction.   
Schema: [ “relation”: “located in or next to body of wa  
ter”,“description”: “Relation between location and body of wa  
ter denotes geographical connectivity. Example: Port of Hull   
located next to River Hull .”}],   
Examples: #content omitted   
Input: The Raz de Sein is bounded by the La Vieille and Petite   
Vieille lighthouses and by the shoreline of the le de Sein.   
Output: GPT-4: $\{$ “located in or next to body of water”: [ “subject”:   
“Raz de Sein”, “object”: “shoreline of le de Sein”}]} Llama2: The answer is too long and the content is omitted. OneKE: “located in or next to body of water”: [] HumLlama2: “located in or next to body of water”: [“sub  
ject”: “La Vieille”, “object”: “Raz de Sein”]}

of the relation “located in or next to body of water”, the description is given in schema to indicate the semantic range of the relation: the subject is a location and the object is the body of water. Two examples are provided (due to space limitations, the content of the examples is omitted) to describe the instances that should be extracted in practice. The output format can also be determined based on the output style of examples. The results of the same input instruction from GPT-4, Llama2, OneKE and $\mathrm { H u m } _ { \mathrm { L l a m a 2 } }$ are listed. The Raz de Sein is a stretch of water, the La Vieille, Petite lighthouses lighthouses and le le de Sein are locations. Thus in the GPT-4 result, it has made a directional error of the subject and object. For OneKE, it may unable to understand the description and examples, thus it fails to extract and relation individuals from the text. The output of Llama2 is omitted since it is too long with the chain of thought, which also makes the result hard to be parsed. Thus we thought Llama2 is failed to understand the output format from the given examples. Finally for the result of $\mathrm { H u m } _ { \mathrm { L l a m a 2 } }$ , it extracts one valid relation instance and out put it in the required format.

# Conclusion

In this paper, we propose a novel instruction synthesis framework to create high-quality instructions aimed at enhancing the language understanding capabilities of LLMs. We find that our synthesized Hum data significantly outperforms previous methods in NLU tasks, and notably improves the language understanding abilities of LLMs while incurring minimal knowledge loss in other dimensions. Through ablation experiments, we discover that our proposed methods (guidelines synthesis, preference rules synthesis, and format variants synthesis) significantly enhance the model’s generalization ability. Our instruction synthesis method is simple to implement and can be easily adapted for instruction synthesis across various tasks.