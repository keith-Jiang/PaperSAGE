# ScholarGEC: Enhancing Controllability of Large Language Model for Chinese Academic Grammatical Error Correction

Zixiao Kong1,2, Xianquan Wang1,2, Shuanghong Shen2\*, Keyu Zhu1,2, Huibo ${ \bf X } { \bf u } ^ { 1 }$ , Yu $\mathbf { S u } ^ { 2 , 3 }$

1Institute of Advanced Technology & State Key Laboratory of Cognitive Intelligence, University of Science and Technology of China 2Institute of Artificial Intelligence, Hefei Comprehensive National Science Center 3School of Computer Science and Artificial Intelligence, Hefei Normal University {kzix, wxqcn, kyzhu3, xhbxhb} $@$ mail.ustc.edu.cn, shshen $@$ iai.ustc.edu.cn, yusu@hfnu.edu.cn

# Abstract

Large language models (LLMs) have demonstrated exceptional error detection capabilities and can correct sentences with high fluency in grammatical error correction (GEC) tasks. However, when correcting Chinese academic papers, LLMs face significant challenges of over-correction. To delve deeper into this issue, we explore the underlying reasons. On one hand, each discipline has its unique vocabulary and expressions, and LLMs have insufficient and incomplete understanding of domain-specific sentences. On the other hand, the controllability of generative LLMs in GEC tasks is inherently poor, and the traditional sequence-to-sequence (Seq2Seq) correction structure exacerbates this issue. Considering the two aforementioned factors, we propose a new error correction framework for Chinese academic GEC tasks using LLMs, named ScholarGEC. To improve LLMs’ understanding of domain-specific knowledge, we construct appropriate disciplinary knowledge prefixes for sentences and use this domain-specific knowledge data to fine-tune the LLM. To enhance the controllability of LLMs, we replace the traditional Seq2Seq structure with a Detection-Correction separated structure. We also introduce a special token during the process to improve the model’s error detection stability. Additionally, we incorporate iterative self-reflection to enhance the stability of the generation, in the three parts of LLM generation. Extensive experiments demonstrate the effectiveness and robustness of our framework on a Chinese GEC dataset composed of academic papers, and further analysis reveals the capabilities of our framework in enhancing LLM performance in general GEC tasks.

Code — https://github.com/kzi2000/ScholarGEC

# Introduction

According to reports, nearly one million master’s and doctoral students graduate annually in China, requiring academic achievements and theses to obtain their degrees. Chinese universities generally mandate that these theses be written in Chinese. Given the sheer volume of theses, relying solely on manual error correction is highly inefficient and

请纠错下述句子： Original Sentence Please correct the following sentence： 由于对气候变化敏感，湖水在沉淀过程中会产生一些列矿物组成。 Sensitive to climate change, the lake produces a some of mineral constituents during sedimentation. ChatGPT 4o mini 由于对气候变化敏感，湖水在沉淀过程中会形成一系列矿物。 Sensitive to climate change, the lake forms a series of minerals   
LLM Qwen 2.5 during sedimentation. 由于气候变化的影响，湖水在沉淀过程中会形成一系列的矿物组合。 Due to the impact of climate change, the lake forms a series of mineral ERNIE Bot 4 0 combinations during sedimentation.   
由于对气候变化敏感，湖水在沉淀过程中会形成一系列矿物组成的沉积物。 Sensitive to climate change, the lake forms a series of sediments composed of Appreciate Correction minerals during sedimentation. 由于对气候变化敏感，湖水在沉淀过程中会产生一系列矿物组成。 Sensitive to climate change, the lake produces a series of mineral constituents during sedimentation.

often results in missed errors, false positives, and subpar correction quality. Applying Chinese automatic error correction technology to the academic thesis review process can enhance correction efficiency and quality, alleviate the workload of teachers and reviewers, and ensure the rigor and reliability of academic achievements.

Chinese Grammatical Error Correction (CGEC) (Zhao et al. 2018) aims to identify and correct potential grammatical errors in a given Chinese sentence while adhering to the principle of minimal edits (Wang et al. 2021). Recently, decoder-only LLMs, with their powerful semantic understanding and logical reasoning capabilities (Zhao et al. 2024; Li et al. 2024), have demonstrated breakthrough performance in various Natural Language Processing (NLP) tasks, showing great potential in CGEC (Fang et al. 2023; Qu and Wu 2023). However, generative LLMs suffer from severe over-correction problems, leading to the unnecessary modification of error-free characters in the source sentence (Wu et al. 2023). As illustrated in Figure 1, the “mineral constituent” is a geological term, but LLMs mistakenly modify it and its collocations. LLMs tend to replace texts with common expression, resulting in unnecessary or incorrect corrections (Park et al. 2020).

Further exploring the phenomenon of over-correction in the CGEC task of academic papers, there are two main reasons for its occurrence: On one hand, there is an insufficient understanding of the semantic information in the text to be corrected, especially evident in sentences that involve strong domain-specific knowledge. Academic papers concentrate on specific issues within particular disciplines or interdisciplinary areas, each with its unique vocabulary and modes of expression. These aspects are essential for professional communication but add complexity to the task of error correction using LLMs. On the other hand, there is the inherent poor controllability of generative LLMs in text correction tasks. Generative LLMs typically adopt the traditional Seq2Seq approach used in GEC tasks. This approach requires the model to generate a mixture of unchanged and corrected parts of the source sentence, which exacerbates the shortcomings associated with poor controllability.

In order to enhance LLMs’ adaptability for Chinese academic GEC task, we proposed a framework named ScholarGEC. Integrating additional auxiliary information into tasks is an effective way to improve model’s capabilities (Zhang et al. 2022a; Liu et al. 2019; Wang et al. 2023). To enable LLMs to integrate disciplinary knowledge into GEC tasks, we trained a prefix generator to add relevant disciplinary knowledge to source sentences before correction. To increase LLMs’ controllability, we introduced a special token. Model avoids unnecessary repetitions by outputting this special token, when a sentence is entirely correct. We also incorporated iterative self-reflection (Piche´ et al. 2024; Ji et al. 2023) into three parts which utilize generative LLMs, to improve generation quality. We created a dataset called AcaCGEC, using master’s and doctoral theses to train the LLM. Experiments on the CGEC benchmark show improved correction abilities and better controllability, reducing over-correction by the LLM. In summary, our main contributions are as follows:

• We proposed a novel approach that integrates disciplinary knowledge into the text correction tasks of LLMs, demonstrating significant effectiveness in the correction of professional academic texts.   
• We designed a framework that enhances the error detection capabilities of LLMs, improving the controllability of the detection-correction structure in text correction tasks, and effectively reducing the phenomenon of overcorrection.   
• We incorporated iterative self-reflection into the text correction tasks of LLMs and demonstrated its effectiveness in improving the accuracy and controllability of LLM text corrections.

# Related Work

Traditional Seq2Seq GEC Methods: Traditional CGEC methods often follow the approaches used in English GEC, which are broadly divided into Seq2Edit and Seq2Seq methods (Bryant et al. 2023). Among them, traditional sequenceto-sequence (Seq2Seq) methods (Zhao et al. 2019; Kaneko et al. 2020; Zhang et al. 2022b) can be considered the predecessors of current LLMs for GEC tasks. These methods use encoder-decoder models inspired by neural machine translation to model GEC tasks, where the encoder encodes the source sentence, and the decoder generates target tokens sequentially. Kaneko et al. (2020) further applied pre-trained knowledge to the encoder-decoder model, and Zhang et al. (2022b) explored incorporating grammatical information.

LLMs for GEC: With the success of LLMs in various NLP tasks, researchers have explored their potential in CGEC. Recent studies (Fang et al. 2023; Li et al. 2023; Qu and Wu 2023) evaluated various LLMs (including closed-source and open-source models) on CGEC tasks. Fang et al. (2023) assessed ChatGPT’s performance on CGEC through incontext learning, highlighting its ability to generate fluent sentences and its sensitivity to over-correction. Fan et al. (2023) explore open-source LLMs for CGEC via instruction tuning (Ouyang et al. 2022). Zhang et al. (2023) showed that fine-tuned LLMs still struggle to match the performance of existing state-of-the-art lightweight GEC models. These works indicate that the limited success of LLMs in GEC tasks is mainly due to the continuation of traditional Seq2Seq patterns. Howerve, these studies often overlook the issue of over-correction.

Controllability of LLMs for GEC: Seq2Seq models tend to generate sentences with higher probabilities, replacing less common words with more frequent ones, leading to over-correction. Recent studies (Li et al. 2023; Li and Wang 2024; Yang and Quan 2024) have explored methods to alleviate this problem. Li et al. (2023) proposed a two-stage approach, integrating the detection results of Seq2Edit models into Seq2Seq correction models. Due to architectural differences, Li and Wang (2024) integrated detection and correction into a single model and designed a multi-task training method for this structure. Yang and Quan (2024) employed an alignment-enhanced correction approach to alleviate the over-correction problem in LLMs. While these methods mitigate over-correction to some extent, they have several drawbacks: 1) They are often significantly limited in performing GEC tasks on domain-specific corpora. 2) They primarily remediate over-correction problems after they occur, meaning these methods do not fundamentally address the poor controllability of LLMs. Our method differs from existing solutions by effectively integrating domain-specific knowledge into LLM GEC tasks while focusing on fundamentally controlling the occurrence of over-correction.

# Method

We propose a framework named ScholarGEC, to enhance the capabilities of LLMs in Chinese academic texts GEC task, with the overall workflow of our approach illustrated in Figure 2. Firstly, we design a discipline knowledge in

Discipline Augmentation Text Correction Original Sentence Knowledge-Enriched Sentence Correct Sentence LLM LLM 𝑩𝑩 𝑬𝑬 𝑩𝑩 𝑬𝑬 𝑩𝑩 𝑬 Error Detection Error Correction Word Embedding CAougnmt ernftacttiuoanl Self-Reflection Template ： Self-Reflection Words Disciplinary Prefixes 𝑩𝑩 𝑪𝑪 𝐄𝐄𝐄𝐄𝐄𝐄𝐄𝐄𝐄𝐄 𝑬𝑬 ： + No Error Situation Match Self-Reflection → S Original Sentence Disciplinary Facts LLM Special Token Direct Output

tegration method that enables LLM to perform adaptive error detection and correction using a structured domainspecific knowledge base. Secondly, we divide the GEC process into two stages: Error Detection and Error Correction. In the Detection stage, we introduce special tokens to enhance the LLM’s ability to identify sentences without errors, thereby skipping the redundant and unpredictable generative correction process. Finally, we introduce an iterative Self-Reflection mechanism that involves generating, providing feedback, and refining in a cyclic manner. Through these methods, we aim to improve the performance of LLMs in handling specialized academic texts.

Discipline Knowledge Integration We designe a text Discipline Augmentation method to enable LLM to perform domain-adaptive GEC for Chinese academic papers. The workflow is shown in the Knowledge Integration section of Figure 2. We have integrated a structured domain knowledge base, which contains multiple academic disciplinary facts. Before executing the GEC task, we map both the source sentence and the disciplinary facts from the knowledge base into the same semantic space, followed by calculating the cosine similarity, to match the source sentence with the most semantically similar disciplinary fact. This retrieved fact serves as supplementary material for correcting the source sentence.

We use the LLM to perform word embeddings, mapping both the source sentence and the knowledge base facts into the same vector space. We can define the LLM mapping function $f$ as follows:

$$
f : \mathrm { T e x t } \to \mathbb { R } ^ { d } ,
$$

where $\mathbb { R }$ is the vector space, $d$ is the dimension of the vector space. For the processing of the source sentence $x _ { s }$ and the domain knowledge $y _ { s }$ from the knowledge base, we can represent them as follows:

$$
X _ { s } = f _ { \mathrm { L L M } } ( x _ { s } ) [ \mathrm { C L S } ] ,
$$

$$
Y _ { s } = f _ { \mathrm { L L M } } ( y _ { s } ) \left[ \mathrm { C L S } \right] ,
$$

where $X _ { s }$ and $Y _ { s }$ are the representations of the source sentence and the domain knowledge in the vector space, respectively. We calculate the cosine similarity between the source sentence and each domain knowledge fact in the knowledge base as Equation below:

$$
{ \mathrm { c o s i n e ~ s i m i l a r i t y } } = { \frac { X _ { s } \cdot Y _ { s } } { \| X _ { s } \| \cdot \| Y _ { s } \| } } .
$$

However, even with a sufficiently large knowledge base, it is challenging to find enough supporting facts to analyze every sentence in an academic paper (Ni et al. 2024). Therefore, to transform the initially retrieved domain knowledge sentences into more useful domain prefixes, we trained a generator, which is an LLM connected to an external network knowledge base. It takes both the collected domain facts and the source sentence as input to generate appropriate domain prefixes $[ p _ { s } ]$ through a Knowledge-Aware Reasoning approach (Wu et al. 2024). These domain prefixes, together with the source sentence, form the complete input content for the error detection model.

Domain prefix $[ p _ { s } ]$ will be concatenated with $x _ { s }$ to form the complete input for the correction model. The actual input tokens are in the form of:

$$
\boldsymbol { x } _ { s } ^ { \prime } = [ p _ { s } ^ { 1 } p _ { s } ^ { 2 } . . . p _ { s } ^ { m } ] x _ { s } ^ { 1 } x _ { s } ^ { 2 } . . . x _ { s } ^ { n } ,
$$

where $p _ { s } ^ { i }$ are the tokens of the domain prefix $\left[ p _ { s } \right]$ . where $x _ { s } ^ { i }$ are the tokens of the source sentence $x _ { s }$ .

Counterfactual generation aims to eliminate spurious correlations in data. Recent studies have attempted to use counterfactual generation to enhance the robustness of models (Temraz and Keane 2022). During the construction of domain prefixes, we utilized counterfactual augmentation, as shown in Figure 2. We introduced intentional errors into some domain prefixes generated by the LLM. Specifically, within the prefix generator’s iterative self-reflection process (which will be detailed later), terminating the loop with a certain probability $\rho$ and introducing text errors at that point. This approach significantly increased the training data’s volume and indirectly trained the LLM to learn from domainspecific data.

Enhance LLMs’ controllability The GEC process can be divided into two stages: detection and correction (Qu and Wu 2023; Coyne et al. 2023). In the detection stage, LLM identifies discrepancies in the sentence and outputs the detected information. Based on this information, a template will be constructed, where the erroneous parts are masked for correction. In the correction stage, given a sentence with MASK, the LLM uses autoregressive blank filling (Du et al. 2021) to generate the appropriate segments for each MASK position. In Figure 3, a comparison is made between traditional GEC methods and the Detection-Correction structure.

Given the tokens of the source sentence as follows:

$$
x _ { s } = x _ { s } ^ { 1 } x _ { s } ^ { 2 } . . . x _ { s } ^ { n } ,
$$

the goal of error detection is to predict the detection labels derived from the alignment between the source text and the target text:

$$
d = d _ { 1 } d _ { 2 } . . . d _ { n } , d _ { i } \in { \cal L } = \{ R , E \} ,
$$

where $d _ { i }$ is the detection label for each token, $R$ is the label indicating that the token is correct and requires no modification, and $E$ is the label indicating that the token should be modified.

The training objective for error detection is given by Equation below:

$$
\begin{array} { r } { \mathcal { L } _ { D } = - \alpha _ { D } ( 1 - p _ { \theta } ( d | x _ { s } ) ) ^ { \gamma } \log ( p _ { \theta } ( d | x _ { s } ) ) , } \end{array}
$$

where $\theta$ represents the model parameters, and $\gamma$ is a hyperparameter set to 2. $\alpha _ { D }$ denotes the weight factor corresponding to the detection labels.

For sentences that do not require modification, we attempt to introduce a special token $S$ to indicate. We hope that LLM can output this special token, during the error detection stage when encountering correct text, thus skipping the error correction process. This is illustrated in Figure 2, where the “No Error Situation” corresponds to the sentences detected as error-free. These sentences will directly output a special token, indicating the model should output the original sentence without any modification. We introduce a new label set $L ^ { \prime } = \{ R , E , S \}$ , where $S$ indicates the sentence is errorfree. We define the updated loss function as Equation below:

$$
\begin{array} { c } { \displaystyle \mathcal { L } _ { D } ^ { \prime } = - \alpha _ { S } ( 1 - p _ { \theta } ( S | x _ { s } ) ) ^ { \gamma } \log ( p _ { \theta } ( S | x _ { s } ) ) } \\ { \displaystyle - \sum _ { i = 1 } ^ { n } \alpha _ { D } ( 1 - p _ { \theta } ( d _ { i } | x _ { s } ^ { i } ) ) ^ { \gamma } \log ( p _ { \theta } ( d _ { i } | x _ { s } ^ { i } ) ) , } \end{array}
$$

where $\alpha _ { S }$ is the weight factor for the special token $S$ . Where $p _ { \theta } ( S \mid x _ { s } )$ represents the probability of predicting $S$ given the source sentence $x _ { s }$ . The second term in Equation 9 extends the objective of Equation 8 to handle each token in the sentence. Here, $p _ { \theta } ( d _ { i } | x _ { s } ^ { i } )$ is the probability of predicting the detection label $d _ { i }$ for each token $x _ { s } ^ { i }$ . We set a higher weight factor $\alpha _ { S }$ than $\alpha _ { D }$ , to make the model more likely to predict

![](images/2daaa501d21e827d53631c9962ea12aa59ca77f0f7c1c5508f7ddd888486c759.jpg)  
Figure 3: The right side shows the Detection-Correction structure, which has stronger generation controllability compared to the traditional Seq2Seq structure on the left. Additionally, we enhance the error detection model’s sensitivity to error-free sentences by training it with a Special Token, highlighted in green in the figure.

$S$ when the sentence is error-free. When the model predicts that the entire sentence is error-free, the first term of the loss function will dominate, prompting the model to output the special token $S$ to indicate that the entire sentence is correct, as illustrated in Figure 3, thus skipping the token-by-token detection. Compared to traditional GEC tasks using LLM, which focus more on correcting text errors, our method emphasizes the model’s recognition of text correctness during the error detection stage.

Iterative Self-Reflection We utilized the LLM SelfReflection method (Ji et al. 2023) multiple times during the correction process. It’s an iterative self-refinement approach that alternates between two generative steps (FEEDBACK and REFINE) (Piche´ et al. 2024). These steps work together to produce high-quality outputs. Self-Reflection relies on an appropriate language model and three prompts (initial generation, feedback, and refinement) and does not require training. Next, we describe Self-Reflection in detail.

After obtaining the disciplinary fact knowledge $y _ { s }$ from the disciplinary knowledge base, the prefix generator initially generates the appropriate disciplinary prefix $[ p _ { s } ^ { 0 } ]$ as Equation below:

$$
[ p _ { s } ] ^ { 0 } = \mathrm { L L M } _ { \mathrm { g e n e r a t o r } } ( y _ { s } , x _ { s } ) ,
$$

where the superscript zero on $[ p _ { s } ] ^ { 0 }$ denotes that this domain prefix $\left[ p _ { s } \right]$ is generated initially. Following the generation of the model’s output, it is passed back to the generator for feedback on the previously generated content. This feedback is then used to refine the initial draft.

Table 1: Results on AcaCGEC-test, ECSpell-test and NaCGEC-test. BART (Lewis et al. 2019) is a traditional Seq2Seq model, while Llama3, Baichuan2, Qwen2 and Qwen2.5 are LLMs pre-trained for Chinese. In the Framework column, the dash - indicates no framework is used. The data for ECSpell-test and NaCGEC-test are subsets of the full test data after cleaning and proportion adjustment. Bolded results represent the better performer between two rows for each individual model.   

<html><body><table><tr><td rowspan="2">Model</td><td rowspan="2">Parameter</td><td rowspan="2">Framework</td><td colspan="3">AcaCGEC-test</td><td colspan="3">ECSpell-test</td><td colspan="3">NaCGEC-test</td></tr><tr><td>P个</td><td>R↑</td><td>F0.5↑</td><td>P个</td><td>R↑</td><td>F0.5↑</td><td>P个</td><td>R↑</td><td>F0.5↑</td></tr><tr><td>BART</td><td>400M</td><td></td><td>9.53</td><td>22.01</td><td>10.75</td><td>24.85</td><td>32.69</td><td>26.10</td><td>34.67</td><td>41.88</td><td>35.91</td></tr><tr><td>Llama3</td><td>8B</td><td></td><td>18.93</td><td>38.19</td><td>21.05</td><td>35.75</td><td>74.25</td><td>39.89</td><td>37.22</td><td>68.16</td><td>40.94</td></tr><tr><td></td><td></td><td>ScholarGEC</td><td>29.38</td><td>46.71</td><td>31.73</td><td>41.14</td><td>77.90</td><td>45.52</td><td>45.19</td><td>64.66</td><td>48.09</td></tr><tr><td>Baichuan2</td><td>7B</td><td></td><td>19.76</td><td>36.94</td><td>21.79</td><td>26.54</td><td>80.07</td><td>30.63</td><td>33.59</td><td>60.49</td><td>36.87</td></tr><tr><td></td><td></td><td>ScholarGEC</td><td>28.58</td><td>42.31</td><td>30.56</td><td>29.10</td><td>74.98</td><td>33.16</td><td>37.86</td><td>62.92</td><td>41.14</td></tr><tr><td>Qwen2</td><td>7B</td><td></td><td>22.74</td><td>47.60</td><td>25.39</td><td>32.77</td><td>71.54</td><td>36.75</td><td>35.16</td><td>55.94</td><td>39.31</td></tr><tr><td></td><td></td><td>ScholarGEC</td><td>33.48</td><td>52.12</td><td>36.06</td><td>37.56</td><td>70.28</td><td>41.42</td><td>40.26</td><td>54.73</td><td>42.51</td></tr><tr><td rowspan="2">Qwen2.5</td><td>14B</td><td></td><td>25.59</td><td>49.63</td><td>28.34</td><td>35.62</td><td>73.05</td><td>39.69</td><td>38.59</td><td>58.28</td><td>41.39</td></tr><tr><td></td><td>ScholarGEC</td><td>37.81</td><td>55.26</td><td>40.36</td><td>42.09</td><td>73.92</td><td>46.06</td><td>45.08</td><td> 59.33</td><td>47.35</td></tr></table></body></html>

Similarly, during both the error detection and correction processes, the results generated by the model are fed back into LLM for feedback and refinement. In this iterative selfreflection process, the model evaluates and provides feedback on the previously generated content, based on the feedback prompt, and subsequently refines the draft, repeating this process. We employ few-shot prompting (Brown et al. 2020) to guide the model in generating feedback and incorporating it into the revised draft. The self-reflective process for acquiring domain facts is described by the following equations:

$$
\begin{array} { r l } & { [ f e e d ] ^ { i } = \mathrm { L L M } _ { \mathrm { f e e d b a c k } } ( [ p _ { s } ] ^ { i } ) , } \\ & { [ p _ { s } ] ^ { i + 1 } = \mathrm { L L M } _ { \mathrm { r e f i n e } } ( [ p _ { s } ] ^ { i } , [ f e e d ] ^ { i } ) , } \end{array}
$$

where $[ f e e d ] ^ { i }$ is the feedback for the $i$ round of generation. Subsequently, the feedback $[ f e e d ] ^ { i }$ will be fed back to refine the previous generation result $[ p _ { s } ] ^ { i }$ , with the refined result $[ p _ { s } ] ^ { i + 1 }$ becoming the new generation result.

# Experiment

# Experimental Setup

Dataset and Evaluation Metrics We constructed a dataset called AcaCGEC, which is derived from the theses of approximately 1,000 master’s and doctoral students. We manually extracted sentences closely related to domainspecific knowledge from the data. After expert annotation, we obtained 51,412 sentence pairs containing academic domain knowledge. Additionally, as mentioned before, we used counterfactual augmentation during the training phase, which increased the amount of usable training data.

To evaluate the model’s GEC capabilities for Chinese academic papers, we assess the model on AcaCGEC-test, NaCGEC-test (Ma et al. 2022), and ECSpell-test (Lv et al. 2023). We report precision, recall and $\mathrm { F _ { 0 . 5 } }$ score for all experiments, and the $\mathrm { F _ { 0 . 5 } }$ score has been found to have a better correlation with human judgment compared to other metrics (Grundkiewicz, Junczys-Dowmunt, and Gillian 2015; Napoles et al. 2015; Chollampatt and $\mathrm { N g } 2 0 1 8 \$ ), it can be considered that this parameter is most suitable to be used to evaluate the GEC capability of the model.

Constructing the Disciplinary Knowledge Base Disciplinary knowledge sentences serve as the initial input for the prefix generator. Since most of the content in our AcaCGEC dataset comes from natural sciences, mathematics, engineering, and humanities and social sciences, We obtained most of the key concept definitions from the mainstream textbooks used in these disciplines in higher education institutions in mainland China, totaling 1,000 sentences, as the disciplinary knowledge base.

Implementation Process To verify the effectiveness of our framework, we chose the Llama3-8B-Chinese-Chat model (Wang et al. 2024), Baichuan2-7B-Chat (Yang et al. 2023), Qwen2-7B-Instruct and Qwen2.5-14BInstruct (Yang et al. 2024) as the base models. The Llama3- 8B-Chinese-Chat model is built on the Meta-Llama-3-8BInstruct model (Dubey et al. 2024). For the error detection and correction part, we applied LoRA fine-tuning (Hu et al. 2021) to the LLMs using the training dataset, with a LoRA scaling factor alpha set to 16, a rank set to 8, and fine-tuning applied to all layers. We performed fine-tuning training on the complete training set for 10 epochs, separately for the model’s error detection and correction capabilities.

# Performance Comparisons

Main Result By comparing the metric results in adjacent rows of Table 1, we find that compared to LLMs without using any framework, ScholarGEC significantly improves the $\mathrm { F _ { 0 . 5 } }$ score across all datasets. Specifically, the improvement on AcaCGEC-test dataset is approximately 10 percentage points higher than on other datasets. This demonstrates the effectiveness of our framework in enhancing the GEC capabilities of LLMs, particularly for corpora containing academic knowledge. A notable feature of the experimental results is that the recall is much higher than the precision. Upon analyzing specific samples, we find that this is because the models perform many correct corrections but also make numerous over-corrections, which lowers the precision. After applying ScholarGEC to LLMs, there is a particularly significant improvement in precision, while the increase in recall is not as noticeable. This suggests that our framework enhances the GEC capability of the models while mitigating over-correction to some extent. However, even without the use of a framework, the latest LLMs outperform the traditional Seq2Seq structure of the BART (Lewis et al. 2019) model in CGEC tasks, especially in datasets heavily related to professional knowledge. This can be attributed to the extensive pretraining of LLMs on large datasets and possibly due to structural differences; traditional CGEC methods are adapted from English GEC, which may result in poorer performance when dealing with complex Chinese text. In addition, models with larger parameters generally perform better. In addition, we observe several interesting facts. First, the performance improvement on the AcaCGEC-test dataset is significantly more pronounced than on other datasets. This can be attributed to the fact that the NaCGEC-test and ECSpell-test datasets mainly consist of materials that generally lack professional content. As a result, our knowledge integration mechanism does not play a significant role, and we will validate this conclusion through subsequent ablation experiments. Second, in some experiments, the Recall metric decreased rather than increased after the LLMs utilized the framework. This may be due to the Detection-Correction structure and the iterative self-reflection we adopted, which make the LLMs more conservative in making modifications. Third, the Qwen model generally performed well on AcaCGEC, but on other datasets, the $\mathrm { F _ { 0 . 5 } }$ score obtained by the Qwen2.5-14B is sometimes even worse than that of Llama3-8B. We speculate that this is due to the differences in the pretraining corpora of the Qwen series models compared to Llama3, giving it an advantage when dealing with highly specialized texts.

![](images/02a09337110adbfd64cd10553c1173ef2807c69857540b48a8eeb13d919f1640.jpg)  
Figure 4: Hyperparameter analysis on Llama3-8B-ChineseChat with the ScholarGEC framework. We examined the temperature $\tau$ of LLM generation and the counterfactual sample ratio $\rho$ employed in our counterfactual augmentation process. Score in the figure means $\mathrm { F _ { 0 . 5 } }$ score.

Hyperparameter Study We analyzed the impact of hyperparameter selection on the Llama3-8B-Chinese-Chat model. The results are shown in Figure 4. The temperature controls the randomness and diversity of the output. Lower temperatures were found to decrease the Recall. This is likely because professional knowledge often involves many uncommon technical terms and a lower temperature favors higher-probability words. The counterfactual ratio $\rho$ determines the proportion of samples undergoing counterfactual augmentation. As shown in the right part of Figure 4, a lower ratio yields higher Recall but much lower Precision. This also indicates the effectiveness of counterfactual augmentation in mitigating over-correction.

Table 2: Efficiency Analysis on the Llama3-8B-ChineseChat, using two NVIDIA RTX 4090 GPUs. We selected 50 MseethnotednceCsonatsean groTuerpmfinoor oegaIcnfhordmaattaisoeLt.anAgvueargeagAeveLraegnegth replaremsae3n-tCshthe a2.v8e4r5age se1.n9t0e5nce le3n.4g2t5h per 3g.2r1o5up, m2.e8a4s7u5red in cthoklaernGsE.CTim3e.8r1e5presen4t.s03the ove3r.7a2ll time3 4ta75ken for3.p7r6ocessitnhgouetaPcrh grou3p.1,3measu2.r8e6d5in sec3.o5n45ds. $w / o$ 2m3eans3.“19w2it5hout”.   

<html><body><table><tr><td>Dataset</td><td>AverageLength</td><td>Method</td><td>Time↓</td></tr><tr><td>ECSpell</td><td>41.77</td><td>ScholarGEC</td><td>34.54 25.62</td></tr><tr><td>AcaCGEC</td><td>37.94</td><td>ScholarGEC w/o Self-Reflection</td><td>51.43 32.11 21.92</td></tr></table></body></html>

![](images/0db83ba51c534fa511393270626c797cbf34dde0b4ca6bb4ee0b0037c3d5de28.jpg)  
Figure 5: Human Evaluation Study focusing on four aspects of the corrected text: Content Consistency, Terminology Consistency, Information Completeness, and Language Accuracy. Participants were selected to rate these aspects on a scale from 1 to 5, where each metric represents the average score obtained from all. ScholarGEC in figure is based on Llama3-Chinese, and the Without Prefix means ScholarGEC without knowledge prefix construction. Bolded results represent the SOTA.

Efficiency Analysis In practical applications of LLMs for the GEC task, it is important to consider not only accuracy but also inference time to meet real-time user needs. We examined the impact of our framework on LLM inference times, as shown in Table 2. The framework generally reduces the time required for inference. Further ablation studies revealed that, although the Self-Reflection mechanism increases processing time, the use of Special Tokens significantly cuts down overall time, by avoiding redundant generations of error-free sentences.

Human Evaluation Study Given the ambiguity in Chinese, it is difficult to find a suitable quantitative metric to evaluate the extent of over-correction in generated results. Therefore, we validated the model’s performance of handling over-correction through human evaluation studies. Following key concepts in Chinese grammar research, we used the following metrics:

Table 3: Ablation experiments on the ScholarGEC framework using the Llama3-8B-Chinese-Chat as the base model. KI stands for Knowledge Integration, DC indicates the use of Detection-Correction architecture, SP represents Special Token training, and SR denotes the LLM’s iterative SelfReflection mechanism. The best results are highlighted in bold, while the second-best results are underlined.   

<html><body><table><tr><td>Pre-</td><td>K</td><td>D</td><td>S</td><td>S</td><td colspan="3">AcaCGEC-test</td><td colspan="3">ECSpell-test</td></tr><tr><td>trained</td><td>I</td><td>C</td><td>P</td><td>R</td><td>P个</td><td>R↑</td><td>F0.5↑</td><td>P↑</td><td>R↑</td><td>F0.5↑</td></tr><tr><td>Yes</td><td>√</td><td>√</td><td>√</td><td>√</td><td>29.38</td><td>46.71</td><td>31.73</td><td>41.14</td><td>77.90</td><td>45.52</td></tr><tr><td>Yes</td><td>√</td><td>√</td><td>√</td><td>×</td><td>27.08</td><td>46.16</td><td>27.60</td><td>38.74</td><td>77.64</td><td>43.05</td></tr><tr><td>Yes</td><td>√</td><td>√</td><td>×</td><td>√</td><td>29.76</td><td>42.20</td><td>31.62</td><td>40.45</td><td>75.01</td><td>44.56</td></tr><tr><td>Yes</td><td>×</td><td>√</td><td>√</td><td>√</td><td>25.64</td><td>43.81</td><td>27.96</td><td>40.92</td><td>78.32</td><td>45.24</td></tr><tr><td>Yes</td><td>×</td><td>√</td><td>√</td><td>×</td><td>24.49</td><td>46.01</td><td>27.02</td><td>39.25</td><td>77.09</td><td>43.52</td></tr><tr><td>Yes</td><td>√</td><td>×</td><td>×</td><td>√</td><td>26.73</td><td>42.77</td><td>28.90</td><td>36.69</td><td>74.31</td><td>40.82</td></tr><tr><td>Yes</td><td>×</td><td>×</td><td>×</td><td>×</td><td>23.93</td><td>41.73</td><td>26.16</td><td>36.22</td><td>74.97</td><td>40.39</td></tr><tr><td>No</td><td>√</td><td>√</td><td>√</td><td>√</td><td>11.07</td><td>40.13</td><td>12.94</td><td>37.79</td><td>76.62</td><td>42.05</td></tr><tr><td>No</td><td>×</td><td>×</td><td>×</td><td>×</td><td>18.93</td><td>38.19</td><td>21.05</td><td>35.75</td><td>74.25</td><td>39.89</td></tr></table></body></html>

• Content Consistency: How does the consistency of core ideas and conclusions in the modified text? • Terminology Consistency: How does the consistency of professional terminology in the modified text? • Information Completeness: How does the completeness of information and data in the modified text? • Language Accuracy: How does the accuracy of language in the modified text?

We invited twenty volunteers to evaluate the correction results of various methods on AcaCGEC. The results are shown in Figure 5, the LLM using ScholarGEC shows improvements in the average scores across all metrics, with a particularly significant increase in the Terminology. This demonstrates the effectiveness of our framework in enhancing the LLMs’ controllability in academic GEC task. Additionally, we removed the knowledge prefix mechanism from the complete framework, as indicated by the $w / o$ KI in the figure. As a result, the score in Terminology is much lower than the complete ScholarGEC, validating the effectiveness of supplementing LLMs with disciplinary knowledge. Meanwhile, the Llama3-Chinese model using ScholarGEC, with far fewer parameters than ChatGPT-3.5, achieved significantly higher scores in Terminology and Content, and set a new SOTA in Average score.

# Ablation Study

To investigate the effectiveness of various components within our framework, we conducted extensive experimental evaluations, using different configurations of the framework. The framework configurations and corresponding experimental results are shown in Table 3.

Fine-tuning Effectiveness Models without pretraining showed significantly lower performance on AcaCGEC-test compared to those with pretraining, even under identical framework configurations. Furthermore, when the framework was applied directly to an un-finetuned LLM, the performance on AcaCGEC-test actually decreased. This suggests that mechanisms specifically designed for domain knowledge, such as constructing Knowledge Prefixes, may introduce instability when the model lacks sufficient understanding of the domain. On the other hand, the metrics on ECSpell-test improved, supporting this hypothesis.

Effectiveness of Knowledge Prefix In Table 3, removing the Knowledge Prefix mechanism resulted in a noticeable decrease in the $\mathrm { F _ { 0 . 5 } }$ score on AcaCGEC-test, while there was almost no change on ECSpell-test. This confirms the unique effectiveness of the Knowledge Prefix mechanism in enhancing the LLM’s understanding of domain-specific knowledge.

Effectiveness of Special Tokens When Special Tokens were removed and the Detection-Correction structure was replaced with a Seq2Seq structure, the $\mathrm { F _ { 0 . 5 } }$ score decreased on both datasets. However, the model performed well on ECSpell-test with the DC structure, which further validates the positive impact of this architecture on the model’s capabilities. Additionally, when Special Tokens were removed, although the model achieved the highest precision on AcaCGEC-test, the change was not significant, while the recall dropped significantly, suggesting that Special Tokens can enhance the model’s ability to detect errors, at the cost of perhaps slightly reducing the precision of corrections.

Effectiveness of Self-Reflection After removing the SelfReflection structure, we observed a decrease in performance across all metrics, particularly a notable drop in the Precision and $\mathrm { F _ { 0 . 5 } }$ score on AcaCGEC-test when comparing the two preceding rows in Table 3. This demonstrates the critical role of the self-reflective structure in the framework, which helps the model generate more accurate answers.

# Conclusion

We introduced a novel and highly controllable framework for leveraging domain knowledge in LLM-based Chinese GEC tasks. This framework specifically addressed two main issues that caused poor controllability in LLMs for traditional correction tasks: insufficient understanding of domain knowledge and instability in Seq2Seq structures. Experimental results showed that our framework effectively improved LLMs’ error correction capabilities for domainspecific texts. On our dataset constructed from real academic papers, our framework significantly improved LLM’s $\mathrm { F _ { 0 . 5 } }$ score. Ablation studies confirmed the effectiveness of our framework, and human evaluation results indicated that our framework significantly mitigated over-correction.

However, our work still has the following limitations: First, due to computational resource constraints, we did not experiment with LLMs with larger parameter counts, which might have performed differently. Second, for the SelfReflection phase, we did not extensively explore prompt engineering efficiency improvements. Third, the improvement in LLM correction abilities by our framework is less pronounced in general domains, compared to academic ones. The future work aims to find a more universally applicable method to enhance the controllability of LLMs when performing GEC tasks.