# Witty: An Efficient Solver for Computing Minimum-Size Decision Trees

Luca Pascal Staus1, Christian Komusiewicz1, Frank Sommer2, Manuel Sorge2

1Institute of Computer Science, Friedrich Schiller University Jena, Germany 2Institute of Logic and Computation, TU Wien, Austria luca.staus $@$ uni-jena.de, c.komusiewicz@uni-jena.de, fsommer@ac.tuwien.ac.at, manuel.sorge@ac.tuwien.ac.at

# Abstract

Decision trees are a classic model for summarizing and classifying data. To enhance interpretability and generalization properties, it has been proposed to favor small decision trees. Accordingly, in the minimum-size decision tree training problem (MSDT), the input is a set of training examples in $\bar { \mathbb { R } ^ { d } }$ with class labels and we aim to find a decision tree that classifies all training examples correctly and has a minimum number of nodes. MSDT is NP-hard and therefore presumably not solvable in polynomial time. Nevertheless, a promising algorithmic paradigm called witness trees which solves MSDT efficiently if the solution tree is small has been developed. In this work, we test this paradigm empirically. We provide an implementation, augment it with extensive heuristic improvements, and scrutinize it on standard benchmark instances. The augmentations achieve a mean 324-fold (median 84-fold) speedup over the naive implementation. Compared to the state of the art they achieve a mean 32-fold (median 7- fold) speedup over the dynamic programming based MurTree solver and a mean 61-fold (median 25-fold) speedup over SAT-based implementations. As a theoretical result we obtain an improved worst-case running-time bound for MSDT.

Full version on arXiv — http://arxiv.org/abs/2412.11954 Code, Data and Experimental Results — https://doi.org/10.5281/zenodo.11235017

# 1 Introduction

Traditional decision trees recursively partition the feature space with axis-parallel binary cuts and assign a class to each part of the partition. When learning decision trees, we are given a training data set that consists of examples $E \subseteq \mathbb { R } ^ { \breve { d } }$ labeled by classes and we want to find a decision tree that classifies the training data set (see Section 2 for the formal definitions). In addition, we want to optimize certain criteria, chiefly among them we want to minimize the number of cuts in the tree (or, equivalently, the size of the tree).1 This is because small trees are more easily interpretable (Molnar 2020; Moshkovitz et al. 2020) and they are thought to be more accurate on unknown data (Fayyad and Irani 1990; Hu et al. 2020). The resulting optimization problems are NP-hard, however (Hyafil and Rivest 1976; Ordyniak and Szeider 2021). The use of heuristics such as CART (Breiman et al. 1984) is therefore widespread. Recent advancements in hardware and algorithms have made it feasible to compute provably optimal trees for training data sets with up to several hundreds of examples (see the surveys by Carrizosa, Molero-R´ıo, and Romero Morales (2021); Costa and Pedreira (2023) and a full list of 26 implementations in the full version). The implementations still suffer from poor scalability, however (Costa and Pedreira 2023). In this paper we contribute towards overcoming this limitation.

To that end, as has been done before (Janota and Morgado 2020; Narodytska et al. 2018; Demirovic et al. 2022), we focus on the training problem in which we want to find a minimum-size perfect decision tree for the input training examples from two classes. Perfect means that all examples are classified correctly. This choice is to create a baseline method and we aim to later extend our approach to weaker accuracy guarantees and more classes. We build on recent theoretical algorithmic research that investigated what properties of the training data make computing smallest decision trees hard or tractable (Ordyniak and Szeider 2021; Eiben et al. 2023; Kobourov et al. 2023; Komusiewicz et al. 2023).

Our starting point is the algorithmic paradigm of witness trees, introduced by Komusiewicz et al. (2023). This paradigm gives an algorithm with the current-best running time bound of $\mathcal { O } ( ( 6 \delta D s ) ^ { s } \cdot s n )$ where $n$ is the number of training examples, $D$ is the largest domain size, $\delta \leq d$ is the largest number of dimensions in which two training examples with different classes differ, and $s$ is the number of cuts in the solution tree. This bound guarantees that the algorithm is fast whenever $D , \delta .$ , and $s$ are reasonably small. For $D$ this is very often the case, in fact many data sets have only binary dimensions. The cut number $s$ should be small since we aim for interpretable models. Finally, $\delta$ was shown to be reasonably small in benchmark data (Ordyniak and Szeider 2021), see also Table 3 in the full version. Thus, the running time bound hints at practical usefulness of the paradigm. Equally important for us is that the paradigm simplified previous theoretical approaches (Ordyniak and Szeider 2021; Eiben et al. 2023) to such an extent as to make it promising as a foundation of a competitive solver. Additionally, the approach generalizes to other learning models and even ensembles (Komusiewicz et al. 2023; Ordyniak et al. 2024), making it particularly interesting to test in practice.

The main idea of the witness-tree paradigm is to start with a trivial decision tree consisting of a single leaf labeled by an arbitrary class. Then we pick a training example which is classified incorrectly, we call it dirty, and we recursively try in a branching over all possibilities to refine the current tree with a new cut and a new leaf in which the dirty example is classified correctly. We label the new leaf with the dirty example as witness and mandate that all future refinements maintain all witnesses at their assigned leafs. This reduces the search space that we need to explore to find the desired decision tree; see Section 3 for a more detailed description. In this work, we provide an implementation of the above paradigm and we extensively augment it with improvements that give heuristic speedups while maintaining the optimality of the computed decision tree.

Our main result is that these improvements substantially speed up the algorithm to the point where the resulting solver, called Witty, performs substantially better than the state of the art (see Section 7). To the best of our knowledge, the state-of-the-art solvers for computing minimumsize perfect decision trees are SAT-based solvers by Narodytska et al. (2018) and Janota and Morgado (2020) and the dynamic-programming algorithm MurTree by Demirovic et al. (2022). All other implementations for computing variants of optimal decision trees solve different optimization problems and are not suitable for the task discussed in the present paper, see the full version for details.

We tested the solvers on standard benchmark data sets from the Penn Machine Learning Benchmarks (Romano et al. 2022). Out of the three state-of-the-art solvers, MurTree performed the best, solving 371 out of the 700 instances. In comparison, Witty was able to solve 388 instances and achieves a mean 32-fold (median 7-fold) speedup2 over MurTree. Compared to MurTree Witty performs especially well on instances that have dimensions with a large number of different values. This is due to the fact that Witty does not require binary dimensions and one of our above-mentioned improvements specifically exploits large domains.

To achieve these results, we employ the following techniques. First, we apply data reduction rules that simplify the instances (Section 3). Second, we improve the branching rule which introduces the next cut into the partial decision tree in several ways (Section 3): We carefully select which dirty examples to use for branching, specify a suitable sequence of the cuts to try, and observe that some cuts can be omitted from branching. Third, we introduce lower-bounding strategies that determine a minimum number of cuts that still need to be added to the tree, to further shrink the search space (Section 4). Fourth, we use symmetry-breaking techniques which we call subset constraints that leverage information from unsuccessfully returning branches which essentially fixes some examples into subtrees of the solution decision tree (Section 5). This also yields an improved running-time bound of $\mathcal { O } ( ( \delta D \log s ) ^ { s }$ $s n$ ) (Theorem 5.9). Finally, during the search we select certain subsets of examples for which we directly compute lower bounds, cache them, and exploit them later in the search (Section 6). We rigorously analyze all of the above techniques and prove them to preserve optimality of the computed trees.

Apart from improved scalability, other key advantages of our implementation include that, different from the state-ofthe-art algorithms, it is not necessary to binarize the dimensions, and that the general paradigm is very flexible so that it can be adapted for reoptimizing a given decision tree, for further optimization goals such as minimizing the number of misclassified examples, and for other models related to decision trees such as decision lists. Similarly, the above heuristic improvements are flexible and they apply to computing minimum-depth trees, for example. In summary, we provide an implementation and extensive heuristic tuning of the witness-tree paradigm for computing minimum-size decision trees which is flexible and at the same time substantially outperforms the state of the art.

# 2 Preliminaries

For $\boldsymbol { n } ~ \in ~ \mathbb { N }$ , we denote $[ n ] : = \{ 1 , 2 , \dots , n \}$ . For a vector $\boldsymbol { x } \in \mathbb { R } ^ { d }$ , we denote by $x [ i ]$ the ith entry in $x$ . Let $\Sigma$ be a set of class symbols. We consider binary classification, so we assume that $\Sigma = \{ \mathrm { b l u e , r e d } \}$ . A data set with classes $\Sigma$ is a tuple $( E , \lambda )$ of a set of examples $E \subseteq \mathbb { R } ^ { d }$ and their class labeling $\lambda \colon E \to \Sigma$ . Note that this formulation captures ordered dimensions because such dimensions can be mapped into $\mathbb { R }$ . We assume that $( E , \lambda )$ does not contain two examples with identical coordinates but different class labels. For a fixed data set $( E , \lambda )$ , we let $n : = | E |$ denote the number of examples and $d$ the dimension of the data set.

For each dimension $i \in [ d ]$ , we let $\mathsf { T h r } ( i )$ be a smallest set of thresholds such that for each pair of examples $e _ { 1 } , e _ { 2 } \in$ $E$ with $e _ { 1 } [ i ] ~ < ~ e _ { 2 } [ i ]$ there is a threshold $t \in \mathsf { T h r } ( i )$ with $e _ { 1 } [ i ] \leq t < e _ { 2 } [ i ]$ . Note that such a set $\mathsf { T h r } ( i )$ can be computed in $\mathcal { O } ( n \log n )$ time and that $| \mathsf { T h r } ( i ) | \leq D$ . A cut is a pair $( i , t )$ where $i \in [ d ]$ is a dimension and $t \in \mathsf { T h r } ( i )$ is a threshold in dimension $d$ . The set of all cuts is denoted by $\mathsf { C u t s } ( E )$ . The left side of a cut with respect to $E ^ { \prime } \subseteq E$ is $E ^ { \prime } [ \leq \left( i , { \dot { t } } \right) ] : = \left\{ { \dot { e } } \in E ^ { \prime } \mid e [ i ] \leq t \right\}$ , and the right side of a cut with respect to $E ^ { \prime }$ is $E ^ { \prime } [ > \ ( i , t ) ] : = \{ e \in E ^ { \prime } \mid e [ i ] > t \}$ .

A decision tree is a tuple $\mathcal { D } = ( T , { \mathsf { c u t } } , { \mathsf { c l a } } )$ where $T$ is an ordered rooted binary tree with vertex set $V ( \mathcal D )$ , that is, each inner vertex has a well-defined left and right child. Furthermore, ${ \mathsf { c u t } } : V ( { \mathcal { D } } ) \to { \mathsf { C u t s } } ( E )$ maps every inner vertex to a cut and ${ \mathsf { c l a } } : V ( { \mathcal { D } } ) \to \Sigma$ labels each leaf. The size of $\mathcal { D }$ is the number of inner vertices. For each vertex $v \in V ( \mathcal { D } )$ we define a set $E [ { \mathcal { D } } , v ] \subseteq E$ of examples that are assigned to $v$ . If $v$ is the root of $\mathcal { D }$ , then $E [ { \mathcal { D } } , v ] : = E$ . For other vertices, the assigned values are defined via the cuts at inner vertices. More precisely, for a parent vertex $p$ with left child $u$ and right child $\boldsymbol { v }$ we set ${ \cal E } [ { \cal D } , u ] : = { \cal E } [ { \cal D } , p ] [ \leq \mathsf { c u t } ( p ) ] $ and $\bar { E [ } \bar { D } , v ] \ : = \ E [ \bar { D } , p ] [ > \ \mathsf { c u t } ( p ) ]$ . If $\mathcal { D }$ is clear from the context, we just write $E [ v ]$ . By definition, each example $\boldsymbol { \mathscr { e } } \in E$ is assigned to exactly one leaf $\ell$ of $\mathcal { D }$ . We say that $\ell$ is the leaf of $e$ in $\mathcal { D }$ and denote $\ell$ by $\mathsf { l e a f } ( \mathcal { D } , e )$ or just $\mathsf { I e a f } ( e )$ if $\mathcal { D }$ is clear. An example $e \in E$ is dirty in $T$ if we have $\dot { \lambda ( e ) } \neq { \mathsf { c l a } ( \ell ) }$ with $\ell$ being the leaf of $e$ . The set of all dirty examples in $T$ is Dirty $( T )$ . A decision tree classifies $( E , \lambda )$ if the class of every example $\boldsymbol { \mathscr { e } } \in E$ matches the class of its leaf, that is, we have $\lambda ( e ) = { \mathsf { c l a } } ( { \mathsf { l e a f } } ( e ) )$ for all $e \in E$ . In this case we call $\mathcal { D }$ perfect.

![](images/ab08355d20a2aba7637d151e03d93a6827dbf68be9fc553c5b869cd2c983c19b.jpg)  
Figure 1: Examples of one-step refinements. The orange path is the classification path of a red example $e$ . (a) A witness tree $W$ where $e$ is misclassified in leaf $z$ . (b), (c), (d) Three possible trees resulting from one-step refinements of $W$ where $e$ is the witness of the new leaf $t$ .

We aim to solve the following computational problem.

MINIMUM-SIZE DECISION TREE (MSDT)   
Instance: A data set $( E , \lambda )$ .   
Task: Find a smallest decision tree that classifies $( E , \lambda )$ .

We let BOUNDED-SIZE DECISION TREE (BSDT) denote the variant where we are also given a number $s$ and need to find a decision tree of size at most $s$ or decide that no such tree exists. We can solve MSDT by solving multiple instances of BSDT as follows: Start with $s = 1$ . Increase $s$ one by one and solve BSDT for each $s$ until a tree is found. This tree must be a solution for MSDT.

Proofs marked with $( { \star } )$ are deferred to the full version

# 3 Base Version – the Witness-Tree Algorithm

The base version of our algorithm is the witness-tree algorithm (Komusiewicz et al. 2023). In the following, we briefly explain the algorithm. The presented algorithm solves the BSDT problem where we have a fixed size threshold $s$ . We then use this algorithm to solve MSDT as described above.

Witness trees and one-step refinements. Witness trees are decision trees augmented with a labeling of the leafs by examples. Formally, a witness tree is a tuple $\begin{array} { l l } { W } & { = } \end{array}$ ( $T$ , cut, cla, wit) where ( $T .$ , cut, cla) is a decision tree and wit : $V ( W ) \to E$ is a map that maps each leaf $\ell$ to an example $e \in E [ \ell ]$ of the same class as $\ell$ . These examples are called witnesses of $W$ . During branching, $W$ is extended by adding a new inner vertex and a new leaf. This is done via one-step refinements. Formally, a one-step refinement of $W$ is a tuple $( v , i , t , e )$ where $v \in V ( W )$ is some vertex in $W$ , $( i , t )$ is a cut in Cuts $( E )$ , and $e \in E [ W , v ]$ is an example.

A one-step refinement $( v , i , t , e )$ is applied to a witness tree $W$ as follows (see Figure 1): First, subdivide the edge from $v$ to its parent $p$ by adding a new inner vertex $u$ with cut $( i , t )$ . Now, $p$ is the parent of $u$ and $u$ is the parent of $v$ . If $v$ was the left (right) child of $p$ then $u$ becomes the left (right) child of $p$ . If $v$ is the root of the tree (hence $\boldsymbol { v }$ has no parent $p _ { \mathrm { \ell } }$ ) then $u$ becomes the new root. Second, add a new leaf $\ell$ as the second child of $u$ (with $\boldsymbol { v }$ being the first child). The example $e$ determines the assignment of $\ell$ and $\boldsymbol { v }$ to the sides of the cut $( i , t )$ : The example $e$ needs to be assigned to leaf $\ell$ , so if $e$ is assigned to the left child, then $\ell$ becomes the left child. Otherwise, $\ell$ becomes the right child. Finally, the class of $\ell$ is set to $\lambda ( e )$ and the witness of $\ell$ is set to $e$ .

Algorithm 1: Base witness-tree algorithm.   

<html><body><table><tr><td>maximum size s ∈ IN. if none could be found.</td><td>Input:Awitness tree W,a data set (E,入),and a Output: A perfect witness tree of size at most s or ⊥</td></tr><tr><td>1</td><td>Function Refine (W, (E,λ),s)</td></tr><tr><td>2</td><td>if Wclassifies(E,λ) then return W</td></tr><tr><td>3</td><td>if W has size s then return⊥</td></tr><tr><td>4</td><td>e ← some dirty example from Dirty(W)</td></tr><tr><td>5</td><td>forall r = (v,i,t,e) ∈ Ref(W) do</td></tr><tr><td>6</td><td>Apply r to W to create a new witness tree R</td></tr><tr><td>7</td><td>R'←Refine(R,(E,λ),s)</td></tr><tr><td>8</td><td>ifR'=⊥then return R'</td></tr><tr><td>9</td><td>return⊥</td></tr></table></body></html>

Let $R$ denote the newly created witness tree. We write $W ~ { \stackrel { r } { \to } } ~ R$ to indicate that $R$ was created by applying $r$ to $W$ . An application of a sequence $r _ { 1 } , \ldots , r _ { q }$ of one-step refinements to create $R$ from $W$ is denoted by $W ~ { \xrightarrow { \ r _ { 1 } , \ldots , r _ { n } } } \ R . \ \mathsf { R e t } ( W )$ is the set of all one-step refinements $r = ( \boldsymbol { v } , i , t , e )$ of $W$ such that $e \in \mathsf { D i r t y } ( \bar { W } )$ is dirty in $W$ , $e$ and wi $\mathsf { t } ( \mathsf { l e a f } ( e ) )$ are on different sides of the cut $( i , t )$ and $r$ does not change the leaf of any witness of $W$ . This set is important because it contains all one-step refinements that are relevant for the algorithm.

Description of the algorithm solving BSDT. Algorithm 1 shows the pseudocode. For the correctness proof, refer to the work of Komusiewicz et al. (2023). Algorithm 1 starts with a witness tree $W$ that consists of just one leaf $\ell$ . An arbitrary witness for this leaf $\ell$ is chosen and the class of $\ell$ is set to the class of this witness. Next, Refine is called (Line 1). Algorithm 1 then recursively chooses a dirty example $e$ and iterates over all one-step refinements in ${ \mathsf { R e f } } ( W )$ in which $e$ is the dirty example. The idea is that since $e$ is currently dirty, we need to assign $e$ to a new leaf with class $\lambda ( e )$ since all examples are required to be correctly classified. The one-step refinements with $e$ as dirty example do this by making $e$ the witness of the newly added leaf and assigning the class of $e$ to that leaf. Algorithm 1 traverses a search tree where each node represents a call of Refine. To avoid confusion, from now on we call the vertices of the search tree nodes, and the vertices in a decision/witness tree vertices. For a node $N$ , we let $\mathsf { T r e e } ( N )$ denote the witness tree $W$ that Refine is called with and we use $\mathsf { e x } ( N )$ to refer to the dirty example that is chosen in Line 4.

We now describe some first improvements to this algorithm, leading to the first version of the solver.

Dirty example priority. For the correctness it is not relevant which dirty example is chosen in Line 4. This permits our first improvement: choose a dirty example that minimizes the number of branches. Ideally one can choose the dirty example such that the number of one-step refinements is as small as possible. Computing this for every dirty example for every call of Refine takes too long, however. Hence, we update this number for an example $e$ only whenever $e$ is assigned to a new leaf; preliminary experiments showed that this is a good trade-off. We can use the same idea to choose the witness of the initial leaf and the initial dirty example. That means before the algorithm starts we can find the pair of examples with different classes that minimizes the number of one-step refinements, that is, the number of cuts separating them and choose one of these two elements as initial witness.

Data reduction. In the following, we briefly describe the used rules. Correctness proofs and their experimental evaluation can be found in the full version. First, if there are two examples $e _ { 1 }$ and $e _ { 2 }$ having the same value in each dimension (recall that $e _ { 1 }$ and $e _ { 2 }$ are required to have the same class label), we remove one of them from $( E , \lambda )$ . Second, if there is a dimension $\mathbf { \chi } _ { i }$ such that all examples have the same value in this dimension, we remove $i$ . Third, if the instance has two equivalent cuts, then remove one of them. Here, two cuts $( i _ { 1 } , t _ { 1 } ) , ( i _ { 2 } , t _ { 2 } ) \in \mathsf { C u t s } ( E )$ are equivalent if $E [ \le \left( i _ { 1 } , t _ { 1 } \right) ] = E [ \le \left( i _ { 2 } , t _ { 2 } \right) ]$ . For the fourth rule, consider a pair of cuts $( i , t _ { 1 } )$ and $( i , t _ { 2 } )$ in the same dimension $i$ with $t _ { 1 } < t _ { 2 }$ . Now, if all examples on the left (right) side of both cuts have the same class, then remove $( i , t _ { 1 } )$ (or $( i , t _ { 2 } )$ respectively). For the last rule, consider a pair of dimensions $i _ { 1 }$ and $i _ { 2 }$ . If there is an ordering of the examples such that the values of the examples do not decrease in both dimensions, then one can construct a new dimension $i _ { 1 , 2 }$ such that for each cut in dimensions $i _ { 1 }$ or $i _ { 2 }$ , there is an equivalent cut in dimension $i _ { 1 , 2 }$ and vice versa. Now, $i _ { 1 }$ and $i _ { 2 }$ are replaced by $i _ { 1 , 2 }$ .

# 4 Lower Bounds

We introduce two lower bounds that we use to prune the search tree. In both lower bounds an instance of SET COVER is constructed and then a lower bound is calculated for this instance. In SET COVER the input is a universe $U$ and a family $S$ of subsets of $U$ , and the task is to compute the smallest integer $k$ such that there is a subset $S ^ { \prime } \subseteq S$ of size exactly $k$ whose union is the universe $U$ .

We show that for our two lower bounds, the size $k$ of the smallest subset $S ^ { \prime }$ is a lower bound for the minimum number of one-step refinements that are needed to correctly classify all examples in the current witness tree. We calculate these lower bounds after Line 5 in each call of Refine in Algorithm 1. If $k$ is bigger than $s$ minus the current size of $W$ we can return $\perp$ . Since SET COVER is NP-hard (Karp 1972), calculating the exact value of $k$ in every call of Refine is not feasible. Instead we are going to introduce different ways of calculating a lower bound for $k$ .

First lower bound: Improvement Lower Bound (ImpLB). The idea of the ImpLB is to find the minimum number of one-step refinements that are necessary to correctly classify only the examples that are dirty in the current witness tree $W$ while ignoring the examples that are already correctly classified. Moreover, we ignore that one-step refinements may interfere with each other and consider the effect of each one-step refinement separately. To assess this effect, we use the following definition.

Definition 4.1. Let $W$ be a witness tree, $E ^ { \prime } \subseteq \mathsf { D i r t y } ( W )$ a set of dirty examples, and $r \in \mathsf { R e f } ( W )$ a one-step refinement with $W \stackrel { r } {  } R$ . Then we define

$$
\mathsf { i m p } ( W , E ^ { \prime } , r ) : = \{ e ^ { \prime } \in E ^ { \prime } \mid e ^ { \prime } \notin \mathsf { D i r t y } ( R ) \}
$$

as the set of dirty examples that get correctly classified by $r$ We call these sets the imp sets.

We now create an instance of SET COVER by choosing Dirty $( W )$ as the universe and the family of subsets $\{ \mathsf { i m p } ( W , \mathsf { D i r t y } ( W ) , r ) \ | \ r \ \in \ \mathsf { R e f } ( W ) \}$ . To show that the solution of this instance is a lower bound, we show that for any series of $s$ one-step refinements $I ^ { \prime }$ that lead to $W$ being perfect there is a set $I \subseteq I ^ { \prime }$ of size at most $s$ such that the union of all sets in $I$ is equal to Dirty $( W )$ .

Theorem $4 . 2 ~ \ ( \star )$ . Let $\begin{array} { r l r } { W } & { { } : = } & { R _ { 0 } } \end{array}$ be $a$ witness tree and $( r _ { 1 } , \ldots , r _ { s } )$ a series of one-step refinements with $R _ { i - 1 } \ { \xrightarrow { r _ { i } } } \ R _ { i }$ , $r _ { i } \in R e f ( R _ { i - 1 } )$ for $i \in [ s ]$ such that $R _ { s }$ is perfect. Then there is a set $I \subseteq R e t ( W )$ , $\mathit { \bar { | } I | } \le s$ , such that

$$
\bigcup _ { r \in I } i m p ( W , D i r t y ( W ) , r ) = D i r t y ( W ) .
$$

Calculating the ImpLB. Instead of considering the content of each set, we only consider their sizes. Thus, we calculate the smallest set of subsets such that the sum of their sizes is bigger or equal to the size of the universe. Hence, to calculate the ImpLB we just need to look at each one-step refinement $r ~ \mathbf { \bar { \mu } } \in \mathsf { R e f } ( \bar { W } )$ , calculate the size of $\mathsf { i m p } ( W , \mathsf { D i r t y } ( W ) , r )$ , sort the sizes in descending order, and then check how many sets are needed to reach a sum that is at least the size of $\mathsf { D i r t y } ( W )$ . We apply the ImpLB in each search-tree node.

Second lower bound: Pair Lower Bound (PairLB). For the PairLB we use a similar idea as for the ImpLB but instead of looking at sets of dirty examples we look at sets of pairs of examples that are assigned to the same leaf but have different classes. For each one-step refinement $r$ we define a pairsplit set as the set of all pairs that are split up by $r$ , that is, all pairs where the two examples are no longer in the same leaf of the tree created by $r$ . With the set of all pairs as the universe and all pairsplit sets as the family of subsets we obtain a SET COVER instance. Similar to the ImpLB, the solution of this instance is a lower bound for the minimum number of one-step refinements that are needed to correctly classify all examples in the current witness tree.

However, preliminary experiments showed that calculating the PairLB in every search-tree node does not improve the running time of the algorithm. Thus, we use the PairLB only to calculate an initial lower bound for the solution of MSDT. For this we use the LP-relaxation of the standard ILP-formulation of SET COVER. Further details and proofs for the PairLB are in the full version.

# 5 Subset Constraints

A subset constraint of a vertex $v$ in a witness tree $W$ is a subset $S \subseteq E [ W , v ]$ of examples which imposes the constraint that one-step refinements are not allowed to remove all examples of $S$ from the subtree of $v$ . The idea is that if such one-step refinements lead to a perfect tree, then there is a different perfect tree that does not violate this constraint and is not larger. For example, if one can replace threshold $t$ in vertex $v$ of $W$ by a different threshold $t ^ { \prime }$ such that there is no example in $v$ with a threshold between $t$ and $t ^ { \prime }$ , we only have to test one of $t$ and $t ^ { \prime }$ . Testing this for each pair of thresholds is too inefficient. Instead, we use subset constraints:

Definition 5.1. Let $W$ be a witness tree and let $v \in V ( W )$ . We call a subset $C \subseteq E$ a Subset Constraint of $v$ . We call $C$ violated if $E [ W , v ] \cap C = \emptyset$ . The set Const $( W , v )$ contains all subset constraints of $v$ in the tree $W$ .

Subset constraints are added continuously during the algorithm. After each one-step refinement, we update for each node $v$ which examples are still in the subtree of a node $v$ , thus immediately detecting any violated subset constraint.

Correctness of subset constraints. We add different subset constraints after the application of one-step refinements. To show that the addition of these constraints is safe, we need the following definition.

Definition 5.2. Let $\begin{array} { r c l } { W } & { = } & { \left( T , \mathsf { c u t } , \mathsf { c l a } , \mathsf { w i t } \right) } \end{array}$ and $\textit { R } =$ $( T ^ { \prime } , \mathsf { c u t } ^ { \prime } , \mathsf { c l a } ^ { \prime } , \mathsf { w i t } ^ { \prime } )$ be two witness trees. We say that $R$ is a refinement of $W$ if and only if $W$ and $R$ fulfill the following properties:

1. $V ( W ) \subseteq V ( R )$ .   
2. A vertex $v \in V ( W )$ is a leaf in $W$ if and only if $v$ is a leaf in $R$ , and for each leaf $\ell \in V ( W )$ we have ${ \mathsf { c l a } } ( \ell ) =$ ${ \mathsf { c l a } } ^ { \prime } ( { \boldsymbol { \ell } } )$ and $w \mathfrak { i } ( \ell ) \in E [ R , \ell ]$ .   
3. Let $v _ { 1 } , v _ { 2 } \in V ( W )$ be a pair of vertices. Vertex $v _ { 1 }$ is in the left subtree of $v _ { 2 }$ in $W$ if and only if $v _ { 1 }$ is in the left subtree of $v _ { 2 }$ in $R$ . Vertex $v _ { 1 }$ is in the right subtree of $v _ { 2 }$ in $W$ if and only if $v _ { 1 }$ is in the right subtree of $v _ { 2 }$ in $R$ .   
4. For every inner vertex $v \in V ( W )$ we have $\mathsf { c u t } ( v ) \ =$ $\mathsf { c u t ^ { \prime } } ( v )$ .

If $R$ was created by applying one or more one-step refinements to $W$ then $R$ is a refinement of $W$ . In the full version, we show that the reverse direction is also true.

We can now define what it means for a subset constraint to be safe. Note that this definition depends on a fixed order in which the algorithm considers one-step refinements, the description of this order is deferred to the full version.

Definition 5.3. Let $N$ be a node in the search tree with witness tree $W$ and the dirty example $\begin{array} { r } { e \ : = \ \mathsf { e x } ( N ) } \end{array}$ and let $r : = ( v , i , t , e ) \in \mathsf { R e f } ( W )$ be a one-step refinement with $W ~ { \stackrel { r } { \to } } ~ W ^ { \prime }$ that introduces a subset constraint $C$ for the newly added inner vertex.

We say that $C$ is correct if for each perfect witness tree $R$ that is a refinement of $W ^ { \prime }$ and violates $C$ , there is a different witness tree $R ^ { \prime }$ with the following properties:

1. $R ^ { \prime }$ is perfect.   
2. $R ^ { \prime }$ is not bigger than $R$ .

3. There is a different one-step refinement $r ^ { \prime } \in \mathsf { R e f } ( W )$ with $W \stackrel { r ^ { \prime } } {  } W ^ { \prime \prime }$ that Algorithm 1 chooses before $r$ such that $R ^ { \prime }$ is a refinement of $W ^ { \prime \prime }$ .

Theorem 5.4 $( { \star } )$ . If there is a perfect witness tree of size at most $s \in \mathbb { N }$ , then there is a perfect witness tree of size at most s that does not violate any correct subset constraints.

Next, we introduce two specific subset constraints.

Threshold Subset Constraints. Our first subset constraint is based on the observation that replacing a threshold by another threshold without changing the leaf assignment of any example can be possible.

Definition 5.5. Let $N$ be a node in the search tree with the witness tree $W : = { \mathsf { T r e e } } ( N )$ and the dirty example $\begin{array} { r l } { \boldsymbol { e } } & { { } : = } \end{array}$ $\mathsf { e x } ( N )$ , let $r ~ = ~ ( v , i , t , { \dot { e } } ) , { \dot { r } } ^ { \prime } ~ = ~ ( v , i , t ^ { \prime } , e ) ~ \in ~ \mathsf { P e f } ( W )$ with $W \stackrel { r } {  } R$ and $W \stackrel { r ^ { \prime } } { \longrightarrow } R ^ { \prime }$ such that we have $e [ i ] \leq t ^ { \prime } < t$ or $t < t ^ { \prime } < e [ i ]$ , and let $\ell$ and $u$ be the leaf and inner vertex that are added to $W$ by $r$ . We add the Threshold Subset Constraint $C : = E [ R , \ell ] \setminus E [ R ^ { \prime } , \ell ]$ to Const $( R , u )$ and call $t ^ { \prime }$ the constraint threshold of $C$ .

If a Threshold Subset Constraint of a vertex $u$ in $W$ is violated then replacing the threshold of $u$ by the constraint threshold $t ^ { \prime }$ does not change the leaf of any example in $W$ .

Theorem 5.6 $( { \star } )$ . Threshold Subset Constraints are correct.

Dirty Subset Constraints. Our second subset constraint is based on the idea that we discard some vertices on the leaf-to-root path for one-step refinements. For example, we may discard one-step refinements $r$ at a vertex $v$ when one of the child subtrees of $v$ is already perfect, since it is also possible to apply $r$ at the root of the other child subtree.

Definition 5.7. Let $N$ be a node in the search tree of Algorithm 1 with the witness tree $W : = { \mathsf { T r e e } } ( N )$ and the dirty example $\boldsymbol { e } : = \boldsymbol { \mathsf { e x } } ( N )$ , let $v$ be an inner vertex in $W$ with the children $v _ { 1 }$ and $v _ { 2 }$ , let $r = ( v , i , t , e ) , r ^ { \prime } = ( v _ { 1 } , i , t , e ) \in$ ${ \mathsf { R e f } } ( W )$ be two one-step refinements with $W \stackrel { r } {  } R$ and $W \ { \overset { r ^ { \prime } } { \to } } \ .$ , let $\ell$ and $u$ be the leaf and inner vertex that are added to $W$ by $r$ . We add the Dirty Subset Constraint $C = E [ W , v _ { 2 } ] \cap \mathsf { D i r t y } ( W )$ to Const $( R , u )$ .

Theorem ${ \pmb 5 . 8 ( \pmb \star ) }$ . Dirty Subset Constraints are correct.

Now, we show that, using Dirty Subset Constraints, we can improve on the running time of ${ \mathcal { O } } ( ( \delta \cdot D \cdot s ) ^ { s } \cdot s \cdot n )$ for MINIMUM-SIZE DECISION TREE shown by Komusiewicz et al. (2023) by replacing the $s$ in the base of the running time by $\log ( s )$ .

Theorem 5.9 $( { \star } )$ . MINIMUM-SIZE DECISION TREE can be solved in $\mathcal { O } ( ( \delta \cdot D \cdot \log ( s ) ) ^ { s } \cdot s \cdot n )$ time.

# 6 Subset Caching

Our final improvement is inspired by the caching of subproblems used in MurTree (Demirovic et al. 2022) to solve the related problem of minimizing the number of misclassifications under a size and depth constraint. They iterate over all possible cuts for the root and then calculate optimal solutions for the left and right subtree recursively. For this approach, caching of subproblems is very natural.

Since Witty can modify any part of the current witness tree, Witty is not directly amenable to caching. Thus, we modify the caching of subproblems as follows: We use a settrie data structure (Savnik 2013) to store lower bounds for specific subsets of the examples. These lower bounds tell us how many inner vertices we need at least to correctly classify that subset of the examples. In any search-tree node $N$ with $W : = { \mathsf { T r e e } } ( N )$ , we then look at each leaf $\ell \in V ( W )$ and the set of examples $L : = E [ W , \ell ]$ assigned to $\ell$ and check if a subset $S$ of $L$ is present in our data structure. If this is the case, then the lower bound $z$ associated with $S$ is also a lower bound for $L$ . Since all examples in $L$ are assigned to the same leaf, this is also a valid lower bound for $W$ . If $z$ is bigger than the remaining size budget $s ^ { \prime }$ , we know that it is not possible to correctly classify the data set by applying at most $s ^ { \prime }$ one-step refinements to $W$ . Consequently, the algorithm can return $\perp$ . Otherwise, if $z$ is not big enough, we keep checking our data structure for another subset of $L$ until we either find a sufficiently large lower bound or until no more subsets of $L$ are left.

Since our algorithm does not naturally calculate lower bounds for subsets of examples, to populate the set trie $\tau$ we do the following: In a search-tree node $N$ , we look at the example set $L : = \mathsf { \bar { E } } [ \mathsf { T r e e } ( N ) , \ell ]$ of any leaf $\ell$ with $| L | \leq$ $\operatorname* { m i n } ( | E | / 4 , 3 0 )$ . Let $s ^ { \prime }$ be the remaining size budget of the current witness tree. We run a separate instance of our algorithm that checks whether the set $L$ can be correctly classified with a tree of size at most $s ^ { \prime }$ . If not, then we can add $L$ to $\tau$ with the lower bound $s ^ { \prime } + 1$ . Of course we could then check if $L$ can be correctly classified with a tree of size at most $s ^ { \prime } + 1$ to improve the lower bound, but we decided to only check size $s ^ { \prime }$ because that is sufficient to show that the current tree cannot correctly classify the data. If we ever need a better lower bound for $L$ at a later point, we can still calculate it then. A limit of the size of $L$ is necessary since otherwise one solves the original problem; preliminary experiments showed that $\operatorname* { m i n } ( | E | / 4 , 3 0 )$ is a good limit.

A set-trie is especially useful when solving MSDT since we can reuse the set-trie for each instance of BSDT until we find the optimal $s$ . For all solved instances, each trie had at most 80 000 vertices, resulting in a maximum space consumption of 3 GB.

# 7 Experimental Evaluation

Experimental setup. For our experiments, we used 35 data sets that were also used in the experimental evaluation of the state-of-the-art SAT-based MSDT solver (Janota and Morgado 2020). The data sets are part of the Penn Machine Learning Benchmarks (Romano et al. 2022). The full version contains an overview.

As Janota and Morgado (2020), we transformed the data sets as follows to meet the requirements of MSDT inputs: First, to ensure that all dimensions are ordered, we replaced each categorical dimension by a set of new binary dimensions indicating whether an example is in the category. Second, we converted each instance into a binary classification problem. For this, we colored all examples of the largest class red, and all remaining examples blue. Finally, if two examples had the same value in all dimensions but are colored differently, we removed one of them arbitrarily.

![](images/39d1e499c4c5c8ac9f901f31fdb3d4ab73915d606c5cd35270cb1538773a2f74.jpg)  
Figure 2: Comparison of different algorithms for MSDT. For each time $t$ it is shown how many instances were solved by each algorithm in less than $t$ seconds.

Following Janota and Morgado (2020), we randomly sampled multiple subsets of the examples from each data set. Specifically, for each data set we chose 10 random subsets with $2 0 \%$ of the examples and 10 random subsets with $5 0 \%$ of the examples. In total we ran our experiments on 700 instances with a time limit of 60 minutes for each instance.

Our experiments were performed on servers with $2 4 \mathrm { G B }$ RAM and two Intel(R) Xeon(R) E5540 CPUs with 2.53 GHz, 4 cores, 8 threads, running Java openjdk 11.0.19. Each individual experiment was allowed to use up to 12 GB RAM. All algorithms were executed on a single core. However, we reserved two additional cores for each experiment to avoid side effects of other threads like the Java garbage collector. We implemented our algorithm in Kotlin (see Zenodo). To solve the LP-relaxation of the PairLB we used Gurobi 10.0.3 (Gurobi Optimization, LLC 2023). Recall that to compute the speedup, we ignored instances that were solved in less than one second by both algorithms.

Comparison with the basic version of Witty. Figure 2 shows the performance of Witty and Basic. Witty is the final version of our algorithm using all improvements while Basic is just Algorithm 1 together with the dirty example priority and the data reduction rules from Section 3.

Basic solved 264 out of the 700 instances. In comparison, the naive version of our algorithm without any improvements only solved 222 instances and Basic is 26 times (median 9 times) faster on instances solved by both. This shows that the dirty example priority and data reduction rules from Section 3 already give a large speedup.

Witty solved 388 instances and is roughly 65 times (median 23 times) faster than Basic on instances that were solved by both, showing that the combination of all of our improvements yields a vast speedup.

A more detailed comparison of the different solver configurations can be found in the full version.

![](images/84036e8ce77da6e26155fb5c158fa122eab3b59014f73d05fb66c133e02fdc8e.jpg)  
Figure 3: Comparison of the running times of Witty and MurTree for each instance with the color representing the largest domain size $D$ .

better than MurTree on instances with a large number of cuts $c$ . This is most likely related to the observation that these instances also tend to have a large value for $D$ . Second, MurTree can solve instances with a larger optimal tree size s. MurTree solved instances with $s \leq 2 0$ while Witty could only solve instances with $s \leq 1 6$ . This suggests that MurTree scales better with the size of the optimal tree as long as the largest domain size $D$ is not too large. In fact, all instances with $s > 1 6$ that MurTree solved have a value of $D = 2$ .

Comparison with heuristics. We evaluated the size, balance, and classification quality on test data of the trees computed by Witty against three heuristics: CART (Breiman et al. 1984), Weka (Frank, Hall, and Witten 2016), and YaDT (Ruggieri 2004, 2019). CART and Weka also compute perfect trees. Our evaluation (see the tables in the full version) shows that the trees of YaDT are much smaller than the trees of Witty which are a bit smaller than the ones of CART and Weka. Also, all computed trees are very balanced and achieve similar classification quality.

# 8 Outlook

Comparison with the state of the art. We compared Witty against the state-of-the-art SAT-based algorithms dtfinder DT1 and dtfinder (Narodytska et al. 2018; Janota and Morgado 2020). We used the improved version of the encoding by Narodytska et al. (2018) that was presented by Janota and Morgado (2020). We also compared Witty against the state-of-the-art dynamic programming based solver, MurTree (Demirovic et al. 2022). Since these algorithms only support binary dimensions, we transformed the data sets following their approach by introducing a binary dimension for each cut indicating whether an example is on the left or right side of the cut. We still used the nonbinarized data sets for Witty.

Figure 2 shows this comparison. Witty solved 57 instances more than dtfinder DT1 which solved 26 instances more than dtfinder. Witty is roughly 61 times (median 25 times) faster than dtfinder DT1. Furthermore, there is only one instance that can be solved by dtfinder or dtfinder DT1 but not by Witty.

MurTree on the other hand solved 371 instances. However, only 341 of these instances were solved by both Witty and MurTree. On these instances, Witty achieved a mean 32-fold (median 7-fold) speedup over MurTree. One notable property of the instances that Witty solved faster than MurTree is that the largest domain size $D$ tends to be a lot bigger than in the instances that MurTree could solve faster than Witty. This can be seen in Figure 3. We assume that the Threshold Subset Constraints from Section 5 are the reason for this: they are particularly effective on dimensions with many thresholds since they allow the algorithm to skip several thresholds within such a dimension.

We also looked at the values of the instance-specific parameters $n , d , \delta , c .$ , and $s$ of these instances. There are two notable observations. First, Witty also tends to perform

We have provided a new fast solver Witty for computing perfect decision trees with a size constraint. While previous algorithms (Narodytska et al. 2018; Janota and Morgado 2020; Demirovic et al. 2022) only support binary dimensions, Witty in particular benefits from dimensions having many thresholds. We conclude with a set of limitations and possible extensions of Witty.

First, we focused on binary classification problems. However, Witty can easily be adapted for more classes: any example having a different class than that of the witness in any leaf is a dirty example; it would be interesting to scrutinize the resulting algorithm on multiclass instances.

Second, it is interesting to adapt and tune Witty to find decision trees with a depth constraint. While this constraint can easily be incorporated into Witty and all of our improvements are still valid, they could be made much tighter and many new improvements are possible that do not apply to the size constraint. For example, once a leaf with maximal depth has been found, the corresponding leaf-to-root path $P$ cannot change anymore. The solution subtrees rooted at vertices in $P$ thus have fixed example sets and can be determined independently of each other.

Finally, it is essential to adapt Witty to looser accuracy guarantees, for instance, to the scenario where a given number $\tau$ of misclassifications are allowed. Gahlawat and Zehavi (2024) showed that the underlying training problem is tractable in theory but the running time of their algorithm is impractical. The witness-tree paradigm could be extended to this problem by replacing dirty examples with a set of $\tau + 1$ dirty examples, of which one needs to be reclassified. While the theoretical running-time guarantee would increase, in practice this drawback could be outweighed by the fact that the size $s$ of the optimal tree could decrease substantially (as shown by the results of YaDT on the benchmark data set).

# Acknowledgments

This work is based on the first author’s Master thesis (Staus 2024). Luca Pascal Staus was supported by the Carl Zeiss Foundation, Germany, within the project “Interactive Inference”. Frank Sommer was supported by the Alexander von Humboldt Foundation and partially supported by the DFG, project EAGR (KO 3669/6-1).