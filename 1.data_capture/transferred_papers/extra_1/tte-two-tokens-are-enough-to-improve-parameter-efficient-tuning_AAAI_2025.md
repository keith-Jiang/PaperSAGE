# TTE: Two Tokens are Enough to Improve Parameter-Efficient Tuning

iacheng Ruan, Mingye Xie, Jingsheng Gao, Xian Gao, Suncheng Xiang, Ting Liu, Yuzhuo Fu\*

Shanghai Jiao Tong University, China jackchenruan $@$ sjtu.edu.cn

# Abstract

Existing fine-tuning paradigms are predominantly characterized by Full Parameter Tuning (FPT) and Parameter-Efficient Tuning (PET). FPT fine-tunes all parameters of a pre-trained model on downstream tasks, whereas PET freezes the pretrained model and employs only a minimal number of learnable parameters for fine-tuning. However, both approaches face issues of overfitting, especially in scenarios where downstream samples are limited. This issue has been thoroughly explored in FPT, but less so in PET. To this end, this paper investigates overfitting in PET, representing a pioneering study in the field. Specifically, across 19 image classification datasets, we employ three classic PET methods (e.g., VPT, Adapter/Adaptformer, and LoRA) and explore various regularization techniques to mitigate overfitting. Regrettably, the results suggest that existing regularization techniques are incompatible with the PET process and may even lead to performance degradation. Consequently, we introduce a new framework named TTE (Two Tokens are Enough), which effectively alleviates overfitting in PET through a novel constraint function based on the learnable tokens. Experiments conducted on 24 datasets across image and few-shot classification tasks demonstrate that our fine-tuning framework not only mitigates overfitting but also significantly enhances PET’s performance. Notably, our TTE framework surpasses the highest-performing FPT framework (DR-Tune), utilizing significantly fewer parameters (0.15M vs. 85.84M) and achieving an improvement of $1 \%$ .

Code — https://github.com/JCruan519/TTE pre-trained model remains frozen, and only a small portion of parameters is introduced or adjusted to acquire the downstream knowledge. Benefiting from large-scale, pretrained datasets and the diversity of downstream tasks, this fine-tuning paradigm has been extensively developed in various fields, including computer vision (Zhong et al. 2020; Zhang et al. 2021; Jia et al. 2022; Chen et al. 2022), natural language processing (Houlsby et al. 2019; Hu et al. 2021; Zaken, Ravfogel, and Goldberg 2021), and multimodal domains (Gao et al. 2021; Khattak et al. 2023; Gao et al. 2024). However, both fine-tuning paradigms are afflicted by overfitting issues (Zheng et al. 2023; Zhuang et al. 2020), which detrimentally affect the fine-tuning performance on downstream tasks. In FPT, a variety of regularization frameworks have been proposed to mitigate this issue (Zhong et al. 2020; Zhang et al. 2021; You et al. 2020; Zhou, Chen, and Huang 2023). For instance, DR-Tune (Zhou, Chen, and Huang 2023), the leading FPT framework, integrates distribution regularization and semantic calibration techniques to avoid overfitting and improve performance. In PET, although considerable research has focused on optimizing performance via well-designed modules (Zhang, Zhou, and Liu 2022; Lian et al. 2022; Jie and Deng 2022; Luo et al. 2023a; Dong et al. 2023; Jiang et al. 2023), the overfitting issues and regularization frameworks remains underexplored.

# Introduction

The fine-tuning paradigm utilizes parameters learned during the pre-training phase as the initialization for the finetuning process, leveraging prior knowledge for enhanced downstream adaptation. Existing fine-tuning paradigms can be categorized into Full Parameter Tuning (FPT) and Parameter-Efficient Tuning (PET) based on whether the model’s pre-trained parameters are frozen. In FPT, the pretrained parameters serve as the initialization, and all model parameters are fine-tuned to accommodate the distribution changes of downstream tasks. In PET, the backbone of the

In this paper, we conduct a pioneering study on the overfitting phenomena in PET, as shown in Figure 1. Specifically, we examine the performance of three classic PET architectures: VPT (Jia et al. 2022), Adapter/AdaptFormer1 (Houlsby et al. 2019; Chen et al. 2022), and LoRA (Hu et al. 2021), on the VTAB-1K benchmark (Zhai et al. 2019). The results reveal that all these PET structures exhibit significant overfitting issues. In (Han et al. 2024), the authors addressed the overfitting of VPT by increasing the number of training samples. Correspondingly, we intuitively reduced the number of parameters introduced by PET while maintaining a fixed number of samples; however, this approach failed to significantly mitigate overfitting and led to decreased performance. Furthermore, we explored the use of various regularization strategies to mitigate the overfitting problem in

![](images/020330bc6056f5dc212f5aa303bf44b3e88597b63967a8b86a2af70fad86923f.jpg)  
Figure 1: Performance and Average Train loss (Blue) vs. Eval loss (Red) on the VTAB-1K benchmark with different PET methods. The y-axis represents the loss value, and $\mathbf { \boldsymbol { x } }$ -axis is the epoch. Vanilla $( 5 0 \% )$ indicates that the parameter count introduced by PET is reduced by half. For instance, Vanilla VPT introduces 20 learnable tokens, while Vanilla $( 5 0 \% )$ VPT introduces 10 learnable tokens. Besides, DR-Tune and TTE indicates that employing various regularization frameworks based on Vanilla.

PET. Unfortunately, the advanced DR-Tune (Zhou, Chen, and Huang 2023) regularization framework proved ineffective in adapting to the PET process and subsequently impaired the fine-tuning performance. Thus, the development of a specialized regularization framework tailored for the PET process has emerged as the central focus of this study.

Consequently, we propose a simple yet effective regularization framework named TTE (Two Tokens are Enough), designed to mitigate overfitting in PET methods and enhance performance on downstream tasks. Our TTE framework is built upon a learnable token module and an innovative constraint function, facilitating seamless integration into existing PET techniques. Specifically, the learnable token module comprises a globally learnable token $( t ^ { g } )$ , an instance-specific token $( t ^ { i n } )$ tailored according to the input, and an adaptive dropout operation. After concatenating the two tokens followed by adaptive dropout, they are further appended to the input sequence of the Transformer, contributing to both forward and backward computations alongside the learnable parameters introduced by PET. Furthermore, in classification tasks, in addition to utilizing crossentropy loss for optimization, we also develop a regularization loss termed the Parameter-Free Cross Attention (PFCA) loss, based on $t ^ { g } , \ t ^ { i n }$ , and the inherent CLS token of the Transformer. This approach effectively alleviates overfitting and enhances the fine-tuning performance of PET methods. For instance, as shown in Figure 1, our TTE framework has achieved significant mitigation of the overfitting issue and an average improvement in performance by $3 . 3 6 \%$ on the

# VTAB-1K benchmark.

The principal contributions of this paper are summarized as follows: 1) For the first time, we present an investigation of the overfitting issue in PET methods, and explore mitigation strategies through various regularization frameworks. Preliminary experiments suggest that existing regularization frameworks are incompatible with PET techniques and may even lead to diminished fine-tuning performance. 2) We introduce a novel framework named TTE, which includes a learnable token module and a regularization constraint function, designed to alleviate the overfitting problem in existing PET methods. 3) Extensive experiments are conducted on the VTAB-1K benchmark, encompassing 19 image classification datasets, and the FGVC benchmark, which includes 5 fine-grained few-shot datasets. The results demonstrate that our framework integrates seamlessly with existing PET processes, enhancing fine-tuning performance by an average of $3 . 3 6 \%$ on the VTAB-1K benchmark without a significant increase in parameter count. It is noteworthy that, with a significantly lower total number of trainable parameters compared to DR-Tune, the currently optimal FPT framework ( $8 5 . 8 4 \mathrm { M } ~ \nu s . ~ 0 . 1 5 \mathrm { M } )$ , our TTE achieves superior performance $( 1 \% \uparrow )$ .

# Related Works

# Regularization frameworks in FPT

In the study of the FPT framework, applying regularization techniques is a popular approach. In (Xuhong, Grandvalet, and Davoine 2018), the authors utilize L2 penalty regularization to retain more pretrained model features, thereby enhancing transfer learning in convolutional networks. DRTune (Zhou, Chen, and Huang 2023) represents state-of-theart work in the design of the FPT framework, introducing distribution regularization and semantic alignment to improve the fine-tuning process of pretrained visual models.

However, the regularization terms introduced in these methods are designed for the FPT framework, requiring all parameters to be updatable during fine-tuning. In the PET process, only a small fraction of parameters are updatable, posing challenges to designing compatible regularization terms. Thus, in this paper, we leverage the prior knowledge of pre-trained models along with downstream task knowledge to introduce more comprehensive and refined regularization constraints for PET methods.

# Parameter-Efficient Tuning

Parameter-Efficient Tuning (PET) is a novel fine-tuning paradigm introduced in recent years, widely applied to the fine-tuning of Transformer-based models. PET techniques freeze the pre-trained backbone and incorporate learnable modules to obtain the specific knowledge of downstream tasks. According to (Yu et al. 2023), existing PET methods mainly include Prompt Tuning, Adapter Tuning, and Parameter Tuning, represented by VPT (Jia et al. 2022), S-Ada./PAda. (Houlsby et al. 2019; Chen et al. 2022), and LoRA (Hu et al. 2021), respectively.

Moreover, numerous innovative PET techniques such as SSF (Lian et al. 2022), FacT (Jie and Deng 2023), ResTuning (Jiang et al. 2023), RLRR (Dong et al. 2024), and others (Luo et al. 2023a; Fu, Zhu, and Wu 2024; Dong et al. 2023; Zhang et al. 2023; Yin, Li, and Zhang 2023; Jie, Wang, and Deng 2023; Ruan et al. 2024b,a,c) have also been proposed to improve performance. However, existing techniques mainly focus on well-designed modules but often overlook the overfitting issue and the importance of regularization constraints during fine-tuning. Therefore, we propose TTE framework, which introduces regularization constraints based on learnable tokens to further unleash the potential of PET methods.

# Empirical Studies

In this section, we conduct an exploration of the overfitting phenomenon for three classical PET methods, including VPT (Jia et al. 2022), S-Ada./P-Ada (Houlsby et al. 2019; Chen et al. 2022). and LoRA (Hu et al. 2021) on the VTAB1K benchmark (Zhai et al. 2019). The experimental settings are the same as illustrated in the Experiments Section.

As shown in Figure 1, the changes in loss values of these classic PET techniques during the training process are visualized. For the VTAB benchmark’s 19 image classification tasks, each task is equipped with only 1,000 training samples and approximately 20,000 test samples. Thus, it is evident that due to the limited training samples for the downstream tasks, these PET techniques all suffer from significant overfitting issues. This phenomenon is similarly observed in (Han et al. 2024). Previous work (Han et al. 2024)

Table 1: Mean Accuracy $( \% )$ on VTAB-1K. The existing regularization methods are insufficient to effectively alleviate the issue of overfitting in PET, and may even lead to decreased performance.   

<html><body><table><tr><td>Reg.</td><td colspan="7">Vanilla </td></tr><tr><td>PET</td><td></td><td>L1</td><td>L2</td><td>USKD</td><td>DR-Tune</td><td>TTE</td></tr><tr><td>VPT</td><td>62.41</td><td>63.01</td><td>62.84</td><td>61.70</td><td>61.60</td><td>66.44</td></tr><tr><td>S-Ada.</td><td>71.55</td><td>72.13</td><td>72.03</td><td>72.91</td><td>71.41</td><td>75.06</td></tr><tr><td>P-Ada.</td><td>71.35</td><td>69.86</td><td>70.72</td><td>70.60</td><td>70.85</td><td>75.24</td></tr><tr><td>LoRA</td><td>70.43</td><td>70.17</td><td>70.01</td><td>68.46</td><td>70.56</td><td>72.45</td></tr></table></body></html>

has addressed overfitting by fixing the parameter count of VPT and increasing the number of training samples. Correspondingly, we first attempt the most intuitive strategy of fixing the number of training samples while reducing the parameter count of PET methods, with the results shown in the second row of Figure 1. It can be observed that reducing the number of parameters does not significantly impact overfitting and can lead to a degradation in performance. Thus, we attempt to introduce regularization constraint for mitigating the overfitting issues.

Further, we investigate three distinct regularization strategies to address the overfitting issue in PET: traditional methods (e.g., L1 and L2 penalty), self-knowledge distillationbased regularization (e.g., USKD (Yang et al. 2023)), and advanced frameworks employed in FPT, such as DR-Tune (Zhou, Chen, and Huang 2023). As demonstrated in Table 1, the application of conventional regularization techniques during the PET process generally results in varying degrees of performance degradation. For instance, even the advanced DR-Tune framework fails to impose effective constraints on PET, particularly for VPT, where the constraints of DR-Tune lead to a $0 . 8 1 \%$ performance decline. Furthermore, as illustrated in Figure 1, this observation underscores that DRTune is ineffective in mitigating the overfitting issue in PET.

One possible reason could be that most regularization methods are typically applied under the condition that all model parameters are updatable, a scenario suitable for pretraining and FPT. However, in PET, typically only about $0 . 5 \%$ of the parameters are learnable. In scenarios with limited training samples, when only a small number of parameters are updatable, the use of conventional regularization constraints may lead to local optima due to insufficiently comprehensive and precise constraints, thus failing to effectively mitigate overfitting (Xu et al. 2023; Luo et al. 2023b). Therefore, in this paper, we introduce learnable and instance-based tokens to capture global and instancespecific information, thereby formulating more comprehensive regularization constraints that effectively alleviate overfitting in the PET process and enhance performance.

# Methods

# TTE framework

In the process of Parameter-Efficient Tuning (PET) for a Vision Transformer (ViT) (Dosovitskiy et al. 2020) with $N$ layers, the input image is transformed through an embedding operation into $E _ { 0 } \in \mathbb { R } ^ { l \times d }$ , where $l$ represents the sequence length and $d$ stands for the embedding dimension. Subsequently, $E _ { 0 }$ and the CLS token $c _ { 0 } \in \mathbb { R } ^ { 1 \times d }$ are concatenated to form the input. The entire process can be represented as follows.

![](images/4fd2980fb11ef15fa14aa361e5903fd21ba74f5c3a75e5fe1053e8bd4afdb406.jpg)  
$E _ { 0 } / E _ { N }$ : The input/output image tokens $t ^ { g } / t _ { 0 } ^ { g } / t _ { N } ^ { g }$ : The initial/input/output globally learnable token $t ^ { i n } / t _ { 0 } ^ { i n } / t _ { N } ^ { i n } ;$ : The initial/input/output instance-specific token   
Figure 2: The overall architecture of our TTE framework, which consists of a Learnable Token Module and a Parameter-Free Cross Attention Loss.

$$
\begin{array} { c c } { { [ c _ { i } , E _ { i } ] = L _ { i } ( [ c _ { i - 1 } , E _ { i - 1 } ] ; \Theta _ { i } , \theta _ { i } ) } } & { { \quad i = 1 , 2 , \cdots , N } } \\ { { s _ { c } = \mathrm { H e a d } ( c _ { N } ) } } & { { } } \end{array}
$$

where each layer $L _ { i }$ comprises a multi-head self-attention module (MHSA) and a feed-forward network (FFN). $\Theta _ { i }$ denotes the backbone parameters of the $i$ -th layer, which are frozen during the PET process. $\theta _ { i }$ represents newly introduced learnable parameters, employed to acquire specific knowledge for downstream tasks. $[ \cdot , \cdot ]$ signifies the concatenation operation. Head is the trainable linear classification head, which generates logits $( s _ { c } )$ from the CLS token of the last layer $( c _ { N } )$ .

In the TTE framework, as illustrated in Figure 2 (a), the PET process involves the introduction of two tokens: a globally learnable token $( t ^ { g } )$ and a token derived from the image instance $( t ^ { i n } )$ . These two tokens, together with the inherent CLS token of the ViT, facilitate the computation of the Parameter-Free Cross Attention loss, serving effectively as a regularization to mitigate overfitting. This process is delineated as follows:

$$
\begin{array} { r l } { [ c _ { i } , t _ { i } ^ { g } , t _ { i } ^ { i n } , E _ { i } ] = L _ { i } ( [ c _ { i - 1 } , t _ { i - 1 } ^ { g } , t _ { i - 1 } ^ { i n } , E _ { i - 1 } ] ; \Theta _ { i } , \theta _ { i } ) } & { { } i = 1 , 2 , \cdots , N } \\ { s _ { c } = \mathrm { H e a d } ( c _ { N } ) ; } & { { } s _ { g } = \mathrm { H e a d } ( t _ { N } ^ { g } ) } \\ { \mathcal { L } _ { a l l } = \mathcal { L } _ { c e } ( s _ { c } , y ) + \alpha \mathcal { L } _ { c e } ( s _ { g } , y ) + \beta \mathcal { L } _ { p f c a } ( c _ { N } , t _ { N } ^ { g } , t _ { N } ^ { i n } ) } & { { } } \end{array}
$$

where the logits $s _ { g }$ is derived from the last layer’s $t _ { N } ^ { g }$ via the classification head. $\mathcal { L } _ { a l l }$ , $\mathcal { L } _ { c e }$ , and $\mathcal { L } _ { p f c a }$ respectively denote the total loss, cross-entropy loss, and the ParameterFree Cross Attention loss, which provide regularization constraints in the TTE framework. $\alpha$ and $\beta$ represent the weight coefficients. Note that we only utilize $s _ { c }$ as the final decision for classification during inference.

# Learnable Token Module

As depicted in Figure 2(b), we present our Learnable Token Module. It comprises a linear projection $W _ { i n } \in \mathbb { R } ^ { 1 \times l }$ that extracts instance information from the input image, yielding $t ^ { i n } ~ \in ~ \mathbb { R } ^ { 1 \times d }$ . Additionally, a globally learnable token $( t ^ { \breve { g } } \in \mathbb { R } ^ { 1 \times d } ,$ ) is introduced to capture the representation of the entire downstream dataset. A dropout operation is then applied to these two tokens, thereby enhancing the robustness of the instance information embedded in $t ^ { i n }$ and the global information inherent in $t ^ { g }$ . However, given the diversity of downstream tasks, searching for a suitable mask ratio for each dataset proves impractical. Consequently, an adaptive dropout is introduced, applied to $t ^ { i n }$ and $t ^ { g }$ , resulting in $t _ { 0 } ^ { g }$ and $t _ { 0 } ^ { i n }$ , which are utilized in the subsequent input sequence. As illustrated in Figure 3, the adaptive dropout has a learnable mask ratio, enabling adaptive adjustment of the dropout intensity according to different downstream tasks.

# Parameter-Free Cross Attention Loss

As illustrated in Figure 2 (c), we introduce the ParameterFree Cross Attention Loss (PFCA loss). The loss function takes three inputs: $c _ { N } \in \mathbb { R } ^ { 1 \times d }$ , $t _ { N } ^ { g } \in \mathbb { R } ^ { 1 \times d }$ , and $t _ { N } ^ { i n } \in \mathbb { R } ^ { 1 \times d }$ , all derived from the final layer of the ViT. Without incorporating any linear transformation layers, $c _ { N }$ serves directly as both key and value, with $t _ { N } ^ { g }$ as the query. The query, key and value are input into the Parameter-Free Cross Attention (PFCA) mechanism, yielding the output $O _ { 1 } \in \mathbb { R } ^ { 1 \times d }$ . Similarly, $t _ { N } ^ { i n }$ acts as both key and value with $t _ { N } ^ { g }$ as the query, subsequently entered into the PFCA to produce the output $O _ { 2 } \in \mathbb { R } ^ { 1 \times \check { d } }$ . Finally, the mean squared error between $O _ { 1 }$ and $O _ { 2 }$ is computed to serve as the output of PFCA loss.

# How does TTE work?

The TTE framework introduces the globally learnable token $t ^ { g }$ and the instance-based token $t ^ { i n }$ , which is derived from the input image instance. Moreover, the CLS token, encapsulating the pre-trained knowledge, is also utilized in the calculation of our PFCA loss. The CLS token is learnable during the pre-training phase while frozen during fine-tuning, hence the pre-trained knowledge it embodies remains unchanged during the PET process. Additionally, for $t ^ { g }$ , an ex

The Pytorch-style code for Adaptive Dropout   
class AdaptiveDropout(nn.Module): def __init__(self, ${ \mathsf { p } } { = } { \mathsf { \boldsymbol { \theta } } } . 9 )$ : super(AdaptiveDropout, self).__init__() ${ \textsf { p } } =$ torch.log(torch.tensor(p / (1 - p))) self.p $\mathbf { \sigma } = \mathbf { \sigma }$ nn.Parameter(p) def forward(self, x): if self.training: ${ \textsf { p } } =$ torch.sigmoid(self.p) mask_ratio $\mathbf { \Sigma } = \mathbf { \Sigma }$ (1-p) $*$ torch.ones_like(x) binary_mask $\mathbf { \sigma } = \mathbf { \sigma }$ torch.Bernoulli(mask_ratio) return binary_mask $* \times /$ (1-p) return x

tra cross-entropy loss is introduced between it and the true labels, enabling it to learn a more comprehensive representation of the downstream task. Finally, $\dot { t } ^ { i n }$ varies according to the input image, capturing more specific and detailed instance information. In other words, through pre-training, the CLS token acquires the most extensive and general knowledge from the large-scale pre-training data. Via fine-tuning, $t ^ { g }$ obtains global knowledge of the downstream task, which is less extensive than that captured by the CLS token. Furthermore, $t ^ { i n }$ represents the instance information of each input image, embodying the most detailed knowledge.

Subsequently, using $t ^ { g }$ , which is positioned centrally in terms of knowledge breadth, as a medium, we perform a cross-attention calculation between $t ^ { g }$ and CLS token to facilitate the interaction between downstream global information and pre-trained knowledge. The output is denoted as $O _ { 1 }$ . Another cross-attention calculation is conducted between $t ^ { g }$ and $t ^ { i n }$ to promote the interaction between downstream global information and instance-specific information, with the resulting output denoted as $O _ { 2 }$ . Finally, a mean square error is calculated between $O _ { 1 }$ and $O _ { 2 }$ to construct a more comprehensive and detailed regularization constraint. This helps alleviate overfitting during the PET process and enhances fine-tuning performance.

# Experiments

# Datasets and metrics

Image classification tasks. We utilize the VTAB-1K benchmark (Zhai et al. 2019) to validate our TTE framework for image classification tasks. Specifically, VTAB-1K includes 19 different datasets, which can be categorized into three groups: Natural, Specialized, and Structured. Each dataset consists of 1,000 samples for training, with an average of 20,000 samples for testing, making it a highly challenging benchmark. Following the empirical setting (Lian et al. 2022), for each dataset, we report the Top-1 accuracy on the test set. For the entire benchmark, we present the arithmetic mean of the Top-1 accuracy.

Fine-grained few-shot tasks. In a few-shot setting, we validate the performance of our framework in the lowdata regime using Food-101 (Bossard, Guillaumin, and Van Gool 2014), OxfordPets (Parkhi et al. 2012), Stanford Cars (Krause et al. 2013), Oxford-Flowers102 (Nilsback and Zisserman 2006), and FGVC-Aircraft (Maji et al. 2013)

datasets. Following the empirical setting (Zhang, Zhou, and Liu 2022; Jie and Deng 2023), we conduct validation under $\{ 1 , 2 , 4 , 8 , 1 6 \}$ -shot settings and report the Top-1 accuracy.

# Implementation details

For the VTAB-1K benchmark and FGVC datasets, we employ the ViT-B/16 (Dosovitskiy et al. 2020) model, pretrained on the ImageNet-21K dataset (Deng et al. 2009), as the backbone. For PET methods, unless specifically stated otherwise, we fix the length of the learnable token introduced by VPT (Jia et al. 2022) at 20, set the hidden layer dimensions of S-Ada. (Houlsby et al. 2019) and P-Ada. (Chen et al. 2022) to 4, fix the scaling factor at 0.1, set the rank of LoRA (Hu et al. 2021) at 4, and the scaling factor at 1. In terms of training configurations, we follow the work of predecessors (Lian et al. 2022; Jie and Deng 2023; Luo et al. 2023a), to ensure fairness and reproducibility.

Regarding our TTE framework, to avoid redundancy brought about by further hyperparameter adjustment, we fix temperature $\alpha$ at 0.5, and only allow $\beta$ to be searched from $\{ 0 . 2 5 , 0 . 5 , 0 . 7 5 \}$ . Pytorch (Paszke et al. 2019) and Transformers (Wolf et al. 2020) are utilized to implement experiments on NVIDIA A100 GPUs.

# Main results

Comparative Results on VTAB-1K We conduct a comprehensive validation of the TTE framework using the VTAB-1K benchmark, with the results presented in Table 2. Initially, we apply the TTE framework to three distinct PET techniques—Prompt Tuning (VPT (Jia et al. 2022)), Adapter Tuning (S-Ada. (Houlsby et al. 2019) and P-Ada. (Chen et al. 2022)), and Parameter Tuning (LoRA (Hu et al. 2021))—as described in (Yu et al. 2023), during the finetuning phase. The results indicate that our framework significantly enhances these classical techniques by an average of $3 . 3 6 \%$ , while maintaining a comparable parameter count. Moreover, to our knowledge, P-Ada. $\dagger$ has surpassed recent state-of-the-art methods. For instance, when compared to RLRR (Dong et al. 2024), P-Ada. $\dagger$ achieves an improvement of $0 . 1 3 \%$ , whilst necessitating only $40 \%$ of the parameters.

Comparative Results on FGVC As shown in Figure 4, comprehensive validation is conducted in a few-shot scenario. The PET methods employed include VPT (Jia et al. 2022), S-Ada (Houlsby et al. 2019), and LoRA (Hu et al. 2021), each fine-tuned both with and without the proposed TTE framework. Overall, even within this constrained fewshot setting, various PET methods combined with our TTE framework are shown to improve performance without an increase in the number of trainable parameters. On average, for three different PET methods, our TTE framework achieves improvements of $2 . 2 7 \%$ , $1 . 5 2 \%$ , $1 . 3 5 \%$ , $1 . 4 1 \%$ , and $1 . 2 2 \%$ under the settings of $\{ 1 , 2 , 4 , 8 , 1 6 \}$ -shot.

Comparative Results with Full Parameter Tuning Framework As illustrated in Table 3, we conduct comparisons of TTE with Full Parameter Tuning frameworks in transfer learning (e.g., Core-tuning (Zhang et al. 2021) and DR-Tune (Zhou, Chen, and Huang 2023)). The results suggest that our P-Ada. $\dagger$ surpasses DR-Tune by $1 \%$ , currently

<html><body><table><tr><td colspan="2"></td><td>Natural</td><td>Specialized</td><td>Structured</td><td></td></tr><tr><td colspan="2">Methods Comments</td><td>s1ed NHAS L69uns</td><td></td><td>o/saidsp</td><td>△</td></tr><tr><td colspan="4"></td></tr><tr><td colspan="2"></td><td></td><td>RecentSOTAmethods</td><td></td></tr><tr><td>ARC</td><td></td><td></td><td>NeurIPS2371.290.975.999.592.190.8 52.087.496.587.676.483.361.154.681.781.057.030.941.374.27</td><td>0.13</td></tr><tr><td>Res-T.</td><td></td><td>NeurIPS2375.292.771.9 99.391.9 86.7 58.586.795.6 85.074.680.2 63.6 50.6 80.2 85.4 55.731.9 42.074.09</td><td></td><td>0.55</td></tr><tr><td>SPT</td><td>Arxiv24</td><td>79.3 92.6 73.2 99.5 91.0 89.1 51.285.4 96.8 84.9 74.870.3 64.8 54.2 75.2 79.3 49.5 36.5 41.573.11</td><td></td><td>0.22</td></tr><tr><td colspan="2">LAST Arxiv24</td><td>66.7 93.4 76.1 99.6 89.8 86.1 54.386.2 96.3 86.8 75.481.9 659 49.4 82.6 87.9 46.7 32.3 51.574.15</td><td></td><td>0.66</td></tr><tr><td>RLRR</td><td>Arxiv24</td><td></td><td>76.7 92.7 76.3 99.6 92.6 91.8 56.0|87.8 96.2 89.1 76.380.4 63.3 54.5 83.3 83.0 53.7 32.0 41.775.11</td><td>0.33</td></tr><tr><td colspan="2"></td><td>Prompttuningmethods</td><td></td><td></td></tr><tr><td colspan="2">VPT ECCV22 60.5 90.6 70.6 99.1 89.3 50.1 50.882.2 93.8 82.5 74.950.6 58.9 41.0 68.1 39.0 32.4 22.3 29.162.41 VPT† Ours</td><td colspan="2">66.5 92.8 73.2 99.2 89.9 84.0 50.581.5 94.0 83.4 73.848.4 63.1 43.0 73.6 57.035.724.3 28.566.44 4.03↑ 0.06</td></tr><tr><td colspan="2"></td><td colspan="2"></td></tr><tr><td colspan="2">70.1 93.5 74.9 99.591.787.2 51.486.9 96.6 87.8 76.984.3 34.5 53.8 80.2 72.8 54.8 22.4 40.271.55</td><td colspan="2">Adaptertuningmethods</td></tr><tr><td>S-Ada. S-Ada.t</td><td>ICML19</td><td>77.4 94.5 77.1 99.7 92.6 90.0 55.288.4 96.2 89.1 76.2|85.5 62.7 52.6 83.0 80.1 54.0 28.743.175.06 3.51↑ 0.13</td><td>0.13</td></tr><tr><td>P-Ada.</td><td>Ours</td><td>NeurIPS2270.4 92.2 74.5 99.491.3 79.151.583.2 96.4 87.776.283.760.353.5 74.6 56.6 54.4 28.342.371.35-0.13</td><td></td></tr><tr><td>P-Ada.t</td><td>Ours</td><td colspan="2">78.6 94.0 77.5 99.7 92.3 90.0 55.887.8 96.5 88.5 76.884.3 62.6 53.3 83.8 81.1 52.9 28.9 45.175.24 3.89↑ 0.13</td></tr><tr><td colspan="2">Parametertuningmethods ICLR21</td><td colspan="2">65.9 91.3 73.6 99.3 91.7 83.2 51.0|84.0 96.2 87.3 76.271.2 57.8 50.5 78.1 58.4 53.2 28.141.170.43 0.19</td></tr></table></body></html>

† denotes employing PET techniques within our TTE framework.

Table 2: Performance and efficiency comparison on the VTAB-1K benchmark with ViT-B/16 (Dosovitskiy et al. 2020) pre trained on ImageNet-21K (Deng et al. 2009). “All Mean” denotes the average accuracy of 19 tasks.

![](images/632f23b6d5ed55e40e0330e38981a1f44eb0fd85d13d48c1311892f759c92cd2.jpg)

Figure 4: Top-1 accuracy of few-shot learning on FGVC datasets. The trainable parameters (M) is shown in parentheses

Table 3: Comparative results with other FPT frameworks.   

<html><body><table><tr><td>Method</td><td colspan="7">Params.(M) Mean|CIFAR-100 Caltech101 DTD Flowers102 Pets</td></tr><tr><td>P-Ada.†(ours)</td><td>0.15</td><td>88.4</td><td>78.6</td><td>94.0</td><td>77.5</td><td>99.7</td><td>92.3</td></tr><tr><td>Core-tuning</td><td>85.84</td><td>83.6</td><td>66.3</td><td>89.7</td><td>70.9</td><td>99.0</td><td>92.3</td></tr><tr><td>DR-Tune</td><td>85.84</td><td>87.4</td><td>81.1</td><td>92.8</td><td>71.4</td><td>99.3</td><td>92.4</td></tr></table></body></html>

recognized as the state-of-the-art FPT framework. Furthermore, it is significant that we achieve a reduction in the trainable parameters during the fine-tuning process by 572x.

# Ablation studies

Extensive ablation experiments are conducted on the VTAB1K benchmark. Unless otherwise specified, the ViT-B/16, pre-trained on the ImageNet-21K, is employed as the backbone, and P-Ada. (Chen et al. 2022) is utilized as the PET method. Furthermore, the symbol $\dagger$ indicates the use of the PET method within our TTE framework, and the arithmetic mean of the Top-1 accuracy is displayed.

The impact of loss function As shown in Equation 2, in addition to the standard classification loss function $\mathcal { L } _ { c e } ( S _ { c } , y )$ , our TTE framework employs two additional loss functions to optimize the PET process: $\mathcal { L } _ { c e } ( S _ { g } , y )$ and $\mathcal { L } _ { p f c a }$ . As demonstrated in Table 4a, we present the performance of different combinations. Clearly, as the number of loss terms increases, the effectiveness of our method also improves. Firstly, by introducing $\mathcal { L } _ { c e } ( S _ { g } , y )$ on top of $\mathcal { L } _ { c e } ( S _ { c } , y )$ , we achieve a $1 . 5 \%$ gain, indicating that providing real labels to the globally learnable token $( t ^ { g } )$ allows it to acquire more accurate global information. Secondly, the introduction of $\mathcal { L } _ { p f c a }$ on top of $\mathcal { L } _ { c e } ( S _ { c } , y )$ results in nearly a $3 \%$ improvement. This significant enhancement further underscores the importance of regularization constraints between pretrained knowledge (represented by the CLS token), global information (represented by $t ^ { g }$ ), and instance information (represented by $t ^ { i n }$ ).

Table 4: The main ablation studies for our TTE framework: (a) loss function utilization in TTE ( $\cdot \mathbf { L } _ { 1 }$ is $\mathcal { L } _ { c e } ( S _ { c } , y )$ , $L _ { 2 }$ is $\mathcal { L } _ { c e } ( S _ { g } , y )$ , $L _ { 3 }$ is $\mathcal { L } _ { p f c a . }$ ). (b) various losses in PFCA loss. (c) token length for $t ^ { g }$ and $t ^ { i n }$ . (d) initialization for mask ratio in Adaptive Dropout. (e) different size of backbone (S is ViT-S/16, L is ViT-L/16). (f) Backbone is Swin-B. Acc.: Top-1 Mean accuracy on the VTAB-1K $( \% )$ . For (a) ${ \sim } ( \mathrm { d } )$ , our baseline is Vanilla P-Ada., which achieves $7 1 . 3 5 \%$ Acc. on the VTAB-1K.   

<html><body><table><tr><td colspan="4">L1 L2 L3|Acc.</td><td rowspan="2">Loss Acc.</td><td rowspan="2"></td><td rowspan="2">Len.|Param. (K) Acc.</td><td rowspan="2"></td><td rowspan="2">Ratiol</td><td rowspan="2">Acc.</td><td rowspan="2">Method</td><td colspan="2" rowspan="2">|Param. (M) Acc.</td><td rowspan="2"></td><td rowspan="2">Method |Param. (M) Acc.</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>Lmse</td><td></td><td></td><td></td><td></td><td></td><td>0.5</td><td></td><td>StPA</td><td></td><td>70</td><td></td><td></td></tr><tr><td></td><td></td><td>√ 72</td><td>LCmge75.24</td><td></td><td>15</td><td>10</td><td>75.24</td><td></td><td>72.92</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>√√75.24</td><td></td><td>Lcos</td><td>73.27</td><td>10</td><td>9.7</td><td>69.97</td><td></td><td>0.9 75.24</td><td></td><td>L+P-Ada.t</td><td>0.30</td><td>75.36</td><td>P-Ada.t</td><td>0.21 75.43</td></tr><tr><td colspan="3">(a)</td><td colspan="2">(b)</td><td colspan="3">(c)</td><td colspan="2">(d)</td><td colspan="3">(e)</td><td colspan="2">(f)</td></tr></table></body></html>

Furthermore, as depicted in Figure 2, we use the mean squared error loss at the end of the PFCA loss to narrow the gap between general knowledge and downstream knowledge. As alternatives to the mean squared error loss, we employ mean absolute error loss and cosine loss to demonstrate the versatility of PFCA loss. As shown in Table 4b, even with the simpler $\mathcal { L } _ { m a e }$ and $\mathcal { L } _ { c o s }$ , our TTE framework achieves improvements of $2 . 8 4 \%$ and $1 . 9 2 \%$ compared to the Vanilla $\mathrm { \bf P }$ -Ada., respectively. This adequately demonstrates that constructing regularization constraints to bridge the gap between global and instance information is highly effective in the PET process.

The impact of token length We increase the token lengths of $t ^ { g }$ and $t ^ { i n }$ , as detailed in Table 4c. Observations indicate that as the introduced token length increases, the fine-tuning performance significantly decreases. A possible explanation for this phenomenon is that the PET introduces a relatively small amount of trainable parameters during fine-tuning. If our TTE framework further introduces an excessive amount of parameters, it may lead to insufficient learning, resulting in constraint deviation and even a decline in performance.

The impact of the initialization of mask ratio In Table 4d, we compare the effects of various initial values of the mask ratio for Adaptive Dropout. The results suggest that as the initial mask ratio increases, our method exhibits enhanced performance. Consequently, in this paper, we have selected an initial mask ratio of 0.9.

The impact of different backbones First, to illustrate the versatility of our TTE across models of varying sizes, we substitute ViT-B/16 with ViT-S/16 and ViT-L/16, as detailed in Table 4e. Next, to highlight our framework’s adaptability to different network structures, we conduct experiments using Swin-B (Liu et al. 2021) as the backbone, as presented in Table 4f. As evident from Tables 4e and 4f, regardless of whether we modify the model size or transition to an alternate backbone, our TTE consistently bolsters performance without an increase in parameters.

![](images/09cec11e19edcd914cf023c64fb14734cd5674d62f1da61b942c7f54bbcfb1a2.jpg)  
Figure 5: Left: The attention map visualization on Sun397 dataset. Right: The t-SNE visualization on SVHN dataset.

# Visualization

We perform attention map and t-SNE (Van der Maaten and Hinton 2008) visualization analysis, as depicted in Figure 5. For this purpose, we extract the CLS token following the final Transformer layer and preceding the linear classification head. Notably, upon integrating the TTE framework, attention becomes more focused on the target object, and the classification clusters become more condensed.

# Conclusions

In this paper, we first conduct a preliminary exploration of the overfitting phenomenon during the PET process and find that existing regularization methods are incompatible with PET. Further, we propose TTE framework, which utilizes both global and instance tokens to fully capture downstream information and construct regularization constraints with pre-trained knowledge. The TTE effectively mitigates overfitting in the PET process and further enhances finetuning performance, while introducing minimal additional parameters. Extensive experiments demonstrate the effectiveness and universality of our framework.