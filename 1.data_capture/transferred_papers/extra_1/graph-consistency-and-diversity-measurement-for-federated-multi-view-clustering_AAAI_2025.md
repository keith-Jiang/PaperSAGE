# Graph Consistency and Diversity Measurement for Federated Multi-View Clustering

Bohang $\mathbf { S u n } ^ { 1 }$ , Yongjian Deng1, Yuena $\mathbf { L i n } ^ { 1 , 2 }$ , Qiuru Hai1, Zhen Yang1, Gengyu Lyu1

1College of Computer Science, Beijing University of Technology 2Idealism Beijing Technology Co., Ltd. sunbohang@emails.bjut.edu.cn, yjdeng $@$ bjut.edu.cn, yuenalin $@$ 126.com, haiqiuru $@$ emails.bjut.edu.cn, yangzhen $@$ bjut.edu.cn, lyugengyu@gmail.com

# Abstract

Federated Multi-View Clustering (FMVC) aims to learn a global clustering model from heterogeneous data distributed across different devices, where each device only stores one view of all clustering samples. The key to deal with such problem lies in how to effectively fuse these heterogeneous samples while strictly preserve the data privacy across multiple devices. In this paper, we propose a novel structural graph learning framework named MGCD, which leverages both consistency and diversity of multi-view graph structure across global view-fusion server and local view-specific clients to achieve desired clustering while better preserves data privacy. Specifically, in each local client, we design a dual autoencoder to extract the latent consensuses and specificities of each view, where self-representation construction is introduced to generate the corresponding view-specific diversity graph. In the global server, the consistency implied in uploaded diversity graphs are further distilled and then incorporated into the consistency graph for subsequent cross-view contrastive fusion. During the training process, the server generates a global consistency graph and distributes it to each client for assisting in diversity graph construction, while the clients extract view-specific information and upload it to the server for more reliable consistency graph generation. The ‚Äúserver-client‚Äù interaction is conducted in an iterative manner, where the consistency implied in each local client is gradually aggregated into the global consistency graph, and the final clustering results are obtained by spectral clustering on the desired global consistency graph. Extensive experiments on various datasets have demonstrated the effectiveness of our proposed method on clustering federated multi-view data.

# Introduction

Multi-view data is usually collected from multiple sources, which is represented by several heterogeneous features. For instance, in personal cyber behavioral analysis, diversified individual information are collected from different network platforms and retained in their associated institutions. If we want to give a reliable analysis results, we need to comprehensively consider all personal information held by different institutions. However, in the practical scenarios, these individual sensitive information are prohibited to be exchanged across different institutions since the data privacy is being emphasized. Under such conditions, traditional multi-view learning methods lose their capability to effectively conduct cross-source information fusion and can not comprehensively represent the feature properties of each individual person.

The key to learn from such sensitive multi-view data lies in how to fuse these heterogeneous cross-source features efficiently while preserve the data secrecy of each independent data source. Recently, federated multi-view learning provides an effective solution, which deploys the multi-view clustering method into federated learning framework and fuses these multi-source feature information into a consistency representation for subsequent clustering. For instance, (Huang et al. 2022) proposed a matrix decomposition based method, which orthogonally decomposes the view-specific sample matrix in each client into a basis matrix and a representation matrix and then the representation matrix is uploaded to the sever to mine cross-view consistency for clustering. (Chen et al. 2023) proposed a deep neural network based method, which generates view-specific latent representation by using deep autoencoder in each client and then uploads these representations to the sever to mine cross-view consistency. However, the above federated multi-view clustering methods suffer from some common limitations: (1) All of the above methods leverage cross-view fusion on the latent feature representations uploaded by the clients, which is easily susceptible to model inversion attacks (Sun et al. 2021). (2) These methods only consider cross-view consistencies while the view-specific diversities are regrettably ignored, which naturally results in a suboptimal performance for the final clustering.

To address the above issues, in this paper, we propose a novel structural graph learning framework for multi-view clustering named MGCD, which leverages both consistency and diversity of multi-view graph structure across global view-fusion server and local view-specific clients to achieve desired clustering while better preserves data privacy. Specifically, in each local client, we first design a dual autoencoder to extract the consensus and specific representations of samples respectively, where the two representations can jointly recover the original data to prevent deviation. Afterwards, a unique self-representation reconstruction is introduced to generate diversity graph that represents latent view-specific diversity relations, where the generation of diversity graph is independent to consensus representation to avoid its negative interference. In the global server, the diversity graphs uploaded from clients are further distilled to refine its implicit consistency information, and these information are incorporated into the last-round global consistency graph for cross-view contrastive fusion to generate the current-round global consistency graph. During the whole training process, different from previous methods that the cross-view consistency extracted by server is only used to guide clients‚Äô training, our model pass it to the next-round server‚Äôs training. As shown in Figure 1, the ‚Äúserver-client‚Äù interaction is conducted in an iterative manner like recurrent neural network, where the server model receive lastround global consistency graph and then enhance its consistency by distilling consistency implied in view-specific local diversity graphs, which makes the consistency implied in each local client is gradually aggregated into the global consistency graph and the final clustering results are obtained by spectral clustering based on the final global consistency graph. In summary, the main contributions of our paper lies in the following aspects:

![](images/1c0eb6d82b6d8085d24f3be24b12a12369ce461d4f808abaf9ba83c5a887429b.jpg)  
Figure 1: The ‚Äúserver-client‚Äù interaction of MGCD.

‚Ä¢ We propose a novel structured graph learning framework MGCD for federated multi-view clustering, which leverages both consistency and diversity across global viewfusion server and local view-specific clients to achieve desired clustering while preserves data privacy. ‚Ä¢ Compared with previous methods, our method is more secure and effective, which is attributed to the employed safer graph structure to alleviate model inversion attacks and the consistency & diversity measurements to generate more desired global consistency graph. ‚Ä¢ Extensive experimental results on various datasets have demonstrated that our proposed model exhibits superior performance against other state-of-the-art algorithms.

# Related Work

# Multi-view Clustering

Multi-view clustering, unsupervisedly fusing the multi-view data to aid differentiate crucial grouping, is a fundamental task in the fields of data mining (Lyu et al. 2024a,b; Zhong, Lyu, and Yang 2024; Gu et al. 2023; Diallo et al. 2023; Xu et al. 2024; Ma et al. 2024), pattern recognition (Liu et al. 2023; Jiang et al. 2022; Zhang et al. 2023; Liu and Tsang 2017; Hu et al. 2024a; Tao et al. 2022), etc. The key to deal with such problem lies in how to fuse cross-view information and obtain consistent representation for clustering. Current multi-view clustering methods are mainly divided into two categories, i.e., subspace-based methods and graph-based methods. For instance, (Wu, Feng, and Yuan 2024) propose a subspace-based method, which first embeds the multi-view features into a unified kernel tensor and then utilizes the low-rank kernel tensor constraint to capture the consistency information. (Yan et al. 2023) propose a subspace-based method, which uses the autoencoder to learn the latent representation of each view and then introduces constrastive learning to extract cross-view consistent representation. (Wang et al. 2023) propose a graph-based method, which first learns a graph structure of each view by selfrepresentation learning and then generates the consistency graph by fusing these graph structures.

# Federated Multi-View Clustering

Federated multi-view clustering aims to cluster multi-view data where the data is distributed among different devices (Huang et al. 2022; Chen and Zhang 2022; Li, Yao, and Liu 2023; Hu et al. 2024b). The key to deal with such problem lies in how to fusion cross-view information under the premise of data privacy. For example, (Ren et al. 2024) propose a self-supervised method, which uses the global consistency prototype from server as self-supervised information to update the latent representation of the sample in each client and then the server combines these representations from clients to update the global consistent prototype. (Chen et al. 2023) propose a deep learning method, which generates view-specific latent representation by deep autoencoder in each client and then the server aligns these representations to mine for consistency representation. Although these methods have made competitive performance in federated multi-view clustering, they still suffer from some drawbacks. (1) Directly sharing the representations of clients are vulnerable to model inversion attacks. (2) These methods only measure cross-view consistency while ignore diversity.

# Methodology

In federated multi-view learning, the learning process is generally decomposed into two parts: one global server and multiple local clients. Formally speaking, multi-view data with $V$ views, denoted by $\mathbf { X } = \left\{ \mathbf { X } ^ { 1 } , \mathbf { X } ^ { 2 } , \ldots , \mathbf { X } ^ { V } \right\}$ o, are distributed among $V$ different clients. For each client $v$ , its data are represented as ${ \bf X } ^ { v } \in \mathbb { R } ^ { N \times D _ { v } }$ , where $D _ { v }$ is the dimensionality of samples in view $v$ and $N$ is the number of samples, $v = 1 , . . . , V$ . The goal of federated multi-view clustering is to fuse these distributed views in different clients and extract consistency in the global server for subsequent clustering. Notably, during the whole learning process, the data privacy in each client are strictly emphasized and preserved.

# Formulation

In this paper, we propose a novel graph-based federated multi-view clustering framework named MGCD, which leverages both consistency and diversity of multi-view graph structure across global server and local clients to achieve

Diversity geraphs Server diverityleaphs coGlistency Contrastive fusion comasteney graph Gt-1   
Gd . Gc 1 AVG fpre .   
G SUM fpost CV Srep 6ral clustering   
G Step 4. Disy from Step:5. Fuse coersistency G diversity graphs graphs and Gt-1   
‚Üì‚Üë Step 1.Distribute global consistency graph $\pmb { G } _ { c } ^ { t - 1 }$ Step 3. Upload local diversity graph G'√§   
Client 1 Client v & View v Step 2. Generate diversity graph $\pmb { G } _ { d } ^ { v }$ in client v !Client V Consensus Consensus Complete Xpre encoder representation representation Decoder   
X1 Xv E Z ZU Dv XV 1 ‚àà--LŒ≥ = |xv- Xprell L‚âå = ‚Äñzùë£ - (Gùë°-1 + GŒ©)zùë£) Ea Zd fu Diversity graph $\pmb { G } _ { d } ^ { v }$ Specificity Specificity Self-representation encoder representation function

desired clustering while better preserves data privacy. Following previous ‚Äúserver-client‚Äù federated architecture, we also decompose our training process into two parts: Local Training in clients and Global Training in server. During each training epoch $t$ , the server first receives the last-round global consistency graph $\mathbf { G } _ { c } ^ { t - 1 }$ and distributes it to each client. Then, under the guidance of $\mathbf { G } _ { c } ^ { t - 1 }$ , each client conducts their own local training and generates the corresponding local diversity graph $\mathbf { G } _ { d } ^ { v }$ to upload to the server. Afterwards, the server conducts its global training and fuse crossview consistency to $\mathbf { G } _ { c } ^ { t - 1 }$ to generate the global consistency graph $\mathbf { G } _ { c } ^ { t }$ . The above operation are conducted in an iterative manner, where the consistent information implied in each local client is gradually aggregated into the global consistency graph, and the final clustering results are obtained by spectral clustering on the final global consistency graph. Figure 2 illustrates the overview of our proposed method.

Local Training In each client $v$ , we separately conduct its own local training to generate the corresponding local diversity graph $\mathbf { G } _ { d } ^ { v }$ and upload it to the server for further crossview fusion. Specifically, we first design a dual autoencoder to extract consensus representation $\pmb { Z } _ { c } ^ { v } \in \mathbb { R } ^ { N \times d _ { v } }$ and specificity representation $\pmb { Z } _ { d } ^ { v } \in \mathbb { R } ^ { N \times d _ { v } }$ of $\mathbf { X } ^ { v }$ respectively, where the dual autoencoder consists of two dual encoders (consensus encoder $E _ { c } ^ { v } \left( \mathbf { X } ^ { v } \right) : \mathbf { X } ^ { v } \mapsto \mathbf { Z } _ { c } ^ { v }$ and specificity encoder $E _ { d } ^ { v } \left( \mathbf { X } ^ { v } \right) : \mathbf { X } ^ { \bar { v } } \mapsto \mathbf { Z } _ { d } ^ { v } )$ and a decoder $\bar { D } ^ { v } \left( { \bf Z } ^ { v } \right) : { \bf Z } ^ { v } \in$ $\mathbb { R } ^ { N \times d _ { v } } \mapsto \mathbf { X } _ { p r e } ^ { v } \in \mathbb { R } ^ { N \times D _ { v } }$ . To force the capability of the representations $\mathbf { \nabla } [ \mathbf { Z } _ { c } ^ { v }$ and $\pmb { Z } _ { d . } ^ { v \cdot }$ ) in recovering complete feature information for each client, a reconstruction loss between the original features $\mathbf { X } ^ { v }$ and the corresponding reconstructed features $\mathbf { X } _ { p r e } ^ { v }$ is defined as follows:

$$
\begin{array} { r l } & { \mathcal { L } _ { r } ^ { v } = \left. \mathbf { X } ^ { v } - D ^ { v } \left( \mathbf { Z } ^ { v } \right) \right. _ { F } ^ { 2 } = \left. \mathbf { X } ^ { v } - D ^ { v } \left( \mathbf { Z } _ { c } ^ { v } + \mathbf { Z } _ { d } ^ { v } \right) \right. _ { F } ^ { 2 } } \\ & { \quad = \left. \mathbf { X } ^ { v } - D ^ { v } \left( E _ { c } ^ { v } \left( \mathbf { X } ^ { v } \right) + E _ { d } ^ { v } \left( \mathbf { X } ^ { v } \right) \right) \right. _ { F } ^ { 2 } , } \end{array}
$$

where $\mathbf { Z } ^ { v } = \mathbf { Z } _ { c } ^ { v } + \mathbf { Z } _ { d } ^ { v } \in \mathbb { R } ^ { N \times d _ { v } }$ indicates the complete representation of $\mathbf { X } ^ { v }$ , and $d _ { v }$ is the dimensionality of latent representation in $v$ -th client. In traditional federated multi-view learning methods, the above generated representation $\pmb { Z } ^ { v }$ (or $\pmb { Z } _ { c } ^ { v }$ and $\pmb { Z } _ { d } ^ { v } .$ ) is directly uploaded to the server for subsequent cross-view fusion. However, in real-world scenarios, such operation carries a significant risk of data leakage since the sever can easily recover the original data by model inversion attack (Sun et al. 2021), especially when the attacker tests out these latent representations come from autoencoder.

To alleviate the model inversion attack and preserve the data security, we intend to bypass traditional feature representation uploading and instead employ the graph structure uploading that only uploads sample relationships to server for subsequent cross-view fusion. Specifically, we define the self-representation term as $\mathbf { Z } ^ { v } = \mathbf { G } ^ { v } \mathbf { Z } ^ { v }$ and utilize a self-representation function $f _ { d } ^ { v } ( \cdot )$ to generate local diversity graph $\mathbf { G } _ { d } ^ { v }$ of each client $v$ with the following loss functions:

$$
\begin{array} { r l } & { \mathcal { L } _ { s } ^ { v } = \left. \mathbf { Z } ^ { v } - \mathbf { G } ^ { v } \mathbf { Z } ^ { v } \right. _ { F } ^ { 2 } } \\ & { \quad \quad = \left. \mathbf { Z } ^ { v } - \left( \mathbf { G } _ { c } ^ { t - 1 } + \mathbf { G } _ { d } ^ { v } \right) \mathbf { Z } ^ { v } \right. _ { F } ^ { 2 } , } \\ & { \quad s . t . \ d i a g \left( \mathbf { G } ^ { v } \right) = 0 , } \end{array}
$$

Algorithm 1: The Training Process of MGCD.

Input: Multi-view data $\mathbf { X } \ = \ \left\{ \mathbf { X } ^ { 1 } , \mathbf { X } ^ { 2 } , \ldots , \mathbf { X } ^ { V } \right\}$ dis tributed in $V$ clients; The number of training epoch $T$ .

Output: Clustering results

1: Initialize global consistency graph ${ \bf G } _ { c } ^ { 0 }$ in server;   
2: for epoch $t = 1$ to $T$   
3: The clients for $v = 1$ to $V$ in parallel:   
4: if $t = = 1$ then   
5: Initialize $\{ \mathbf { E } _ { c } ^ { v } , \mathbf { E } _ { d } ^ { v } , \mathbf { D } ^ { v } \}$ by minimizing Eq.(1);   
6: end if   
7: Receive $\mathbf { G } _ { c } ^ { t - 1 }$ from server;   
8: Local training by Eq.(3) to obtain $\mathbf { G } _ { d } ^ { v }$ ;   
9: Upload $\mathbf { G } _ { d } ^ { v }$ to server;   
10: The server:   
11: Receive $\left\{ \mathbf { G } _ { d } ^ { 1 } , \mathbf { G } _ { d } ^ { 2 } , . . . , \mathbf { G } _ { d } ^ { V } \right\}$ from clients;   
12: Global training by Eq.(6) to obtain $\mathbf { G } _ { c } ^ { t }$ ;   
13: Distribute $\mathbf { G } _ { c } ^ { t }$ to clients;   
14: end for   
15: Perform spectral clustering on ${ \bf G } _ { c } ^ { T }$

where $\mathbf { G } ^ { v } = \mathbf { G } _ { c } ^ { t - 1 } + \mathbf { G } _ { d } ^ { v } \in \mathbb { R } ^ { N \times N }$ is the complete graph in $\boldsymbol { v }$ -th client, $\mathbf { G } _ { c } ^ { t - 1 } \in \mathbb { R } ^ { N \times N }$ is the consistency graph distributed from the server, and $f _ { d } ^ { v } ( \cdot )$ is a fully connected layer. In our method, we employ the global consistency graph $\mathbf { G } _ { c } ^ { t - 1 }$ to guide the generation of local diversity graph $\mathbf { G } _ { d } ^ { v }$ where $\mathbf { G } _ { c } ^ { t - 1 }$ represents the consistency that the server has extracted. Therefore, under the guidance of $\mathbf { G } _ { c } ^ { t - 1 }$ , the unextracted consistency in $\mathbf { X } ^ { v }$ will be first transfered to $\mathbf { G } _ { d } ^ { v }$ in client $v$ and then further distilled to generate more compact global consistency graph in the server. The whole loss function in each client is represented as:

$$
\mathcal { L } _ { c l i e n t } ^ { v } = \mathcal { L } _ { r } ^ { v } + \gamma \mathcal { L } _ { s } ^ { v } ,
$$

where $\gamma$ is a trade-off coefficient between reconstruction loss and self-representation loss. After local training, the generated $\mathbf { G } _ { d } ^ { v }$ is uploaded to the server for further global training.

Global Training In the server, we receive the diversity graphs from clients and conduct a unified global training to generate the global consistency graph $\mathbf { G } _ { c } ^ { t }$ , which is utilized for the final clustering. During the global training process, both the consistency and diversity of multi-view graph structure are measured simultaneously to make $\mathbf { G } _ { c } ^ { t }$ more compact so as to improve the final clustering performance. Specifically, considering that the diversity graph $\mathbf { G } _ { d } ^ { v }$ uploaded from clients still contains some consistent information, we further distill these diversity graphs and integrate the distilled consistent information into $\mathbf { G } _ { c } ^ { t - 1 }$ to generate the refined consistency graph Gc_v = fpost fpre (Gvd) + Gtc‚àí1 ‚àà RN√óN , where $f _ { p r e } ( \cdot )$ and $f _ { p o s t } ( \cdot )$ are two fully connect layers that distill the consistent information from $\mathbf { G } _ { d } ^ { v }$ and fuse the distilled consistent information into $\mathbf { G } _ { c } ^ { t - 1 }$ , respectively.

(1) Graph Consistency Measurement. The above distillation operation generates $V$ refined consistency graphs $\{ \mathbf { G } _ { c _ { - } v } \} _ { v = 1 } ^ { V }$ , whose consistency are further measured to realize cross-view fusion. Specifically, we design a graph contrastive fusion strategy, which applies contrastive learning into the refined consistency graphs $\{ \mathbf { G } _ { c _ { - } v } \} _ { v = 1 } ^ { V }$ . Such strategy encourages the similarity relationship $\left\{ \mathbf { g } _ { i } ^ { v } \right\} _ { v = 1 } ^ { V }$ of each instance across different views to be consistent while requires the similarity relationship of diverse instance to be different, where $\mathbf { g } _ { i } ^ { v }$ are the $i$ -th row of the graph $\mathbf { G } _ { c _ { - } v }$ and indicates the similarity between the $i$ -th instance and other instances. When formulating the graph contrastive fusion loss, we select $\{ ( \mathbf { g } _ { i } ^ { v } , \mathbf { g } _ { i } ^ { q } ) , v \neq \bar { q } \}$ to serve as positive pairs and the other relationship pairs to be negative pairs. Accordingly, our designed graph contrastive fusion loss is formulated as:

$$
\mathcal { L } _ { c l } = - \frac { 1 } { N } \sum _ { i = 1 } ^ { N } \sum _ { 1 < v < q < V } \log \frac { e ^ { s \left( \mathbf { g } _ { i } ^ { v } , \mathbf { g } _ { i } ^ { q } \right) / \tau _ { g } } } { \sum _ { i , j = 1 \frac { i } { \neq } j } ^ { N } \sum _ { p = 1 } ^ { V } e ^ { s \left( \mathbf { g } _ { i } ^ { v } , \mathbf { g } _ { j } ^ { p } \right) / \tau _ { g } } } ,
$$

where $s ( \mathbf { g } _ { i } ^ { v } , \mathbf { g } _ { i } ^ { q } )$ is similarity between $\mathbf { g } _ { i } ^ { v }$ and $\mathbf { g } _ { i } ^ { q }$ measured by consine distance, $\tau _ { g }$ is a tunable hyper-parameter for the softmax temperature.

(2) Graph Diversity Measurement. While measuring the graph consistency of the refined $\{ \mathbf { G } _ { c _ { - } v } \} _ { v = 1 } ^ { V }$ , the specific information in $\mathbf { G } _ { d } ^ { v }$ is remained as a refined diversity graph $\mathbf { G } _ { c \_ d } ~ \in ~ \mathbb { R } ^ { N \times N }$ , where ${ \bf G } _ { c } ^ { t - 1 } + { \bf G } _ { d } ^ { v } = { \bf G } _ { c _ { - } v } + { \bf G } _ { d _ { - } v }$ . In real-world scenarios, the $\mathbf { G } _ { d _ { - } v }$ tends to contain both viewspecific information and noises/outliers in each individual view, which is generally sparse across different views. Thus, we measure the graph diversity by minimizing the sum of the products among $\left\{ { \bf G } _ { d _ { - } v } \right\} _ { v = 1 } ^ { V }$ :

$$
\mathcal { L } _ { d d } = \sum _ { v , q = 1 } ^ { V } _ { \frac { v } { \neq } q } T r \left( \left( \mathbf { G } _ { d _ { - } v } \right) \left( \mathbf { G } _ { d _ { - } q } \right) ^ { T } \right) ,
$$

where $T r ( \cdot )$ represents the trace of a matrix.

By measuring multi-view graph consistency and diversity simultaneously in Global Training, we can enforce all consistent information from different clients into the consistency graph $\{ \mathbf { G } _ { c _ { - } v } \} _ { v = 1 } ^ { V }$ and store extra view-specific information or noises/outliers in the diversity graph $\{ \mathbf { G } _ { d _ { - } v } \} _ { v = 1 } ^ { V }$ which can jointly contribute to generate a more compact global consistency graph $\begin{array} { r } { \mathbf { G } _ { c } ^ { t } = \frac { \bar { 1 } } { V } \sum _ { v = 1 } ^ { V } \mathbf { G } _ { c _ { - } v } } \end{array}$ . The whole loss function in the global server is represented as:

$$
\begin{array} { r } { \mathcal { L } _ { s e r v e r } = \mathcal { L } _ { c l } + \lambda \mathcal { L } _ { d d } . } \end{array}
$$

# Optimization

Algorithm 1 summarizes the training process of MGCD, which consists of two main parts: the clients and the server, where the clients perform local training in parallel and the server conducts global training for multi-view fusion. At each training epoch $t$ , each client first receives the global consistency graph $\mathbf { G } _ { c } ^ { t - 1 }$ and conducts local training to generate its local diversity graph $\mathbf { G } _ { d } ^ { v }$ . Then, these local diversity graphs are uploaded to the server for global training, which generates the global consistency graph $\mathbf { \bar { G } } _ { c } ^ { t }$ and distribute it to clients for the next round training. After $T$ round iterations, we obtain the desired global consistency graph ${ \bf G } _ { c } ^ { T }$ , which can perform spectral clustering on it for clustering results.

# The Superiorities of MGCD

1) Our proposed MGCD is more secure. In local client, we upload the graph structure to the server instead of the auto-encoder feature representations, which can effectively alleviate the model inversion attack and reduce the risk of data leakage. Especially, our graph structure only contains instance similarity relationship while not contains any latent feature representations, which can prevent the attacker from recovering the original data easily even if he has tested out the data generation strategy in clients.

2) Our proposed MGCD is more effective. In global server, we leverages both consistency and diversity of multiview graph structure to generate more compact global consistency graph for clustering. Compared with previous methods that only measure consistency, such operation can gradually aggregate the consistency information from different clients into the global consistency graph while store the remaining view-specific information and noises/outliers in the corresponding diversity graphs.

# The Further Explanation of MGCD

1) What is the diversity in MGCD. In our paper, the diversity represents a much broader concept than view-specific feature attributes. It could be caused by not only viewspecific attributes, but also noise and outliers, which is not conducive to clustering. Additionally, diversity measurement emphasizes the cross-view mutual exclusions in diversity graphs, formulated by Eq. (5), which will lead the learned consistency in $\{ \mathbf { G } _ { c _ { - } v } \} _ { v = 1 } ^ { V }$ to be more compact.

2) Why distill consistency from diversity graphs. At training epoch $t$ , the global consistency graph $\mathbf { \bar { G } } _ { c } ^ { t - 1 }$ represents the consistency that the server has extracted. However, at the beginning of model training, there must be some unextracted consistency that implied in each client. Besides, in local training, the diversity graphs are generated under the guidance of $\mathbf { G } _ { c } ^ { t - 1 }$ , which results in the unextracted consistency is transferred to diversity graphs from clients‚Äô samples. Therefore, it is necessary to distill consistency from diversity graphs. Finally, as the server continues to distill, the diversity graphs will eventually contain only diversity.

# Experiments

# Experimental Settings

Datasets We employ six widely-used multi-view datasets for comparative studies, including Mfeat (Wang, Yang, and Liu 2019), Scene (Fei-Fei and Perona 2005), Aloi (Li et al. 2023), Animal (Li et al. 2016), Cifar10 (Zhang et al. 2018) and NoisyMNIST (Peng et al. 2019). The specific characteristics of these datasets are recorded in Table 1.

The Compared Methods In order to verify the effectiveness of our proposed MGCD, we employ eight state-of-theart multi-view clustering methods for comparative experiments, which includes five centralized methods of LMVSC (Kang et al. 2020), SiMVC (Trosten et al. 2021), CoMVC (Trosten et al. 2021), MFLVC (Xu et al. 2022), GCFAgg (Yan et al. 2023) and three federated methods of FedMVL (Huang et al. 2022), FedDMVC (Chen et al. 2023), FCUIF (Ren et al. 2024), where all compared methods are implemented according to the source codes released by the authors, and the optimal parameters are set according to the suggestion in the corresponding literature.

Table 1: Statistical characteristics of the six datasets.   

<html><body><table><tr><td>Data</td><td>Samples</td><td>Clusters</td><td>View dimensions</td></tr><tr><td>Mfeat</td><td>2000</td><td>10</td><td>216/76/64/6/240/47</td></tr><tr><td>Scene</td><td>4485</td><td>15</td><td>20/59/40</td></tr><tr><td>Aloi</td><td>10800</td><td>100</td><td>77/13/64/125</td></tr><tr><td>Animal</td><td>11673</td><td>20</td><td>2689/2000/2001/2000</td></tr><tr><td>Cifar10</td><td>50000</td><td>10</td><td>512/2048/1024</td></tr><tr><td>NoisyMNIST</td><td>50000</td><td>10</td><td>784/784</td></tr></table></body></html>

Metrics There are four widely-used metrics applied to quantitatively evaluate the performance of multi-view clustering methods, including Accuracy (ACC), Normalized Mutual Information (NMI), Purity(Pur) and Adjusted Rand Index (ARI), whose detailed definitions are illustrated in (Liang et al. 2022). For each of the above metric, the higher value indicates the better performance.

Implementation Details. The diversity encoder $E _ { d } ^ { v }$ , consistency encoder $E _ { c } ^ { v }$ and decoder $D ^ { v }$ are formulated by four fully-connected layers and the dimensions are set to $\{ D _ { v } , 5 0 0 , 5 0 0 , 2 0 0 0 , 5 1 2 \}$ , $\{ D _ { v } , 5 0 0 , 5 0 0 , 2 0 0 0 , 5 1 2 \}$ and $\{ 5 1 2 , 2 0 0 0 , 5 0 0 , 5 0 0 , D _ { v } \}$ respectively, where the activation function is RELU. The $f _ { d } ^ { v } ( \cdot )$ in client is composed of a fully-connected layer with dimendisons $\{ 5 1 2 , N \}$ . To reduce the size of server model, the dimensions of $f _ { p r e } ( \cdot )$ and $f _ { p o s t } ( \cdot )$ are respectively set as $\{ N , 5 0 0 , N \}$ and $\{ N , 5 0 0 , \mathrm { { \bar { N } } } \}$ , where $N > > 5 0 0$ . At the first training epoch, we pre-train dual autoencoder 20 epochs in each client. Then, at the following training epoch, the clients and server iteratively train on mini-batches of size 256 by using Adam optimizer(Kingma and Ba 2014) with learning rate of 0.000001 in PyTorch(Paszke et al. 2019) framework. The hyperparameters $\gamma$ and $\lambda$ are set to 100 and 0.001 respectively. All experiments are conducted on the same machine with the Intel(R) Xeon(R) Gold 6148 2.40GHz CPU, GeForce RTX 3090 GPUs, and 512GB RAM.

# Experimental Results

Comparisons with other methods Table 2 records the experimental comparisons between our proposed MGCD and the other 8 comparing methods, where the best and the suboptimal performance are highlighted in bold and underlined, respectively. In addition, Figure 3 illustrates the visualization of clustering results of each method on the Aloi dataset. According to Table 2 and Figure 3, we can observe that:

(1) Among the employed all datasets, our MGCD is superior to all comparing methods on all evaluation metrics, even has a significant leading gap compared with sub-optimal methods. Especially on the Animal dataset, the improvements over the sub-optimal method are $3 2 . 9 1 \%$ , $4 8 . 3 1 \%$ , $3 2 . 9 1 \%$ , and $3 6 . 8 5 \%$ on ACC, NMI, ARI and PUR, respectively. These experimental results demonstrate the effectiveness of our proposed method and we attribute such success

Table 2: Comparative results between our proposed MGCD and 8 state-of-the-art methods on six datasets, where the best results are presented in bold and the second-best are in underline.   

<html><body><table><tr><td rowspan="2">Data set</td><td rowspan="2">Metric</td><td colspan="5"></td><td colspan="4">FedDMVCd FCUIF</td></tr><tr><td>LMVSC</td><td>SiMVC</td><td>CenMvced</td><td>MFLVC</td><td>GCFAgg</td><td>FedMVL</td><td></td><td></td><td>Ours</td></tr><tr><td rowspan="4">Mfeat</td><td>ACC</td><td>0.6550</td><td>0.8001</td><td>0.7750</td><td>0.8665</td><td>0.5945</td><td>0.1300</td><td>0.9365</td><td>0.9341</td><td>0.9390</td></tr><tr><td>NMI</td><td>0.6386</td><td>0.8407</td><td>0.8243</td><td>0.8736</td><td>0.7401</td><td>0.0085</td><td>0.9063</td><td>0.8951</td><td>0.9173</td></tr><tr><td>ARI</td><td>0.5283</td><td>0.7563</td><td>0.7207</td><td>0.8166</td><td>0.5043</td><td>0.1790</td><td>0.9002</td><td>0.8854</td><td>0.9005</td></tr><tr><td>PUR</td><td>0.7461</td><td>0.8413</td><td>0.8147</td><td>0.8665</td><td>0.6565</td><td>0.1320</td><td>0.9503</td><td>0.9491</td><td>0.9671</td></tr><tr><td rowspan="5"> Scene</td><td>ACC</td><td>0.3222</td><td>0.4383</td><td>0.4347</td><td>0.3173</td><td>0.2022</td><td>0.0945</td><td>0.4360</td><td>0.4252</td><td>0.5285</td></tr><tr><td>NMI</td><td>0.3396</td><td>0.4657</td><td>0.4627</td><td>0.3392</td><td>0.1842</td><td>0.0100</td><td>0.4184</td><td>0.3880</td><td>0.5625</td></tr><tr><td>ARI</td><td>0.1714</td><td>0.2787</td><td>0.2710</td><td>0.1784</td><td>0.0746</td><td>0.0643</td><td>0.2697</td><td>0.2474</td><td>0.3665</td></tr><tr><td>PUR</td><td>0.3922</td><td>0.5084</td><td>0.5001</td><td>0.3456</td><td>0.2486</td><td>0.1064</td><td>0.4237</td><td>0.4020</td><td>0.5845</td></tr><tr><td>ACC</td><td>0.6390</td><td>0.6730</td><td>0.7010</td><td>0.7490</td><td>0.5745</td><td>0.0349</td><td>0.8566</td><td>0.7460</td><td>0.9160</td></tr><tr><td rowspan="4">Aloi Animal</td><td>NMI</td><td>0.7700</td><td>0.8530</td><td>0.8940</td><td>0.8570</td><td>0.8268</td><td>0.0731</td><td>0.9210</td><td>0.8426</td><td>0.9668</td></tr><tr><td>ARI</td><td>0.5030</td><td>0.5550</td><td>0.6530</td><td>0.6680</td><td>0.5184</td><td>0.0374</td><td>0.8050</td><td></td><td></td></tr><tr><td>PUR</td><td>0.6900</td><td>0.8150</td><td>0.7940</td><td>0.7810</td><td>0.5968</td><td>0.0361</td><td>0.8941</td><td>0.6285</td><td>0.8992</td></tr><tr><td>ACC</td><td>0.1310</td><td>0.1600</td><td>0.1560</td><td>0.1910</td><td>0.1528</td><td>0.0791</td><td>0.1829</td><td>0.7926</td><td>0.9302</td></tr><tr><td rowspan="4"></td><td>NMI</td><td>0.0290</td><td>0.1360</td><td>0.1350</td><td>0.1660</td><td>0.1480</td><td>0.0147</td><td>0.1641</td><td>0.1793 0.1590</td><td>0.5201</td></tr><tr><td>ARI</td><td>0.0290</td><td>0.0530</td><td>0.0500</td><td>0.0750</td><td>0.0639</td><td>0.0125</td><td>0.0694</td><td></td><td>0.6491</td></tr><tr><td>PUR</td><td>0.1390</td><td>0.1720</td><td>0.1640</td><td>0.2030</td><td>0.1929</td><td></td><td>0.1720</td><td>0.0665</td><td>0.4010</td></tr><tr><td>ACC</td><td>0.8753</td><td>0.8359</td><td>0.9275</td><td>0.9925</td><td></td><td>0.1010</td><td></td><td>0.1673</td><td>0.5715</td></tr><tr><td rowspan="4">Cifar10</td><td>NMI</td><td>0.7798</td><td>0.7324</td><td>0.8925</td><td>0.9795</td><td>0.9902 0.9744</td><td>0.1646 0.0533</td><td>0.9917 0.9781</td><td>0.9888</td><td>0.9948</td></tr><tr><td>ARI</td><td>0.3274</td><td></td><td></td><td></td><td></td><td>0.1673</td><td>0.9818</td><td>0.9719</td><td>0.9851</td></tr><tr><td>PUR</td><td></td><td>0.8057</td><td>0.9836</td><td>0.9836</td><td>0.9787</td><td></td><td></td><td>0.9756</td><td>0.9885</td></tr><tr><td>ACC</td><td>0.8753</td><td>0.8359</td><td>0.9275</td><td>0.9925</td><td>0.9902</td><td>0.1691</td><td>0.9917</td><td>0.9888</td><td>0.9948</td></tr><tr><td rowspan="4">NoisyMNIST</td><td></td><td>0.3274</td><td>0.3831</td><td>0.4141</td><td>0.2497</td><td>0.6465</td><td>0.1246</td><td>0.4564</td><td>0.4263</td><td>0.7791</td></tr><tr><td>NMI</td><td>0.3027</td><td>0.3266</td><td>0.4047</td><td>0.2054</td><td>0.6469</td><td>0.0130</td><td>0.4137</td><td>0.3893</td><td>0.7261</td></tr><tr><td>ARI</td><td>0.1603</td><td>0.2988</td><td>0.3616</td><td>0.0778</td><td>0.4522 0.6497</td><td>0.1221</td><td>0.2861 0.4564</td><td>0.2758</td><td>0.6351</td></tr><tr><td>PUR</td><td>0.5196</td><td>0.4109</td><td>0.4667</td><td>0.1905</td><td></td><td>0.1467</td><td></td><td>0.4263</td><td>0.7791</td></tr></table></body></html>

![](images/d567b731f2e09df80535004a47f5e8458943fc87f2d48dafd2937fda63f5a115.jpg)  
Figure 3: The visualizations of the clustering results of different methods on Aloi dataset.   
tFhiegucroen4si:stTehnecyc ugrstaeprhi $\hat { \mathbf { G } } _ { c } ^ { t }$ earnfdortmheandcievecrosimtypagriaspohn $\{ \mathbf { G } _ { d } ^ { v } \} _ { v = 1 } ^ { V }$ on Aloi datasets as the training epoch increases.

1.0 200 1.0 200 Gt 190 G 190   
0.9 0.9 {Gy}Y=1 180 {GyY=1 180   
0.8 loss 1700.8 loss 170   
0.7 1600.7 160 150 150   
0.6 0.6 140 140   
0.50 1300.5 130 2 4 6 8 2 4 6 8 10 (a) ACC (b) ARI

to the measurement of consistency and diversity in server, which makes our model generate a more compact consistency graph with a clear cluster structure.

(2) As shown in Figure 3, we select three centralized multi-view consistency clustering methods (GCFAGG,

MFLVC, LMVSC) and three federated multi-view consistency clustering methods (FedMVL, FedDMVC, FCUIF) to conduct the visualization comparisons of clustering results with our proposed MGCD. We can observe that our MGCD exhibits a more clear cluster structure than all other methods, which demonstrates the superiority of MGCD in exploring consistency information across different views.

Comparisons between global consistency graph and local diversity graphs of our model Figure 4 illustrates the clustering performance comparisons between the consistency graph $\mathbf { \dot { G } } _ { c } ^ { t }$ and the diversity graphs $\{ \mathbf { G } _ { d } ^ { v } \} _ { i = 1 } ^ { V }$ on Aloi dataset, where the diversity graph is represented by the averaging of local diversity graphs from $V$ clients. According to Figure 4, we can find that, as the training epoch increases, the clustering performance of consistency graph gradually increases while that of diversity graph gradually decreases, which demonstrates that our proposed MGCD gradually transfer the consistent information from local diversity graphs to the global consistency graph.

1.0 2001.0 240 0.9 ACC 190 0.8 AMC 220 1.0 1 0.7 0.8 0.7 0.6 0.5 2 4 6 PR loss 8 101300.0 1700.6 160 0.4 1400.2 150 2 4 6 ARR loss 8 10120 200 160 140 10-3 10-101 10310-3 102 101 10.5 8 0.8 0.6 0.5 10-3 10-1101 103 10-3 10- 101 103 0.2 p 0.5 0.2 0.3 (a) Aloi (b) Animal (c) Aloi (d) Animal

Table 3: Ablation studies of loss components on Aloi dataset.   

<html><body><table><tr><td></td><td>Ls</td><td>Lr</td><td>Lcl</td><td>Ldd</td><td>ACC NMI</td><td>ARI PUR</td></tr><tr><td>(A)</td><td>‚àö</td><td></td><td>‚àö</td><td>‚àö</td><td>0.853 0.924</td><td>0.774 0.868</td></tr><tr><td>(B)</td><td>‚àö</td><td>‚àö</td><td></td><td>‚àö</td><td>0.903 0.954</td><td>0.867 0.919</td></tr><tr><td>(C)</td><td>‚àö</td><td>‚àö</td><td>‚àö</td><td></td><td>0.807 0.899</td><td>0.599 0.838</td></tr><tr><td>(D)</td><td>‚àö</td><td>‚àö</td><td></td><td></td><td>0.795 0.883</td><td>0.598 0.816</td></tr><tr><td>(E)</td><td>‚àö</td><td>‚àö</td><td></td><td></td><td>0.916 0.966</td><td>0.899 0.930</td></tr></table></body></html>

Table 4: Ablation studies on some components of MGCD.   

<html><body><table><tr><td></td><td>Dual AE</td><td>Distillation</td><td>ACC NMI ARI</td><td>PUR</td></tr><tr><td>(a)</td><td></td><td>‚àö</td><td>0.796 0.898 0.638</td><td>0.822</td></tr><tr><td>(b) (cÔºâ</td><td>‚àö ‚àö</td><td>‚àö</td><td>0.859 0.927 0.777 0.916 0.966 0.899</td><td>0.874 0.930</td></tr></table></body></html>

# Model Analysis

Ablation Study. We conduct two series of ablation studies from the perspective of loss functions and model components. Table 3 records the loss ablation studies on Aloi dataset, where $\mathcal { L } _ { s }$ is the loss to generate diversity graph in client, $\mathcal { L } _ { r }$ is the loss to obtain latent representation of samples in client, $\mathcal { L } _ { c l }$ is the loss to measure consistency in server and $\mathcal { L } _ { d d }$ is the loss to measure diversity in server. Table 4 records the model ablation studies on Aloi dataset, where Dual $A E$ represents dual autoencoder in client and Distillation represents the consistency distillation operation $f _ { p r e } ( \cdot )$ in server. According to Table 3-4, we can find that:

(1) According to Table 3, (E) is superior to (A), which indicates that the reliable representation of samples is helpful to generate desired graphs and can further contribute to improve the clustering performance. Meanwhile, (E) also shows better clustering performance than (B), (C) and (D), which demonstrates the effectiveness of our employed graph consistency and diversity measurement. In addition, according to the comparison between (B) and (C), we can find that both graph consistency measurement and graph diversity measurement are helpful to the generation of global consistency graph, while the later has greater contribution.

(2) In Table 4, (a) replaces the designed dual autoencoder with traditional autoencoder in each client and (b) removes the consistency distillation operation $f _ { p r e } ( \cdot )$ from global training in server. According to Table 4, (c) shows better performance than (a), which indicates that the specificity representation from our designed dual autoencoder is more suitable for the generation of diversity graph in each client and our designed dual autoencoder performs significant superiorities against traditional autoencoder. Meanwhile, (c) outperforms (b), which demonstrates the fact that the diversity graphs from clients still contain consistent information. Our designed distillation operation can gradually transfer the consistent information implied in diversity graph to the global consistency graph, which avoids the loss of consistent information from local clients and enhances the robustness of the global consistency graph.

Convergence analysis. Figure 5 shows the convergence curves of MGCD on Aloi, Animal datasets, where the values of loss and evaluation metrics are illustrated in each subfigure. According to Figure 5, we can observe that the value of loss drops significantly at the beginning of the iteration process and gradually reaches stability as the number of iterations increases. And the values of evaluation metrics gradually increase and fluctuate in a narrow range. These results verified the convergence of our proposed MGCD.

Parameter sensitivity analysis. We experimentally evaluate the effect of hyperparameters on the clustering performance of MGCD, which includes $\gamma$ in clients and $\lambda$ in server. Figure 5 shows the NMI metric value of MGCD on Aloi, Animal datasets, where $\gamma$ is varied from $1 0 ^ { - 3 }$ to $1 0 ^ { 3 }$ and $\lambda$ from $1 0 ^ { - 3 }$ to $1 0 ^ { 3 }$ . According to Figure 5, the clustering results of MGCD are insensitive to both $\gamma$ and $\lambda$ ranging from 10 to 1000, and 0.001 to 0.01, respectively. In our experiments, we set $\gamma$ to 100 and $\lambda$ to 0.001.

# Conclusion

In this paper, we proposed a new graph-based federated multi-view clustering method, which leverages both consistency and diversity of multi-view graph structure to achieve desired clustering while preserves data privacy. Compared with previous methods, our proposed method conducts multi-view fusion according to the graph structure rather than feature representation, which can better mitigate model inversion attacks and preserve the client privacy. Meanwhile, the measurement of both consistency and diversity can further assist in generating more compact consistency graph, which naturally improves the final clustering performance. Extensive experimental results on various datasets have verified the effectiveness of our proposed method.

# Acknowledgments

This work was supported by the National Key Research and Development Program of China (No. 2023YFB3107100), the National Natural Science Foundation of China (No. 62306020, 62203024, 62173286), the Young Elite Scientist Sponsorship Program by BAST (No. BYESS2024199), the R&D Program of Beijing Municipal Education Commission (No. KM202310005027), the Major Research Plan of National Natural Science Foundation of China (No. 92167102), and the Beijing Natural Science Foundation (No. L244009).