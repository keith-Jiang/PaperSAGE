# Reinforcement Active Client Selection for Federated Heterogeneous Graph Learning

Jia Wang1,2, Yawen $\mathbf { L i } ^ { 3 * }$ , Yingxia Shao1,2, Zhe Xue1,2, Zeli Guan1,2, $\mathbf { A n g L i } ^ { 2 }$ , Guanhua $\mathbf { Y e } ^ { 1 , 2 }$

1School of Computer Science (National Pilot School of Software Engineering), Beijing University of Posts and Telecommunications 2Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia 3SChool of Economics and Management, Beijing University of Posts and Telecommunications Beijing 100876, PR China Wangj2021110865, shaoyx, xuezhe, guanzeli, david.lee, g.ye $@$ bupt.edu.cn

# Abstract

Careful client selection for aggregation can help improve the global model’s performance. However, existing research on federated heterogeneous graph learning (FHGL) has paid limited attention to the client selection (CS) problem. Current CS algorithms struggle to accurately assess client contributions and select suitable participants in FHGL, creating a trade-off between convergence and accuracy. In this paper, we propose a Reinforcement Active client selection based Federated Heterogeneous Graph Learning (RAFHGL), which precisely evaluates the importance of local heterogeneous graph data and selects high-contributing clients for aggregation. RAFHGL employs an active learning agent to select representative nodes for local training. The statistical features of the active scores are used to assess client contributions. A client selection agent then chooses clients conducive to global model convergence for aggregation. To address heterogeneity introduced by sample and client selection, the training process stabilizes by correcting local losses based on data prototypes. Experimental results on 4 publicly available heterogeneous graph datasets show that RAFHGL outperforms existing Client Selection algorithms in federated heterogeneous graph learning scenarios in terms of performance and convergence.

# Introduction

Similar to other neural networks, a substantial amount of data can enhance the performance of Heterogeneous Graph Neural Network (HGNN). However, in reality, it is often challenging to collect extensive data for training due to constraints such as hardware limitations or privacy concerns from multiple data sources (Lin et al. 2020; Zhang et al. 2022a; Chen et al. 2021; Peng et al. 2021). Federated Learning (FL) (McMahan et al. 2017; Chai et al. 2020; Dennis, Li, and Smith 2021) has emerged as a promising approach for collaborative model training without the need to exchange raw data, particularly well-suited for training machine learning models on distributed devices. Consequently, research on Federated Graph Learning (FGL) (Zhang et al. 2021; Liu et al. 2022b; Tan et al. 2023; Hu et al. 2022) has emerged, with Federated Heterogeneous Graph Learning (FHGL) allowing local clients to maintain Heterogeneous Information Network (HIN) data with multiple node or edge types. Common FHGL still requires all clients to participate in global aggregation, resulting in significant computational resource and communication time wastage or randomly select clients for global training without the ability to choose clients that could better aid global model convergence or performance improvement (Fu and King 2023; Yan et al. 2023; Qu et al. 2022; Song et al. 2023). Although existing client selection (CS) (Ribero and Vikalo 2020) algorithms have been extensively studied in the context of Euclidean data, the utilization of CS algorithms on FHGL has not received much attention. Furthermore, the unique characteristics of HIN and the complexity of HGNN make it challenging to accurately assess client contributions and select appropriate clients for aggregation in the FHGL scenario.

In FHGL scenarios, client selection (CS) faces two main challenges. On one hand, the diverse node and edge types in HINs introduce complex topological information, requiring more advanced HGNN architectures to handle more difficult tasks. Existing CS algorithms that rely on model information and performance metrics introduce biases when evaluating client quality (Wang et al. 2024; Shi and Shen 2021). As a result, when applied to FHGL, these CS algorithms struggle to accurately select clients that most contribute to global model aggregation. On the other hand, existing CS algorithms often face a trade-off between convergence and generalization due to high data heterogeneity (Zhan, Li, and Guo 2020; Guan et al. 2023). The complexity and diversity of HIN increase the data heterogeneity in FL. Data distributions across clients may vary significantly, with diverse node and edge combinations creating complex topological information, challenging FL’s robustness in managing data heterogeneity (Song et al. 2023; Yang, Liu, and Kassab 2023). Traditional CS algorithms may worsen the trade-off between convergence and accuracy in such scenarios (Goetz et al. 2019; Rjoub et al. 2022; Jiang et al. 2022).

In this paper, we introduce a novel approach, Reinforcement Active Client Selection-based Federated Heterogeneous Graph Learning (RAFHGL), which combines Reinforcement Learning (RL) and Active Learning (AL) to enhance CS in FHGL. Our RAFHGL algorithm dynamically adapts to evolving client scenarios, offering an effective CS method that balances short-term convergence with long-term contributions to the global model. By leveraging reinforcement learning’s ability to handle delayed rewards, RAFHGL enables intelligent client decision-making, benefiting both local models and the overall performance of the federated learning framework. The following sections will provide a detailed exposition of the proposed algorithm and present experimental results demonstrating its effectiveness across various federated learning scenarios.

The primary contribution of this paper can be summarized as follows:

1. We present a reinforcement active learning based method for evaluating the information content of nodes in HINs prioritizing the participation of nodes with higher perplexity in local training. Evaluate the distribution of effective samples as an indicator of client contributions, addressing the challenge in accurately evaluating the quality of client data.

2. We present a CS strategy designed for the FHGL scenario, which employs a RL agent to assess the distribution of locally effective nodes. It selectively chooses clients for aggregation training, aiming to mitigate the trade-off between convergence and performance inherent in traditional CS approaches.

3. We propose a data prototype-based local training correction method, which constrains the distance between the node embeddings obtained by different clients in the feature space and the prototype set. Effectively alleviate client drift caused by active selection on both the client and server sides.

# Related Work

# Federated Learning Client Selection

Existing CS strategies based on Euclidean data primarily rely on model features (Fraboni et al. 2021; Balakrishnan et al. 2022), such as parameters, gradients, parameter variations, and performance metrics (Huang et al. 2023; Cho, Wang, and Joshi 2020; Tang et al. 2022), including loss, accuracy, and accuracy variations, to decide client participation in training. However, model performance results from the interaction between the global model and local data, with differences primarily arising from variations in client-side data.

# Heterogeneous Graph Learning

HGNN is an extension of graph neural networks designed to handle HIN. In heterogeneous graphs, nodes and edges of different types have distinct semantics and attributes (Wang et al. 2022; Tian et al. 2023; Liu et al. 2023; Yang et al. 2023). This heterogeneity presents challenges for directly applying conventional homogeneous graph neural networks. Consequently, HGNN shows great potential in addressing the complex relationships in HIN and has been widely studied in practical applications, such as legal statute identification (Paul, Goyal, and Ghosh 2022), drug repurposing (Mei

et al. 2022), and sentiment analysis (Lu, Li, and Wei 2022;   
An et al. 2022).

# Federated Active Selection Algorithm

RL provides a compelling solution for dynamic CS in federated learning (Wang et al. 2020; Zhang, Lin, and Zhang 2022). Unlike traditional models that require pre-training on extensive selection data, RL models can adaptively learn CS patterns (Tang et al. 2022). The introduction of AL (Ren et al. 2021; Liu et al. 2022a), by focusing on assessing the quality of client-contributed data, further enhances the CS process. Integrating AL into the process allows for a more nuanced evaluation of client data quality (Chen et al. 2019; Zhang et al. 2022c), using the distribution of effective samples as an indicator of client contributions, while respecting privacy constraints.

# Methodology

# Problem Formulation

In this paper, we define a federated heterogeneous graph learning framework consisting of a global server and $K$ clients. Each client, indexed as the $k ^ { t h }$ client, stores and maintains an independent heterogeneous graph dataset $D ^ { k } = ( \mathcal { G } ^ { k } , X ^ { k } , Y ^ { k } )$ , where $X ^ { k }$ and ${ \bar { Y } } ^ { k }$ are feature matrix and label matrix, $\mathcal { G } ^ { k } = ( V ^ { k } , E ^ { k } , A ^ { k } , R ^ { k } )$ is the heterogeneous graph. All clients will engage in federated learning to jointly train a HGNN model without compromising local privacy.

# Framework Overview

The objective of RAFHGL is to collaboratively train a unified HGNN without disclosing local client data. Through AL to assess the quality of client-side data, we selectively choose samples that are more informative for the model. Utilizing the distribution of effective samples as an indicator for evaluating client quality can mitigate interference from other factors while ensuring data privacy. The overall framework of RAFHGL is illustrated in Figure 1.

# Active Learning Agent on Local Clients

On the local client side, ALA calculates the active scores of samples based on the local state. It prioritizes selecting nodes with higher scores to participate in the training of the local HGNN. Simultaneously, the statistical features of active scores are transmitted to the server. Since the outcomes of local AL serve as crucial inputs for the global reinforcement learning state, generating stable and accurate AL results is paramount. RL algorithm can adaptively adjust sample selection strategies to address diverse usage scenarios and the continually evolving global model.

To achieve this objective, the instantiation of AL on the client side is structured as a Markov Decision Process (MDP). The ALA on the $k ^ { t h }$ client can be represented as a tuple $\mathcal { M } ^ { k } = \langle S ^ { k } , U ^ { k } , r ^ { k } \rangle$ , where $S ^ { k }$ denotes the local state set, $U ^ { k }$ signifies the action set, specifically the probability distribution over output selections, and $r ^ { k }$ signifies the reward associated with the chosen action.

![](images/d07412c1cbf9bf4fb050a924bef8e1e48c442b680a71f838648f7a2d42a2b5db.jpg)  
Figure 1: Architecture of the proposed Reinforcement Active Client Selection based Federated Heterogeneous Graph Learning (RAFHGL), which primarily relying on 2 distinct agents, the local Active Learning Agent (ALA) and the global Client Selection Agent (CSA), to assist the server in precisely assessing client information and selecting the most informative clients for global model convergence. Simultaneously, the proactive selection by the 2 agents introduces bias into the training data, thereby prompting the proposal of a data-prototype-based mitigating method, which aims to alleviate the overly personalized development of local models.

State. The local active state $s ^ { k }$ comprises 3 key aspects: Node centrality, reflecting a node’s significance in the data network, is effectively calculated using the PageRank algorithm (Zhang et al. 2022b). Information entropy gauges the classifier’s ease in accurately classifying a node’s embedding, with high entropy aiding the learning of ambiguous information and low entropy reinforcing existing knowledge. In a federated system, information density involves AL on a client, selecting samples with the highest training priority instead of creating a core set for labeling. This paper utilizes the hidden layer representation of nodes to assess the embedding density of samples, as traditional methods relying on distance computation with core sets are challenging to apply.

Action. In accordance with the state of the local node, ALA computes active scores for all local samples using a fixed batch size. The top- ${ \bf \nabla } \cdot { \cal B } _ { s }$ samples with the highest proactive scores are selected to participate in local training. Simultaneously, statistical features of the active scores are calculated.

Reward. The objective of local AL can be summarized as enhancing the model’s performance, specifically in terms of both local training performance $A c c ^ { L }$ and global model performance $A c c ^ { G }$ . It is crucial to note that elevating the global performance takes precedence; hence, the change in global performance is computed and exponentially amplified through an exponential base $B _ { L }$ . To ensure that samples possessing lower or even negative local performance changes, but which could contribute to the enhancement of global performance, are not overlooked, local performance is accorded a linear weight. The specific computational formula is provided in Eq. 1.

$$
r _ { t } ^ { k } = B _ { L } ^ { ( A c c _ { t } ^ { G } - A c c _ { t - 1 } ^ { G } ) } + A c c _ { t } ^ { L } .
$$

# Client Selection Agent on Global Server

On the global server side, CSA on global server constructs a global state derived from the aggregated statistical features of active scores across all clients. Subsequently, the server identifies clients most likely to make significant contributions to the global model for model aggregation. Therefore, in each round of federated communication, we employ CSA to select $K$ devices for participation in training. The specific design of the agent CSA for CS is outlined as follows:

State. The selection state of the global client can be represented as a vector $s _ { G } = \{ u _ { 1 } , u _ { 2 } , . . . , u _ { K } \}$ , where $u _ { k }$ signifies the statistical features of the active score results of the $k ^ { t h }$ client. For a given parameter $n _ { q }$ , the statistical features correspond to the $n _ { g } ^ { k ^ { t h } }$ quantile of the assessment results.

Action. Similar to the work presented in (Wang et al. 2020), the action space is defined as $\{ 1 , 2 , . . . , K \}$ , where $a = k$ indicates the selection of the $k ^ { t h }$ device for participation in federated training.

Reward. The reward, on the other hand, is computed according to Eq. 2. This is designed to incentivize the agent to approach the target accuracy $\mathbf { \bar { \boldsymbol { A } } } \boldsymbol { c } \boldsymbol { c } ^ { T }$ , thereby achieving higher precision while concurrently controlling the number of training rounds. Here, $B _ { G }$ represents the global exponential base.

$$
r _ { g l o b a l } = B _ { G } ^ { ( A c c ^ { G } - A c c ^ { T } ) } - 1 .
$$

# Mitigating Active Drift through Data Prototype

Due to the data selection process on both the client and server sides, the global model in each aggregation round is influenced by only a subset of distinctive data. This may potentially lead to the convergence of the global model to a local optimum and exacerbate client drift phenomena. To address this issue, we propose a mitigation strategy based on data prototypes (Tan et al. 2022; Long et al. 2023). This strategy aims to constrain local training, thereby preventing overly significant impacts of outlier samples on the model and ensuring training stability.

Specifically, each client initially calculates the local data prototypes $C _ { k }$ based on the hidden layer representations of their local dataset $D _ { k }$ .

$$
C _ { k } = \frac { 1 } { | D _ { k } | } \sum _ { ( x , y ) \in D _ { k } } f _ { k } ( \theta _ { k } ; x ) ,
$$

where $f _ { k } ( \theta _ { k } ; \cdot )$ represents the local heterogeneous graph neural network on $\bar { k } ^ { t h }$ client.

Subsequently, the RAFHGL server collects all client prototypes to obtain a global prototype set $\begin{array} { r l } { \mathcal { P } } & { { } = } \end{array}$ $\mathbf { \bar { \{ C _ { 1 } , \bar { C _ { 2 } } , . . . , C _ { K } \} } }$ , which is then distributed to the clients. During this process, the server refrains from aggregating the prototypes. Instead, it introduces a regularization term Lkmitigate to penalize those nodes whose hidden layer features deviate from the entire federated system.

$$
\mathcal { L } _ { m i t i g a t e } ^ { k } = \sum _ { ( \boldsymbol { x } , \boldsymbol { y } ) \in D _ { k } } \operatorname* { m i n } _ { i _ { k } ^ { * } } \| \boldsymbol { f } _ { k } ( \boldsymbol { \theta } _ { k } ; \boldsymbol { x } ) - C _ { i _ { k } ^ { * } } \| ^ { 2 } .
$$

The addition of the regularization term aims to mitigate client drift induced by repeated active selections between both the client side and the server side. Excessive penalization, however, might restrict the pace of client exploration in the solution space, leading to a reduced convergence speed. Therefore, rather than computing a global prototype, we intuitively select the local prototype with the smallest deviation from the respective local client for correction.

$$
C _ { i _ { k } ^ { * } } = \mathcal { P } \odot C _ { k } = \operatorname* { m i n } _ { 0 < i < N , i \neq k } \left\| C _ { k } - C _ { i } \right\| ^ { 2 } .
$$

# Training Process

The complete training process of RAFHGL is outlined in Algorithm 1. On the client side, ALA evaluates local heterogeneous graph nodes based on topology, entropy, and embedding information, generating statistical features of the active score. It prioritizes the top- ${ \bf \nabla } \cdot { \cal B } _ { s }$ samples with the highest active scores for local updates. During local updates, the algorithm calculates the loss $\mathcal { L } ^ { k } \theta$ of the HGNN and simultaneously computes the mitigation term ${ \mathcal { L } } ^ { k }$ mitigate based on Eq. 4. The HGNN is then updated according to the total loss $\mathcal { L } ^ { \hat { k } }$ . After each training round, the state transition is written into the Local Transition Replay Buffer (LTRB). Randomly selected transition samples from LTRB are used to

1: Procedure SERVEREXECUTION 2: Initialize CSA, $\mathcal { P }$ and $f _ { k } ( \theta _ { k } )$ for all clients. 3: for each communication round $\mathbf { t } = 1$ , 2, ..., T do 4: CSA selects a subset $S _ { t }$ of clients. 5: for each client $s \in S _ { t }$ do 6: $f _ { s } ^ { t } ( \theta _ { s } ^ { t } ) , \ u _ { s } ^ { t } , \ C _ { s } ^ { t } \ \gets \ \mathbf { C L I E N T U P D A T E } ( s , \ \mathcal { P } ^ { ( t - 1 ) } ,$ $f ^ { ( t - 1 ) } ( \theta ^ { ( t - 1 ) } ) ;$ ) 7: end for 8: Update global information $f ^ { t } ( { \boldsymbol { \theta } } ^ { t } ) , \mathcal { P } ^ { t } , s _ { G } ^ { t }$ 9: Store global transition and train CSA. 10: end for 11: 12: Procedure CLIENTUPDATE $( k , { \mathcal { P } } , f ( \theta ) )$ 13: for epoch $\mathbf { e } = 1$ , 2, ..., E do 14: CSA calculates active scores for all nodes. 15: Select top- $B _ { s }$ samples as $D _ { s } ^ { k }$ . 16: for minibatch $m$ sampled from $D _ { s } ^ { k }$ do 17: Calculate $\mathcal { L } _ { \theta } ^ { k }$ using $Y ^ { k }$ and $f _ { k } ( \breve { \theta } _ { k } ; x ^ { k } )$ . 18: Calculate Lkmitigate according to Eq. 4. 19: Lk = Lθk + λLkmitigate 20: Update local model according to ${ \mathcal { L } } ^ { k }$ . 21: end for 22: Store local transition and train ALA. 23: end for 24: Calculate $u _ { k } ^ { t }$ and $C _ { k } ^ { t }$ . 25: Update $f _ { k } ^ { t } ( \ddot { \theta } _ { k } ^ { t } )$ , $u _ { k } ^ { t }$ , $\dot { C } _ { k } ^ { t }$ to Server.

train the ALA. On the server side, a stochastic probability $\epsilon$ is employed to determine whether to select a client using actions generated by CSA. With probability $\epsilon$ , the global server selects a client based on CSA-generated actions, and with probability $1 - \epsilon$ , it adopts a CS strategy using AFL with the mean active score. In the initial stages, when $\epsilon$ is relatively large, clients are selected using a heuristic approach, preparing a substantial training dataset for CSA. Similarly, the global state transition is recorded in a global replay buffer for CSA training. During each communication round using CSA to select clients, the server utilizes stored statistical features of active scores to obtain global states. Using actions generated by CSA, the server selects clients $S _ { t }$ to participate in aggregation. It obtains local models from the selected clients to aggregate the global model, and collects corresponding updates to the global prototype set $\mathcal { P }$ . The selected clients also upload statistical feature updates of active scores to update the CSA state, eliminating additional communication overhead.

# Experiments

# Experiment Setting

Datasets. We conducted node classification experiments on 4 popular public HG datasets, as shown in Table 1.

Data partition. We employed 2 distinct data partitioning methods for creating a federated environment. Uniform: nodes in the HIN were randomly divided into $K$ subsets. Subsequently, a subgraph for each subset was constructed

Acc on Academic Acc on DBLP Acc on ACM Acc on Yelp 0.8   
0.5 0.6 Accuracy 0.6 0.4 0.4 0.3 0.4 0 50 100 150 0 50 100 150 0 50 100 0 50 100 Communication Rounds Communication Rounds Communication Rounds Communication Rounds Loss on Academic Loss on DBLP Loss on ACM Loss on Yelp 1.5 1.0 1.2   
1.0 1.0 1.0   
0.5 0.5 0.8   
1 1 0.0 0.0 0.0 0.6 0 5R0and1o0m0 150 Clus0ter_G50 100 Fe1d5C0or 0 AFL 50 1F0e0dMarl RA5F0HGL 100 Cluster_N DivFL pow-d ACFL FAVOR

Table 1: Description of datasets.   

<html><body><table><tr><td>Datasets</td><td>#Nodes</td><td>#Edges</td><td>#Labels</td></tr><tr><td>Academic(Zhang et al.2019)</td><td>49,708</td><td>202.067</td><td>5</td></tr><tr><td>DBLP(Fu et al. 2020)</td><td>26,128</td><td>239,566</td><td>4</td></tr><tr><td>ACM(Yun et al.2019)</td><td>11,246</td><td>34,852</td><td>3</td></tr><tr><td>Yelp(Hu,Fang,and Shi 2019)</td><td>3,913</td><td>77,360</td><td>3</td></tr></table></body></html>

to represent a sub-dataset in the federated system. This ensured roughly equal node quantities and uniform label distributions across clients. Dirichlet: utilize a Dirichlet distribution $D ( \beta )$ to partition target nodes for classification, while the remaining nodes were randomly assigned. The resulting subgraphs represented $K$ clients with varying label distributions and node quantities. These approaches simulate different degrees of data heterogeneity among clients in the FL scenario.

Baseline. In the context of FHGL, we implemented various CS algorithms for comparative experiments to validate the performance of RAFHGL, including Random(Li et al. 2020), Cluster N(Fraboni et al. 2021), Cluster G(Fraboni et al. 2021), DivFL(Balakrishnan et al. 2022), FedCor(Tang et al. 2022), pow-d (Cho, Wang, and Joshi 2020), AFL(Goetz et al. 2019), ACFL (Huang et al. 2023), FedMarl(Zhang, Lin, and Zhang 2022), FAVOR (Wang et al. 2020). To ensure fairness, all methods use a HAN with 8 attention heads and a hidden layer size of 128 as the local training model, and are trained with the same set of hyperparameters in . We employ the Adam optimizer with a learning rate of [0.005, 0.002, 0.003, 0.003] across 4 datasets, and weight decay is set to $1 0 ^ { - 7 }$ in all experiments.

Implementation details. Our implementation of heterogeneous graph networks is based on the DGL(Wang et al. 2019) library, while the processing of heterogeneous information network data relies on the OpenHGNN(Hui Han 2022) library. GPU acceleration is performed on NVIDIA RTX 2080 TI. To maximize the disparity in partition results and achieve a significant difference from random partitioning, the $\beta$ parameter in the $D ( \beta )$ is set to 0.5. For RAFHGL, CSA is trained using Double Deep Q-Network (DDQN) (Van Hasselt, Guez, and Silver 2016), while ALA is trained using Deep Q-Network (DQN) (Mnih et al. 2015). The neural network architectures for both agents consist of a two-layer perceptron with a hidden layer size of 256. The learning rate for the agents is set to 0.001.

# Performance Analysis

To validate the robustness of the RAFHGL algorithm and assess its performance across diverse federated environments, we conducted a comprehensive comparison with baseline algorithms under various federated settings, including different data partitioning methods, federated client quantities, and local training epochs. Some representative training curves are illustrated in Figure 2. It is evident that RAFHGL consistently demonstrates stable convergence and outstanding accuracy across all datasets. Baseline methods either exhibit overall inferior performance compared to RAFHGL or involve a noticeable trade-off between convergence and accuracy. Methods with faster convergence often struggle to ensure final performance, while those exhibiting better performance require a higher number of communication rounds.

Different setting of partition method. We conducted experiments on 4 datasets using different partitioning methods, and the results are presented in Table 2. RAFHGL not only achieves high accuracy across various data partitions for each dataset but also exhibits smaller accuracy disparities among clients. The highest improvement, notably, reaches up to $1 1 . 8 1 \%$ and $9 \%$ on the Yelp dataset. In the case of the DBLP dataset with Dirichlet partitioning, the accuracy variance also decreases by $6 . 2 \%$ to $9 . 1 8 \%$ . It is worth noting that when partitioning graph data, some edges are inevitably discarded.

Table 2: Comparison of method Accuracy $\left( \% \right)$ across different data partition strategies. When sampling according to the Dirichlet distribution, similar nodes are more likely to be clustered on the same client, preserving more edge information. Therefore, the performance differences between the two partitioning methods are not solely attributed to data heterogeneity.   

<html><body><table><tr><td rowspan="2"></td><td colspan="2">Academic</td><td colspan="2">DBLP</td><td colspan="2">ACM</td><td colspan="2">Yelp</td></tr><tr><td>Uniform</td><td>Dirichlet</td><td>Uniform</td><td>Dirichlet</td><td>Uniform</td><td>Dirichlet</td><td>Uniform</td><td>Dirichlet</td></tr><tr><td>Random</td><td>56.27±4.45</td><td>66.57±8.76</td><td>67.42±5.94</td><td>73.40±8.87</td><td>85.85±4.32</td><td>81.10±12.86</td><td>70.01±5.82</td><td>74.84±8.53</td></tr><tr><td>Clusterd_N</td><td>56.42±4.66</td><td>66.65±8.79</td><td>67.71±6.04</td><td>73.12±9.47</td><td>86.21±4.54</td><td>81.03±13.02</td><td>69.85±4.23</td><td>74.90±8.61</td></tr><tr><td>Clusterd_G</td><td>55.91±4.70</td><td>65.91±9.55</td><td>67.61±5.79</td><td>73.14±10.28</td><td>84.93±4.40</td><td>81.22±12.81</td><td>67.58±6.69</td><td>74.91±14.07</td></tr><tr><td>DivFL</td><td>52.86±6.74</td><td>66.03±8.23</td><td>67.33±6.71</td><td>73.73±8.17</td><td>86.11±4.19</td><td>81.38±12.91</td><td>63.51±5.16</td><td>72.75±14.28</td></tr><tr><td>FedCor</td><td>56.13±4.71</td><td>65.46±10.20</td><td>66.09±7.20</td><td>69.35±16.48</td><td>86.23±5.14</td><td>79.62±16.01</td><td>72.27±4.09</td><td>66.88±16.81</td></tr><tr><td>pow-d</td><td>56.25±4.64</td><td>66.82±8.75</td><td>67.21±6.26</td><td>73.33±8.21</td><td>84.99±4.39</td><td>81.60±14.10</td><td>67.24±7.00</td><td>74.81±8.51</td></tr><tr><td>AFL</td><td>56.27±4.46</td><td>66.95±8.33</td><td>66.84±6.51</td><td>73.47±9.04</td><td>86.23±4.76</td><td>79.77±12.82</td><td>70.76±5.83</td><td>74.82±8.43</td></tr><tr><td>ACFL</td><td>56.41±4.79</td><td>66.51±9.39</td><td>67.14±6.77</td><td>73.53±9.17</td><td>86.10±5.15</td><td>80.72±12.78</td><td>70.22±6.46</td><td>74.67±7.53</td></tr><tr><td>FedMarl</td><td>51.75±6.29</td><td>65.66±8.66</td><td>67.04±6.05</td><td>73.47±8.79</td><td>85.72±7.32</td><td>78.52±12.95</td><td>71.31±5.84</td><td>69.14±14.69</td></tr><tr><td>FAVOR</td><td>55.73±4.84</td><td>66.10±8.73</td><td>67.12±7.17</td><td>73.52±9.03</td><td>85.82±4.88</td><td>80.82±12.83</td><td>61.05±10.71</td><td>66.07±6.92</td></tr><tr><td>RAFHGL</td><td>56.62±3.47</td><td>69.01±8.16</td><td>67.73±5.06</td><td>74.68±7.30</td><td>86.57±4.08</td><td>82.24±12.71</td><td>72.86±3.92</td><td>75.07±6.86</td></tr></table></body></html>

<html><body><table><tr><td rowspan="2"># Total</td><td colspan="3">10</td><td colspan="3">20</td><td colspan="3">30</td></tr><tr><td># Selected 2</td><td>3</td><td>5</td><td>2</td><td>5</td><td>10</td><td>5</td><td>10</td><td>15</td></tr><tr><td>Random</td><td>91(1.6x)</td><td>78(1.6x)</td><td>75(2.2x)</td><td>128(1.4x)</td><td>110(1.7x)</td><td>100(1.7x)</td><td>104(1.2x)</td><td>93(1.3x)</td><td>91(1.4x)</td></tr><tr><td>Cluster-N</td><td>101(1.7x)</td><td>88(1.8x)</td><td>87(2.6x)</td><td>91(1x)</td><td>84(1.3x)</td><td>80(1.4x)</td><td>116(1.4x)</td><td>86(1.2x)</td><td>81(1.3x)</td></tr><tr><td>Cluster-G</td><td>145(2.5x)</td><td>84(1.7x)</td><td>52(1.5x)</td><td>145(1.6x)</td><td>90(1.4x)</td><td>63(1.1x)</td><td>104(1.2x)</td><td>82(1.2x)</td><td>71(1.1x)</td></tr><tr><td>DivFL</td><td>130(2.2x)</td><td>93(1.9x)</td><td>78(2.3x)</td><td>155(1.6x)</td><td>67(1x)</td><td>59(1x)</td><td>131(1.5x)</td><td>98(1.4x)</td><td>80(1.3x)</td></tr><tr><td>FedCor</td><td>132(2.3x)</td><td>95(1.9x)</td><td>84(2.5x)</td><td>127(1.7x)</td><td>82(1.2x)</td><td>79(1.4x)</td><td>123(1.4x)</td><td>96(1.4x)</td><td>82(1.3x)</td></tr><tr><td>pow-d</td><td>87(1.5x)</td><td>67(1.3x)</td><td>40(1.2x)</td><td>121(1.4x)</td><td>77(1.2x)</td><td>62(1.1x)</td><td>89(1x)</td><td>84(1.2x)</td><td>75(1.2x)</td></tr><tr><td>AFL</td><td>93(1.6x)</td><td>100(2x)</td><td>104(3x)</td><td>115(1.3x)</td><td>83(1.3x)</td><td>75(1.3x)</td><td>88(1x)</td><td>70(1x)</td><td>110(1.7x)</td></tr><tr><td>ACFL</td><td>105(1.8x)</td><td>99(2x)</td><td>77(2.3x)</td><td>155(1.7x)</td><td>80(1.2x)</td><td>64(1.1x)</td><td>114(1.3x)</td><td>99(1.4x)</td><td>74(1.2x)</td></tr><tr><td>FedMarl</td><td>141(2.4x)</td><td>130(2.6x)</td><td>76(2.2x)</td><td>122(1.4x)</td><td>99(1.5x)</td><td>103(1.8x)</td><td>115(1.4x)</td><td>92(1.3x)</td><td>86(1.4x)</td></tr><tr><td>FAVOR</td><td>94(1.6x)</td><td>80(1.6x)</td><td>48(1.4x)</td><td>107(1.2x)</td><td>94(1.4x)</td><td>63(1.1x)</td><td>127(1.5x)</td><td>76(1.1x)</td><td>107(1.7x)</td></tr><tr><td>RAFHGL</td><td>58(1x)</td><td>50(1x)</td><td>34(1x)</td><td>90(1x)</td><td>65(1x)</td><td>56(1x)</td><td>85(1x)</td><td>69(1x)</td><td>63(1x)</td></tr></table></body></html>

Table 3: Convergence rounds required under a distinct number of total clients and selected participation in aggregation pe ound on Academic. Diverse client quantities serve to simulate various federated scenarios.

Different setting of client number. Diverse client quantities serve to simulate various federated scenarios. We conducted experiments with total clients set at [10, 20, 30], and the results in Table 3 clearly demonstrate that RAFHGL exhibits significant convergence speed advantages over baseline algorithms across different client quantity settings. Specifically, when selecting 2 clients from 10, 2 clients from 20, and 5 clients from 30, RAFHGL demonstrates improved convergence efficiency by $3 6 \%$ , $30 \%$ , and $18 \%$ , respectively, compared to the Random method.

Different setting of local training epoch. The number of local training epochs directly impacts the overall training effectiveness. RAFHGL demonstrates more pronounced performance advantages with an increase in local training rounds as shown in Figure 3. In scenarios where local training rounds are set at [3, 5, 10], RAFHGL exhibits accuracy improvements of $1 . 1 \%$ , $1 . 0 8 \%$ , and $1 . 6 9 \%$ , respectively. Additionally, even with lower local training rounds, RAFHGL ensures a convergence advantage, outperforming the Random method by 20 rounds when local training epochs are set at 1.

# Parameter Analysis

RAFHGL’s hyperparameters consist of common hyperparameters shared among algorithms and hyperparameters unique to RAFHGL. Common hyperparameters like model learning rate and weight decay, which are adjusted and selected through simple tuning and shared across all algorithms. RAFHGL’s unique hyperparameters like the loss weight $\lambda$ , the learning rates and the length of the hidden layer of the 2 agents. It is satisfying to note that most of these unique hyperparameters demonstrate considerable robustness, as variations across datasets have minimal impact on model performance. While parameters like the strategy probability $\epsilon$ exert significant influence on model performance as shown in Figures 4, but this influence follows consistent patterns across different datasets. For unique hyperparameter that exhibit minimal variation across datasets, we conduct parameter tuning on Academic dataset and apply the same settings across all datasets. A notably unique hyperparameter is the quantiles $n _ { q }$ , which yields significant differences in results across different datasets, as illustrated in Figure 5 for the 4 datasets.

![](images/36d54d524e7c3ca6ba8759d7355351a9287b2c46109e571ec7eb34cd489887f1.jpg)  
Figure 3: Performance comparison under various local epochs. More local training epochs can accelerate convergence but may intensify the client drift effect, consequently diminishing overall performance.

![](images/7467dad7b542f627577d0ebbf138c9bb780828209bc07d9d2b6e45aac6159a47.jpg)  
Figure 4: Parameter sensitivity under different $\epsilon$ descent behavior. Subfigure (a) depicts the scenario with an initial $\epsilon$ value of 1, while Subfigure (b) illustrates the situation with an initial $\epsilon$ value of 0.8.

# Ablation Study

To validate the effectiveness of the RAFHGL modules, we designed eight different ablation experiment methods. $( 1 ) P$ : Data prototypes are introduced to alleviate client drift stemming from random client selection. (2) RA: Built upon random client selection, it involves local training node filtration through ALA during training. (3) $R A { + } P$ : Introduces ALA for local node selection while mitigating data distribution drift based on data prototypes, while excluding CSA from RAFHGL and randomly selecting clients. (4) $R A { + } C S$ : Utilizes ALA to assess data node quality and perform selection, with CSA employed for server-side client selection, but without utilizing prototype-based loss correction to mitigate data distribution drift. (5) LC, (6) $E$ , and (7) MS each incorporate active selection algorithms based on least confidence, information entropy, and marginal confidence, respectively, as alternatives to ALA within the RAFHGL framework. (8) agg, building upon RAFHGL, aggregates ALA while also aggregating local HGNN. Experimental results, as presented in Table 4, confirm significant performance advantages of

![](images/66cf93e1c92b04c8f0144c6f86a116785789fdadc0affbc1143b00c24ac1ceef.jpg)  
Figure 5: Performance on different quantiles $n _ { q }$ . Excessively small $n _ { q }$ hinder the comprehensive representation of client data quality, while excessively large $n _ { q }$ lead to redundancy, making it difficult to distinguish between different clients. The optimal $n _ { q }$ values are concentrated around 4 or 6.

RAFHGL compared to degradation methods, thereby validating the effectiveness of its combined component usage.   
Table 4: Ablation study of RAFHGL in terms of Accuracy $( \% )$ and convergence Rounds on DBLP.   

<html><body><table><tr><td>method</td><td>Acc</td><td>Rounds</td><td>method</td><td>Acc</td><td>Rounds</td></tr><tr><td>RAFHGL</td><td>75.19</td><td>52</td><td>RAFHGL</td><td>75.19</td><td>52</td></tr><tr><td>P</td><td>72.20</td><td>95</td><td>LC</td><td>73.83</td><td>50</td></tr><tr><td>RA</td><td>73.03</td><td>59</td><td>E</td><td>72.56</td><td>53</td></tr><tr><td>RA+P</td><td>74.03</td><td>65</td><td>MS</td><td>73.66</td><td>53</td></tr><tr><td>RA+CS</td><td>73.99</td><td>52</td><td>agg</td><td>74.21</td><td>84</td></tr></table></body></html>

# Conclusion

In conclusion, this paper presents RAFHGL, a novel method aimed at overcoming challenges in CS for FHGL. By integrating RL and AL, RAFHGL dynamically adapts CS strategies during the FL process. The RL component CSA enables intelligent decision-making by considering delayed rewards. Concurrently, the introduction of AL on clients prioritizes nodes with higher perplexity in local training, allowing for a nuanced evaluation of client data quality by assessing the distribution of effective samples. Furthermore, we propose a local training correction algorithm based on data prototypes, which prevents node embeddings from deviating significantly from the prototype set. Experimental results across diverse federated learning scenarios highlight the effectiveness of RAFHGL. The method not only enhances model performance but also respects privacy constraints inherent in federated learning.

# Acknowledgments

This work is supported in part by the National Key Research and Development Program of China (2023YFF0725103), National Natural Science Foundation of China(62192784,U23A20319,62422202,62272054), the 8th Young Elite Scientists Sponsorship Program by CAST (2022QNRC001).