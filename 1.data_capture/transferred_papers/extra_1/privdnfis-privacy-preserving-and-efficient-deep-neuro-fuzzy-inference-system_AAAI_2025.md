# PrivDNFIS: Privacy-preserving and Efficient Deep Neuro-Fuzzy Inference System

Hao Ren 1 2 3, Xiao Lan 1 2 3, Rui Tang $^ \textrm { \scriptsize 1 2 3 * }$ , Xingshu Chen 1 2 3 †

1 School of Cyber Science and Engineering, Sichuan University, Chengdu 610065, China. 2 Key Laboratory of Data Protection and Intelligent Management (Sichuan University), Ministry of Education, China. 3 Cyber Science Research Institute, Sichuan University, Chengdu, China. hao.ren, lanxiao, tangrscu, chenxsh@scu.edu.cn

# Abstract

Deep Neuro-Fuzzy Inference Systems (DNFIS) seamlessly fuse neural networks with the fuzzy inference system enabling intricate decision-making and knowledge representation, while upholding a commendable degree of adaptability and interpretability. However, the challenge of privacypreserving inference (PI) over DNFIS has remained largely uncharted, with no prior research addressing this critical issue. In this paper, we embark on an exploration of this issue. We introduce an efficient and secure PI framework for DNFIS, named PrivDNFIS, which leverages the postquantum lattice-based homomorphic encryption to implement secure computation protocols for PI over DNFIS. Our work incorporates several non-trivial performance enhancements. Firstly, it consolidates multiple elements of input feature vectors into a single message, reducing encryption/decryption overhead. Secondly, building upon this novel encoding approach, PrivDNFIS can perform ciphertext aggregation and vector-vector inner production without necessitating time-consuming ciphertext rotation operations. Thirdly, we replace the softmax function in the DNFIS layer with a quadratic function to further enhance inference efficiency, without compromising the inference accuracy. Under the given threat model, we provide formal security proof for PrivDNFIS. In comprehensive experimental results, PrivDNFIS demonstrates an approximately 1.9 to 4.4 times reduction in end-to-end time cost compared to the benchmark.

# Introduction

Background Deep Neural Networks (DNNs) (LeCun, Bengio, and Hinton 2015; He et al. 2016) excelling in areas like image recognition, natural language processing (NLP), and medical diagnosis (Jin et al. 2024). However, their complexity, involving billions of connection weights, introduces challenges in understanding and trust. This necessitates explainable AI (Talpur et al. 2023; Yeganejou, Dick, and Miller 2019) to provide human-friendly explanations and build trust. A promising solution is deep neuro-fuzzy inference systems (DNFIS) (Yeganejou, Dick, and Miller 2019; Yeganejou et al. 2023), which combine deep learning’s pattern recognition with fuzzy logic’s interpretability.

This integration enables precise and transparent decisionmaking, especially in healthcare and legal contexts (Talpur et al. 2023). DNFIS leverages rule-based representations and intuitive linguistic variables for clarity, with proven high performance in fusing a DNN for feature extraction with a fuzzy system for classification (Yeganejou et al. 2023).

Despite the benefits of DNFIS, privacy concerns pose significant obstacles to its development. When users send inference requests to third-party model owners, they must share their original input, risking their privacy. In the case of DNFIS, input privacy is critical in scenarios like medical diagnosis. Users may upload sensitive health data to leverage the system’s capability for handling uncertainty and imprecision in decision-making. A breach in such cases could reveal private health records, leading to severe personal data leakage. Therefore, safeguarding input privacy for model inference services like DNFIS is critical and urgently needed, as mandated by regulations like GDPR (Lu et al. 2021).

Related Work Preserving input privacy in DNN model inference services has been extensively studied by both AI and security communities (Liu et al. 2021). The main objective of a privacy-preserving inference (PI) scheme is to compute inference results without accessing the original input. A promising approach involves using advanced cryptographic tools like fully homomorphic encryption (FHE) (Fan and Vercauteren 2012; Viand, Jattke, and Hithnawi 2021) and secure multiparty computation (MPC) (Hastings et al. 2019; Rathee et al. 2020). These methods allow the server to evaluate inference functions on the encrypted input. FHE supports arbitrary computation on ciphertexts without decryption or interaction (Viand, Jattke, and Hithnawi 2021), but its processing of non-linear functions is computationally intensive. Therefore, state-of-the-art (SOTA) PI schemes (Rathee et al. 2020; Huang et al. 2022; Lu et al. 2025) often use FHE for linear function evaluations and MPC for non-linear functions, such as ReLU and softmax. While MPC has lower computational overhead than FHE, it incurs higher communication costs and requires multiple interaction rounds (Hastings et al. 2019). Due to the complexity of DNNs and cryptographic techniques, the existing PI scheme (Huang et al. 2022) takes over two minutes to process a single query, indicating room for efficiency improvements.

To our knowledge, PI for DNFIS has not been explored in existing work. This paper seeks to initiate this topic and encourage future research. Our proposed scheme, PrivDNFIS, involves a co-design of the DNFIS network architecture (Yeganejou et al. 2023) and cryptographic primitives (Viand, Jattke, and Hithnawi 2021) to achieve PI for DNFIS, incorporating several non-trivial performance optimizations.

Technical Challenges It is non-trivial to build a PI scheme that accommodates DNFIS (Yeganejou et al. 2023) with provable security and high efficiency.

• Functionality. The main challenge is scrutinizing the DNFIS network architecture and the internal structure of its neurons to specify the computational tasks. Moreover, there is no existing secure computation protocol capable of accommodating fuzzy membership functions as indicated in (Yeganejou et al. 2023). This necessitates an investigation of both DNFIS and cryptographic techniques.   
• Security. The preservation of user input privacy necessitates a theoretical guarantee. Particularly, formally establishing its semantic security under the given threat model is a non-trivial task.   
• Efficiency. Excising PI schemes are often criticized for their inefficiency. However, cost reduction becomes difficult when complex inference functions and provable security are essential requirements.

Our Contributions We sum the contribution of PrivDNFIS as follows.

• PrivDNFIS initializes the research on designing a PI scheme for DNFIS. A secure and efficient PI system is presented using somewhat homomorphic encryption (SHE) (Fan and Vercauteren 2012) and ciphertext extraction technique (Chen et al. 2021). PrivDNFIS is expected to motivate future efforts on this pivotal issue. • We give a formal security proof for PrivDNFIS under the widely applied semi-honest threat model (Hastings et al. 2019). The analysis is sound and succinct. • PrivDNFIS proposes several optimizations for secure aggregation and vector-vector inner production protocols. Specifically, the heavy ciphertext rotation operation is eliminated. Besides, we carefully tailor the last layer (softmax) of the existing DNFIS model (Yeganejou et al. 2023) to further boost the overall performance without undermining the accuracy. Compared to the benchmark, PrivDNFIS delivers roughly $1 . 9 \sim 4 . 4 \times$ end-to-end time cost reduction as evidenced by the experimental results.

# Preliminaries

Deep Neuro-fuzzy Inference Systems The classical Adaptive Neuro-Fuzzy Inference System (ANFIS) (Jang 1993) alters the network architecture to mimic the fuzzy inference system (Jang, Sun, and Mizutani 1997). ANFIS consists of the following five layers. $\bullet$ Input layer. It receives the input features from the user. Input nodes pass the input to the next layer. $\pmb { \theta }$ Fuzzification layer. It fuzzifies the inputs, mapping input values to fuzzy sets. Each input node is linked to fuzzy set (i.e., membership) functions, typically triangular or Gaussian, for fuzzifying input values and yielding membership degrees that signify the input values’ association with each fuzzy set. $\pmb { \otimes }$ Rule layer. It calculates the “firing strength” for each fuzzy rule, typically obtained as the product of all antecedent membership functions. $\pmb { \varrho }$ Hidden layer. It computes the output for each rule, and its output results from multiplying the rule’s activation by the fuzzification layer’s output. The output values will be aggregated using node weights (trainable parameters), typically through a linear combination. $\pmb { \Theta }$ Output layer. This layer computes and outputs the class probabilities. As shown in Fig. 1, DNFIS uses CNNs for feature extraction that produce the inputs for ANFIS. This framework follows the paradigm of the sequential deep neuro-fuzzy system (DNFS) (Talpur et al. 2023). It enjoys the benefits provided by both CNNs and ANFIS and is easy to deploy in practice.

![](images/04c0502003e92477f80f17884a85f002cc1f26a7b23a6db94572ffbda14d81a5.jpg)  
Figure 1: Diagram of Deep Neuro-Fuzzy Inference System.

Somewhat Homomorphic Encryption (SHE) SHE (Viand, Jattke, and Hithnawi 2021) is rooted in the Learning With Errors (LWE) problem (Gentry, Sahai, and Waters 2013) and its ring variant (RLWE) (Fan and Vercauteren 2012). They share common public parameters denoted as ${ \mathsf { H E . p p } } = N , p , q , \sigma$ , where $p$ and $q$ are integers with $q \gg$ $p > 0$ , and $\sigma$ represents the standard deviation of error sampling. In the RLWE scheme, plaintext messages are polynomials in $R _ { N , p }$ . This scheme is comprised of three essential algorithms, namely ${ \mathsf { R . K e y G e n } } ( { \mathsf { H E . p p } } )$ for public/private key $( \mathrm { p k _ { R } } , \mathrm { s k _ { R } } )$ generation, ${ \mathsf { R } } . { \mathsf { E n c } } ( { \mathrm { p k } } _ { \mathrm { R } } , { \widehat { m } } )$ for encryption of messages $\widehat { \ b { m } } \in { \cal R } _ { N , p }$ into ciphertexts $\dot { \mathsf { C T } } \in R _ { N , q } ^ { 2 }$ , and ${ \mathsf { R . D e c } } ( { \mathrm { s k _ { R } , C T } } )$ for recovering message $\widehat { \ b { m } }$ . In contrast, the LWE scheme operates with plaintexts in $\mathbb { Z } _ { p }$ and ciphertexts in $\mathbb { Z } _ { q } ^ { N + 1 }$ . Its structure mirrors that of the RLWE scheme, encapsulated in $\mathsf { L . K e y G e n ( \cdot ) , L . E n c ( \cdot ) , L . D e c ( \cdot ) }$ . SHE shall support the following homomorphic evaluations.

• $\mathsf { C t P t A d d } ( \mathsf { C T } _ { \widehat { u } } , \widehat { v } ) \to \mathsf { C T }$ . It takes the ciphertext ${ \mathsf { C T } } _ { \widehat { \boldsymbol { u } } }$ of the plaintext mb esbsage $\widehat { u }$ and another plaintext messagbe $\widehat { v }$ as the inputs. It returnsbCT, that is a ciphertext of $\widehat { u } + \widehat { v }$ .b   
• $\mathsf { C t C t A d d } ( \mathsf { C T } _ { \widehat { u } } , \mathsf { C T } _ { \widehat { v } } ) \to \mathsf { C T } .$ . It takes the ciphertexbt ${ \mathsf { C T } } _ { \widehat { u } }$ , ${ \mathsf { C T } } _ { \widehat { v } }$ of the plabintetebxt messages ${ \widehat { u } } , { \widehat { v } } .$ , respectively as thbe inpubts. It returns $\mathsf { C T }$ , that is a ciphertext of $\widehat { u } + \widehat { v }$ .   
• $\mathsf { C t P t M u l } ( \mathsf { C T } _ { \widehat { u } } , \widehat { v } ) \to \mathsf { C T }$ . It takes the ciphebrtextb $\mathsf { C T } _ { \widehat { \boldsymbol { u } } }$ of the plaintext bmebssage $\widehat { u }$ and another plaintext messagbe $\widehat { v }$ as the inputs. It returnsbCT i.e. a ciphertext of ${ \widehat { u } } \times { \widehat { v } }$ .   
• $\mathsf { C t C t M u l } ( \mathsf C \mathsf T _ { \widehat { u } } , \mathsf C \mathsf T _ { \widehat { v } } ) \to \mathsf C \mathsf T$ . It takes the ciphebrtextb $\mathsf { C T } _ { \widehat { \boldsymbol { u } } }$ of $\widehat { u }$ and anotbher cibphertext of $\widehat { v }$ as the inputs. It returnbs CTbi.e. a ciphertext of ${ \widehat { u } } \times { \widehat { v } }$ .   
• $\mathsf { E x t r a c t } ( \mathsf { C T } , i )$ . For a gibvenbmessage $\widehat { \ b { m } }$ and its RLWE ciphertext CT, this function can extractbthe $i$ -th coefficient of $\widehat { \ b { m } }$ from CT, and transfer it to a LWE format ciphertextb. The decryption key can be computed by a key switch algorithm (Chen et al. 2021).

Private query Private features CNN Extractedfeatures! Encrypted resultsANFIS Cloud Server A 、Model User Cloud_ServerB

# Problem Statement

System Model As shown in Fig. 2, the system of PrivDNFIS consists of three entities, that are the cloud server A $( \mathcal { C } S _ { A } )$ , cloud server B $( \mathcal { C } S _ { B } )$ , and model user $( { \mathcal { M } } { \mathcal { U } } )$ . In the following, we elaborate on the role of each entity.

• $\mathcal { C } \mathcal { S } _ { A }$ . It receives the private query request from the $\mathcal { M } \mathcal { U }$ to extract the features using the CNN model. This task is considered as the prelude of PrivDNFIS. • $\mathcal { M } \mathcal { U }$ . It could be any individual or organization in practice, that needs to issue inference service requests in a privacy-preserving manner. It first obtains the encrypted extracted features from $\mathcal { C } \mathcal { S } _ { A }$ and interacts with $\mathcal { C }  { \boldsymbol { S } } _ { B }$ to acquire the encrypted results over ANFIS. • $\mathcal { C }  { \boldsymbol { S } } _ { B }$ . It receives the private encrypted features from $\mathcal { M } \mathcal { U }$ and computes the inference over the ciphertext domain. At last, it returns the final results to $\mathcal { M } \mathcal { U }$ . In PrivDNFIS, we put main efforts into designing secure computing protocols for $\mathcal { C }  { \boldsymbol { S } } _ { B }$ over the modified ANFIS model.

Threat Model $\mathcal { M } \mathcal { U }$ is considered to be fully trusted. It will strictly follow the designed secure protocols. In practice, $\mathcal { M } \mathcal { U }$ has no motivation to manipulate the queries at the price of receiving inaccurate inference results. Cloud service providers follow pre-defined secure protocols and return the correct results for economic rewards. However, the cloud service providers may be interested in the content of the received data and peek at the users’ privacy (Lu et al. 2021) for economic interests. This threat model is practical and prevalently applied by existing schemes (Lu et al. 2021). Prior works dubbed it as ”semi-honest” (Lindell 2017). Under this model, $\mathcal { C } \mathcal { S } _ { A }$ and $\mathcal { C }  { \boldsymbol { S } } _ { B }$ will faithfully execute the given private computing protocols but attempt to peek into user data. We acknowledge that it is vital to develop malicious user detection mechanisms. Due to space limitations, we will study this issue in future work.

# Proposed Scheme

We now present PrivDNFIS layer by layer, detailing how the secure computation tasks are evaluated. We commit to co-design on ANFIS (Jang 1993) and SHE acceleration to boost the efficiency with mild accuracy loss.

# Input Layer

The input layer takes the encrypted input from $\mathcal { M } \mathcal { U }$ and feeds it to the next layer. However, this is non-trivial to generate the inputs that meet the following requirements. First, the original content of the features should be strictly concealed from the server $\mathcal { C }  { \boldsymbol { S } } _ { B }$ with semantic security. Second, the private input should support the processing of the consecutive layers. Third, the message packing method needs to be compatible with the homomorphic evaluation functions. It is non-trivial to achieve these three goals simultaneously because they demand strong privacy preservation, rich functionality, and high efficiency in one scheme, that is the design goal of PrivDNFIS.

Instead of using traditional Chinese Remainder Theorem (CRT) packing methods like SV (Smart and Vercauteren 2014), PrivDNFIS directly packs messages into the coefficients of the plaintext polynomial. For example, given a feature vector $\mathbf { v } = [ 1 , 2 , 3 , 4 ]$ , the vector is encoded as the polynomial $\widehat { v } = 1 x ^ { \mathrm { 0 } } + 2 x ^ { 1 } \dot { + } 3 x ^ { 2 } + 4 x ^ { 3 }$ . Each element of $\mathbf { v }$ is mapped into the polynomial coefficients, with unused coefficients set to 0. This method can also support Single Instruction Multiple Data (SIMD) (Viand, Jattke, and Hithnawi 2021) homomorphic evaluations. Let $\widehat { u } , \widehat { v } \in R _ { N , p }$ , then we have the addition $\widehat { a } = \widehat { u } + \widehat { v }$ over $R _ { N , p }$ ibs defined as $\widehat { a } [ i ] = \widehat { u } [ i ] + \widehat { v } [ i ]$ . The probduc ${ \widehat { p } } [ i ] = { \widehat { u } } \times { \widehat { v } }$ is calculated as tbhe fol bowing bequation.

$$
\begin{array} { r c l } { { } } & { { } } & { { \displaystyle \widehat { p } [ i ] = \sum _ { 0 \leq j \leq i } \widehat { u } [ j ] \widehat { v } [ i - j ] - } } \\ { { } } & { { } } & { { \displaystyle \sum _ { i < j < N } \widehat { u } [ j ] \widehat { v } [ N + j - i ] \bmod p . } } \end{array}
$$

The correctness of Equation 1 is based on the property $x ^ { N } \equiv$ $- 1$ mod $x ^ { N } { + } 1$ . Given RLWE ciphertexts $\mathsf { C T } _ { \widehat { u } }$ and ${ \mathsf { C T } } _ { \widehat { v } }$ , invoking $\mathsf { C t P t A d d } ( \mathsf { C T } _ { \widehat { u } } , \widehat { v } )$ or $\mathsf { C t C t A d d } ( \mathsf { C T } _ { \widehat { u } } , \mathsf { C T } _ { \widehat { v } } )$ retubrns a ciphertext of $\widehat { u } + \widehat { v }$ , subppborting element-wisbe addibtion homomorphically (bSIMbD). Note that, invoking $\mathsf { C t P t M u l } ( \mathsf { C T } _ { \widehat { u } } , \widehat { v } )$ results in a ciphertext of $\widehat { p }$ , not element-wise multiplicatbiobn, meaning SIMD isn’t suppborted.

Let $\mathbf { d }$ be the feature vector, $\mathcal { M } \mathcal { U }$ first maps the elements into a polynomial using the above method. We write the polynomial as $\widehat { d } \in R _ { N , p }$ . Then $\mathcal { M } \mathcal { U }$ obtains the ciphertext of $\widehat { d }$ as $\mathsf { C T } _ { \widehat { d } } \gets \mathsf { R . E n c } ( \mathrm { p k _ { R } } , \widehat { d } ) \ \in \ R _ { N , q } ^ { 2 }$ . In practice, the timeb cost of bciphertext-cipher ebxt multiplication homomorphic evaluation can be $1 0 0 \times$ than CtCtAdd( ), $\mathsf { C t P t A d d } ( \cdot )$ , and $\mathsf { C t P t M u l ( \cdot ) }$ (Mughees and Ren 2023). Thus, if we can refrain from this operation, the entire performance will be significantly improved. To achieve this, $\mathcal { M } \mathcal { U }$ calculates $\mathbf { d } ^ { * } [ i ] { \bf \bar { \alpha } } = ( \mathbf { d } [ i ] ) ^ { \bar { 2 } } , i \in [ | \mathbf { d } | ]$ . Then it is encoded as a polynomial $\widehat { d } ^ { * }$ . At last, $\mathcal { M } \mathcal { U }$ encrypts $\widehat { d } ^ { * }$ as $\mathsf { C T } _ { \widehat { d } ^ { * } } \gets \mathsf { R . E n c } ( \mathrm { p k } _ { \mathrm { R } } , \widehat { d } ^ { * } )$ . Tbhus far, $\mathcal { M } \mathcal { U }$ has finished tbhe prepa rbation of the privatebinput, that is a pair of RLWE SHE ciphertexts $\{ \mathsf { C T } _ { \widehat { d } } , \mathsf { C T } _ { \widehat { d } ^ { * } } \}$ . It will be uploaded to $\mathcal { C }  { \boldsymbol { S } } _ { B }$ as the output of the inpbut layber.

# Fuzzification Layer

The fuzzification layer converts input data into fuzzy linguistic variables. It does this by linking each input variable to fuzzy sets (rules) defined by membership functions, which determine how strongly an input value corresponds to linguistic terms like ”low,” ”medium,” or ”high.” For a feature vector with $n$ dimensions and $l$ fuzzy rules, $n \cdot l$ membership functions are needed. In PrivDNFIS, Gaussian membership functions, commonly used in fuzzy systems (Bai et al. 2021; Zhang et al. 2021), are employed for each input and rule. These functions have two trainable parameters: the mean and the standard deviation.

For each input value $\mathbf { d } [ i ] , i \in [ n ]$ , all $j \in [ l ]$ , then the Gaussian membership functions can be computed as:

$$
\omega _ { i , j } \gets \mathsf { M } _ { i , j } ( \mathbf { d } [ i ] ) = \exp ( - \frac { ( \mathbf { d } [ i ] - \mu _ { i , j } ) ^ { 2 } } { 2 \sigma _ { i , j } ^ { 2 } } ) .
$$

The parameter $\mu _ { i , j }$ is the mean and $\sigma _ { i , j }$ is the standard deviation. A straightforward method to evaluate Equation 2 over ciphertexts $\{ \mathsf { C T } _ { \widehat { d } } , \mathsf { C T } _ { \widehat { d } ^ { * } } \}$ is using a polynomial to simulate the Gaussian f ubnctio bn. However, this method will not only compromise accuracy but also place a substantial computational burden on $\mathcal { C }  { \boldsymbol { S } } _ { B }$ . Thus, we compute the natural logarithm instead of the Gaussian function (Yeganejou et al. 2023). Then we are relieved from handling exponential computation over ciphertext. In addition, the logarithm offers better numerical stability in the tails. As shown in the Equation 3, the problem is transformed into computing a quadratic polynomial.

$$
\log \omega _ { i , j } = - \frac { 1 } { 2 \sigma _ { i , j } ^ { 2 } } ( \mathbf { d } [ i ] ) ^ { 2 } - \frac { 1 } { 2 } ( \frac { \mu _ { i , j } } { \sigma _ { i , j } } ) ^ { 2 } + \frac { \mu _ { i , j } } { \sigma _ { i , j } } \mathbf { d } [ i ] .
$$

Then $\mathcal { C }  { \boldsymbol { S } } _ { B }$ maps all the constant terms into polynomials. Note that, all the input values are packed and encrypted as one ciphertext. Thus, for any $j$ -th rule, all the $n$ parameters (e.g., $- 1 / 2 \sigma _ { i , j } ^ { 2 } , \mu _ { i , j } / \dot { \sigma _ { i , j } } )$ should be packed using the same method. For simplicity, we omit it as a default operation. $\bullet$ Then the first term can be computed as $\mathsf { C T } _ { : , j _ { \ast } } ^ { 1 } \gets \mathsf { C t P t M u l } ( \mathsf { C T } _ { \widehat { d ^ { \ast } } } , - 1 / 2 \sigma _ { \cdot , j } ^ { 2 } ) .$ $\pmb { \theta }$ The compumomorphic evaluation. $\pmb { \otimes }$ The third term can be computed as $\mathsf { C T } _ { : , j } ^ { 3 } \gets \mathsf { C t P t M u l } ( \mathsf { C T } _ { \widehat { d } } , \mu . , { j } / \sigma . , { j } ) . \Theta$ Then, $\mathcal { C }  { \boldsymbol { S } } _ { B }$ merge the th·ree terms one by o bne. It calculates $\mathsf { C T } _ { \cdot , j } ^ { 1 , 2 } \gets$ $\mathsf { C t P t A d d } ( \mathsf { C T } _ { \cdot , j } ^ { 1 } , - \mu _ { \cdot , j } ^ { 2 } / 2 \sigma _ { \cdot , j } ^ { 2 } )$ . $\pmb \Theta$ At last, $\mathcal { C }  { \boldsymbol { S } } _ { B }$ obtains a ciphertext of $\log \omega _ { \cdot , j }$ by $\mathsf { C T } _ { \log \omega . , j } \gets \mathsf { C t C t A d d } ( \mathsf { C T } _ { \cdot , j } ^ { 1 } , \mathsf { C T } _ { \cdot , j } ^ { 1 , 2 } )$ . For all rules $j \in [ l ]$ , $\mathcal { C }  { \boldsymbol { S } } _ { B }$ repeats the above calculations and passes $\mathsf { C T } _ { \log \omega _ { \cdot , j } }$ to the rule layer.

# Rule Layer

This layer is committed to evaluating the firing strength (Talpur et al. 2023; Bai et al. 2021) for each fuzzy rule. The existing schemes usually compute the product of all antecedent membership functions like $\begin{array} { r } { \omega _ { \cdot , j , } ^ { \times } = \prod _ { i = 1 } ^ { n } \omega _ { i , j } } \end{array}$ . This needs ciphertext-ciphertext multiplication evaluation over the $n$ ciphertext slots within the same packed and encrypted input vector. Unfortunately, it seems out of reach to achieve this using SHE schemes (Viand, Jattke, and Hithnawi 2021). To conquer this problem, PrivDNFIS turns to compute the summation of the logarithm of the memberships. In specific, we have $\begin{array} { r } { \omega _ { . , j } ^ { + } = \sum _ { i = 1 } ^ { n ^ { - } } \log \omega _ { i , j } } \end{array}$ .

Before introducing our solution, we first show off an interesting observation as follows. Assume that we have two polynomials $\widehat { p } _ { 1 } = 1 + 2 x + 3 x ^ { 2 } + 4 x ^ { 3 } , \widehat { p } _ { 2 } = 1 + x + x ^ { 2 } + x ^ { 3 }$ . According tobthe Equation 1, $\widehat { p } _ { 1 } \times \widehat { p } _ { 2 }$ eqbuals: $1 + ( 2 + 1 ) x +$ $( 3 + 2 + \bar { 1 } ) x ^ { 2 } + ( 4 + 3 + 2 + 1 ) x ^ { 3 } + ( 4 + 3 + 2 ) x ^ { 4 } + ( 4 +$ $3 ) x ^ { 5 } + 4 x ^ { 6 }$ . We can find that the coefficient of the fourth term $( \dot { x } ^ { 3 } )$ equals the summation of all the coefficients of $\widehat { p } _ { 1 }$ . By extension, if we can extract the ciphertext of a certain cboefficient over the ciphertext domain, we can compute the sum of the coefficients of any polynomial. In PrivDNFIS, $\mathcal { C }  { \boldsymbol { S } } _ { B }$ generates a polynomial $\hat { e } = \hat { 1 } + x + x ^ { 2 } + , . . . , + x ^ { n - 1 }$ and then invokes $\mathsf { C T } _ { : , j } ^ { \prime } \gets \mathsf { C t P t M u l } ( \mathsf { C T } _ { \log \omega . , j } , \widehat { e } )$ for all $j \in [ l ]$ . At last, $\mathcal { C }  { \boldsymbol { S } } _ { B }$ extr·acts LWE ciphertexts ·of $n$ -th coeffient of ${ \mathsf { C T } } _ { : , j } ^ { \prime }$ . This can be achieved using an existing ciphertext extraction function (Chen et al. 2021). In specific, $\mathcal { C }  { \boldsymbol { S } } _ { B }$ generates LWE ciphertexts for all $j \in [ l ]$ as $\mathsf { L } \bar { \mathsf { C } } \mathsf { T } _ { \omega _ { \cdot , j } ^ { + } } \gets \mathsf { E x t r a c t } ( \mathsf { C T } _ { \cdot , j } ^ { \prime } , n )$ and $\mathsf { L C T } _ { \omega _ { \cdot , j } ^ { + } }$ are then feed to the hidden layer.

# Hidden Layer

In the hidden layer, activation is computed by taking a linear combination of input values d and multiplying it by the normalized firing strength of the corresponding rule. To simplify this, it is adjusted to use the sum of the logarithm of the firing strength and the linear combination of inputs, without applying the logarithm to the inputs themselves. This approach creates fuzzy regions (clusters) while keeping the deep convolutional backend fully trainable, avoiding gradient explosion issues. Let the $n \times l$ matrix $\mathbf { M }$ represent activation weights, and $\mathbf { b }$ be the bias vector for all rules. The activation for the $j$ -th rule is then computed as follows.

$$
\rho _ { j } = \omega _ { \cdot , j } ^ { + } + ( \sum _ { i = 1 } ^ { n }  { \mathbf { M } } [ i ] [ j ]  { \mathbf { d } } [ i ] +  { \mathbf { b } } [ j ] ) .
$$

The task of $\mathcal { C }  { \boldsymbol { S } } _ { B }$ is to evaluate the above equation privately. Intuitively, the main challenge of computing Equation 4 is designing a privacy-preserving vector inner protocol for $\textstyle \sum _ { i = 1 } ^ { n } \mathbf { M } \bar { [ { i } ] } [ j ] \cdot \bar { \mathbf { d } [ { i } ] }$ . Specifically, the problem is computing  the ciphertext-plaintext vector inner product in a privacypreserving manner. A widely applied method is packing vectors using CRT based scheme (Smart and Vercauteren 2014), and then evaluating the element-wise multiplication by simply invoking $\mathsf { C t P t M u l ( \cdot ) }$ . For instance, given two vectors $\begin{array} { r } { \dot { \bf v } _ { 1 } = [ a _ { 1 } , \bar { a } _ { 2 } , a _ { 3 } , a _ { 4 } ] , \dot { \bf v } _ { 2 } = [ b _ { 1 } , b _ { 2 } , b _ { 3 } , \bar { b _ { 4 } } ] } \end{array}$ , one can obtain the ciphertext of the vector $\mathbf { v } _ { 0 } ^ { \prime } = [ a _ { 1 } b _ { 1 } , a _ { 2 } b _ { 2 } , a _ { 3 } b _ { 3 } , a _ { 4 } b _ { 4 } ]$ using the above method. Afterward, one needs to rotate the ciphertext of $\mathbf { v } ^ { \prime }$ for one slot to acquire the ciphertext of vector $\mathbf { v } _ { 1 } ^ { \prime } = [ a _ { 2 } b _ { 2 } , a _ { 3 } b _ { 3 } , a _ { 4 } b _ { 4 } , a _ { 1 } b _ { 1 } ]$ . By evaluating the homomorphic addition of $\mathbf { v } _ { 0 } ^ { \prime }$ and $\mathbf { v } _ { 1 } ^ { \prime }$ , we can have the ciphertext of vector $\mathbf { v } _ { 2 } ^ { \prime } = [ a _ { 1 } b _ { 1 } + a _ { 2 } b _ { 2 }$ , $a _ { 2 } b _ { 2 } + a _ { 3 } b _ { 3 }$ , a3b3 + a4b4, a4b4 + $a _ { 1 } b _ { 1 } ]$ . Then it rotates the vector $\mathbf { v } _ { 2 } ^ { \prime }$ for two ciphertext slots and obtain a ciphertext of vector $\mathbf { v } _ { 3 } ^ { \bar { \prime } } = [ a _ { 3 } b _ { 3 } + \bar { a } _ { 4 } b _ { 4 } , a _ { 4 } b _ { 4 } +$ $a _ { 1 } b _ { 1 } , a _ { 1 } b _ { 1 } + a _ { 2 } b _ { 2 } , a _ { 2 } b _ { 2 } + a _ { 3 } b _ { 3 } ] ,$ Lastly, one-time addition homomorphic evaluation on ciphertexts of $\mathbf { v } _ { 2 } ^ { \prime } , \mathbf { v } _ { 3 } ^ { \prime }$ will outputs a ciphertext of vector $\mathbf { v } _ { 4 } ^ { \prime } = [ \bar { a } _ { 1 } b _ { 1 } + a _ { 2 } b _ { 2 } + \bar { a } _ { 3 } \bar { b } _ { 3 } + a _ { 4 } b _ { 4 } , \bar { . . . ] }$ . Apparently, the first element of $\mathbf { v } _ { 4 } ^ { \prime }$ is the inner product of $\mathbf { v } _ { 1 }$ and $\mathbf { v } _ { 2 }$ . This method introduces prohibitive computational costs. The ciphertext rotation operation is extremely timeconsuming, costing roughly $3 0 \times$ more than modular exponentiation (Huang et al. 2022; Ren et al. 2024).

PrivDNFIS proposes to use a novel vector encoding method to compute the inner product without rotation. Here we give a toy example. Given two integer vectors $\mathbf { v } _ { 1 } \ =$ $[ a _ { 1 } , \bar { a } _ { 2 } , a _ { 3 } , a _ { 4 } ] , { \bf v } _ { 2 } \ = \ [ b _ { 1 } , b _ { 2 } , b _ { 3 } , b _ { 4 } ]$ , the $\mathbf { v } _ { 1 }$ is encoded in reverse order onto the coefficients of a polynomial $\widehat { v } _ { 1 } \ =$ $a _ { 4 } + a _ { 3 } x + a _ { 2 } x ^ { 2 } + a _ { 1 } x ^ { 3 }$ , and $\mathbf { v } _ { 2 }$ is encoded in order ontbo the

coefficients of a polynomial $\widehat { v } _ { 2 } = b _ { 1 } + b _ { 2 } x + b _ { 3 } x ^ { 2 } + b _ { 4 } x ^ { 3 }$ .   
$\widehat { v } _ { 1 } \times \widehat { v } _ { 2 }$ is computed as followbs.

$$
\begin{array} { r l } & { \widehat { v } _ { 1 } \times \widehat { v } _ { 2 } = a _ { 4 } b _ { 1 } + ( a _ { 4 } b _ { 2 } + a _ { 3 } b _ { 1 } ) x } \\ & { \qquad + ( a _ { 4 } b _ { 3 } + a _ { 3 } b _ { 2 } + a _ { 2 } b _ { 1 } ) x ^ { 2 } } \\ & { \qquad + ( a _ { 4 } b _ { 4 } + a _ { 3 } b _ { 3 } + a _ { 2 } b _ { 2 } + a _ { 1 } b _ { 1 } ) x ^ { 3 } } \\ & { \qquad + ( a _ { 3 } b _ { 4 } + a _ { 2 } b _ { 3 } + a _ { 1 } b _ { 2 } ) x ^ { 4 } } \\ & { \qquad + ( a _ { 2 } b _ { 4 } + a _ { 1 } b _ { 3 } ) x ^ { 5 } + a _ { 1 } b _ { 4 } x ^ { 6 } . } \end{array}
$$

The coefficient of the term (marked blue) equals the inner product. By leveraging this finding and the coefficient extraction function Extract $( \cdot )$ , $\mathcal { C }  { \boldsymbol { S } } _ { B }$ can privately compute the vector inner product efficiently without any decryption or rotation operation (Viand, Jattke, and Hithnawi 2021).

Algorithm 1: Privately compute the hidden layer on $\mathcal { C } { \cal { S } } _ { B }$

1: Input: The LWE ciphertexts $\mathsf { L C T } _ { \omega _ { \cdot , j } ^ { + } }$ , the private input   
values $\mathsf { C T } _ { \widehat { d } } .$ The weight matrix $\mathbf { M }$ and the bias vector   
b.   
2: Output: The LWE ciphertexts $\mathsf { L C T } _ { \rho _ { j } }$ of $\rho _ { j }$ for all $j \in$   
$[ l ]$ .   
3: for $j \in [ l ]$ do   
4: for $i \in [ n ]$ do   
5: $\mathbf { m } [ i ] \dot { } \longleftarrow \mathbf { M } [ i ] [ j ]$ .   
6: end for   
7: ${ \widehat { m } } \gets \pi ( \mathbf { m } )$ ; $\mathsf { C T } _ { \alpha } \gets \mathsf { C t P t M u l } ( \mathsf { C T } _ { \widehat { d } } , \widehat { m } )$ .   
8: $\mathsf { L C T } _ { \alpha } \gets \mathsf { E x t r a c t } ( \mathsf { C T } _ { \alpha } , n )$ .   
9: $\mathsf { L C T } _ { \beta } \gets \mathsf { C t P t A d d } ( \mathsf { L C T } _ { \alpha } , \mathbf { b } [ j ] )$ .   
10: $\mathsf { L C T } _ { \rho _ { j } } \gets \mathsf { C t C t A d d } ( \mathsf { L C T } _ { \beta } , \mathsf { L C T } _ { \omega _ { \cdot , j } ^ { + } } )$   
11: end for   
12: return a set of ciphertexts $\{ \mathsf { L C T } _ { \rho _ { j } } \} , j \in [ l ]$ .

Let $\pi ( \cdot )$ denote the inverse mapping function that takes an integer vector as the input and outputs a polynomial. We give the detailed technical design for private evaluation for the hidden layer (i.e., Equation 4) in Algorithm 1.

# Output Layer

The output layer normalizes the computed scores of all the classes into the range of $[ 0 , 1 ]$ . The most used function is softmax (LeCun, Bengio, and Hinton 2015; Yeganejou et al. 2023). Given the score vector $[ \rho _ { 1 } , \rho _ { 2 } , . . . , \rho _ { l } ]$ , the softmax for each rule $j \in [ l ]$ is computed as follows:

$$
P _ { j } \gets \mathrm { s o f t m a x } ( \rho _ { j } ) = \exp ( \rho _ { j } ) / \sum _ { i = 1 } ^ { l } \exp ( \rho _ { i } ) .
$$

The evaluation of softmax is challenging as it needs to compute non-linear function exp intensively. Most existing schemes (Mohassel and Zhang 2017; Li et al. 2023; Dong et al. 2023) intend to investigate approximations to softmax, which is very expensive. Thus, in this paper, we propose to use an aggressive approximation using a quadratic function:

$$
P _ { j } \gets \mathrm { s o f t m a x } ( \rho _ { j } ) = ( \rho _ { j } + c ) ^ { 2 } / \sum _ { i = 1 } ^ { l } ( \rho _ { i } + c ) ^ { 2 } .
$$

$c$ is a small random constant.

The processing of reciprocals and ciphertext-ciphertext multiplications continues to be time-consuming. PrivDNFIS optimizes the straightforward method as follows. $\mathcal { C }  { \boldsymbol { S } } _ { B }$ first extends $( \rho _ { j } + c ) ^ { 2 }$ to a quadratic polynomial $\rho _ { j } ^ { 2 } + c ^ { 2 } + $ $2 c \rho _ { j }$ . Given $\mathsf { L C T } _ { \rho _ { j } }$ , for all $j ~ \in ~ [ l ]$ it conducts the following evaluations. $\bullet \mathsf { L C T } _ { 1 } \gets \mathsf { C t C t M u l } ( \mathsf { L C T } _ { \rho _ { j } } , \mathsf { L C T } _ { \rho _ { j } } )$ . $\pmb { \theta }$ $\mathsf { L C T } _ { 2 }$ $\mathsf { C t P t M u l } ( \mathsf { L C T } _ { \rho _ { j } } , 2 c )$ . $\begin{array} { r l } { \pmb { \Theta } } & { { } \mathsf { L C T } _ { j } ^ { \ast } } \end{array} \quad $ $\mathrm { C t C t A d d } ( \mathsf { L C T _ { 1 } } , \mathsf { C t P t A d d } ( \mathsf { L C T _ { 2 } } , c ^ { 2 } ) )$ . Apparently, $\mathsf { L C T } _ { j } ^ { * }$ is a ciphertext of $\rho _ { j } ^ { 2 } + c ^ { 2 } + 2 c \rho _ { j } .$ $\pmb { \varrho }$ Then $\mathcal { C }  { \boldsymbol { S } } _ { B }$ can repeatedly invokes $O ( \log ( l ) )$ times function $\mathsf { C t C t A d d } ( \cdot )$ to obtain a ciphertext of $\textstyle \sum _ { i = 1 } ^ { l } ( \rho _ { i } + c ) ^ { 2 }$ denoted as $\mathsf { L C T } _ { \rho } ^ { * }$ . Intuitively, in the next step, $\mathcal { C } { \cal S } _ { B }$ should compute the reciprocal of $\textstyle \sum _ { i = 1 } ^ { \cdot } ( \rho _ { i } + c ) ^ { 2 }$ over the ciphertext domain. To reduce the co mputational cost, PrivDNFIS let $\mathcal { C }  { \boldsymbol { S } } _ { B }$ send the ciphertext back to $\mathcal { M } \mathcal { U }$ for decryption. Then the extra cost is merely one LWE ciphertext transmission (roughly 100KB in practice). In exchange, the overall time costs are substantially reduced as $k$ times reciprocal processing is moved to the $\mathcal { M } \mathcal { U }$ . And it is computed over the plaintext domain. Here, the $k$ is number of the returned ciphertexts $\mathsf { L C T } _ { j } ^ { * } , j \in [ l ]$ and $k < n$ .

At last, the service provider $\mathcal { C }  { \boldsymbol { S } } _ { B }$ needs to send the top- $k$ $P _ { j } , j \in [ l ]$ to user $\mathcal { M } \mathcal { U }$ . In PrivDNFIS, it returns the top- $k$ $( \rho _ { j } + c ) ^ { 2 }$ , i.e., their ciphertexts $\mathsf { L C T } _ { j } ^ { * }$ . For the implementation of homomorphic sorting, we adopt the existing scheme (Hong et al. 2021; Viand, Jattke, and Hithnawi 2021). After receiving the $k$ LWE ciphertexts, $\mathcal { M } \mathcal { U }$ simply decrypts them and divides the plaintexts by $\textstyle \sum _ { i = 1 } ^ { l } ( \rho _ { i } + c ) ^ { 2 }$ .

# Security Analysis

We prove the security of PrivDNFIS formally following the simulation paradigm (Lindell 2017). Specifically, we need to prove that there exists a probabilistic polynomial time (PPT) simulator that interacts with a PPT adversary, and the adversary can not distinguish the view generated by the simulator from the real protocol execution. Any PPT adversary can not distinguish the view produced by the simulator from the real protocol execution. The simulator can observe the input/output of the adversary. According to the theory of provable security (Lindell 2017), if we can construct such a simulator, then PrivDNFIS is semantic secure (i.e., provable secure). PrivDNFIS is secure against the semi-honest PPT $\mathcal { A }$ , which is formalized as following theorem.

Theorem 1 (Security of PrivDNFIS). If the applied RLWE/LWE SHE schemes used in PrivDNFIS are semantically secure against the semi-honest PPT adversaries, then the proposed protocol PrivDNFIS is secure against the semihonest PPT .

Proof sketch. As the user $\mathcal { M } \mathcal { U }$ is fully trusted, the main task to prove Theorem 1 is to prove the security of PrivDNFIS against the semi-honest $\textit { A } ( \boldsymbol { \mathcal { C } } \boldsymbol { S } _ { B } )$ . To achieve this, we should construct a simulator $\mathsf { S i m } _ { 0 }$ that makes the simulated view indistinguishable from the real execution of PrivDNFIS. Due to the space limitation, the concrete hybrid arguments in $\mathsf { S i m } _ { 0 }$ will be provided in the full version of this paper. The existence of $\mathsf { S i m } _ { 0 }$ confirms that PrivDNFIS provides semantic security under the given threat model.

![](images/b436a235a46747a480dc5e13da8e151007bf60d532c796dc43c121bc290200d9.jpg)  
Encryption Time vs.Number of Feature Vectors

![](images/00649404ab0d7499e3a237ed734c32bfd58b9cc8d9e3ad99acb175516248c5ca.jpg)  
Figure 3: Encryption time cost on $\mathcal { M } \mathcal { U }$ .   
Figure 4: Communication cost on $\mathcal { M } \mathcal { U }$ .

# Performance Evaluation

Implementation settings. Experiments are conducted on a computing machine with Intel (R) Xeon (R) CPU E5-26800 $\textcircled { a } ~ 2 . 7 0 \mathrm { G H z }$ processor with 8 cores, 4 GB RAM storage, and Ubuntu 20.04 operation system. This server is used to simulate $\mathcal { C }  { \boldsymbol { S } } _ { B }$ and we fully utilize the server’s computing power. When simulating the end user $\mathcal { M } \mathcal { U }$ , we use two cores to run the encryption/decryption algorithms. The network delay is set to $6 0 \mathrm { { m s } }$ (simulate the WAN environment.) and the network bandwidth is set to 2Gbps when simulating the end-to-end time costs. In PrivDNFIS we use the classic RLWE-based HE scheme BFV (Fan and Vercauteren 2012) to encrypt the private input and the homomorphic evaluations are naturally operated over the BFV ciphertexts. The ciphertext extraction function $\mathsf { E x t r a c t ( \cdot ) }$ is implemented by (Chen et al. 2021; Huang et al. 2022), we use their opensourced code. To implement BFV, the RLWE/LWE FHE library SEAL (Laine, K.; Cruz, R.; Boemer, F.; Angelou, N.; and et al 2015) is applied with the parameters that guarantee 128-bit security. The results presented are the average of 10 trials.

$\mathcal { M } \mathcal { U }$ first needs to encode and encrypt the private input and generate a pair of RLWE ciphertexts. Compared to encryp

# Performance evaluation of

![](images/11bf043c128e36d7fb306276f238d3901a8a0b5a1ddd761f903b9abbb0fd2884.jpg)  
Figure 5: End-to-end running time comparison.

tion, the cost of mapping the plaintext messages onto the coefficients of a polynomial is negligible. As shown in Fig. 3, the cost of encryption increases linearly as the number of input vectors grows. Note that, the length of the input feature vector $n$ and the number of the ciphertext slots $N$ should satisfy $n ^ { 2 } < N$ . Here we set $N = 4 0 9 6$ , then $n \leq 6 4$ . Thus in the real implementation, we need to segment the large feature vector into small vectors with 64 elements. Let $T _ { E }$ be the amortized RLWE SHE encryption time, then the time cost for one feature vector encryption is roughly 2 $\left\lceil \frac { n } { 6 4 } \right\rceil \underline { { \cdot } } T _ { E }$ . We report the concrete running times for encryption in Fig. 3 by varying the number and length of feature vectors. Specifically, for $n = 2 0 4 8$ , the total time cost for encrypting 100 feature vectors is roughly 44.15s.

The second part is the communication overhead. Assume that the size of one RLWE SHE ciphertext is $S _ { R }$ , then the total communication overhead for uploading a pair of ciphertexts is $2 \left\lceil { \frac { n } { 6 4 } } \right\rceil \cdot S _ { R }$ . As shown in Fig. 4, the total communication load increases linearly with the number of issued queries. When the amount of queries reaches $1 0 ^ { 3 }$ , and $n = 2 0 4 8$ , the total communication cost is around 5.4GB.

Table 1: Decryption time cost on $\mathcal { M } \mathcal { U }$ .   

<html><body><table><tr><td>Number of ciphertexts (k)</td><td>2</td><td>5</td><td>10</td><td>15</td><td>20</td></tr><tr><td>Decryption time (ms)</td><td>19</td><td>21</td><td>30</td><td>45</td><td>55</td></tr></table></body></html>

The third part is decrypting the LWE ciphertext of $\scriptstyle \sum _ { i = 1 } ^ { l } ( \rho _ { i } + c ) ^ { 2 }$ . $k$ LWE ciphertexts also need to be decrypted. Let $T _ { D }$ be the amortized LWE ciphertext decryption time, then the total decryption time is around $( k + 1 ) \cdot T _ { D }$ . We report the concrete running time with different $k$ in Table 1. When examining the total time expenditure, this cost is considered trivial.

# Performance evaluation of $\mathcal { C }  { \boldsymbol { S } } _ { B }$

For the fuzzification layer, the main task is evaluating the Equation 3. Let $T _ { \alpha } , T _ { \beta } , T _ { \gamma } , T _ { \delta } , T _ { \varepsilon }$ be the amortized time cost on one-time evaluation of function $\mathsf { C t P t A d d ( \cdot ) } , \mathsf { C t C t A d d ( \cdot ) } , \mathsf { C t P t M u l ( \cdot ) } , \mathsf { C t C t M u l ( \cdot ) }$ , and Extract(·); respectively. Given an encrypted feature vector with $n$ elements, the asymptotic time cost of the fuzzification layer is $O ( l \left\lceil \frac { n } { 6 4 } \right\rceil ( \dot { T } _ { \alpha } \dot { + } T _ { \beta } + 2 T _ { \gamma } ) )$ . In the rule layer, the main task is to compute the aggregation of the polynomial coefficients over the received ciphertexts. Specifically, it invokes one time $\mathsf { C t P t M u l ( \cdot ) }$ and $\bar { \mathsf { E } } { \mathsf { x t r a c t } } ( \cdot )$ function for each ciphertext received from the previous layer. Note that when $n \ > \ 6 4$ , we can aggregate the extracted LWE ciphertext by simply invoking $\textstyle { l \cdot \operatorname { l o g } ( \left\lceil { \frac { n } { 6 4 } } \right\rceil ) }$ times of function ${ \mathsf { C t C t A d d } } ( \cdot )$ . In sum, the asymptotic time cost of rule layer is $\begin{array} { r } { O ( l ( \left\lceil \frac { n } { 6 4 } \right\rceil ( T _ { \gamma } + T _ { \varepsilon } ) + \log ( \left\lceil \frac { n } { 6 4 } \right\rceil ) T _ { \beta } ) ) } \end{array}$ .

For Hidden layer, $\mathcal { C }  { \boldsymbol { S } } _ { B }$ needs to evaluate Equation 4. If $n > 6 4$ , for all $\left\lceil { \frac { n } { 6 4 } } \right\rceil$ segmented encrypted feature vectors, $\mathcal { C }  { \boldsymbol { S } } _ { B }$ repeats the same evaluation protocol and conducts addition aggregation over the output of the Algorithm 1. Theoretically, for all $l$ rules, the asymptotic time cost of hidden layer is $\begin{array} { r } { { \dot { O } } ( l ( T _ { \alpha } + \left( \log ( \left\lceil \frac { n } { 6 4 } \right\rceil ) \right) + 1 ) T _ { \beta } + \left\lceil \frac { n } { 6 4 } \right\rceil ( T _ { \gamma } + T _ { \varepsilon } ) ) , } \end{array}$ ).

In the last layer, $\mathcal { C } S _ { B }$ evaluates the Equation 7. Specifically, to reduce the overall computational cost, $\mathcal { C }  { \boldsymbol { S } } _ { B }$ returns a LWE ciphertext of ${ \textstyle \sum _ { i = 1 } ^ { l } } ( \rho _ { i } + c ) ^ { 2 }$ instead of computing its reciprocal. PrivDNFIS adopts the SOTA homomorphic sorting method (Hong et al. 2021) to obtain the top- $k$ classification scores. Any advanced scheme can be plugged into our scheme. We use $T _ { S }$ to denote its time cost and we omit the technical details for simplicity. In theory, the asymptotic time cost of output layer is $\overset { \cdot } { O ( } ( \log ( l ) + \overset { . } { l } ) T _ { \beta } + \overset { . } { l } ( \overset { . } { T _ { \alpha } } \overset { . } { + }$ $T _ { \gamma } + T _ { \delta } ) + T _ { S } )$ . We have the total computational complexity Compx as shown in Equation 8, where $\begin{array} { r } { n ^ { \prime } = \left\lceil \frac { n } { 6 4 } \right\rceil } \end{array}$ .

$$
\begin{array} { r l } & { \mathsf { C o m p x } \cong O ( ( 2 + n ^ { \prime } ) l \cdot T _ { \alpha } } \\ & { \qquad + ( 2 l + l n ^ { \prime } + ( l + 1 ) \mathrm { l o g } n ^ { \prime } + \mathrm { l o g } l ) \cdot T _ { \beta } } \\ & { \qquad + ( 4 l n ^ { \prime } + l ) \cdot T _ { \gamma } + l \cdot T _ { \delta } } \\ & { \qquad + ( l + 1 ) n ^ { \prime } \cdot T _ { \varepsilon } + T _ { S } ) . } \end{array}
$$

Table 2: Running time on $\mathcal { C }  { \boldsymbol { S } } _ { B }$ .   

<html><body><table><tr><td>Parameteranddataset</td><td>Running time (ms)</td></tr><tr><td>n = 1024,Dataset: CIFAR-10</td><td>431.47 + Ts</td></tr><tr><td>n = 2048, Dataset: CIFAR-10</td><td>711.16 + Ts</td></tr><tr><td>n= 1024,Dataset: CIFAR-100</td><td>3850.90 + Ts</td></tr><tr><td>n= 2048,Dataset: CIFAR-100</td><td>7003.87 + Ts</td></tr></table></body></html>

In Table. 2, we report the concrete running time on $\mathcal { C }  { \boldsymbol { S } } _ { B }$ . We use $T _ { S }$ to represent the cost of the sorting operation rather than give the concrete cost. When we process classification with a few categories like 10, simply downloading all 10 ranking scores may only introduce a few milliseconds that are negligible. In this case, it is unnecessary to run a secure sorting protocol. For reference, it takes roughly two minutes to find the top five among $1 0 0 \mathrm { H E }$ ciphertexts (Hong et al. 2021). However, it only needs a few seconds $( \approx 3 s )$ to download the $1 0 0 ~ \mathrm { H E }$ ciphertexts. Furthermore, any latest secure sorting protocol can be seamlessly plugged into PrivDNFIS if we have to manage large-scale datasets.

The communication load on $\mathcal { C }  { \boldsymbol { S } } _ { B }$ depends on $k$ chosen by $\mathcal { M } \mathcal { U }$ . Totally, $\mathcal { C }  { \boldsymbol { S } } _ { B }$ needs to return $k + 1$ LWE ciphertexts back to $\mathcal { M } \mathcal { U }$ . It roughly takes $6 4 \mathrm { { m s } }$ to download 11 $k = 1 0 ,$ ) HE ciphertexts under our network setting that are negligible.

# End-to-end time cost

The total running time includes the local query encryption, the server-side evaluation, and the upload & download communication overhead. Fig. 5 shows the total end-to-end time costs by varying the amount of queries. When processing 200 queries on CIFAR-100 (Krizhevsky, A.; Nair, V.; and Hinton, G 2013), PrivDNFIS takes 1194.62s in total. On average, it merely needs roughly 6s to process one query. To demonstrate the high efficiency of PrivDNFIS, we also simulate the performance of a previously proposed scheme CryptFlow (Rathee et al. 2020) as the benchmark that uses rotation to evaluate the vector inner product (Viand, Jattke, and Hithnawi 2021; Rathee et al. 2020). As shown in Fig. 5, compared with the benchmark scheme (Rathee et al. 2020) PrivDNFIS has compressed roughly $1 . 9 \times$ , $4 . 4 \times$ running time on CIFAR-10 and CIFAR-100 (Krizhevsky, A.; Nair, V.; and Hinton, G 2013), respectively.

# Inference accuracy

In PrivDNFIS, the network architecture of the fuzzy classifier is similar to the latest work (Yeganejou et al. 2023) except for the last layer. Recall that we replace the last layer (i.e., softmax) with a quadratic function for efficiency improvement. Fortunately, it seems that we have a free lunch for such an approximation, and the classification results are the same as the original results. PrivDNFIS only changes the last layer, and the score ranking is not changed which leads to the same inference accuracy. For two testing datasets CIFAR-10 and CIFAR-100, the accuracy of the non-private scheme DCNFIS (Yeganejou et al. 2023) and PrivDNFIS are the same. Specifically, they are $9 3 . 0 2 \%$ on CIFAR-10 and $7 4 . 5 2 \%$ on CIFAR-100, respectively.

In the future, We plan to develop more efficient schemes tailored to DNFIS, drawing on the latest advancements in schemes (Bian et al. 2024; Lu et al. 2025; Zeng et al. 2023).

# Conclusion

This paper initiates the investigation into the unexplored territory of PI over DNFIS, introducing PrivDNFIS, a scheme that melds DNFIS network architecture with advanced cryptographic primitive lattice-based SHE. PrivDNFIS offers formal security guarantees and efficiency improvements by investigating several concrete optimizations, addressing several pressing technical challenges. It presents a foundation for future research in the critical domain of PI over DNFIS.

# Acknowledgments

This work was supported by the National Natural Science Foundation of China (NSFC Grant No. 62402331, and No. 62202320), the Fundamental Research Funds for the Central Universities (Grant No. YJ202429), the Fundamental Research Funds for the Central Universities ( No. SCU2024D012), the Science and Engineering Connotation Development Project of Sichuan University (No. 2020SCUNG129), the Natural Science Foundation of Sichuan Province (Grant No. 2024NSFSC1450).