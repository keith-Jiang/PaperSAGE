# Fair Federated Survival Analysis

Md Mahmudur Rahman, Sanjay Purushotham

University of Maryland, Baltimore County, Baltimore, Maryland, USA mrahman6@umbc.edu, psanjay $@$ umbc.edu

# Abstract

Federated Survival Analysis (FSA) is an emerging Federated Learning (FL) paradigm that enables training survival models on decentralized data while preserving privacy. However, existing FSA approaches largely overlook the potential risk of bias in predictions arising from demographic and censoring disparities across clients’ datasets, which impacts the fairness and performance of federated survival models, especially for underrepresented groups. To address this gap, we introduce FairFSA, a novel FSA framework that adapts existing fair survival models to the federated setting. FairFSA jointly trains survival models using distributionally robust optimization, penalizing worst-case errors across subpopulations that exceed a specified probability threshold. Partially observed survival outcomes in clients are reconstructed with federated pseudo values (FPV) before model training to address censoring. Furthermore, we design a weight aggregation strategy by enhancing the FedAvg algorithm with a fairness-aware concordance index-based aggregation method to foster equitable performance distribution across clients. To the best of our knowledge, this is the first work to study and integrate fairness into Federated Survival Analysis. Comprehensive experiments on distributed non-IID datasets demonstrate FairFSA’s superiority in fairness and accuracy over state-of-the-art FSA methods, establishing it as a robust FSA approach capable of handling censoring while providing equitable and accurate survival predictions for all subjects.

# Introduction

Survival analysis plays a critical role in healthcare, enabling the analysis of time-to-event data, such as duration until death or recovery from a disease. Leveraging survival analysis techniques enables healthcare professionals to optimize treatment strategies and resource allocation, thereby enhancing patient care and survival outcomes. A key challenge in survival analysis is handling censored data, where events of interest remain unobserved for some individuals due to the end of the study, loss-to-follow-up, or withdrawal from the study. Additionally, stringent privacy regulations often limit data sharing across multiple institutions. Consequently, a significant amount of data cannot be leveraged to build efficient survival models, leading to suboptimal predictive performance. Federated Survival Analysis (FSA) (Andreux et al. 2020; Zhang, Toni, and Williams 2022; Rahman and Purushotham 2023c) has emerged as a solution, facilitating the analysis of distributed, sensitive survival data without necessitating direct data sharing among participating clients. This approach preserves privacy and data ownership by exchanging model parameters rather than raw data, fostering the development of robust and generalizable models that enhance local survival predictions. Moreover, FSA allows clients to fine-tune global models to their specific data distributions, ensuring that the model is optimally adapted to the specific characteristics of the client’s data.

Despite these advancements, a critical challenge in FSA is the potential for bias introduced by sensitive attributes, such as race, gender, age, or ethnicity, which are often present in survival data. Electronic health records (EHRs) from minority groups often exhibit smaller sample sizes, shorter follow-up periods, fewer events, and higher censoring rates (Seyyed-Kalantari et al. 2020; Chen et al. 2023). These disparities can lead to unintentional bias in survival models (Gianfrancesco et al. 2018), and within the federated learning framework, there is a risk that these biases could be propagated and even amplified, resulting in unfair survival predictions (Paulus and Kent 2020; Mhasawade, Zhao, and Chunara 2021). Additionally, nonuniform censoring distributions across clients may introduce additional bias into the predictions made by federated survival models. Although addressing fairness in FSA is a pressing concern, incorporating fairness constraints and debiasing techniques remains a relatively unexplored research area due to the complexity of the challenges involved. This paper introduces FairFSA, a novel fair federated survival analysis framework that integrates a novel Federated Pseudo Value (FPV)-based deep learning model with Distributionally Robust Optimization (DRO) (Deng, Kamani, and Mahdavi 2020; Hu and Chen 2022a), called PseudoDRO, to address the following identified challenges:

• Challenge 1: Requiring Access to Entire Training Data. Traditional fairness approaches in survival analysis typically require full access to the entire training dataset to apply fairness constraints, often relying on pairwise or group comparisons (Keya et al. 2021; Rahman and Purushotham 2022; Do et al. 2023; Sonabend et al. 2022). Many of these methods optimize Cox partial likelihood loss or ranking loss (Keya et al. 2021; Hu and Chen 2022a), both of which involve expensive pairwise comparisons for ranking or similarity score evaluations (Steck et al. 2007; Chen 2020; Wu et al. 2021; Lee et al. 2018). This reliance on pairwise comparison makes these approaches unsuitable for FSA, where data access is decentralized. FairFSA addresses this issue by reformulating the client-specific survival analysis problem as a regression task using independent and identically distributed federated pseudo values (FPV) (Rahman and Purushotham 2023c,b). FPVs effectively handle censoring and ensure the separability of the loss function, satisfying the requirement for independent losses in Distributionally Robust Optimization (DRO). This allows for the incorporation of fairness without the need for complete data access or pairwise comparisons, facilitating the successful integration of fairness into the federated learning framework.

• Challenge 2: Dependence on Sensitive Demographic Information. Most of the existing fair survival models require explicit specification and inclusion of sensitive demographic attributes (Keya et al. 2021; Rahman and Purushotham $2 0 2 3 \mathrm { c }$ ; Do et al. 2023), which may not always be available or easily identifiable in certain survival datasets. Additionally, removing such attributes can result in information loss or potentially increase bias, as they could be correlated with other non-sensitive features. Our proposed model PseudoDRO overcomes this challenge by using DRO to ensure fairness without requiring to specify sensitive attributes, making the framework applicable even in scenarios where such demographic information is missing or unidentified.

• Challenge 3: Handling Censoring in Federated Settings. Censoring can vary significantly across different clients and can be correlated with sensitive attributes, potentially leading to poor convergence and biased predictions in the global model (Rahman and Purushotham 2023c,b). FairFSA addresses this by applying federated pseudo values (FPV) at each institution, improving survival predictions. While the use of covariate-dependent FPV (Binder, Gerds, and Andersen 2014) could address the dependency of censoring on sensitive attributes, it lies beyond the scope of this paper.

• Challenge 4: Achieving Local and Global Fairness. Local fairness ensures that individuals or subgroups who are similar in relevant characteristics should receive similar predictions from a local survival model. On the other hand, global fairness ensures that the performance of the global survival model is equitable across different clients in a federated learning setting1 Achieving fairness at the local level does not automatically guarantee fairness in the aggregated global model (Makhija et al. 2024). The classical Federated Averaging (FedAvg) method (McMahan et al. 2017) often gives more weight to clients with larger datasets, which does not guarantee improvement for all clients. FairFSA introduces a fairness-aware concordance index (CI) aggregation technique, which considers the CI performance on the validation set during the aggregation, ensuring that clients with poorer performance have less influence on the global model, thereby promoting fairness across all participating clients. In summary, FairFSA addresses the above challenges of incorporating fairness into FSA and provides a robust and generalizable survival model.

# Our Main Contributions.

• To the best of our knowledge, this is the first effort to integrate fairness into federated survival analysis (FSA). • We developed FairFSA, a novel fair FSA framework that integrates Federated Pseudo Value (FPV)-based deep learning with Distributionally Robust Optimization (DRO) to address fairness challenges in FSA. • To ensure global fairness, we introduced a fairness-aware concordance index (CI) model aggregation technique. • Extensive experiments on public survival datasets demonstrate that our FairFSA approach improves the performance and fairness of local models and achieves comparable performance to centralized survival models.

# Problem Formulation

Consider a horizontal federated survival analysis (FSA) framework with $K$ clients and one global server, where all participating clients $/$ silos (e.g. hospitals) have the same set of features but different patients in their local survival dataset $D _ { k }$ , where $D _ { k } = \{ { \bf X } _ { i k } , Y _ { i k } , \delta _ { i k } \}$ . For a patient $i$ in client $k$ , $\mathbf { X } _ { i k } \in \mathbb { R } ^ { p }$ is a $\mathfrak { p }$ -dimensional feature vector, $\mathbf { Y } _ { i k }$ is the observed event time, and $\delta _ { i k } \in 0 , 1$ is the event indicator. If $\delta _ { i k } = 1$ , the event time is the failure time $T _ { i k }$ and if ${ { \delta } _ { i k } } \ = \ 0$ , the event time is the censoring time $C _ { i k }$ , i.e., actual failure time $T _ { i k } > C _ { i k } . \ K$ participating clients train their own fairness-aware local models $M _ { \theta _ { i } }$ to obtain a fair global model $M _ { \theta }$ to predict the conditional survival function $S ( t | \mathbf { X } _ { i k } )$ at time $t$ given the feature vector $\mathbf { X } _ { i k }$ where $S ( t | \mathbf { X } _ { i k } ) = P ( T _ { i k } > t | \mathbf { X } _ { i k } )$ , i.e., the probability that the failure time $T _ { i k }$ is greater than a particular time $t$ given $\mathbf { X } _ { i k }$ .

# Related Work

Federated Survival Analysis (FSA) is becoming increasingly prominent in healthcare for its ability to enable privacypreserving collaborative modeling of time-to-event data. Most FSA studies (Andreux et al. 2020; Zhang, Toni, and Williams 2022; Wang et al. 2022; Masciocchi et al. 2022) have utilized the Federated Averaging (FedAvg) algorithm (McMahan et al. 2017) in combination with Cox-based survival models. However, these models face challenges due to the non-separable loss function and proportional hazards (PH) assumptions within clients, which may not hold across different clients. Rahman et al. (Rahman and Purushotham 2023c) advanced the field by proposing FPVbased deep learning methods, addressing the shortcomings of Cox-based models. To enhance communication efficiency in resource-constrained environments, Archetti et al. (Archetti and Matteucci 2023) and Rahman et al. (Rahman and Purushotham 2023a) introduced federated survival forests (FedSurF) and a pseudo-value-based random forest model (FedPRF), respectively. Despite these advancements, existing approaches do not ensure fairness in predictions, a critical issue in healthcare that can lead to biased outcomes.

Fairness has been less explored in survival analysis due to the challenges of applying common fairness definitions to survival models. Keya et al. (Keya et al. 2021) introduced hazard-based fairness definitions and used them as constraints into the partial log-likelihood objective function, while Rahman et al. (Rahman and Purushotham 2022) introduced generalized fairness definitions for all survival models and enforced fairness constraints into the pseudovalue-based objective function. Additionally, Rahman et al. propose censoring-based fairness definitions. Zhang et al. (Zhang and Weiss 2022) focused on model accuracy in fairness metrics. Hu et al. (Hu and Chen 2022a) used Distributionally Robust Optimization (DRO) to achieve fairness in CoxPH models, though their approach relied on sample splitting. Our proposed FairFSA framework ensures local fairness by applying DRO to the pseudo-value-based objective function, which does not require sensitive attribute specification, pairwise patient comparisons, or sample splitting. FairFSA can effectively handle censoring by leveraging FPV and ensures global fairness through a fairness-aware aggregation process.

# Our Proposed Approach: FairFSA

In this paper, we present a novel framework for fair federated survival analysis, named FairFSA, illustrated in Figure 1. FairFSA enables multi-institution collaboration by jointly training our proposed local fair survival model, PseudoDRO, across their distributed datasets. PseudoDRO is a deep neural network-based survival model which utilizes Distributionally Robust Optimization (DRO) to optimize a Federated Pseudo Values (FPV)- based objective function to enforce fairness during the local training process. By employing a sigmoid activation in the output layer, PseudoDRO generates survival probabilities via FPV predictions. Our FairFSA framework integrates three core components that collectively ensure fairness and effectively handle censoring challenge in FSA. First, it utilizes FPV to address non-uniform censoring in FSA. Second, it integrates DRO within the pseudo value-based objective function, which not only guarantees fairness in the local models but also facilitates fair federated training across all clients. Finally, the framework employs a concordance index (CI)-weighted aggregation process to ensure global fairness.

Federated Pseudo Values (FPV): For censored patients, the actual failure time remains unknown, making traditional regression analysis infeasible for time-to-event data. However, we can reformulate the survival analysis problem as a regression problem at the client level by replacing the incompletely observed survival function with consistent Federated Pseudo Values (FPV) (Rahman and $\mathrm { P u } -$ rushotham 2023c,a), which enables patient-specific survival predictions across all clients. Under the assumption that the failure time $T _ { i k }$ and the censoring time $C _ { i k }$ are independent given covariates $\mathbf { X } _ { i k }$ (Graw, Gerds, and Schumacher 2009), the FPVs for the survival function for a subject $i$ in client $k$

![](images/e4343ab4c4a434766f5cb2204e482890442223bcd43f01c5849560fb4ddc516e.jpg)  
Figure 1: Our proposed FairFSA Framework. DRO: Distributionally Robust Optimization, FPV: Federated Pseudo Values, CI: Concordance Index.

at time $t$ are defined as:

$$
J _ { i k } ( t ) = n \hat { S } _ { G } ( t ) - ( n - 1 ) \hat { S } _ { G } ^ { - i k } ( t ) ; i = 1 , . . , n _ { k } , k = 1 , . . , K 
$$

Here, $\begin{array} { r } { n = \sum _ { k = 1 } ^ { K } n _ { k } . \hat { S } _ { G } ( t ) } \end{array}$ is the Kaplan Meier (KM) estimate of the global survival function, and $\hat { S } _ { G } ^ { - i k } ( t )$ is the KM estimate of the leave-one-out global survival function, obtained by omitting $i ^ { t h }$ subject from client $k . \mathrm { \Delta } t$ are the set of unique time points in the training data.

Using FPVs in federated settings offers several advantages: 1) FPVs address data heterogeneity and non-uniform censoring, 2) FPVs are computed without the need to share raw data, complying with privacy regulations, 3) FPVs make it feasible to apply FL techniques to survival analysis, 4) Due to their IID properties, FPVs can be easily used in separable loss functions, such as mean squared error loss, which relaxes the requirement for access to the entire training dataset, 5) The separable loss with FPVs as output allows applying DRO to ensure fairness without violating the assumption of independent loss terms.

DRO on FPV-based Objective Function: Let $\mathcal { P } _ { k }$ denote the joint distribution of data points $( \mathbf { X } _ { i k } , J _ { i k } ( t ) )$ in client $k$ , where $\mathbf { X } _ { i k }$ are the feature vector and $J _ { i k } ( t )$ are the FPVs at unique time point $t$ . The joint distribution $\mathcal { P } _ { k }$ can be decomposed into $L$ sub-distributions $\mathcal { P } _ { k l }$ , each occurring with a probability $\pi _ { k l }$ where $\begin{array} { r } { \sum _ { l = 1 } ^ { L } { \pi _ { k l } } = 1 } \end{array}$ . In other words, $\mathcal { P } _ { k }$ be a mixture of $L$ distr butions corresponding to $\mathrm { ~ L ~ }$ groups, $\begin{array} { r } { \mathcal { P } _ { k } : = \sum _ { l = 1 } ^ { L } \pi _ { k l } \mathcal { P } _ { k l } } \end{array}$ . We assume that the specific details of these subpopulations, such as the number of subpopulations $L$ , are unknown. The goal of DRO is to minimize the risk $\mathcal { R } _ { m a x } ( w _ { k } )$ , defined as:

$\begin{array} { r } { \overbrace { \mathscr { R } _ { m a x } } ( \overbrace { w _ { k } } ) : = \underset { l = 1 , 2 , \ldots , L } { m a x } \mathbb { E } _ { ( X _ { k } , J _ { k } ( t ) ) \sim \mathcal { P } _ { k l } } [ \ell ( w _ { k } ; X _ { k } , J _ { k } ( t ) ) ] } \end{array}$ (2) where $\ell ( . )$ is the FPV-based loss function dependent on model parameters $w _ { k }$ and data point $( \mathbf { X } _ { k } , J _ { k } ( t ) )$ . The FPVbased loss function (Rahman and Purushotham 2022) for client $k$ at time $t$ , $\ell _ { k } ( t )$ , is,

$$
\ell _ { k } ( t _ { j } ) = \frac { 1 } { n _ { k } } \sum _ { i = 1 } ^ { n _ { k } } [ J _ { i k } ( t _ { j } ) ( 1 - 2 \hat { S } ( t _ { j } | x _ { i k } ) ) + \hat { S } ^ { 2 } ( t _ { j } | x _ { i k } ) ]
$$

where $\hat { S } ( t _ { j } | x _ { i k } )$ are the predicted survival probability at time point $t _ { j }$ for $i ^ { t h }$ patient in client $k$ . FPVs are calculated at $M$ unique time points in the training data, and the total loss over $M$ unique time points is $\begin{array} { r } { \ell _ { k } ( t ) \dot { = } \frac { 1 } { M } \sum _ { j = 1 } ^ { M } \ell _ { k } ( t _ { j } ) } \end{array}$ .

Directly minimizing risk $\mathcal { R } _ { m a x } ( w _ { k } )$ is infeasible, since $( \mathcal { P } _ { k l } , \pi _ { k l } ) _ { l = 1 } ^ { L }$ and $L$ are unknown. Thus, we solve an optimization problem that minimizes an empirical upper bound on $\mathcal { R } _ { m a x } ( w _ { k } )$ . We employ the DRO formulation proposed by Hashimoto et al. (Hashimoto et al. 2018) and Hu et al. (Hu and Chen 2022a), which provides a tractable approach to minimizing an upper bound on the worst-case risk $\mathcal { R } _ { D R O } ( w _ { k } ; r _ { m a x } )$ . We can define the $\mathcal { R } _ { D R O } ( w _ { k } ; r _ { m a x } )$ following the proposition below.

Proposition 1 (Follows from Lemma $\boldsymbol { { \mathit { 1 } } }$ in (Duchi and Namkoong 2021; Hu and Chen 2022a))

Let $\ell ( w _ { k } , X _ { k } , J _ { k } ( t ) )$ be an upper semi-continuous with respect to $w _ { k }$ . Then

$$
\begin{array} { r l } { } & { \qquad \mathcal { R } _ { D R O } ( w _ { k } ; r _ { m a x } ) : = i n f \{ \sqrt { 2 ( \frac { 1 } { \alpha } - 1 ) ^ { 2 } + 1 } } \\ & { \sqrt { \mathbb { E } _ { ( X _ { k } , J _ { k } ( t ) ) \sim \mathcal { P } _ { k l } } m a x [ 0 , ( \ell ( w _ { k } ; X _ { k } , J _ { k } ( t ) ) - \epsilon ) ] ^ { 2 } } + \epsilon } \end{array}
$$

Here, where $\epsilon$ is a regularization parameter. Similar to (Hu and Chen 2022a), we minimize an empirical version of $\mathcal { R } _ { D R O } ( w _ { k } ; r _ { m a x } )$ by replacing the expectation in equation 4 by an empirical average, resulting in following optimization problem:

$$
\underset { \Theta _ { k } , \epsilon \in \mathbb { R } } { m i n } \mathcal { L } _ { D R O } ( w _ { k } ; \epsilon )
$$

Here, $\Theta _ { k }$ is the feasible set of parameters of the model in client $k$ . The empirical loss $\bar { \mathcal { L } _ { D R O } } ( w _ { k } ; \epsilon )$ is defined as:

$$
\begin{array} { r } { \mathcal { L } _ { D R O } ( w _ { k } , \epsilon ) : = \sqrt { 2 ( \frac { 1 } { \alpha } - 1 ) ^ { 2 } + 1 } } \\ { \sqrt { \frac { 1 } { n } \sum _ { i = 1 } ^ { n _ { k } } m a x [ 0 , ( \ell _ { i } ( w _ { k } ; X _ { k } , J _ { k } ( t ) ) - \epsilon ) ] ^ { 2 } } + \epsilon } \end{array}
$$

For an optimal value of $\epsilon$ , the loss of a patient that does not exceed $\epsilon$ is ignored. To solve the optimization problem, we use an iterative gradient descent approach $\mathrm { H u }$ et al. 2022; Hu, Wang, and Lyu 2023; Hu and Chen 2022a). The procedure involves the following steps: Initialization: Initialize model parameters $w _ { k }$ . Update $\epsilon$ : Fix $w _ { k }$ and update $\epsilon$ by finding the value that minimizes $\mathcal { L } _ { D R O } ( w _ { k } ; \epsilon )$ . This is achieved using binary search due to the convexity of $\mathcal { L } _ { D R O } ( w _ { k } ; \epsilon )$ with respect to $\epsilon$ . Update $w _ { k }$ : Fix $\epsilon$ and update $w _ { k }$ by minimizing $\mathcal { L } _ { D R O } ( w _ { k } ; \epsilon )$ using gradient descent. This process iterates until specified stopping criteria are met, such as a maximum number of iterations or early stopping based on a validation metric (Hu and Chen 2022a).

Concordance Index-Weighted Aggregation: While we use the classical Federated Averaging (FedAvg) (McMahan et al. 2017) to aggregate the local models from clients, combining fair local models does not necessarily guarantee fairness in the federated global model. This is because the aggregation process used in FedAvg performs a simple weighted average based on clients’ sample sizes to combine local models, which can introduce or amplify biases, even if the individual local models are fair. FedAvg enforces that clients with larger sample sizes have more influence in the global model. However, clients with smaller sample sizes may still show good performance when the data is less noisy and instances are influential. Therefore, the performance of the models should be taken into consideration during the weight aggregation. To address this issue, we propose a fairness-aware weighted aggregation based on the local models’ validation C-index performance. For a communication round $t$ , the global weights can be computed as: wt = PkK=1 kKC=1IkCnIk nk w where $C I _ { k }$ is the validation C-index of local client $k$ . Note that, we can replace the validation C-index with validation fairness metrics, such as individual fairness or the average of individual, group, and intersectional fairness, to ensure global fairness in terms of fairness metrics.

Federated Training: Once the local fair PseudoDRO models are trained across clients, the FairFSA framework employs a global server to coordinate the communication and aggregation of these models. During each communication round, the server sends the clients a global PseudoDRO model, represented by $w ^ { v }$ . The local clients then update their respective local models by incorporating the global model parameters and training on their local data. These newly trained local models, denoted as $\Delta w _ { k } ^ { v }$ , are sent back to the global server. The global server then performs a CIaggregation process to aggregate the local model parameters and update the global model. This CI-aggregation process weighs the contributions of each local model based on its validation C-index performance, as described earlier. The updated global model is subsequently sent back to the local clients by the server. This communication and aggregation process is repeated for a user-specified number of communication rounds, denoted as $V$ . Once the $V$ rounds are completed, the globally updated model is utilized to make subject-specific fair survival probability predictions. By iteratively aggregating the local models through CI-aggregation, FairFSA aims to ensure that the global model benefits from the collective knowledge of all clients while maintaining fairness in the final predictions.

# Experiments

We conduct extensive experiments on both centralized and decentralized non-IID survival datasets to assess the performance of our proposed PseudoDRO and FairFSA models. Our study aims to answer the following research questions: RQ1: How does our centralized fair PseudoDRO model compare to existing fair survival models in terms of accuracy and fairness in a centralized setting? RQ2: In a federated setting, how do the performance and fairness of the FairFSA models compare with baseline fair survival models? RQ3: How effectively does the proposed FairFSA model handle censoring in decentralized settings?

Datasets: We evaluated four publicly available realworld survival datasets namely FLChain (Dispenzieri et al. 2012), SUPPORT (Knaus et al. 1995), SEER (TENG 2019), and MSK-MET (Nguyen et al. 2022) for centralized and federated fair survival analysis. Detailed descriptions of these datasets are provided in the supplementary materials.

Model Comparisons: We conducted a comprehensive evaluation of various survival models in both centralized and federated settings. (a) Centralized Models: To evaluate the performance of our proposed PseudoDRO model in centralized settings, we compared with the following baseline survival models with different properties. No Fairness Constraints: CoxPH (Cox 1972), DeepSurv (Katzman et al. 2018), DeepHit (Lee et al. 2018), DeepPseudo (Rahman et al. 2021; Rahman and Purushotham 2022); With Fairness Constraints: FairSurv (Cox) (Keya et al. 2021), FairSurv (DeepSurv) (Keya et al. 2021), FIDP (Rahman and Purushotham 2022); With DRO: DRO-Cox (Hu and Chen 2022a), Deep DRO-Cox (Hu and Chen 2022a), DRO-Cox (Split) (Hu and Chen 2022a), Deep DRO-Cox (Split) (Hu and Chen 2022a), DRO-DeepHit (Split) (Hu and Chen 2022b). (b) Federated Models: In the federated settings, we compare our FairFSA framework with the federated variant of the corresponding baseline models: No Fairness Constraints: FedCox (Andreux et al. 2020), FedDP (Zhang, Toni, and Williams 2022), Fed-DeepHit (Rahimian et al. 2022; Rahman and Purushotham 2023c), FedPseudo (Rahman and Purushotham 2023c); With Fairness Constraints: Fair-FedCox, Fair-FedDP, FIDP-FSA; With DRO: Fed-DRO-Cox, Fed-Deep-DRO-Cox, FedDRO-Cox (Split), Fed-Deep-DRO-Cox (Split), Fed-DRODeepHit (Split).

Performance Metrics: In both centralized and federated settings, the accuracy and fairness of the models are evaluated using the combined test data shared from clients to the server. Accuracy metrics: We employ the time-dependent concordance index (C-Index) (Harrell Jr, Lee, and Mark 1996), integrated Brier Score (IBS) (Graf et al. 1999), MAEUncensored (Qi et al. 2023), and MAE-Hinge (Qi et al. 2023) as our accuracy metrics. These metrics are computed using the SurvivalEVAL package (Qi, Sun, and Greiner 2023). Fairness metrics: The fairness of the models is assessed using individual fairness (FI) (Rahman and Purushotham 2022), group fairness (FG) (Rahman and Purushotham 2022), intersectional fairness (FIN) (Foulds et al. 2020; Hu and Chen 2022a), and a summary fairness metric Favg F I+F G+F IN . We assess the global fairness of the federated survival models by analyzing the standard deviation of accuracy and fairness metrics across local clients.

Implementation Details: At each client, local datasets are split into $80 \%$ training and $20 \%$ test sets. The local test datasets are evaluated in both centralized and federated settings, ensuring that the combined test data remains the same across all experiments. We perform 5-fold cross-validation and compute evaluation metrics on the same combined test set, reporting the mean and standard deviation (shown in the supplementary materials) of each metric. For federated settings, we simulate a non-IID federated environment by assigning subjects to clients in a manner that skews the event time distribution towards specific quantiles of the time horizon. Different clients have different quantiles for the skewness of the event time distribution. We use the Adam optimizer (Kingma and Ba 2014) with early-stopping based on the best validation C-index. In the federated settings, we consider 5 clients, with a total of 10 communication rounds and 20 local epochs per round. We also choose the learning rate from [0.01, 0.001] and set the batch size to 128. We compute the pseudo values for the unique time points in the training data. Detailed hyperparameter settings are provided in the supplementary materials.

# Results and Discussion

# Performance of our PseudoDRO in centralized settings.

Table 1 presents the performance comparison of the proposed PseudoDRO model against the baseline survival models in the centralized settings in terms of accuracy and fairness metrics across three real-world survival datasets: SUPPORT, FLChain, and SEER. The results indicate that PseudoDRO consistently achieves significant performance improvements across all three datasets. It demonstrates competitive accuracy, securing the best or second-best C-Index and MAE scores, which are critical indicators of model precision. In terms of fairness, PseudoDRO outperforms the baselines by obtaining the lowest $F _ { a v g }$ values across all datasets, highlighting its ability to produce unbiased predictions. The results for individual fairness (FI), group fairness (FG), and intersectional fairness (FIN) are shown in the supplementary materials. PseudoDRO outperforms other survival models significantly in fairness while maintaining high accuracy. PseudoDRO’s superior performance is attributed to the utilization of pseudo values for handling censoring and DRO for ensuring fair predictions, which effectively balances the trade-offs between accuracy and fairness, ensuring robust and equitable survival predictions.

Performance of our FairFSA in federated settings. Table 2 provides a comprehensive evaluation of the survival models in federated settings, including the proposed FairFSA, across three non-IID decentralized datasets: SUPPORT, FLChain, and SEER. FairFSA consistently demonstrates top-tier performance across all datasets, securing the best or second-best scores in both accuracy and fairness metrics. It achieves high C-Index values, indicating robust discriminative ability, and maintains competitive scores in MAE-Uncen and MAE-Hinge. Notably, FairFSA excels in fairness metrics, consistently obtaining the lowest $F _ { a v g }$ values across all datasets. This indicates its strong ability to produce unbiased and equitable predictions. Specifically, in the SUPPORT dataset, FairFSA outperforms other models significantly in fairness while maintaining high accuracy. In the FLChain and SEER datasets, it performs similar or better than the best-performing models in accuracy and leads in fairness metrics.

Handling censoring in federated settings. To demonstrate the efficacy of our pseudo-value-based approach in handling censoring, we compare the performance on uncensored and censored decentralized datasets. The uncensored dataset consists of three clients, each with the same number of uncensored patients and no censored patients. For the censored dataset, we replace two-thirds of the uncensored patients in client 2 with censored patients to investigate the impact of censoring on global model performance. In Figure 3, we illustrate the difference in C-index performance between uncensored and censored datasets. We observe that the performance of the pseudo-value-based models is less affected by censoring and remains consistent across clients. In contrast, non-pseudo-value-based models are significantly impacted by censoring and exhibit inconsistent performance across clients. In the supplementary materials, we provide a detailed performance comparison of the models between censored and uncensored data, highlighting the superior censoring handling capability of pseudo-value-based models, including FairFSA.

Table 1: Performance comparison of the models in the centralized settings on SUPPORT, FLChain, and SEER datasets. The best performance is marked with $( ^ { * } )$ , and the second-best performance is marked with $( ^ { * * } )$ .   

<html><body><table><tr><td rowspan="2">Dataset</td><td rowspan="2">Metric</td><td colspan="4">Without Fairness</td><td colspan="3">With Fairness Constraint</td><td colspan="6">DRO</td></tr><tr><td colspan="4">CoxPHepSur</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td rowspan="7">JPPPPPP</td><td></td><td></td><td>0.61</td><td>0.57</td><td>0.62</td><td>0.51</td><td>0.57</td><td>0.22</td><td>0.53</td><td>0.5</td><td>0.54</td><td></td><td></td><td>0.61**</td></tr><tr><td>C-Index</td><td>0.20</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.57</td><td>0.53</td><td>0.25</td></tr><tr><td>MAE-Uncen</td><td>387</td><td>526</td><td>479</td><td>474</td><td>262</td><td></td><td></td><td>261</td><td>301</td><td>219</td><td>3251</td><td>841</td><td>364</td></tr><tr><td>MAE-Hinge</td><td></td><td>495</td><td>472</td><td>467</td><td>460</td><td>263</td><td>524</td><td></td><td></td><td></td><td></td><td></td><td>445*</td></tr><tr><td></td><td>442</td><td>0.075</td><td>0.024</td><td>0.072</td><td>0.003</td><td>461</td><td>503</td><td>457 0.004</td><td>468</td><td>464</td><td>2116 0.003</td><td>643</td><td></td></tr><tr><td>Favg</td><td>0.049</td><td></td><td></td><td></td><td></td><td>0.002</td><td>0.009</td><td></td><td>0.018</td><td>0.003</td><td></td><td>0.004</td><td>0.000*</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.71</td><td>0.7</td><td>0.77</td></tr><tr><td rowspan="7"></td><td>C-Index</td><td>0.79</td><td>0.7</td><td>0.78</td><td>0.79 8165</td><td>0.70 8736</td><td>0.72</td><td>0.80</td><td>0.78 6868</td><td>0.79</td><td>0.7</td><td></td><td></td><td></td></tr><tr><td>MAE-Uncen</td><td>8885</td><td>9369</td><td>2674</td><td></td><td></td><td>8733</td><td>8921</td><td></td><td>8291</td><td>14312</td><td>21973</td><td>1158</td><td>1986**</td></tr><tr><td>MAE-Hinge</td><td>1812</td><td>1907</td><td>538</td><td>1666</td><td>1756</td><td>1756</td><td>1820</td><td>1380</td><td>1668</td><td>2877</td><td>4417</td><td>1549</td><td>426*</td></tr><tr><td>Favg</td><td>0.064</td><td>0.064</td><td>0.022</td><td>0.062</td><td>0.001</td><td>0.000</td><td>0.019</td><td>0.017</td><td>0.029</td><td>0.001</td><td>0.001</td><td>0.002</td><td>0.001**</td></tr><tr><td>C-Index</td><td>0.73</td><td>0.73</td><td>0.71</td><td>0.75</td><td>0.64</td><td>0.69</td><td>0.74</td><td>0.72</td><td>0.61</td><td>0.72</td><td>0.69</td><td>0.63</td><td>0.73</td></tr><tr><td></td><td>0.10</td><td>0.0</td><td>0.10</td><td>010</td><td>112</td><td>0.2</td><td>0.10</td><td>1</td><td>0</td><td>012</td><td>0.17</td><td>0.28</td><td>0.2</td></tr><tr><td> MAE-Uncen</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td rowspan="3"></td><td>MAE-Hinge</td><td>30</td><td>38</td><td>11 0.031</td><td>28</td><td>30</td><td>30</td><td>29</td><td>26</td><td>76</td><td>34</td><td>80</td><td>19</td><td>11*</td></tr><tr><td>Favg</td><td>0.041</td><td>0.050</td><td></td><td>0.038</td><td>0.001</td><td>0.001</td><td>0.009</td><td>0.012</td><td>0.040</td><td>0.001</td><td>0.007</td><td>0.008</td><td>0.003**</td></tr></table></body></html>

Table 2: Performance comparison of the models in the federated (decentralized) settings on SUPPORT, FLChain, and SEER datasets. The best performance is marked with $( ^ { * } )$ , and the second-best performance is marked with $( ^ { * * } )$ .   

<html><body><table><tr><td rowspan="2">Dataset</td><td rowspan="2">Metric</td><td colspan="3">Without Fairness</td><td colspan="3">With Fairness Constraint</td><td colspan="6">DRO</td></tr><tr><td>FedCox FedDPFed-DeepHit FedPseudo|Fair-FedCoxFair-FedDPFIDP-FSA</td><td></td><td></td><td></td><td></td><td></td><td></td><td>Fed-DRO -Cox</td><td>Fed-Deep -DRO-Cox -Cox (Split)</td><td>Fed-DRO</td><td>Fed-Deep-DRO -Cox (Split)</td><td>Fed-DRO- DeePHit (Split)FairFSA</td></tr><tr><td rowspan="6"></td><td></td><td>0.60</td><td>0.60</td><td>0.53</td><td>0.22</td><td>0.58</td><td>0.60</td><td>0.61</td><td>0.55</td><td>0.5</td><td></td><td></td><td>0.61**</td></tr><tr><td>C-Index</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.52</td><td>0.53</td><td>0.57</td><td>0.25</td></tr><tr><td>MAE-Uncen</td><td>387</td><td>819</td><td>1246</td><td>510</td><td>262</td><td>262</td><td>2559</td><td>262</td><td>633</td><td>277</td><td>801</td><td>336</td></tr><tr><td>MAE-Hinge</td><td>443</td><td>661</td><td>834</td><td>493</td><td>459</td><td>460</td><td>1830</td><td>457</td><td>329 652</td><td>483</td><td>629</td><td>422*</td></tr><tr><td>Favg</td><td>0.048</td><td>0.094</td><td>0.021</td><td>0.077</td><td>0.003</td><td>0.002</td><td>0.117</td><td>0.003</td><td>480 0.024 0.003</td><td>0.003</td><td>0.011</td><td>0.001*</td></tr><tr><td>C-Index</td><td>0.77</td><td>0.78</td><td>0.78</td><td>0.79</td><td>0.78</td><td>0.78</td><td>0.78</td><td>0.78</td><td></td><td></td><td></td><td></td></tr><tr><td rowspan="6"></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.77</td><td>0.76</td><td>0.75</td><td>0.67</td><td>0.7</td></tr><tr><td>MAE-Uncen</td><td>9275</td><td>12303</td><td>2729</td><td>9243</td><td>6588</td><td>11905</td><td>6786</td><td>7330</td><td>22329</td><td>38938</td><td>1175</td><td>2139**</td></tr><tr><td>MAE-Hinge</td><td>1890</td><td>2499</td><td>549</td><td>1885</td><td></td><td>2417</td><td>1364</td><td>1473</td><td>4489</td><td>7827</td><td>1468</td><td>447*</td></tr><tr><td></td><td>0.064</td><td>0.064</td><td>0.024</td><td>0.064</td><td>1324 0.019</td><td>3758 0.001</td><td>0.064</td><td>0.016 0.023</td><td>0.001</td><td>0.001</td><td>0.009</td><td>0.001*</td></tr><tr><td>C-Index Favg</td><td>0.71</td><td>0.68</td><td>0.66</td><td>0.72</td><td>0.71</td><td></td><td></td><td></td><td></td><td></td><td>0.53</td><td>0.70</td></tr><tr><td> MAE-Uncen</td><td>0.10</td><td>0.11</td><td>0.12</td><td>0.10</td><td>111</td><td>0.66 0.77</td><td>0.72 0.10</td><td>0.70 0.11</td><td>0.63 011</td><td>0.68 0.12</td><td>0.67 0.23</td><td></td></tr><tr><td rowspan="4"></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>MAE-Hinge</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>130</td><td>55</td><td>22</td><td>0.34</td><td>0.23</td></tr><tr><td>Favg</td><td>33</td><td>117 0.046</td><td>11 0.028</td><td>41 0.036</td><td>27 0.008</td><td>56</td><td>53 0.040</td><td>26</td><td></td><td></td><td>28</td><td>12**</td></tr><tr><td></td><td>0.040</td><td></td><td></td><td></td><td></td><td>0.001</td><td></td><td>0.015 0.040</td><td>0.001</td><td>0.017</td><td>0.026</td><td>0.000*</td></tr></table></body></html>

Trade-off Between Fairness and Accuracy. We show the trade-off between fairness and accuracy by varying the trade-off parameter $\alpha$ (ranging from 0.001 to 1.0) in Figure 2 across three survival datasets: FLChain, SEER, and SUPPORT. The accuracy metrics used include the Concordance Index (C-index), Integrated Brier Score (IBS), Mean Absolute Error-Uncensored (MAE-Uncen), and Mean Absolute Error-Hinge (MAE-Hinge). For fairness, we utilize the summary fairness metric $F _ { a v g }$ . As $\alpha$ increases, both the C-index and $F _ { a v g }$ show an upward trend, while the IBS decreases. The MAE-based metrics, however, exhibit instability with varying $\alpha$ values. We select the value of $\alpha$ at which $F _ { a v g }$ and IBS intersect, balancing fairness and accuracy. In table 1 and 2, we present the accuracy levels achieved while optimizing for the best fairness performance. It is important to note that for C-index, higher values indicate better performance, while for IBS, MAE-Uncen, MAE-Hinge, and $F _ { a v g }$ lower values suggest better performance.

Global Fairness. Table 3 illustrates the effectiveness of our proposed CI-Weighted aggregation method in enhancing global fairness within the FairFSA model, compared to the traditional FedAvg aggregation. We assess both accuracy and fairness across clients, along with the standard deviation of these performance metrics, on the imbalanced MSK-MET dataset (Nguyen et al. 2022), which contains an unequal distribution of patients across white and nonwhite groups within all clients. A lower standard deviation reflects more consistent local performance, indicating that the models provide equitable predictions across all clients. The results show that FairFSA when combined with our CI-Weighted aggregation technique, achieves better global fairness (as evidenced by a lower standard deviation) compared to FairFSA using FedAvg. Furthermore, a comparison of global fairness across all models on three survival datasets is presented in the supplementary materials. The results highlight the performance consistency of FairFSA across local clients, with a particular focus on its lowest standard deviation in fairness metrics. This consistency underscores FairFSA’s ability to deliver fair and uniform predictions across different clients.

Trade-off Between Accuracy And Trade-off Between Accuracy And Trade-off Between Accuracy And Fairness On FLChain Data Fairness On SEER Data Fairness On SUPPORT Data C-Index IBS MAE-Uncen C-Index IBS MAE-Uncen C-Index IBS MAE-Uncen MAE-Hinge Favg MAE-Hinge Favg MAE-Hinge Favg   
0.02.52 0.25 0.5   
0.010.515 0.01.52 Rn 0.1 Standardized Value 0.34 0.2 St 0.05 t 0.1 0 0 8 ： α α 2 α

Data Distribution Uncensored Vs Censored 800 Overall Client 1 Client 2 Client 3 400 1 A 12 0 100 0 0 1 Uncensored Censored Uncensored Censored ■ 0 Uncensored Data Censored Data 1 0 0 00 0 1U 1i Client 1 Client 2 Client 3 FedCox FedDP Fair-FedCox Fair-FedDP FedPseudo FIDP-FSA FairFSA

Table 3: Comparison of global fairness between FairFSA with FedAvg and with our CI-Weighted aggregation. Std is the standard deviation of clients’ performance.   

<html><body><table><tr><td>Metric</td><td>Model</td><td>Client 1</td><td>Client2 Client3</td><td>Global Fairness (Std)↓</td></tr><tr><td rowspan="2">C-Index</td><td>FairFSA-FedAvg</td><td>0.67 0.75</td><td>0.73</td><td>0.04</td></tr><tr><td>FairFSA</td><td>0.69 0.73</td><td>0.73</td><td>0.03</td></tr><tr><td rowspan="2">IBS</td><td>FairFSA-FedAvg</td><td>0.17 0.17</td><td>0.14</td><td>0.02</td></tr><tr><td>FairFSA</td><td>0.17 0.17</td><td>0.14</td><td>0.02</td></tr><tr><td rowspan="2">MAE-Uncen</td><td>FairFSA-FedAvg</td><td>836 537</td><td>557</td><td>168</td></tr><tr><td>FairFSA</td><td>828 560</td><td>592</td><td>147</td></tr><tr><td rowspan="2">MAE-Hinge</td><td>FairFSA-FedAvg</td><td>348 257</td><td>246</td><td>56</td></tr><tr><td>FairFSA</td><td>345 269</td><td>255</td><td>49</td></tr><tr><td rowspan="2">FI</td><td>FairFSA-FedAvg</td><td>0.190 0.191</td><td>0.199</td><td>0.005</td></tr><tr><td>FairFSA</td><td>0.187 0.190</td><td>0.193</td><td>0.003</td></tr></table></body></html>

# Conclusion

To the best of our knowledge, this study is the first to integrate fairness into federated survival analysis. We developed FairFSA, a novel framework that jointly trains Federated Pseudo Value (FPV)-based deep learning models, coupled with Distributionally Robust Optimization (DRO) on top of the pseudo-value-based objective function. To ensure global fairness, we introduced a fairness-aware concordance index aggregation process in FedAVG. Extensive experiments on publicly available survival datasets demonstrate that our FairFSA approach balances fairness and accuracy, achieving performance comparable to centralized survival models. Experimental results indicate that FairFSA consistently achieves high accuracy, as evidenced by competitive C-index and MAE metrics while excelling in fairness metrics across various datasets. Future work will investigate the calibration of predicted probabilities to enhance IBS performance while maintaining the balance between fairness and accuracy. Overall, FairFSA sets a new benchmark in federated survival analysis, offering a promising direction for developing fair and accurate predictive models in decentralized settings, with potential applications in healthcare and beyond.

# Acknowledgments

This work is supported by CAREER grant #2238743 from the US National Science Foundation (NSF).