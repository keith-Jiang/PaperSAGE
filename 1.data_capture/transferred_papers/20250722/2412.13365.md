# Quantitative Predictive Monitoring and Control for Safe Human-Machine Interaction

Shuyang Dong1, Meiyi $\mathbf { M } \mathbf { a } ^ { 2 }$ , Josephine Lamp3, Sebastian Elbaum1, Matthew B. Dwyer1, Lu Feng

1University of Virginia 2Vanderbilt University 3DexCom {sd3mn, se4ja, md3cn, lf9u} $@$ virginia.edu, meiyi.ma $@$ vanderbilt.edu, josephine.lamp@dexcom.com

# Abstract

There is a growing trend toward AI systems interacting with humans to revolutionize a range of application domains such as healthcare and transportation. However, unsafe humanmachine interaction can lead to catastrophic failures. We propose a novel approach that predicts future states by accounting for the uncertainty of human interaction, monitors whether predictions satisfy or violate safety requirements, and adapts control actions based on the predictive monitoring results. Specifically, we develop a new quantitative predictive monitor based on Signal Temporal Logic with Uncertainty (STL-U) to compute a robustness degree interval, which indicates the extent to which a sequence of uncertain predictions satisfies or violates an STL-U requirement. We also develop a new loss function to guide the uncertainty calibration of Bayesian deep learning and a new adaptive control method, both of which leverage STL-U quantitative predictive monitoring results. We apply the proposed approach to two case studies: Type 1 Diabetes management and semi-autonomous driving. Experiments show that the proposed approach improves safety and effectiveness in both case studies.

# 1 Introduction

There is a growing trend toward AI systems interacting with humans to revolutionize a range of application domains such as healthcare and transportation. However, unsafe humanmachine interaction can lead to catastrophic failures (e.g., crashes of automated vehicles (Banks, Plant, and Stanton 2018) and robot-caused fatalities (Yang et al. 2022). Ensuring the safety of human-machine interaction poses significant challenges. First, safety is an emergent property that requires holistic reasoning about AI systems and human operators (Ma, Stankovic, and Feng 2021). Second, modeling human-machine interaction should account for the inherent uncertainty of human behavior. Moreover, safe and prompt decision-making under uncertainty entails predictive monitoring, i.e., making predictions about future states and monitoring if safety requirements would be violated. We concretize these challenges using a motivating example below.

Type 1 Diabetes (T1D) is a chronic disease that affects millions of patients whose pancreas produces little to no insulin to regulate blood glucose (BG). Uncontrolled diabetes may cause hypoglycemia (BG below $7 0 ~ \mathrm { m g / d L }$ ) or

Historical Optimal SRT, CGM BG levels Bayesian dropout rate Uncertainty Sensor RNN Calibration (Section 3.2) Predicted flowpipe of BG levels STL-U Quantitative Monitor (Section 3.1) Insulin Robustness degree interval Insulin dosages AdaptiveController Trainingtime Pump (Section3.3) Runtime hyperglycemia (BG above $\mathrm { 1 8 0 m g / d L }$ ), which over time can lead to serious damage to organs such as the kidneys and heart. Over the past decades, advanced technologies such as continuous glucose monitoring (CGM) sensors and insulin pumps have been developed to reduce the need for patients to check BG via finger-pricking and self-injections of insulin. Recently, there have been promising breakthroughs in the development of Artificial Pancreas Systems (APS), which are automated or semi-automated closed-loop insulin delivery systems to regulate BG levels. A typical APS controller calculates insulin dosages based on CGM sensor readings and user input (e.g., meal carbohydrates). There has been increasing interest in using machine learning techniques to predict future BG levels, which are then fed into an APS controller. To guarantee a safety requirement, such as “BG levels should be regulated within the range of 70-180 $\mathrm { m g / d L }$ to avoid hypoglycemia or hyperglycemia”, it is not sufficient to only check APS control actions. Instead, it is necessary to reason about the behavior of the entire closedloop system of APS, including the insulin pump, CGM sensor, as well as patient physiology (e.g., glucose metabolism) and behavior (e.g., eating).

To tackle these challenges, we propose a novel logicbased quantitative predictive monitoring and control approach, as illustrated in Figure 1. We adopt Recurrent Neural Networks (RNNs), which are well-suited to time series data (Bengio, Goodfellow, and Courville 2017), for making sequential predictions about future BG levels. Commonly used RNNs, such as long short-term memory (LSTM) networks, are deterministic models that generate the same predictions with the same input (Hochreiter and Schmidhuber

1997; Ma et al. 2020). To account for the uncertainty of human physiology and behavior, we cast deterministic RNNs into Bayesian RNNs using stochastic regularization techniques (SRTs) (Gal 2016). Bayesian RNNs yield uncertain sequential predictions with the uncertainty estimated by a sequence of posterior probability distributions.

(Ma et al. 2021) characterize Bayesian RNN predictions as a flowpipe signal containing an infinite set of predicted traces, and present Signal Temporal Logic with Uncertainty (STL-U) to check if a flowpipe strongly or weakly satisfies a requirement (i.e., whether the requirement satisfaction holds for all or some traces contained in a flowpipe). Nevertheless, existing STL-U monitors do not provide quantitative information about the degree to which a flowpipe satisfies or violates a requirement, which is imperative for fine-grained decision-making in safe human-machine interactions such as diabetes management.

In this work, we develop a new STL-U quantitative monitor that computes a robustness degree interval, indicating the degree to which a requirement is satisfied or violated. The lower and upper bounds of a robustness degree interval correspond to the worst-case and best-case estimates of the degree to which a flowpipe satisfies a requirement. Additionally, we define a loss function that leverages STL-U quantitative monitoring results to calibrate the uncertainty estimation of Bayesian RNNs during training. We select the optimal combination of SRT and dropout rate that yields the smallest loss. Predictions made by Bayesian RNNs using the calibrated SRT and dropout rate improve the quality of uncertainty estimates with respect to requirement satisfaction. Furthermore, we adapt control actions based on STL-U robustness degree intervals. For instance, we present a proof-of-concept adaptive APS controller that increases or decreases insulin dosages depending on the robustness degree for predicted BG levels that violate the safety requirement. Finally, we evaluate the proposed approach through experiments using the state-of-the-art UVA/PADOVA T1D patient simulator (Man et al. 2014). To demonstrate the generalizability of the proposed approach, we also apply it to a second case study of semi-autonomous driving using the CARLA simulator (CARLATeam 2023), which is included in the appendix of (Dong et al. 2024) due to page limits.

each step $t$ along the sequence, a Gaussian distribution $\Phi _ { t } \sim \bar { N ( \theta _ { t } , \sigma _ { t } ^ { 2 } ) }$ can be estimated, whose mean $\theta _ { t }$ and variance $\sigma _ { t }$ are calculated based on the Monte Carlo samples $\{ x _ { t } ^ { ( 1 ) } , \cdot \cdot \cdot , x _ { t } ^ { ( N ) } \}$ xt(N)}. The uncertainty estimates of Bayesian RNN predictions are bounded by the Gaussian distribution’s confidence interval $[ \Phi _ { t } ^ { - } ( \varepsilon ) , \Phi _ { t } ^ { + } \mathbf { \bar { ( } } \varepsilon ) ]$ under a confidence level $\varepsilon \in \mathsf { \Gamma } ( 0 , 1 )$ . The larger the confidence interval range, the higher the estimated uncertainty.

# 2.2 Signal Temporal Logic with Uncertainty

(Ma et al. 2021) characterize Bayesian RNN predictions as a flowpipe signal $\omega$ over a discrete time domain $\mathbb { T }$ . At each time $t$ , the flowpipe contains all values bounded within a confidence interval $[ \Phi _ { t } ^ { - } ( \varepsilon ) , \Phi _ { t } ^ { + } ( \varepsilon ) ]$ . Figure 2 shows an example flowpipe of predicted BG levels.

Signal Temporal Logic with Uncertainty (STL-U) with the following syntax is proposed in (Ma et al. 2021).

$$
\varphi : = \mu ( \varepsilon ) \mid \neg \varphi \mid \varphi _ { 1 } \land \varphi _ { 2 } \mid \bigsqcup _ { I \varphi } \mid \bigodot _ { I \varphi } \mid \varphi _ { 1 } U _ { I } \varphi _ { 2 }
$$

where $\smash { \bigcirc _ { I } } , \emptyset _ { I }$ and $U _ { I }$ are temporal operators “always”, “eventually”, and “until” with a time interval $I \subseteq \mathbb { T }$ , respectively. $\mu ( \varepsilon )$ is an atomic predicate whose value is determined by a function $f ( x ) > 0$ for $x \in [ \Phi _ { t } ^ { - } ( \varepsilon ) , \Phi _ { t } ^ { + } ( \varepsilon ) ]$ under a confidence level $\varepsilon$ . For example, $\Sigma _ { [ 0 , 3 ] } ( B G _ { \varepsilon = 9 0 \% } > 7 0 )$ is an STL-U formula expressing the requirement that “the predicted BG level under a $90 \%$ confidence level should always be above $7 0 \mathrm { m g / d L }$ in the next three hours”.

STL-U semantics defined in (Ma et al. 2021) include two indices: strong satisfaction (i.e., all values bounded within the flowpipe’s confidence interval satisfy $\varphi$ ), and weak satisfaction (i.e., there exists some value within the flowpipe’s confidence interval satisfying $\varphi ,$ ). For example, the flowpipe shown in Figure 2 strongly satisfies $\square _ { [ t , t _ { 1 } ] } ( B G _ { \varepsilon } ~ > ~ 7 0 )$ , weakly satisfies $\boxed { \begin{array} { r l r } \end{array} } \boxed { B G _ { \varepsilon } } > 7 0 )$ , and strongly violates $\boxed { t , t _ { 3 } } \big ( B G _ { \varepsilon } > 7 0 \big )$ .

Additionally, a loss function, denoted by $L _ { s a t }$ , is proposed in (Ma et al. 2021) based on STL-U strong/weak satisfaction relations to calibrate the uncertainty estimation of Bayesian RNNs by guiding the choice of SRTs and dropout rates.

# 2 Background

# 2.1 Uncertain Sequential Prediction

Stochastic regularization techniques (SRTs) are commonly employed to transform deterministic deep learning models into Bayesian models, enabling uncertainty estimation. In this work, we transform a deterministic RNN model into a Bayesian RNN model via SRTs. We consider four commonly used SRTs: Bernoulli dropout, Bernoulli dropConnect, Gaussian dropout, and Gaussian dropConnect (Gal 2016). These SRTs have various ways to determine which neuron connections to drop based on sampling from a probability distribution with certain dropout rate $p$ . The larger the value of $p$ , the more neuron connections are retained.

A Bayesian RNN model yields a set of sequential predictions by applying Monte Carlo sampling $N$ times. At

![](images/ca0dbe79e263d248cd16a0d39d99e2432fdf50ad0ec65b22205f1560965fa9ae.jpg)  
Figure 2: An example flowpipe of predicted BG levels under a confidence level $\varepsilon$ .

# 3 Approach

The goal of our approach is to provide quantitative information about the degree to which an STL-U formula is satisfied or violated, which is imperative for fine-grained decision making in safe human-machine interaction. To achieve this goal, we develop a new STL-U quantitative monitor in Section 3.1. The monitoring results are leveraged to improve the uncertainty calibration through a new loss function in Section 3.2 and an adaptive control method in Section 3.3.

# 3.1 STL-U Quantitative Monitor

We propose a new quantitative semantics of STL-U, which computes a robustness degree function $\rho ( \varphi , \omega , t )$ indicating how much an STL-U formula $\varphi$ is satisfied or violated by a flowpipe signal $\omega$ at time $t$ .

Let $v = [ \underline { { \upsilon } } , \overline { { \upsilon } } ]$ denote a real-valued interval. We define the following three interval operations: $\begin{array} { l } { - ^ { * } v \stackrel { \mathrm { d e f } } { = } [ - \overline { { v } } , - \underline { { \upsilon } } ] } \\ { m i n ^ { * } ( \upsilon _ { 1 } , \ldots , \upsilon _ { n } ) \stackrel { \mathrm { d e f } } { = } [ \operatorname* { m i n } ( \underline { { \upsilon } } _ { 1 } , \ldots , \underline { { \upsilon } } _ { n } ) , \operatorname* { m i n } ( \overline { { \upsilon } } _ { 1 } , \ldots , \overline { { \upsilon } } _ { n } ) ] } \\ { m a x ^ { * } ( \upsilon _ { 1 } , \ldots , \upsilon _ { n } ) \stackrel { \mathrm { d e f } } { = } [ \operatorname* { m a x } ( \underline { { \upsilon } } _ { 1 } , \ldots , \underline { { \upsilon } } _ { n } ) , \operatorname* { m a x } ( \overline { { \upsilon } } _ { 1 } , \ldots , \overline { { \upsilon } } _ { n } ) ] } \end{array}$

# Definition 1 (STL-U quantitative semantics)

$$
\begin{array} { r l } { \rho ( \mu ( \varepsilon ) , \omega , t ) } & { { } = { \mathrm { [ i n i n } ( f ( x ) ) , ~ } { \mathrm { m a x } } \left( f ( x ) \right) ] , } \\ { \mathrm { v a c ~ } } & { { } } \\ { \rho ( \mathbf { \vec { v } } \circ \omega , t ) } & { { } = - \rho ( \varphi , \omega , t ) } \\ { \rho ( \varphi _ { 1 } \wedge \varphi _ { 2 } , \omega , t ) } & { { } = m i n ^ { * } \left( \rho ( \varphi _ { 1 } , \omega , t ) , \rho ( \varphi _ { 2 } , \omega , t ) \right) } \\ { \rho ( \Omega _ { r } \varphi , \omega , t ) } & { { } = \rho _ { \mathrm { r e f f } } ( \varphi , \omega , t ) } \\ { \rho ( \Omega _ { r } \varphi , \omega , t ) } & { { } = { \mathrm { [ } } _ { r ^ { \prime } \in \{ ( \ell + l ) \} } \rho ( \varphi , \omega , t ^ { \prime } ) } \\ { \rho ( \varphi _ { 1 } \varphi , \omega , t ) } & { { } = { \mathrm { [ } } _ { r ^ { \prime } \in \{ ( \ell + l ) \} } \rho ( \varphi , \omega , t ^ { \prime } ) } \\ { \rho ( \varphi _ { 1 } U _ { \mathcal { V } ^ { 2 } } \circ \omega , t ) = { \mathrm { ~ } } _ { r ^ { \prime } \in \{ ( \mu + r ) \} } \left( \operatorname* { m i n } ^ { * } \left( \rho ( \varphi _ { 2 } , \omega , t ^ { \prime } ) , \right. \right. } \\ { \left. \left. e ^ { \mathrm { [ } \varphi _ { 1 } \varphi , \omega , t ^ { \prime } ) } \rho ( \varphi _ { 1 } , \omega , t ^ { \prime \prime } ) \right) \right) } & { { } = \rho _ { \mathrm { r e f f } } ( \varphi _ { 1 } , \omega , t ^ { \prime \prime } ) ) . } \end{array}
$$

Intuitively, a robustness degree function yields an interval whose lower/upper bounds corresponding to the worst/best cases of a flowpipe satisfying or violating an STL-U formula. A positive (resp. negative) robustness value indicates the degree of satisfaction (resp. violation).

Algorithm 1 illustrates STL-U quantitative monitoring algorithm based on Definition 1. We can apply this algorithm recursively to monitor complex STL-U formulas with multiple levels of nesting temporal operators. The algorithm has a linear time complexity with respect to the length of the flowpipe, $| \omega |$ .

Here is an example of checking the flowpipe in Figure 2 against an STL-U formula $\begin{array} { r l } { \prod _ { [ t , t _ { 3 } ] } ( B G _ { \varepsilon } } & { { } > } \end{array}$ 70). First, we check the atomic predicate at each time $\tau { \bf \bar { \Delta } } \in \{ t , t _ { 3 } \}$ , and compute the robustness degree interval $[ \operatorname* { m i n } ( f ( x ) ) , \operatorname* { m a x } \bigl ( f ( x ) \bigr ) ]$ for all $x \in [ \Phi _ { \tau } ^ { - } ( \varepsilon ) , \Phi _ { \tau } ^ { + } ( \varepsilon ) ]$ , where $f ( x ) { \stackrel { . } { = } } x - 7 0$ . The flowpipe at $t _ { 2 }$ is bounded by [60, 80] and yields a robustness degree interval $[ - 1 0 , + 1 0 ]$ . The flowpipe at $t _ { 3 }$ is bounded by [40, 65] and its robustness degree interval is $[ - 3 0 , - 5 ]$ . Finally, we obtain a robustness degree interval for the always operator $\boxed { \begin{array} { r l } \end{array} }$ by taking the minimal of the lower/upper bounds of the atomic predicate’s robustness degree intervals over all time steps $\bar { \boldsymbol { \tau } } \in [ t , t _ { 3 } ]$ . The resulting robustness degree interval, $[ - 3 0 , - 5 ]$ , indicates that the predicted flowpipe would violate the requirement by $- 3 0$ and $- 5$ in the worst and best-case scenarios, respectively.

# Algorithm 1 STL-U quantitative monitoring algorithm

Function Monitor $( \varphi , \omega , t )$ : switch $\varphi$ do Case $\mu ( \varepsilon )$ $\rho \gets [ \operatorname* { m i n } \bigl ( f ( x ) \bigr ) , \operatorname* { m a x } \bigl ( f ( x ) \bigr ) ] ,$ , for all $x \in [ \Phi _ { t } ^ { - } ( \varepsilon ) , \Phi _ { t } ^ { + } ( \varepsilon ) ]$ return $\rho$ Case $\neg \varphi$ return $- ^ { * } \left( M o n i t o r ( \varphi , \omega , t ) \right)$ Case φ1∧φ2 return min∗ M onitor(φ1, ω, t), M onitor(φ2, ω, t) Case □Iφ ρ ← M onitor(φ, ω, t) for t′ (t + I) do ρ min∗ ρ, M onitor(φ, ω, t′) return ρ Case ♢Iφ ρ ← M onitor(φ, ω, t) for t′ (t + I) do ρ ← max∗ ρ, M onitor(φ, ω, t′) return ρ Case $\varphi _ { 1 } ~ U _ { I } ~ \varphi _ { 2 }$ $\rho \gets ( - \infty , - \infty )$ ; $\rho _ { 1 } \gets M o n i t o r ( \varphi _ { 1 } , \omega , t )$ for $t ^ { \prime } \in ( t + I )$ do ρ2 ← M onitor(φ2, ω, t′) for t′′ [t, t′] do ρ1 ← min∗ ρ1, M onitor(φ1, ω, t′′) ρ ← max∗ ρ, min∗(ρ1, ρ2) return ρ

The soundness of the proposed STL-U quantitative monitor is stated below and the proof is given in the appendix of (Dong et al. 2024).

Theorem 1 Given an STL-U formula $\varphi$ and a flowpipe $\omega$ , the following properties hold.

1. $\underline { { \rho } } > 0 \Rightarrow ( \omega , t ) \vdash _ { s } \varphi$   
2. $\rho \le 0 \Rightarrow ( \omega , t ) \not \in _ { s } \varphi$   
3. $\overline { { \rho } } > 0 \Rightarrow \left( \omega , t \right) \left| = _ { w } \varphi \right.$   
4. $\overline { { \rho } } \le 0 \Rightarrow ( \omega , t )  \neq _ { w } \varphi$

where ρ and $\overline { { \rho } }$ are the lower and upper bounds of the robustness degree interval $\rho ( \varphi , \omega , t )$ , and $\left| = _ { s } \right.$ (resp. $\models _ { w . }$ ) denotes the strong (resp. weak) satisfaction relations.

# 3.2 Uncertainty Calibration

A Bayesian RNN model may produce divergent uncertainty estimates for a model trained on identical data, depending on various choices of SRTs and dropout rates. The current practice often selects an SRT and dropout rate empirically or guided by traditional deep learning metrics such as prediction accuracy, which tend to overestimate uncertainty (i.e., the wider the flowpipe, the higher the accuracy of containing the ground truth trace).

We propose a loss function based on STL-U quantitative monitoring results to guide the choice of SRTs and dropout rate. The proposed loss function, denoted as ${ L } _ { q t } ( \omega , \hat { \omega } , \bar { \varphi } )$ , is a linear combination of two parts: $\eta _ { r } ( \omega , \hat { \omega } , \varphi )$ for comparing the predicted flowpipe $\omega$ and the target trace $\hat { \omega }$ in terms of the robustness degrees of satisfying an STL-U formula $\varphi$ , and $\eta _ { d } ( \omega , \hat { \omega } )$ for measuring the distance between the predicted flowpipe $\omega$ and the target trace $\hat { \omega }$ . Formally,

$$
\eta _ { r } ( \omega , \hat { \omega } , \varphi ) = \left\{ \begin{array} { l l } { \underline { { \rho } } ( \varphi , \omega , t ) } & { , \quad \hat { \omega } \in \varphi } \\ { - \overline { { \rho } } ( \varphi , \omega , t ) } & { , \quad \hat { \omega } \notin \varphi } \end{array} \right.
$$

where $\underline { { \rho } } ( \varphi , \omega , t )$ and $\overline { { \rho } } ( \varphi , \omega , t )$ are the lower and upper bounds of robustness degree intervals.

$$
\eta _ { d } ( \omega , \hat { \omega } ) = \sum _ { \tau = 0 } ^ { | \hat { \omega } | } \left\{ \begin{array} { l l } { 0 } & { , \quad \quad \Phi _ { \tau } ^ { - } ( \varepsilon ) \leq \hat { \omega } _ { \tau } \leq \Phi _ { \tau } ^ { + } ( \varepsilon ) } \\ { \Phi _ { \tau } ^ { - } ( \varepsilon ) - \hat { \omega } _ { \tau } } & { , \quad \hat { \omega } _ { \tau } < \Phi _ { \tau } ^ { - } ( \varepsilon ) } \\ { \hat { \omega } _ { \tau } - \Phi _ { \tau } ^ { + } ( \varepsilon ) } & { , \quad \quad \Phi _ { \tau } ^ { + } ( \varepsilon ) < \hat { \omega } _ { \tau } } \end{array} \right.
$$

where $| \hat { \omega } |$ is the length of the target trace and $\hat { \omega } _ { \tau }$ is the target trace’s value at time $\tau$ .

The loss function is then given by

$L _ { q t } ( \omega , \hat { \omega } , \varphi ) = - \beta \cdot \eta _ { r } ( \omega , \hat { \omega } , \varphi ) + ( 1 - \beta ) \cdot \eta _ { d } ( \omega , \hat { \omega } )$ (3) where $\beta \in [ 0 , 1 ]$ is a real-valued coefficient indicating the relative importance of the two parts.

The goal is to calibrate the uncertainty estimation of a Bayesian RNN model by choosing an optimal combination of SRT and dropout rate that yield flowpipe predictions with minimal loss $\bar { L _ { q t } } ( \omega , \hat { \omega } , \varphi )$ . Intuitively, the lower the loss, the higher the quality of predicted flowpipes, which achieve a higher (resp. lower) robustness degree of satisfying (resp. violating) an STL-U formula and a smaller distance from the target trace.

# 3.3 Adaptive Controller

A typical (deterministic) controller, denoted by $\pi : S  A$ , takes an input state $s \in S$ from the environment and produces an output action $a \in A$ . We develop an adaptive controller $\pi ^ { \prime } : S \times \rho \to A$ that adapts control actions based on STL-U quantitative monitoring results $\rho ( \varphi , \omega , t )$ as shown in Figure 3. The adaptation schema can be domain-specific.

As a proof of concept, we present an adaptive controller based on the Basal-Bolus Controller (Kovatchev et al. 2009) included in the UVA/PADOVA T1D Simulator. The default Basal-Bolus Controller takes input such as the current BG level and meal carbohydrates, and computes the basal and bolus insulin dosages as control actions to regulate BG levels. A constant amount of basal insulin is delivered at each step, denoted by defaultBasal, whose value is calculated by multiplying the patient’s body weight with a constant representing the steady state insulin rate per kilogram. Additionally, the controller issues a (non-zero) bolus insulin at a step when the patient takes a meal with carbohydrates. The bolus insulin dosage, denoted by mealBolus, is calculated based on the amount of carbohydrates, the current and target BG levels, and the patient’s carbohydrate ratio and correction factor.

![](images/fb8ab9514931091d2bdc6ad2a98193fa8da8c767ae6f23fdbf0039a2b5268466.jpg)  
Figure 3: Adapting control actions based on STL-U quantitative monitoring results.

# Algorithm 2 Adapting a Basal-Bolus Controller

Input : STL-U quantitative monitoring results $\rho ( \varphi _ { l } , \omega , t )$ and $\rho ( \varphi _ { h } , \omega , t )$ , current BG level $g _ { t }$ , next planned meal time $t _ { m }$ ,time-window length $K$ , and bolusF lag for a meal bolus   
Output: Control action $a _ { t }$ at time $t$   
$/ /$ Adapting basal insulin dosages   
basal defaultBasal   
if $\rho ( \varphi _ { l } , \omega , t ) < - 2 0$ then   
$\lfloor \mathit { \bar { b } a s a l } \gets 0$   
else if $- 2 0 \le \rho ( \varphi _ { l } , \omega , t ) \le 0$ then $\underline { { \cdot } } \ b a s a l \gets \bar { d e } f a u l t B a s a l \times 0 . 8$   
else if $- 7 0 \leq \rho ( \varphi _ { h } , \omega , t ) \leq 0$ then   
$\lfloor \ b a s a l \gets \bar { d e } f a u l t B a s a l \times 1 . 2$   
else if $\rho ( \varphi _ { h } , \omega , t ) < - 7 0$ then   
$\lfloor \ b a \overline { { s } } a l \gets d e f a u l t B a s a l \times 1 . 5$   
// Adapting bolus insulin timing   
$b o l u s  0$   
if bolus $F l a g = = f a l s e$ then if $t _ { m } - K \leq t < t _ { m }$ then if $\rho ( \varphi _ { l } , \omega , t ) \leq 0$ or $g _ { t } \leq 7 0$ then $\underline { \mathsf { L } } { \overline { { \mathsf { \Pi } } } } b o l u s \gets 0$ else bolus mealBolus; bolusF lag true else if $t = t _ { m }$ then bolus mealBolus; bolusF lag true

return $a _ { t } = \langle b a s a l , b o l u s \rangle$

Algorithm 2 adapts the Basal-Bolus Controller based on quantitative results of monitoring two STL-U formulas: $\bar { \varphi } _ { l } = \bigsqcup _ { [ 0 , \infty ) } ( B G _ { \varepsilon } > 7 0 )$ and $\varphi _ { h } \bar { = } \sqcup _ { [ 0 , \infty ) } ( B G _ { \varepsilon } < 1 8 0 )$ . It decreases or increases basal insulin dosages based on the worst-case robustness degrees of predicted hypoglycemias and hyperglycemias as follows. It reduces the basal dose to zero when $\underline { { \rho } } ( \varphi _ { l } , \omega , t ) ~ < ~ - 2 0$ , indicating severe hypoglycemia with BG below $5 0 ~ \mathrm { m g / d L }$ . It decreases the basal dose to $80 \%$ of the default when $- 2 0 \le \underline { { \rho } } ( \varphi _ { l } , \omega , t ) \le 0$ , indicating mild hypoglycemia. It increases the basal dose to $120 \%$ when $- 7 0 ~ \le ~ \underline { { \rho } } ( \varphi _ { h } , \omega , t ) ~ \le ~ 0$ , indicating mild hyperglycemia. Finally, it increases the basal dose to $1 5 0 \%$ of the default when $\underline { { \rho } } ( \varphi _ { h } , \omega , t ) < - 7 0$ , indicating severe hyperglycemia with BG above $2 5 0 ~ \mathrm { m g / d L }$ . We set these BG thresholds and basal change percentages following medical guidelines (American Diabetes Association 2022).

Furthermore, the adaptive controller adapts the time to administer a bolus insulin based on the current and predicted BG levels. Studies (Slattery, Amiel, and Choudhary 2018) have shown that taking a bolus 15-30 minutes before a meal helps to improve the glucose control. The optimal bolus timing varies with patient circumstances and insulin effects. Drawing on this insight, we design the adaptive controller to encourage pre-meal boluses. As shown in Algorithm 2, the adaptive controller decides the bolus timing by checking the current and predicted BG levels from $K$ steps before a meal, where $K$ is a constant recommended by medical guidelines (e.g., 45 minutes). The adaptive controller would not issue a pre-meal bolus when the current or predicted BG levels are below $7 0 \mathrm { m g / d L }$ because of the risk of hypoglycemia.

# 4 Experiments

We evaluate the proposed approach via experiments using the UVA/PADOVA T1D Patient Simulator (Man et al. 2014), which has been approved by the U.S. Food and Drug Administration (FDA) for pre-clinical experiments with in silico populations. We investigate three research questions:

• RQ1: How useful is the proposed loss function for the uncertainty calibration of Bayesian RNN predictions? • RQ2: How good is the proposed predictive monitor for the early and accurate detection of safety hazards? • RQ3: How safe and effective is the proposed predictive monitoring and control approach in the closed-loop simulation of T1D management?

Datasets and experimental setup. We use the simulator to generate data based on 30 virtual patient profiles including: 10 adults, 10 adolescents and 10 children. Each patient is simulated for an 85-day period, with each time step in the simulation representing 3 minutes. We use 70-day, 5-day, and 10-day data for training, validation, and testing, respectively. We segment the data into samples of 20 steps (1 hour) by sliding windows, and obtain about 413,326 samples in total for each patient population. Violations are observed in $23 \%$ of adolescent data, $48 \%$ of adult data, and $52 \%$ of child data.

We train three different LSTM models for adults, adolescents, and children, respectively. They seek to predict BG levels in the future 30 minutes using the historical data of the past 30 minutes. The data inputs include CGM sensor readings, meal carbohydrates, insulin dosages, low/high blood glucose indexes, hypo/hyper risk, and time of a day. Each model is trained for 50 epochs. Given a chosen SRT and dropout rate, we repeat Bayesian LSTM predictions for 30 times using the Monte Carlo method. We estimate Gaussian distributions using these predictions and obtain flowpipes under a $9 5 \%$ confidence level. Using a higher confidence level broadens the predicted flowpipe, which can increase requirement violations. While this may appear conservative, it aligns with our focus on safety in STL-U requirements, where conservatism helps mitigate risks proactively. We use the validation datasets to select the optimal SRT and dropout rate under the guidance of the proposed loss function, and use the selected optimal SRT and dropout rate to generate Bayesian LSTM predictions for the testing datasets.

![](images/225c684fd4c4083e7083632930576e935726c0c275df5246041b6fd794d477b6.jpg)  
Figure 4: Loss values of using different SRTs and dropout rates in the Bayesian LSTM model for adults.

Lastly, we apply the proposed predictive monitoring and control approach in the closed-loop simulation of T1D management over a 7-day period (different from the 85-day data mentioned before) for 30 virtual patients.

The experiments were run on a machine with $2 . 1 \mathrm { G H z }$ CPU, Nvidia Quadro RTX5000 GPU, 128GB memory, and CentOS 7 operating system.

# 4.1 RQ1: Evaluation of Uncertainty Calibration

Figure 4 plots values of the proposed loss function $\boldsymbol { L _ { q t } }$ with respect to an STL-U formula $\varphi = \square _ { [ 0 , \infty ) } ( 7 0 < \dot { B } G _ { \varepsilon } <$ 180), when varying SRTs and dropout rates of the Bayesian LSTM model for adults with the validation dataset. The results show that Bernoulli dropConnect with a dropout rate of 0.8 is the best choice with the smallest loss. For the LSTM models of adolescents and children (plots omitted due to page limits), we found Bernoulli dropConnect with a rate of 0.9 and Gaussian Dropout with a rate of 0.9 to be the best, respectively.

We compare the performance of the proposed loss function $L _ { q t }$ with two baselines taken from (Ma et al. 2021): $L _ { a c c }$ which captures prediction accuracy (i.e., whether the target trace is entirely contained in a predicted flowpipe), and $L _ { s a t }$ which captures STL-U strong/weak satisfaction. We evaluate the $_ { F I }$ scores of requirement satisfaction metric defined as $\frac { T P } { T P + \frac { 1 } { 2 } \left( F P + F N \right) }$ , where $T P$ denotes the number of true positives (i.e., when the target trace satisfies $\varphi$ and the predicted flowpipe $\omega$ yields $\underline { { \rho } } ( \varphi , \omega , t ) > 0 \}$ , $F P$ denotes the number of false positives (i.e., when the target trace violates $\varphi$ and the predicted flowpipe $\omega$ yields $\underline { { \rho } } ( \varphi , \omega , t ) > 0 )$ , and $F N$ denotes the number of false negatives (i.e., when the target trace satisfies $\varphi$ and the predicted flowpipe $\omega$ yields $\underline { { \rho } } ( \bar { \varphi } , \omega , t ) < 0 )$ .

Table 1 shows F1 scores achieved by Bayesian LSTM predictions generated for the testing datasets using the optimal SRTs and dropout rates selected via different loss functions. $L _ { a c c }$ has the worst results because it tends to over-estimate the uncertainty (i.e., making the flowpipe wider) in order to improve the prediction accuracy. Both $\boldsymbol { L _ { s a t } }$ and $L _ { q t }$ check

<html><body><table><tr><td>Model</td><td>Lacc</td><td>Lsat</td><td>Lqt (proposed)</td></tr><tr><td>Adults(β = 0.5)</td><td>0.66</td><td>0.88</td><td>0.93</td></tr><tr><td>Adolescents(β = 0.5)</td><td>0.38</td><td>0.60</td><td>0.71</td></tr><tr><td>Children(β = 0.5)</td><td>0.68</td><td>0.81</td><td>0.90</td></tr></table></body></html>

Table 1: F1 scores of requirement satisfaction for comparing the proposed loss function with two baselines.

if the target trace and the predicated flowpipe yield consistent STL-U monitoring results. $L _ { q t }$ achieves higher F1 scores than $L _ { s a t }$ in all three models, because $L _ { q t }$ accounts for quantitative information in the form of robustness degree of requirement satisfaction.

In summary, experiments demonstrate that the proposed loss function can be used to calibrate the uncertainty estimation of Bayesian RNNs by guiding the selection of optimal SRTs and dropout rates, which improve the quality of uncertainty estimates and predictions.

# 4.2 RQ2: Evaluation of Predictive Monitors

We compare the performance of the proposed STL-U quantitative predictive monitor with a baseline predictive monitor that does not account for the uncertainty. Specifically, we use the STL monitor (Maler and Nickovic 2004) to check the predicted flowpipes’ mean traces as the baseline. For a fair comparison, both predictive monitors use the same Bayesian LSTM models equipped with the optimal SRTs and dropout rates. We consider two performance metrics: the average pre-alert time (i.e., the time interval between the earliest point when a predictive monitor detects an impending hazard and its actual occurrence time) over all possible safety hazards, and F1 score of requirement satisfaction. Following the convention in hazard calculations for artificial pancreas systems (Lum et al. 2021), we make the assumption that if two hazards of the same type happen closely within 30 minutes, then they are counted as one hazard.

Table 2: Comparing the baseline and the proposed predictive monitors in terms of average pre-alert time (minutes) and F1 scores of requirement satisfaction.   

<html><body><table><tr><td>Model</td><td>Hazard</td><td>Baseline Time F1</td><td>Time</td><td>Proposed F1</td></tr><tr><td rowspan="2">Adults</td><td>Hypo</td><td>0.6</td><td>0.54</td><td>23.9 0.96</td></tr><tr><td>Hyper</td><td>1.9 0.56</td><td>22.2</td><td>0.63</td></tr><tr><td rowspan="2">Adolescents</td><td>Overall Hypo</td><td>1.2 4.2</td><td>0.54 0.57</td><td>23.0 0.93</td></tr><tr><td>Hyper</td><td>10.6</td><td>0.82</td><td>24.9 0.48 22.6 0.78</td></tr><tr><td rowspan="2"></td><td>Overall</td><td>9.2</td><td>0.78</td><td>23.1 0.71</td></tr><tr><td>Hypo</td><td>3.9</td><td>0.89</td><td>13.1 0.91</td></tr><tr><td rowspan="2">Children</td><td>Hyper</td><td>21.2</td><td>0.71</td><td>27.7 0.75</td></tr><tr><td>Overall</td><td>10.6</td><td>0.88</td><td>18.7 0.90</td></tr></table></body></html>

Table 2 shows that, compared to the baseline, the proposed STL-U quantitative predictive monitor leads to earlier detection (i.e., larger pre-alert time) of impending hazards across all three patient populations with statistical significance. The results of paired t-test are $\mathrm { t } ( 1 2 7 ) { = } 2 8 . 2$ , $\mathrm { { \tt p } } { < } 0 . 0 1$ , $\mathrm { d } { = } 3 . 2$ , significant) for adults, $( \mathrm { t } ( 3 1 6 ) { = } 2 2 . 6 \$ , $\mathsf { p } { < } 0 . 0 1$ , $\mathrm { d } { = } 1 . 4$ , significant) for adolescents, and $( \mathrm { t } ( 3 5 4 ) { = } 1 7 . 0$ , $\mathsf { p } { < } 0 . 0 1$ , $\mathrm { d } { = } 0 . 7$ , significant) for children. Table 2 also shows that the proposed predictive monitor achieves higher F1 scores than the baseline for adults and children models, indicating more accurate detection of impending hazards. But the proposed predictive monitor has slightly lower F1 scores than the baseline for the adolescents model. One possible explanation is that the simulated adolescent patients have higher glycemic variability index (1.96) than adults (1.69) and children (1.80), making the prediction more challenging.

![](images/91759276713705376b9e06a1bf04577d4700190548ef56b96eca6c6bab12b3a4.jpg)  
Figure 5: Comparing the number of hazards that occurred during the simulated 7-day period (mean and standard deviation over each patient population).

In summary, experiments demonstrate that the proposed STL-U quantitative monitor can provide early and accurate detection of impending safety hazards.

# 4.3 RQ3: Closed-Loop Simulation

We apply the proposed STL-U quantitative monitor and adaptive controller in the closed-loop simulation of T1D management. We use the simulator’s Basal-Bolus Controller (Kovatchev et al. 2009) as a baseline for comparison.

We measure the following commonly used metrics for the safety and effectiveness of T1D management: number of hazards (i.e., number of hypoglycemias and hyperglycemias that occur to a patient during the simulated period) and time in range (i.e., the percentage of time that a simulated patient’s BG levels stay within the range of $7 0 - 1 8 0 \mathrm { m g / d L } \rangle$ ).

Figure 5 shows that the proposed approach reduces the average number of hazards for all three types of patients. The results of paired t-test are $( \mathrm { t } ( 9 ) = - 3 . 5 \$ , $\scriptstyle \mathtt { p = 0 . 0 1 }$ , $\scriptstyle \mathrm { d } = - 0 . 9$ , significant) for adults, $( { \mathfrak { t } } ( 9 ) { = } { - } 1 . 9 \$ , $\scriptstyle { \mathrm { p = 0 . 0 9 } }$ , $\mathrm { d } { = } { - } 0 . 2$ , insignificant) for adolescents, and $( { \mathfrak { t } } ( 9 ) { = } { - } 1 . 0 \$ , $\mathrm { p } { = } 0 . 3 3$ , $\mathrm { d } { = } { - } 0 . 4$ , insignificant) for children.

Table 3 shows that the proposed approach improves the time in range across all three patient populations with statistical significance. The results of paired t-test are $( \mathrm { t } ( 9 ) \substack { = } 3 . 4$ , $\scriptstyle \mathtt { p = 0 . 0 1 }$ , $\mathrm { d } { = } 0 . 6$ , significant) for adults, $\mathrm { ( t ( 9 ) } = 2 . 7$ , $\scriptstyle { \mathrm { p = 0 } } . 0 2$ , $\mathrm { d } { = } 0 . 3$ , significant) for adolescents, and $( \mathfrak { t } ( 9 ) = 2 . 6$ , $\scriptstyle { \mathrm { p = 0 } } . 0 3$ , $\mathrm { d } { = } 0 . 4$ , significant) for children. We observe that adults have the most effective glucose control, while adolescents (resp. children) tend to have more hyperglycemias (resp. hypoglycemias) in the simulation.

In summary, results of the closed-loop simulation demonstrate that the proposed predictive monitoring and control approach improves the safety and effectiveness of T1D management by increasing the time in range and decreasing the

Table 3: Comparing the baseline controller and the proposed approach’s performance in closed-loop simulation.   

<html><body><table><tr><td>Model</td><td>Metric</td><td>Baseline</td><td>Proposed</td></tr><tr><td>Adults</td><td>Time in range Hypo time Hyper time</td><td>90.9% 4.8% 4.3%</td><td>96.3% 2.4% 1.3%</td></tr><tr><td>Adolescents</td><td>Time in range Hypo time Hyper time</td><td>80.9% 4.2% 14.9%</td><td>85.2% 3.3% 11.5%</td></tr><tr><td>Children</td><td>Time in range Hypo time Hyper time</td><td>63.6% 29.4% 7.0%</td><td>74.8% 19.3% 5.9%</td></tr></table></body></html>

number of safety hazards.

# 5 Related Work

Safe human-machine interaction via formal methods. Traditional methods of human-machine interaction design primarily rely on user studies for safety assurance (Sharp, Preece, and Rogers 2019). To reduce the burden of human testing, model-based design using formal methods has been explored to provide mathematically rigorous safety guarantees for human-machine interaction (Bolton, Bass, and Siminiceanu 2013). For example, a control protocol for an unmanned aerial vehicle (UAV) is synthesized by modeling the human-UAV interaction as a two-player stochastic game (Feng et al. 2016). There are also several works on the formal specification and verification of human-robot interaction (Luckcuck et al. 2019).

However, these existing works mostly focus on modeling and analyzing human-machine interaction at design time. By contrast, in this work, we consider the predictive monitoring and control of safe human-machine interaction at runtime. We use data-driven RNN models as abstract representations of complex human behaviors, capturing their uncertainty through Bayesian deep learning. We then develop logic-based approaches to monitor predictions made by Bayesian RNNs and adapt control actions based on the monitoring results.

Logic-based predictive monitoring and control. Temporal logic specifications such as Signal Temporal Logic (STL) have been used for runtime monitoring (also called runtime verification) and control of cyber-physical systems, such as automobiles and medical devices (Bartocci et al. 2018). Recently, there have been increasing efforts on predictive monitoring, which checks predictions about future states to support prompt decision making. For instance, (Qin and Deshmukh 2020) apply an STL monitor to check glucose levels predicted by an ARIMA statistical model. (Yoon and Sankaranarayanan 2021) presents a logic-based Bayesian intent inference to forecast a robot’s future positions and avoid impending collisions. (Ma et al. 2021) presents an STL-U predictive monitor to check predictions of air pollution and traffic in smart cities.

Following this line of work, we contribute to the state-ofthe-art by developing a novel STL-U quantitative predictive monitor that computes robustness degrees indicating how far a signal is from satisfying or violating a logic specification. Our work is inspired by (Fainekos and Pappas 2009), which introduces the concept of robustness degree for checking continuous-time (single-sequence) signals against temporal logic specifications. We adopt this concept and extend it for checking flowpipe signals that represent uncertain sequential predictions made by Bayesian RNNs.

There is some related work on uncertainty-aware STL monitoring. For example, (Baharisangari et al. 2021) define the lower and upper bounds of robustness by selecting a single trace out of an interval trajectory. (Visconti et al. 2021) define lower and upper bounds for specific time points with missing values for a single trace. (Lindemann et al. 2023) construct prediction regions that quantify prediction uncertainty using conformal prediction, a statistical tool for uncertainty quantification. By contrast, we define STL-U quantitative semantics over all possible traces included in a flowpipe, capturing the uncertainty of Bayesian RNNs via confidence intervals at every time point.

Lastly, existing work on utilizing predictive monitoring results for downstream tasks such as control and design modification is limited. This work addresses this gap by developing a new loss function to guide the uncertainty calibration of Bayesian deep learning and a new adaptive control method, both of which leverage STL-U quantitative predictive monitoring results.

# 6 Conclusion

In this work, we present a logic-based quantitative predictive monitoring and control approach to enhance the safety of human-machine interaction under uncertainty. Using Bayesian RNN models, we represent the uncertainty of human behavior and employ a novel STL-U quantitative predictive monitor to compute robustness degree intervals, which indicate the satisfaction or violation of STL-U requirements. We design a new loss function leveraging STLU results to optimize uncertainty estimation in Bayesian RNNs by selecting the best combination of SRT and dropout rate. Additionally, adaptive controllers adjust control actions based on robustness intervals.

Experiments with a T1D patient simulator demonstrate that the proposed approach enables early and accurate detection of safety hazards and improves the safety and effectiveness of T1D management. Furthermore, the loss function outperforms state-of-the-art baselines in uncertainty estimation. Results from a semi-autonomous driving case study also show enhanced safety, confirming the approach’s generalizability.

Future work includes testing alternative RNN models, developing principled adaptive control for broader domains, incorporating priority-based dynamic enforcement of requirements, validating in real-world settings, and extending to diverse case studies like human-robot interaction.

# Acknowledgments

This work was supported in part by the U.S. Air Force Office of Scientific Research under Grant FA9550-21-1-0164 and the U.S. National Science Foundation under Grants CCF1942836, CCF-2131511, 2220401, and 2427711. The opinions, findings, conclusions, or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsoring agencies.