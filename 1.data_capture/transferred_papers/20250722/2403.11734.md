# Learning More Expressive General Policies for Classical Planning Domains

Simon St˚ahlberg1, Blai Bonet2, Hector Geffner1

1RWTH Aachen University, Germany 2Universitat Pompeu Fabra, Spain simon.stahlberg@gmail.com, bonetblai@gmail.com, hector.geffner@ml.rwth-aachen.de

# Abstract

GNN-based approaches for learning general policies across planning domains are limited by the expressive power of $C _ { 2 }$ , namely; first-order logic with two variables and counting. This limitation can be overcame by transitioning to $k$ - GNNs, for $k = 3$ , wherein object embeddings are substituted with triplet embeddings. Yet, while 3-GNNs have the expressive power of $C _ { 3 }$ , unlike 1- and 2-GNNs that are confined to $C _ { 2 }$ , they require quartic time for message exchange and cubic space to store embeddings, rendering them infeasible in practice. In this work, we introduce a parameterized version $\mathbf { \bar { R } - G N N } [ t ]$ (with parameter $t$ ) of Relational GNNs. Unlike GNNs, that are designed to perform computation on graphs, Relational GNNs are designed to do computation on relational structures. When $t = \infty$ , $\mathbf { R - G N N } [ t ]$ approximates 3-GNNs over graphs, but using only quadratic space for embeddings. For lower values of $t$ , such as $t = 1$ and $t = 2$ , $\mathbf { R - G N N } [ t ]$ achieves a weaker approximation by exchanging fewer messages, yet interestingly, often yield the expressivity required in several planning domains. Furthermore, the new $\mathbf { R - G N N } [ t ]$ architecture is the original R-GNN architecture with a suitable transformation applied to the inputs only. Experimental results illustrate the clear performance gains of R-GNN[1] over the plain R-GNNs, and also over Edge Transformers that also approximate 3-GNNs.

# Introduction

General policies are policies that can be used to solve a collection of planning problems reactively (Srivastava, Immerman, and Zilberstein 2008; Hu and Giacomo 2011; Belle and Levesque 2016; Bonet and Geffner 2018; Illanes and McIlraith 2019; Jime´nez, Segovia-Aguas, and Jonsson 2019). For example, a general policy for solving all Blocksworld problems can place all blocks on the table, and then build up the target towers from the bottom up. Yet while nearly perfect general policies have been learned for many classes of planning domains (Toyer et al. 2020; Rivlin, Hazan, and Karpas 2020; St˚ahlberg, Bonet, and Geffner 2022a), one key expressive limitation results from the type of features used to classify state transitions or actions. In combinatorial approaches, features are selected from a domain-independent pool, created using a description logic grammar (Baader et al. 2003) based on the given domain predicates (Bonet and Geffner 2018; Bonet, Franc\`es, and Geffner 2019), while in deep learning approaches, the features are learned using relational versions of graph neural networks (Scarselli et al. 2009; Gilmer et al. 2017; Hamilton 2020). A shared limitation of both approaches, however, is their inability to learn policies requiring complex logical features. This limitation arises in description logics from the $C _ { 2 }$ fragment of firstorder logic that they capture; namely, first-order logic limited to two variables and counting (Baader et al. 2003), and in GNNs, from the type of message passing that is accommodated, where direct communication involves pairs of objects but no triplets (Grohe 2021).

This expressive limitation, not always acknowledged, is serious. For example, although these methods can learn general policies for guiding an agent to a specific cell in an $n \times n$ grid containing obstacles, with positions and adjacency relations defined in terms of cells and atoms such as $\mathrm { A T } ( c )$ and $\mathrm { A D J } \left( c , c ^ { \prime } \right)$ , they lack the expressive capacity when the relations are represented with atoms like $\operatorname { A r } ( x , y )$ , $ { \mathrm { A D J } _ { 1 } } ( x , x ^ { \prime } )$ , and $\mathrm { A D J _ { 2 } } ( y , y ^ { \prime } )$ . Similarly, these methods are unable to learn policies for classical benchmark domains such as Logistics and Grid, that require composition of binary relations, which is beyond the scope of $C _ { 2 }$ (Sta˚hlberg, Bonet, and Geffner 2022b, 2023).

In principle, this limitation can be addressed by using richer grammars to generate non- $C _ { 2 }$ features, in the logical setting, or by using $k$ -GNNs, with $k = 3$ , on the neural setting, where triplets of objects are embedded instead of individual objects (Morris et al. 2019). It is known that 3-GNNs have the expressive power of $C _ { 3 }$ logic, unlike the $C _ { 2 }$ expressive power of 1- and 2-GNNs (Grohe 2021). Yet 3-GNNs do not scale up as they require cubic number of embeddings, and quartic time for exchanging messages.

In this paper, we introduce an alternative, parameterized version of Relational GNNs (R-GNNs). R-GNNs are designed to perform computation over relational structures, unlike GNNs that can only process graphs. The architecture for $\mathbf { R - G N N } [ t ]$ mirrors that of plain R-GNNs and differs only in the input. While a plain R-GNNs takes the set of atoms $S$ representing a planning state as input, $\mathbf { R - G N N } [ t ]$ accepts a transformed set of atoms $A _ { t } ( S )$ instead. At $t = 0$ , $\mathbf { R - G N N } [ t ]$ approximates 3-GNNs weakly, while at $t = \infty$ , it offers a strong approximation. Thus, the parameter $t$ serves to balance expressive power with computational effort. Crucially, for lower values of $t$ , such as $t = 1$ and $t = 2$ , $\mathbf { R - G N N } [ t ]$ ’s message passing runs in quadratic time in general while capturing the $C _ { 3 }$ features that are essential in several planning domains. Our experiments demonstrate that $\mathbf { R - G N N } [ t ]$ , even with small values of $t$ , is practically feasible and significantly improves both the coverage and the quality of the learned general plans when compared to four baselines: plain R-GNN, 2-GNN, $\mathrm { R - G N N _ { 2 } }$ , and Edge-Transformers (Bergen, O’Donnell, and Bahdanau 2021), where the last two aim to approximate 3- GNNs (Bergen, O’Donnell, and Bahdanau 2021) more accurately than $\mathbf { R - G N N } [ t ]$ .

The rest of the paper is organized as follows. We review first related work and background on planning, generalized planning, GNNs and relational GNNs, and the WeisfeilerLeman coloring algorithms. Then we introduce the parametric R-GNNs, the learning task and baselines, and the experimental results. The paper ends with a discussion on the expressivity of the model, and conclusions.

# Related Work

General policies from logic. The problem of learning general policies has a long history (Khardon 1999; Mart´ın and Geffner 2004; Fern, Yoon, and Givan 2006), and general policies have been formulated in terms of logic (Srivastava, Immerman, and Zilberstein 2011; Illanes and McIlraith 2019), regression (Boutilier, Reiter, and Price 2001; Wang, Joshi, and Khardon 2008; Sanner and Boutilier 2009), and policy rules (Bonet and Geffner 2018; Bonet, France\`s, and Geffner 2019) that can be learned (Franc\`es, Bonet, and Geffner 2021; Drexler, Seipp, and Geffner 2022).

General policies from neural nets. Deep learning (DL) and deep reinforcement learning (DRL) (Sutton and Barto 1998; Bertsekas 1995; Franc¸ois-Lavet et al. 2018) have been used to learn general policies (Kirk et al. 2023). In some cases, the planning representation of the domains is used (Toyer et al. 2020; Bajpai, Garg et al. 2018; Rivlin, Hazan, and Karpas 2020); in most cases, it is not (Groshev et al. 2018; Chevalier-Boisvert et al. 2019), and in practically all cases, the neural networks are GNNs or variants. Closest to our work is the use of GNNs for learning general policies for classical planning (Sta˚hlberg, Bonet, and Geffner, 2022b; 2023).

GNNs, R-GNNs, and $C _ { k }$ logics. The use of GNNs is common when learning general policies where the number of objects change from instance to instance. This is because GNNs trained with small graphs can be used for dealing with larger graphs (Scarselli et al. 2009; Gilmer et al. 2017; Hamilton 2020), and because states in classical planning are closely related to graphs: they represent relational structures that become graphs when there is a single nonunary relation that is binary and symmetric. In such a case, the graph vertices stand for the objects and the edges for the relation. Relational GNNs extend GNNs to relational structures (Schlichtkrull et al. 2018; Vashishth et al. 2019; Barcelo et al. 2022), and our R-GNNs borrow from those used for max-CSP (Toenshoff et al. 2021) and generalized planning (Sta˚hlberg, Bonet, and Geffner 2022a).

There is a tight correspondence between the classes of graphs that can be distinguished by GNN, the WL procedure (Morris et al. 2019; Xu et al. 2019), and $C _ { 2 }$ logic (Cai, Fu¨rer, and Immerman 1992; Barcelo´ et al. 2020; Grohe 2021). The expressive power of GNNs can be extended by replacing graph vertices by tuples of $k$ -vertices. The resulting $k$ -GNNs have the the power of the $k$ -WL coloring algorithm, and hence the expressivity of $C _ { k }$ for $k > 2$ . The “folklore” variant of the $k$ -WL algorithm, $k$ -FWL (Cai, Fu¨rer, and Immerman 1992), is more efficient as it has the power of $\left( k { + } 1 \right)$ -WL while using $\mathcal { O } ( n ^ { k } )$ memory. Maron et al. (2019b) define a parameterized family of permutation-invariant neural networks, which for $k = 2$ has the expressiveness of 3- GNNs (Maron et al. 2019a). In the experiments, we consider a baseline based on Edge Transformers that has the same expressiveness (Bergen, O’Donnell, and Bahdanau 2021).

# Background

We review planning, generalized planning, GNNs, relational GNNs, and the Weisfeiler-Leman graph coloring algorithms.

# Planning and Generalized Planning

A classical planning problem is a pair $P = \langle D , I \rangle$ , where $D$ represents a first-order domain and $I$ contains information specific to the problem instance (Ghallab, Nau, and Traverso 2004; Geffner and Bonet 2013; Haslum et al. 2019). The domain $D$ mainly consists of two components: a set of predicate symbols, and a set of action schemas. The action schemas come with preconditions and effects expressed with atoms $p ( x _ { 1 } , x _ { 2 } , \ldots , x _ { k } )$ where $p$ is a predicate symbol (also called domain predicate) of arity $k$ , and each term $x _ { i }$ is a schema argument. An instance is a tuple $I = \langle O , S _ { I } , G \rangle$ , where $O$ represents a set of object names, $S _ { I }$ is the initial state expressed as a set of ground atoms $p ( o _ { 1 } , o _ { 2 } , \ldots , o _ { k } )$ , where $o _ { i } \in O$ and $p$ is a predicate of arity $k$ , and $G$ is also a set of ground atoms encoding the goal. A problem $P$ compactly defines a transition system over a finite set of states.

A generalized policy $\pi$ for a class $\mathcal { Q }$ of planning instances over the same domain $D$ represents a collection of state transitions $( S , S ^ { \prime } )$ in each instance $P$ of $\mathcal { Q }$ that are said to be in $\pi$ . A $\pi$ -trajectory is a sequence of states $S _ { 0 } , S _ { 1 } , \ldots , S _ { n }$ that starts in the initial state of $P$ and whose transitions $( S _ { i } , S _ { i + 1 } )$ are all in $\pi$ . The trajectory is maximal if $S _ { n }$ is the first goal state of the sequence or there is no transition $( S _ { n } , S )$ in $\pi$ . The policy $\pi$ solves $P$ if all maximal $\pi$ - trajectories in $P$ reach the goal, and it solves $\mathcal { Q }$ if it solves each $P$ in $\mathcal { Q }$ . A policy $\pi$ can be represented in many forms from formulas or rules to general value functions $\dot { V } ( S )$ ; in the latter, the state transitions $( S , S ^ { \prime } )$ in $\pi$ are those that minimize the value $V ( S ^ { \prime } )$ , for the successor states $S ^ { \prime }$ of $S$ .

# Graph Neural Networks (GNNs)

GNNs are parametric functions that operate on graphs (Scarselli et al. 2009; Gilmer et al. 2017; Hamilton 2020). GNNs maintain and update embeddings $f _ { i } ( v ) \in \mathbb R ^ { k }$ for each vertex $v$ in a graph $\dot { G }$ . The process is iteratively performed over $L$ layers, from initial embeddings $f _ { 0 } ( v )$ , and progressing for $i \stackrel { . } { = } 0 , \ldots , L - 1$ :

$$
{ \pmb f } _ { i + 1 } ( v ) = \mathrm { c o m b } _ { i } \left( { \pmb f } _ { i } ( v ) , { \pmb \mathrm { a g g } } _ { i } \left( \left\{ \left\{ { \pmb f } _ { i } ( w ) \ | \ w \in N _ { G } ( v ) \right\} \right\} \right) \right)
$$

Algorithm 1: Relational GNN (R-GNN)   

<html><body><table><tr><td></td><td>1:Input: Set of ground atoms S (state),and objects O 2:Output:Embeddings f,(o) for each objecto ∈ O</td></tr><tr><td></td><td>3:Initialize fo(o)~ Ok for each object o ∈ O</td></tr><tr><td></td><td>4:fori∈{0,...,L-1}do</td></tr><tr><td>5:</td><td>for each atom q := p(O1,O2,...,Om) ∈ S do</td></tr><tr><td>6:</td><td>mq,oj := [MLPp(fi(o1),fi(o2),...,fi(Om))lj</td></tr><tr><td>7: 8:</td><td>end for</td></tr><tr><td>9:</td><td>for each objecto ∈Odo fi+1(o) := fi(o)</td></tr><tr><td>10:</td><td>+MLPu(fi(o),agg({mq,o|o∈q,q∈S}))</td></tr><tr><td>11：</td><td></td></tr><tr><td></td><td>end for</td></tr><tr><td>12:end for</td><td></td></tr><tr><td></td><td></td></tr></table></body></html>

where $\mathsf { a g g } _ { i }$ and $\mathrm { c o m b } _ { i }$ are aggregation and combination functions, respectively, and $\{ \{ \mathbf { } \mathbf { { \bar { f } } } _ { i } ( w ) \mid w \in N _ { G } ( v ) \} \}$ is the multiset of embeddings ${ f } _ { i } ( w )$ for the neighboring vertices $w$ of $v$ in the graph $G$ . The aggregation functions ${ \tt a g g } _ { i }$ (e.g., max, sum, or smooth-max) condense multiple vectors into a single vector, whereas the combination functions $\mathrm { c o m b } _ { i }$ merge pairs of vectors. The function implemented by GNNs is well defined for graphs of any size, and invariant, under (graph) isomorphisms, for permutation-invariant aggregation functions. The aggregation and combination functions are parametric, allowing the vertex embeddings $f _ { i } ( \cdot )$ to be learnable functions.

# Relational GNNs (R-GNNs)

GNNs operate over graphs, whereas planning states are relational structures over predicates of varying arities. The Relational GNN (R-GNN) for processing relational structures (Sta˚hlberg, Bonet, and Geffner 2022a) is inspired by those used for max-CSPs (Toenshoff et al. 2021). Like GNNs, RGNNs is a message-passing architecture where messages are exchanged between the objects in the input relational structure $\mathcal { A }$ , but the messages are not directly associated with edges. Instead, messages are exchanged according to the atoms that are true in the structure. That is, initial embeddings $f _ { 0 } ( o )$ for each object $o$ in $\mathcal { A }$ are updated as follows:

$\pmb { f } _ { i + 1 } ( o ) = \mathrm { c o m b } _ { i } \left( \pmb { f } _ { i } ( o ) , \mathsf { a g g } _ { i } \left( \left\{ \pmb { m } _ { q , o } \ | \ o \in q , \pmb { A } \Vdash q \right\} \right) \right) ,$ (2) where $m _ { q , o }$ is the message that atom $q$ (that is true in the relational structure $\mathcal { A }$ , and that mentions object $\dot { o }$ ) sends to object $o$ . For a $m$ -ary predicate $p$ , an atom of the form $q = { \bar { p ( } } o _ { 1 } , o _ { 2 } , \ldots , o _ { m } )$ sends $m$ (non-necessarily equal) messages to the objects ${ } ^ { ) } 1 , o _ { 2 } , \ldots , o _ { m }$ , respectively. All such messages are computed (in parallel) using a learnable combination function $\mathrm { c o m b } _ { p } ( \cdot ) ^ { \bullet }$ , one for each symbol $p$ , that maps $m$ input embeddings into $m$ output messages:

$$
\begin{array} { r } { { m _ { q , o _ { j } } } = \left[ { \operatorname { c o m b } _ { p } } \left( \pmb { f } _ { i } ( o _ { 1 } ) , \pmb { f } _ { i } ( o _ { 2 } ) , \ldots , \pmb { f } _ { i } ( o _ { m } ) \right) \right] _ { j } , } \end{array}
$$

where $[ \ldots ] _ { j }$ refers to the $j$ -th embedding of its argument. The $\mathrm { c o m b } _ { i } \bar { ( \cdot ) }$ function in (2) merges two vectors of size $k$ , the current embedding $\pmb { f } _ { i } ( o )$ and the aggregation of the messages received at object $o$ .

The relational neural network for planning states $S$ is detailed in Algorithm 1, where the update for the embeddings in (2) is implemented via residual connections. In our implementation, the aggregation function $\arg \mathrm { { g } } ( \cdot )$ is smooth maximum that approximates the (component-wise) maximum.

The combination functions are implemented using MLPs. The functions $\mathrm { c o m b } _ { i } ( \cdot )$ correspond to the same $\mathbf { M L P } _ { U }$ that maps two real vectors in $\mathbb { R } ^ { k }$ into a vector in $\mathbb { R } ^ { k }$ , while $\mathrm { c o m b } _ { p } ( \cdot )$ , for a predicate $p$ of arity $m$ , is an ${ \mathrm { M L P } } _ { p }$ that maps $m$ vectors in $\mathbb { R } ^ { k }$ into $m$ vectors in $\mathbb { R } ^ { k }$ . In all cases, each MLP has three parts: first, a linear layer; next, the Mish activation function (Misra 2020); and then another linear layer. The architecture in Algorithm 1 requires two inputs: a set of atoms denoted as $S$ , and a set of objects denoted as $O$ . The goal $G$ is encoded by goal atoms that are assumed to be in $S$ : if $p ( o _ { 1 } , o _ { 2 } , \ldots , o _ { m } )$ is an atom in $G$ , the atom $p _ { g } ( o _ { 1 } , o _ { 2 } , \ldots , o _ { m } )$ is added to $S$ , where $p _ { g }$ is a new “goal predicate” (Mart´ın and Geffner 2004).

The set of object embeddings $f _ { L } ( \overset { \cdot } { o } )$ at the last layer is the result of the net; i.e., $\mathrm { R - G N N } ( S , O ) = \left\{ \left\{ \mathbf { } f _ { L } ( o ) \mathrm { ~ } | \mathrm { ~ } o \mathrm { ~ } \in O \right\} \right\}$ . Such embeddings are used to encode general value functions, policies, or both. In this work, we encode a learnable value function $V ( S )$ through a simple additive readout that feeds the embeddings into a final MLP:

$$
\begin{array} { r } { V ( S ) = \mathrm { M L P } \big ( \sum _ { o \in O } \pmb { f } _ { L } ( o ) \big ) . } \end{array}
$$

# Weisfeiler-Leman Coloring Algorithms

Weisfeiler-Leman (WL) coloring algorithms provide the theory for establishing the expressive limitation of GNNs. These algorithms iteratively color each vertex of a graph, or each $k$ -tuple of vertices, based on the colors of their neighbors, until a fixed point is reached. Colors, represented as natural numbers, are generated with a RELABEL function that maps structures over colors into unique colors. We borrow notation and terminology from Morris et al. (2023).

1-Dimensional WL (1-WL). For a graph $G = ( V , E )$ , the node coloring $C _ { i + 1 } ^ { 1 }$ at iteration $i$ is defined as:

$$
C _ { i + 1 } ^ { 1 } ( v ) = \mathrm { R E L A B E L } \big ( \big \langle C _ { i } ^ { 1 } ( v ) , \big \ S \big \{ C _ { i } ^ { 1 } ( u ) \ | \ u \in N ( v ) \big \} \big \rangle \big )
$$

where $N ( v )$ is the neighborhood of node $v$ , and the initial coloring is determined by the given vertex colors, if any, or uniform otherwise.

Folklore $k$ -Dimensional WL ( $k$ -FWL). For a graph $G$ and tuple $\langle v \rangle \in V ( G ) ^ { k }$ , the coloring $C _ { i + 1 } ^ { k }$ at iteration $i$ is:

$$
C _ { i + 1 } ^ { k } \big ( \langle v \rangle \big ) = \mathrm { R E L A B E L } \big ( \big \langle C _ { i } ^ { k } \big ( \langle v \rangle \big ) , M _ { i } \big ( \langle v \rangle \big ) \big \rangle \big )
$$

where $M _ { i } ( \langle v \rangle )$ is the multiset of tuples

$$
\begin{array} { c } { { M _ { i } (  v  ) = \{ \} ( C _ { i } ^ { k } { ( \phi _ { 1 } (  v  , w ) ) } , \ldots ,  } } \\ { {  C _ { i } ^ { k } { ( \phi _ { k } (  v  , w ) ) } ) \mid w \in V ( G ) \} \mathrm { , } } } \end{array}
$$

the function $\phi _ { j } ( \langle v \rangle , w )$ replaces the $j$ -th component of the tuple $\left. v \right.$ with the node $w$ , and the initial color for tuple $\left. v \right.$ is determined by the structure of the subgraph induced by $\left. v \right.$ , and the order of the vertices in the tuple $\left. v \right.$ .

Oblivious $k$ -Dimensional WL ( $k$ -OWL). The coloring $C _ { i + 1 } ^ { k * }$ for the $k$ -OWL variant at iteration $i$ is defined as:

$$
C _ { i + 1 } ^ { k * } \bigl ( \langle v \rangle \bigr ) = \mathrm { R E L A B E L } \bigl ( \bigl \langle C _ { i } ^ { k * } ( \langle v \rangle ) , M _ { i } ^ { * } ( \langle v \rangle ) \bigr \rangle \bigr )
$$

where the multiset $M _ { i } ( \langle v \rangle )$ of vectors in $k$ -FWL is replaced by a $k$ -dimensional vector $\mathbf { \widetilde { \mathit { M } } } _ { i } ^ { * } ( \langle v \rangle )$ of multisets:

$$
\left[ M _ { i } ^ { * } ( \langle v \rangle ) \right] _ { j } = \big \{ { C } _ { i } ^ { k * } ( \phi _ { j } ( \langle v \rangle , w ) ) \ | \ w \in V ( G ) \big \} \big \}
$$

for $j = 1 , 2 , \dots , k$ , where $\phi _ { j } ( \langle v \rangle , w )$ is the same function as in $k$ -FWL, and the initial coloring $M _ { 0 } ^ { * } ( \langle v \rangle )$ is also the same.

For a tuple $\left. v \right.$ of $k$ vertices, there are potentially $k \cdot n$ neighbor-tuples resulting from replacing each $j$ -th component $v _ { j }$ of $\left. v \right.$ with each of the $n$ nodes in the graph, for $j = 1 , 2 , \dots , k$ . The key difference between $k$ -FWL and $k$ - OWL lies in how these $k \cdot n$ tuples are grouped to determine the new color of $\left. v \right.$ . In $k$ -FWL, the tuple $\left. v \right.$ “sees” a multiset of $n$ vectors, each with $k$ colors, resulting from replacing $v _ { j }$ with $w$ for each $j$ from 1 to $k$ , providing one such vector or “context” for each node $w$ in the graph. In contrast, in $k$ - OWL, the tuple $\left. v \right.$ “sees” a $k$ -vector whose elements $\langle v \rangle _ { j }$ are multisets of $n$ colors, with the $j$ component $v _ { j }$ of $\langle v \rangle$ replaced by each of the $n$ nodes in the graph. In $k$ -OWL, the “contexts” mentioned above are broken, hence the method is termed “oblivious” as it is oblivious to such contexts.

2-FWL vs. 2-OWL. The case for $k = 2$ clearly illustrates the difference between the two algorithms. For a graph $G = ( V , E )$ and coloring $C$ , the context for the pair $\mathbf { \bar { \langle } } u , v \mathbf { \rangle }$ considered by 2-FWL is

$$
M ( \langle u , v \rangle ) = \{ ( C ( \langle w , v \rangle ) , C ( \langle u , w \rangle ) ) | w \in V \} \} .
$$

It considers pairs of tuples $\langle u , w \rangle$ and $\langle w , v \rangle$ whose “join” results in $\langle u , v \rangle$ . On the other hand, the context considered by 2-OWL is

$$
\begin{array} { r } { M ^ { * } ( \langle u , v \rangle ) = \big ( \big \{ \big \{ C ( \langle w , v \rangle ) | w \in V \big \} \big \} , \big \{ \big \{ C ( \langle u , w \rangle ) | w \in V \big \} \big \} \big ) . } \end{array}
$$

It is clear the “loss of information” suffered by 2-OWL with respect to 2-FWL as the context $M ^ { * } ( \langle u , v \rangle )$ can be recovered from $M ( \langle u , v \rangle )$ , but not the other way around.

Expressive power. Cai, Fu¨rer, and Immerman (1992) established that two graphs are indistinguishable by $k$ -FWL if and only if they satisfy the same set of formulas in the logic $C _ { k + 1 }$ . In terms of expressive power, 1-OWL is equivalent to 2-OWL, $k$ -OWL is strictly more expressive than $( k - 1 )$ - $\mathrm { O W L }$ , for $k \geq 3$ , and $k$ -OWL has the same expressiveness as $( k - 1 )$ -FWL, for $k \geq 2$ . More importantly, the discriminative power of $C _ { 3 }$ can be achieved either by using 3-OWL over triplets in cubic space, or by using 2-FWL over pairs in quadratic space.

# Parametric Extended R-GNN: $\mathbf { R } { \mathbf { - G N N } } [ t ]$

The new architecture extends the expressive power of RGNNs beyond $C _ { 2 }$ by capitalizing the relational component of R-GNNs, outlined in Algorithm 1. Indeed, the function computed by the new architecture, $\mathrm { R - G N N } [ t ] ( S , O )$ , where $t$ is a non-negative integer parameter, is defined as:

$$
\mathrm { R - G N N } [ t ] ( S , O ) = \mathrm { R - G N N } ( A _ { t } ( S ) , O ^ { 2 } )
$$

where $O ^ { 2 } = O \times O$ stands for the pairs $\langle o , o ^ { \prime } \rangle$ of objects in $O$ , and $A _ { t } ( S )$ stands for a transformation of the atoms in $S$ that depends on the parameter $t$ . Specifically, if $w = \langle o _ { 1 } , o _ { 2 } , \dots , o _ { m } \rangle$ is a tuple of objects, $\langle w \rangle ^ { \bar { 2 } }$ refers to the tuple of $m ^ { 2 }$ pairs obtained from $w$ as:

$$
\left. w \right. ^ { 2 } = \left. { \left( o _ { 1 } , o _ { 1 } \right) , \ldots , \left( o _ { 1 } , o _ { m } \right) , \ldots , \left( o _ { m } , o _ { 1 } \right) , \ldots , \left( o _ { m } , o _ { m } \right) } \right.
$$

Then, for $t = 0$ , the set of atoms $A _ { t } ( S )$ is:

$$
A _ { 0 } ( S ) = \{ p ( \langle w \rangle ^ { 2 } ) \mid p ( w ) \in S \} .
$$

That is, predicates $p$ of arity $m$ in $S$ transform into predicates $p$ of arity $m ^ { 2 }$ in $A _ { 0 } ( S )$ , and each atom $p ( w )$ in $S$ is mapped to the atom $p ( \langle w \rangle ^ { 2 } )$ .

For $t > 0$ , the set of atoms $A _ { t } ( S )$ extends $A _ { 0 } ( S )$ with atoms for a new ternary predicate $\bigtriangleup$ as: $A _ { t } ( S ) = \dot { A } _ { 0 } ( S ) \cup$ $\Delta _ { t } ( S )$ where

$$
\Delta _ { t } ( S ) = \left\{ \triangle ( \langle o , o ^ { \prime } \rangle , \langle o ^ { \prime } , o ^ { \prime \prime } \rangle , \langle o , o ^ { \prime \prime } \rangle ) \mid \langle o , o ^ { \prime } \rangle , \langle o ^ { \prime } , o ^ { \prime \prime } \rangle \in R _ { t } \right\} ,
$$

and the binary relation $R _ { t }$ is defined from $S$ and $G$ as:

$$
\langle o , o ^ { \prime } \rangle \in R _ { t } { \mathrm { ~ i f f ~ } } \left\{ { o \mathrm { ~ a n d ~ } } o ^ { \prime } { \mathrm { ~ a r e ~ b o t h ~ i n ~ a n ~ a t o m ~ i n ~ } } S \quad { \mathrm { i f ~ } } t = 1 , \right.
$$

In words, for the R-GNN to emulate a relational version of 2-FWL, two things are needed. First, object pairs need to be embedded. This is achieved by replacing the atoms in $\boldsymbol { S }$ with the atoms in $A _ { 0 } ( S )$ whose arguments are object pairs. Second, object pairs $\langle o , o ^ { \prime } \rangle$ need to receive and aggregate messages from object triplets, the “contexts” in 2-FWL, which are formed by vectors of pairs $\left. o , o ^ { \prime \prime } \right.$ and $\left. { { o ^ { \prime \prime } } , o ^ { \prime } } \right.$ . This interaction is captured through the new atoms $\dot { \bigtriangleup } ( \langle o , \dot { o } ^ { \prime \prime } \rangle , \langle o ^ { \prime \prime } , o ^ { \prime } \rangle , \langle o , o ^ { \prime } \rangle )$ and the associated $\mathbf { M L P } _ { \triangle }$ . The relational GNN architecture in Algorithm 1 allows each argument to communicate with every other argument in the context of a third one, with messages that depend on all the arguments. This is similar to the “triangulation” found in the Edge Transformer. But, rather than adding all possible $\triangle ( \langle o , \bar { o } ^ { \prime \prime } \rangle , \langle o ^ { \prime \prime } , o ^ { \prime } \rangle , \langle o , o ^ { \prime } \rangle )$ atoms to $A _ { 0 } ( S )$ , the atoms are added in a controlled manner using the parameter $t$ to avoid a cubic number of messages to be exchanged. The parameter $t$ controls the maximum number of sequential compositions that can be captured. In problems that require a single composition, a value of $t = 1$ suffices to yield the necessary $C _ { 3 }$ features without having to specify which relations need to be composed. Moreover, all this is achieved by simply changing the input from $\langle S , O \rangle$ to $\langle A _ { t } ( S ) , O ^ { 2 } \rangle$ .

The final embeddings produced by $\mathbf { \tilde { R } - G N N } [ t ]$ are then used to define a general value function $V ( S )$ as

$$
\begin{array} { r } { V ( S ) = \mathrm { M L P } \big ( \sum _ { o \in O } { f _ { L } ( \langle o , o \rangle ) } \big ) , } \end{array}
$$

where the readout only takes the final embeddings for object pairs $\langle o , o \rangle$ that represent single objects, and passes their sum to an MLP that outputs the scalar $V ( S )$ . The reason is to avoid summing the embeddings for all pairs $\langle o , o ^ { \prime } \rangle$ as it leads to high variance, and a more difficult learning.

Since $\mathbf { R - G N N } [ t ]$ is a regular R-GNN over a transformed input, the objects in a R-GNN are indistinguishable a priori, and the readout function only considers pairs of type $\langle o , o \rangle$ , some way to make such pairs different from others must be incorporated so that the message passing mechanism learns where to send the information for the readout. This is automatically achieved by adding static atoms ${ \mathrm { O B J } } ( o )$ , for each object $o$ , for a new static unary predicate OBJ. Such atoms are then transformed into atoms $\mathrm { O B J } \big ( \langle o , o \rangle \big )$ in $A _ { 0 } ( S )$ that mark the pairs $\langle o , o \rangle$ as different from other pairs $\left. o , o ^ { \prime } \right.$ .

# Learning Task

We aim at extending the expressivity of R-GNNs for finding policies for generalized planning. For this purpose, for each domain in the benchmark, we learn a general value function $V$ in a supervised manner from the optimal values $V ^ { * } ( S )$ over a small collection of training states $S$ . Such states $S$ belong to planning instances with small state spaces which makes the computation of $V ^ { * }$ straightforward with a standard breadth-first search. The loss function that is minimized during training is:

$$
L ( S ) = \left| V ^ { * } ( S ) - V ( S ) \right| .
$$

Additionally, batches for training are created containing as many distinct $V ^ { * }$ values as possible. This can be done as the $V ^ { * }$ values for the states in the training set are pre-computed.

# Baselines

We compare the new “architecture” $\mathbf { R - G N N } [ t ]$ with four baseline architectures: (plain) R-GNN, Edge Transformers (ETs), $\mathrm { R - G N N _ { 2 } }$ , and 2-GNNs. While ETs and $\mathbf { R } { \mathbf { - G N N _ { 2 } } }$ aim to match the expressive power of 2-FWL and hence $C _ { 3 }$ , 2- GNNs match the expressive power of 2-OWL and hence $C _ { 2 }$ , but embedding also pairs of objects. 3-GNNs are unfeasible in practice given the large number of objects; e.g., with 50 objects, there are 125,000 object triplets.

# Edge Transformers (ETs)

Briefly, ETs are designed to operate on a complete graph with $n$ nodes and $n ^ { 2 }$ directed edges (Bergen, O’Donnell, and Bahdanau 2021). Each edge is embedded as a $k$ -dimensional feature vector. The core computation of an ET layer is described by the equation:

$$
\pmb { f } _ { i + 1 } ( u , v ) = \mathrm { M L P } ( \operatorname { L N } ( \pmb { f } _ { i } ( u , v ) + \operatorname { T r i } . \operatorname { A t t } . ( \operatorname { L N } ( \pmb { f } _ { i } ( u , v ) ) ) ) )
$$

where LN represents layer normalization, and $f _ { i } ( u , v )$ is the feature vector for pair $\langle \dot { u } , v \rangle$ at layer $i$ . A fundamental aspect of ETs is the triangular attention mechanism. This mechanism functions by aggregating information from all pairs of edges that share a common vertex; i.e., for $\langle u , v \rangle$ , it aggregates information from the pairs $\{ ( \langle u , w \rangle , \langle w , v \rangle ) | w \in V \}$ , like 2-FWL, using a self-attention-based combination of contributions. The expressive power of ETs is the same as for 2-FWL (Mu¨ ller et al. 2024).

Note that, ETs requires that information about true atoms in a state $S$ and goal $G$ to be included in the initial embeddings. This restricts ET to binary relations, and unary predicates are mapped to binary ones by repeating the first term. To encode the state and the goal, we learn two $k$ -dimensional vectors, $e _ { p }$ and $e _ { p _ { g } }$ , for each predicate $p$ . The initial embedding $\boldsymbol { e } _ { o , o ^ { \prime } }$ for the pair $\langle o , o ^ { \prime } \rangle$ is:

$$
\begin{array} { r } { \pmb { e _ { o , o ^ { \prime } } } = \sum _ { p } \big ( \pmb { e _ { p } } \cdot \mathbb { I } p ( o , o ^ { \prime } ) \in S \mathbb { I } ] + \pmb { e _ { p _ { g } } } \cdot \mathbb { I } p ( o , o ^ { \prime } ) \in G \mathbb { I } ] \big ) , } \end{array}
$$

where $\mathbb { I } \mathbb { \cdot } \mathbb { I }$ is the Iverson bracket.

These initial embeddings encode the state and the goal in a way that is suitable for the network. For the value function, we use the same readout function as for $\mathbf { R - G N N } [ t ]$ in all baselines, which aggregates the final embeddings for pairs of identical objects and feeds the resulting vector into an MLP; cf. (15). Hence, the number of embeddings aggregated in the final readout is the same for R-GNN, $\mathbf { R - G N N } [ t ]$ , and ET.

![](images/56387c37d595b1116188383a3c625c4b84328dd1c0526a41a3544b93d4c6085f.jpg)  
Figure 1: Two $8 \times 4$ test instances of the Navig-xy domain where the robot has to reach the green cell in a grid with obstacles, and where the objects are the values of each one of the two coordinates, and not the cells themselves. The problem is not in $C _ { 2 }$ in this representation, and indeed, after training, the baseline R-GNN solves the instance on the left but not the one on the right, while $\mathbf { R - G N N } [ t ]$ , for $t = 1$ , solves all the instances in the test set.

# $\mathbf { R { \mathbf { - G N N } } _ { 2 } }$

The final two baselines are our own. Rather than selectively adding $\bigtriangleup$ atoms, as in $\mathbf { R - G N N } [ t ]$ , we introduce these atoms based on the object pairs rather than the state and the goal. For this baseline, we aim to emulate 2-FWL by augmenting the input with all possible atoms of the form:

$$
\triangle ( \langle o , o ^ { \prime } \rangle , \langle o ^ { \prime } , o ^ { \prime \prime } \rangle , \langle o , o ^ { \prime \prime } \rangle ) ,
$$

where each atom encodes a composition of two object pairs. This approach is similar to $\mathbf { R - G N N } [ t ]$ , but also ET. In all three, expressivity beyond $C _ { 2 }$ is achieved through a “triangulation” mechanism specifically designed to mirror the 2- FWL procedure. In WL terms, both ETs and $\mathrm { R - G N N _ { 2 } }$ maintain the “context” of triplets, thereby achieving greater expressiveness.

# 2-GNNs

The other baseline is designed to emulate 2-OWL instead of 2-FWL. This allows us to test whether the performance improvement is due to the object pairs themselves rather than to the additional atoms. In 2-OWL, the color $C _ { i + 1 } ( \langle u , v \rangle )$ of a pair $\langle u , v \rangle$ is determined based on the color $C _ { i } ( \langle u , v \rangle )$ and the multisets $\left\{ \left\{ C _ { i } ( \left. w , v \right. ) \mid w \in V \right\} \right\}$ and $\left\{ \left. C _ { i } ( \left. u , w \right. ) \ : \middle | w \in V \right\} \right\}$ . This is emulated by introducing two binary predicates, $p _ { 1 }$ and $p _ { 2 }$ to represent these multisets. The ground atoms that determine which pair communicates are all possible atoms with one of the following forms:

$$
\begin{array} { r } { p _ { 1 } ( \langle w , v \rangle , \langle u , v \rangle ) } \\ { p _ { 2 } ( \langle u , w \rangle , \langle u , v \rangle ) } \end{array}
$$

The initial embeddings encode the state and goal using the same approach described for the ET baseline.

# Example: Grid Navigation with Obstacles

We illustrate the expressivity demands on a simple example and how these demands are met by the different architectures. We call the domain Navig-xy and two instances are shown in Figure 1. In this domain, a robot has to reach the goal (green) cell in a $n \times m$ grid with blocked cells, that is represented with $n + m$ objects in $X \cup Y$ , where $X = \{ x _ { 1 } , \ldots , x _ { n } \}$ and $Y = \{ y _ { 1 } , \dots , y _ { m } \}$ , and successor relations SUCC-X and SUCC-Y. The domain also includes the binary relations $\mathbf { A } \mathbf { T } ( x , y )$ to specify the initial and goal cells, $\mathbf { B L O C K E D } ( x , y )$ to specify the cells that are blocked, and a dummy CELL $( x , y )$ to identify the cells in the grid, for $x \in X$ and $y \in Y$ .

Under the experimental settings described below and 12 hours of training over 105 random $n \times m$ solvable instances, with $n m < 3 0$ , policies strictly greedy in the learned value function $V$ achieve coverages of $5 9 . 7 2 \%$ , $8 0 . 5 5 \%$ , and $100 \%$ for the baseline R-GNN, R-GNN[0], and R-GNN[1], respectively, on instances with different sets of blocked cells and up to a slightly larger size nm $\leq \ 3 2$ . The ET performs poorly and achieves $4 . 1 6 \%$ of coverage. The instances are not difficult as there is just one free path to the goal on which the robot just has to keep moving forward, but when the value function is wrong, it can drive the robot backwards creating a cycle.

The explanation for the coverage results is simple. For computing the true distance to the goal in these grids, emulating a shortest path algorithm, each cell $( x , y )$ in the grid must be able to communicate with each of its neighbor cells $( x , y ^ { \prime } )$ and $( x ^ { \prime } , y )$ . In the R-GNN architecture captured by Alg. 1, this means that there must be atoms involving the three objects $x , y$ , and $y ^ { \prime }$ , and similarly, $x , x ^ { \prime }$ , and $y$ . There are no such atoms in the state $S$ , except in $\mathbf { R - G N N } [ t ]$ , for $t \geq 1$ , where $A _ { t } ( S )$ includes the composition atoms $\triangle ( ( x , x ^ { \prime } ) , ( x ^ { \prime } , y ) , ( x , y ) )$ and $\triangle ( ( x , y ) , ( y , \bar { y ^ { \prime } } ) , ( x , y ^ { \prime } ) )$ . As a result, R-GNN[1] and R-GNN[2] can compute the true distances, while R-GNN[0] and R-GNN can only compute “Manhattan distances”, that in some cases (e.g., the left grid in Fig. 1) are good or perfect approximations of $V ^ { \ast } ( s )$ .

# Experiments

A learned value function $V$ , for a domain, defines a general policy $\pi _ { V }$ that at state $S$ selects an unvisited successor state $S ^ { \prime }$ with lowest $V ( S ^ { \prime } )$ value. We test such policies on instances until reaching a goal state, executing 1000 steps, or reaching a state with no unvisited successors. Reaching a goal is counted as a success, else as a failure.

For learning value functions, we implemented the architectures in PyTorch, and trained the models on NVIDIA A10 GPUs with $2 4 \ \mathrm { G B }$ of memory over 12 hours, using Adam (Kingma and Ba 2015) with a learning rate of 0.0002, batches of size 16, and without applying any regularization loss.1 For each domain, a total of three models were trained, and the model with the lowest loss on the validation set was selected as the final model. We used embedding dimension $k = 6 4$ , $L = 3 0$ layers for R-GNN, $\mathbf { R - G N N } [ t ]$ and the ETs. For $\mathbf { R - G N N _ { 2 } }$ , we used $k = 3 2$ to avoid running out of memory during training. In all approaches, all layers share weights, and the ETs have 8 self-attention heads.

Inference time depends on the size of the net, but it is typically in the order of tens of milliseconds. The time to decide which successor to take is the number of successor states multiplied by this time.

# Domains

Brief descriptions of the domains used in the experiments, mostly taken from Sta˚hlberg, Bonet, and Geffner (2022a;

2022b; 2023), follow. In all cases, the instances in the training set are small, while those in the test set are significantly larger as they contain more objects.

Blocks. In Blocks-s (resp. Blocks-m), a single tower (resp. multiple towers) must be built. Both have training and validation sets with 4 to 9 blocks. The test set for Blocks-s (resp. Blocks-m) has 10 to 17 blocks (resp. up to 20 blocks).

Grid. The goal is to fetch keys and unlock doors to reach a cell. A generator creates random instances with given layouts. Test instances usually have more keys and locks than those for training and validation, have different layouts, and their state spaces are too big to be fully expanded.

Gripper. A robot with two grippers must move balls from one to another room. The training and validation instances have up to 14 balls, while test instances have 16-50 balls.

Logistics. Transportation domain with packages, cities, trucks, and one airplane. Training and validation instances have 2-5 cities and 3-5 packages, while testing instances have 15-19 cities and 8-11 packages.

Miconic. An elevator must pick and deliver passengers at different floors. Training and validation instances involve 2- 20 floors and 1-10 passengers, while those for testing contain 11-30 floors and 22-60 passengers.

Rovers. The domain simulates planetary missions where a rover must travel to collect soil/rock samples, take pictures, and send information back to base. Training and validation instances use 2-3 rovers and 3-8 waypoints; those for testing have 3 rovers and 21-39 waypoints.

Vacuum. Robot vacuum cleaners that move around and clean different locations. The robots have their own traversal map, so some robots can go between two locations while others cannot. In our version, there is a single dirty location in the middle. The training and validation sets involve 8-38 locations and 1-6 robots. The test set includes 40-93 locations and 6-10 robots.

Visitall. A robot must visit multiple cells in a grid without obstacles. In Visitall-xy, the grid is described with coordinates as in the Navig-xy domain, while in Visitall there is an object for each cell in the grid. Both versions come with training and validation sets with up to 21 locations, while the test set includes strictly more, up to 100 cells.

# Results

Tables 1 and 2 show the results. We anticipate that the improved expressiveness of the networks will result in:

Maintaining performance levels on $C _ { 2 }$ domains; and Achieving broader coverage on $C _ { 3 + }$ domains, or Generating plans of superior quality.

These expections are mostly confirmed by the experiments. The coverage results for $\mathbf { R - G N N } [ t = 0 , 1 ]$ on $C _ { 2 }$ domains, as seen in Table 1, remain consistent with R-GNN, with plan quality largely unchanged. Just in one case, Gripper, increasing the parameter $t$ from 0 to 1 leads to a decline in coverage for $\mathbf { R - G N N } [ t ]$ . We attribute this to the high volume of messages that are exchanged, which slows down training and may result in incomplete convergence. The plan quality across all approaches is comparable for the $C _ { 2 }$ domains, except in the Gripper domain, where R-GNN produces longer plans. This is not due to a lack of expressiveness; rather, we believe that the additional expressiveness provided by the other approaches result in a more stable general policy.

Table 1: Coverage and plan lengths for $C _ { 2 }$ domains. In these domains, R-GNNs performs best, and R-GNN[1] is competitive, except in Gripper.   

<html><body><table><tr><td rowspan="2">Domain</td><td rowspan="2">Model Coverage (%)</td><td rowspan="2"></td><td colspan="3">Plan Length</td></tr><tr><td>Total</td><td>Median</td><td>Mean</td></tr><tr><td rowspan="6">Blocks-s</td><td>R-GNN</td><td>17/17 (100 %)</td><td>674</td><td>38</td><td>39</td></tr><tr><td>R-GNN[0]</td><td>17 /17 (100 %)</td><td>670</td><td>36</td><td>39</td></tr><tr><td>R-GNN[1]</td><td>17 /17 (100 %)</td><td>684</td><td>36</td><td>40</td></tr><tr><td>R-GNN2</td><td>14/17 (82 %)</td><td>922</td><td>35</td><td>65</td></tr><tr><td>2-GNN</td><td>17 /17 (100 %)</td><td>678</td><td>36</td><td>39</td></tr><tr><td>ET</td><td>16 /17 (94 %)</td><td>826</td><td>38</td><td>51</td></tr><tr><td rowspan="6">Blocks-m</td><td>R-GNN</td><td>22/22 (100 %)</td><td>868</td><td>40</td><td>39</td></tr><tr><td>R-GNN[0]</td><td>22/22(100 %)</td><td>830</td><td>39</td><td>37</td></tr><tr><td>R-GNN[1]</td><td>22/22 (100 %)</td><td>834</td><td>39</td><td>37</td></tr><tr><td>R-GNN2</td><td>22 /22 (100 %)</td><td>936</td><td>39</td><td>42</td></tr><tr><td>2-GNN</td><td>20 /22 (91 %)</td><td>750</td><td>40</td><td>37</td></tr><tr><td>ET</td><td>18/22 (82 %)</td><td>966</td><td>39</td><td>53</td></tr><tr><td rowspan="6">Gripper</td><td>R-GNN</td><td>18 /18 (100 %)</td><td>4,800</td><td>231</td><td>266</td></tr><tr><td>R-GNN[0]</td><td>18 /18 (100 %)</td><td>1,764</td><td>98</td><td>98</td></tr><tr><td>R-GNN[1]</td><td>11/18 (61 %)</td><td>847</td><td>77</td><td>77</td></tr><tr><td>R-GNN2</td><td>18 /18 (100 %)</td><td>1,764</td><td>98</td><td>98</td></tr><tr><td>2-GNN</td><td>1/18 (6 %)</td><td>53</td><td>53</td><td>53</td></tr><tr><td>ET</td><td>4/18 (22 %)</td><td>246</td><td>61</td><td>61</td></tr><tr><td rowspan="6">Miconic</td><td>R-GNN</td><td>20 /20 (100 %)</td><td>1,342</td><td>67</td><td>67</td></tr><tr><td>R-GNN[0]</td><td>20 /20 (100 %)</td><td>1,566</td><td>71</td><td>78</td></tr><tr><td>R-GNN[1]</td><td>20/20(100 %)</td><td>2,576</td><td>71</td><td>128</td></tr><tr><td>R-GNN2</td><td>20/20 (100 %)</td><td>1,342</td><td>67</td><td>67</td></tr><tr><td>2-GNN</td><td>12 /20 (60 %)</td><td>649</td><td>54.5</td><td>54</td></tr><tr><td>ET</td><td>20/20(100 %)</td><td>1,368</td><td>68</td><td>68</td></tr><tr><td rowspan="6">Visitall</td><td>R-GNN</td><td>18/22 (82 %)</td><td>636</td><td>29</td><td>35</td></tr><tr><td>R-GNN[0]</td><td>21/22 (95 %)</td><td>1,128</td><td>35</td><td>53</td></tr><tr><td>R-GNN[1]</td><td>22/22 (100 %)</td><td>886</td><td>35</td><td>40</td></tr><tr><td>R-GNN2</td><td>20 /22 (91 %)</td><td>739</td><td>33</td><td>36</td></tr><tr><td>2-GNN</td><td>18 /22 (82 %)</td><td>626</td><td>32</td><td>34</td></tr><tr><td>ET</td><td>18 /22 (82 %)</td><td>670</td><td>29</td><td>37</td></tr></table></body></html>

For the $C _ { 3 }$ domains, shown in Table 2, we observe that R-GNN has limited coverage across all domains except Vacuum, where it generates very long plans. The Vacuum domain requires $C _ { 3 }$ expressiveness, as each robot has its own traversal capabilities, necessitating the network to determine which agent is closest relative to their capabilities. While R-GNN achieves high coverage, actions are executed without clear intention, and goal states are reached incidentally. This is reflected in the long plan lengths for R-GNN, whereas other approaches produce optimal or near-optimal plans.

In the other $C _ { 3 }$ domains, R-GNN[1] consistently outperforms R-GNN in coverage due to its increased expressiveness. The performance difference between R-GNN[0] and R-GNN[1] depends on the need for composition. In Grid,

Table 2: Coverage and plan lengths for $C _ { 3 }$ domains. In these domains, R-GNN[1] performs best, but both R-GNN[0] and $\mathrm { R - G N N _ { 2 } }$ outperform R-GNN and ET.   

<html><body><table><tr><td></td><td></td><td></td><td colspan="3">Plan Length</td></tr><tr><td>Domain</td><td>Model</td><td>Coverage (%)</td><td>Total</td><td>Median</td><td>Mean</td></tr><tr><td>Grid</td><td>R-GNN</td><td>9 /20 (45 %)</td><td>109</td><td>11</td><td>12</td></tr><tr><td></td><td>R-GNN[0]</td><td>12/20 (60 %)</td><td>177</td><td>11</td><td>14</td></tr><tr><td></td><td>R-GNN[1]</td><td>15 /20 (75 %)</td><td>209</td><td>13</td><td>13</td></tr><tr><td></td><td>R-GNN2</td><td>10 /20 (50 %)</td><td>124</td><td>11.5</td><td>12</td></tr><tr><td></td><td>2-GNN</td><td>6/20 (30 %)</td><td>82</td><td>11.5</td><td>13</td></tr><tr><td></td><td>ET</td><td>1/20 (5 %)</td><td>15</td><td>15</td><td>15</td></tr><tr><td>Logistics</td><td>R-GNN</td><td>10 /20 (50 %)</td><td>510</td><td>51</td><td>51</td></tr><tr><td></td><td>R-GNN[0]</td><td>9/20 (45 %)</td><td>439</td><td>48</td><td>48</td></tr><tr><td></td><td>R-GNN[1]</td><td>20 /20 (100 %)</td><td>1,057</td><td>52</td><td>52</td></tr><tr><td></td><td>R-GNN2</td><td>15 /20 (75 %)</td><td>799</td><td>52</td><td>53</td></tr><tr><td></td><td>2-GNN</td><td>0 /20 (0 %)</td><td></td><td></td><td></td></tr><tr><td></td><td>ET</td><td>0 /20 (0 %)</td><td></td><td></td><td></td></tr><tr><td>Rovers</td><td>R-GNN</td><td>9 /20 (45 %)</td><td>2,599</td><td>280</td><td>288</td></tr><tr><td></td><td>R-GNN[0]</td><td>14 /20 (70 %)</td><td>2,418</td><td>153</td><td>172</td></tr><tr><td></td><td>R-GNN[1]</td><td>14 /20 (70 %)</td><td>1,654</td><td>55</td><td>118</td></tr><tr><td></td><td>R-GNN2</td><td>11 /20 (55 %)</td><td>2,225</td><td>239</td><td>202</td></tr><tr><td></td><td>2-GNN ET</td><td>Unsuitable domain: ternary predicates</td><td></td><td></td><td></td></tr><tr><td>Vacuum</td><td>R-GNN</td><td>20 /20 (100 %)</td><td>4,317</td><td>141</td><td>215</td></tr><tr><td></td><td>R-GNN[0]</td><td>20 /20 (100 %)</td><td>183</td><td>9</td><td>9</td></tr><tr><td></td><td>R-GNN[1]</td><td>20/20 (100 %)</td><td>192</td><td>9</td><td>9</td></tr><tr><td></td><td>R-GNN2</td><td>20 /20 (100 %)</td><td>226</td><td>9</td><td>11</td></tr><tr><td></td><td>2-GNN</td><td>Unsuitable domain: ternary predicates</td><td></td><td></td><td></td></tr><tr><td>Visitall-xy</td><td>ET</td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>R-GNN</td><td>5 /20 (25 %)</td><td>893</td><td>166</td><td>178</td></tr><tr><td></td><td>R-GNN[0]</td><td>15/20 (75 %)</td><td>1,461</td><td>84</td><td>97</td></tr><tr><td></td><td>R-GNN[1]</td><td>20/20 (100 %)</td><td>1,829</td><td>83</td><td>91</td></tr><tr><td></td><td>R-GNN2</td><td>19 /20 (95 %)</td><td>2,428</td><td>116</td><td>127</td></tr><tr><td></td><td>2-GNN</td><td>12 /20 (60 %)</td><td>1,435</td><td>115</td><td>119</td></tr><tr><td></td><td>ET</td><td>3 /20 (15 %)</td><td>455</td><td>138</td><td>151</td></tr></table></body></html>

Logistics, and Visitall-xy, at least one level of composition is required, and by including these atoms, we observe improved coverage. In Rovers, although the necessity for composition is unclear, the plan quality is significantly improved. Optimal planning in Grid (Helmert 2003) is NPhard, and it seems to be challenging in Rovers as well, and this appears to be the reason why less than $100 \%$ coverage was achieved.

The baseline $\mathbf { R - G N N _ { 2 } }$ surpasses ET in all domains except Blocks-s. We believe this is due to the aggregation function: the output of the softmax in the attention mechanism depend on the number of objects, leading to value magnitudes that differ from those encountered during training. This is not an issue in $\mathrm { R - G N N _ { 2 } }$ , where a smooth maximum is used as an aggregation function. While $\mathrm { R { - } G N N _ { 2 } }$ performs better than R-GNN in $C _ { 3 }$ domains, it underperforms compared to R-GNN[1]. This discrepancy is not due to expressiveness, as $\mathrm { R - G N N _ { 2 } }$ is theoretically more expressive. Rather, it may be easier to identify the relevant compositions since R-GNN[1] has far fewer compositions in its input.

The baseline 2-GNN consistently performs worse than R-GNN[0] in our experiments, even though both models use object pairs and do not derive compositions. This disparity is likely due to the reduced volume of messages passed in R-GNN[0], which allows for clearer messages. Additionally, each message in R-GNN[0] is computed using MLPs tailored to the predicate symbols of the atoms, leading to more inductive bias and thus better generalization.

# On the Expressivity of the Model

We establish next that the $\mathbf { R - G N N } [ t ]$ model has the capability to capture compositions of binary relations that can be expressed in $C _ { 3 }$ . This capability is critical in many domains, and can be achieved by adding derived predicates (Sta˚hlberg, Bonet, and Geffner 2022b; Haslum et al. 2019; Thie´baux, Hoffmann, and Nebel 2005). In particular, we are interested in derived predicates that correspond to relational joins in $C _ { 3 }$ :

Definition 1 ( $C _ { 3 }$ -Relational Joins). Let σ be a relational language. The class $\mathcal { I } _ { 3 } = \mathcal { I } _ { 3 } [ \sigma ]$ of relational joins over the language $\sigma$ is the smallest class of formulas that satisfy the following properties:

1. $\{ R ( x , y ) , \neg R ( x , y ) \} \subseteq \mathcal { T } _ { 3 }$ for binary relation $R$ in $\sigma$ ,   
2. $\varphi ( x , y ) \land \phi ( x , y ) \in { \mathcal { I } } _ { 3 }$ if $\{ \varphi ( x , y ) , \phi ( x , y ) \} \subseteq \mathcal { T } _ { 3 } \mathrm { { , } }$ ,   
3. $\varphi ( x , y ) \vee \phi ( x , y ) \in \mathcal { J } _ { 3 } \ : i f \ : \{ \varphi ( x , y ) , \phi ( x , y ) \} \subseteq \mathcal { J } _ { 3 } ,$ and   
4. $\exists z [ \varphi ( x , z ) \land \phi ( y , z ) ] \in { \mathcal { I } } _ { 3 } i f \left\{ \varphi ( x , y ) , \phi ( y , z ) \right\} \subseteq { \mathcal { I } } _ { 3 } .$

The notation $\varphi ( x , y )$ means that $\varphi$ is a formula whose free variables are among $\{ x , y \}$ .

For example, if $\sigma$ contains the relations $\operatorname { K E Y } ( k , s )$ and $\operatorname { L o c K } ( \ell , t )$ to express that the key $k$ has shape $s$ , and the lock $\ell$ has shape $t$ , respectively, then $\mathcal { I } _ { 3 }$ contains $\varphi ( k , \ell ) =$ $\exists s [ \mathrm { K E Y } ( k , s ) \land \mathrm { L O C K } ( \ell , s ) ]$ that is true for the pair $\langle k , \ell \rangle$ when the key $k$ opens the lock $\ell$ .

Let ${ \mathsf { S T R U C } } = { \mathsf { S T R U C } } [ \sigma ]$ be the class of finite structures for language $\sigma$ . A network that maps structures $\mathcal { A }$ in STRUC into embeddings for all the $k$ -tuples $\langle u _ { 1 } , u _ { 2 } , \ldots , u _ { k } \rangle$ of objects in $\mathcal { A }$ is called a $k$ -embedding network, and a collection of such networks is a $k$ -embedding architecture. For example, the class of all nets in $\mathbf { R - G N N } [ t ]$ for $\sigma$ is a 2- embedding architecture. The architecture $\mathrm { R - G N N } [ \sigma , t , k , L ]$ is the collection of networks in $\mathbf { R - G N N } [ t ]$ for the language $\sigma$ , embedding dimension $k$ , and $L$ layers.

Let $\varphi ( x , y )$ be a relational join, and let $\mathcal { A }$ be a structure with universe $U$ . The denotation of $\varphi ( x , y )$ over $\mathcal { A }$ , denoted by $\mathcal { A } ^ { \varphi }$ , is the set of pairs $\{ \langle u , v \rangle \in U ^ { 2 } \mid A \vdash \varphi ( u , v ) \}$ . A 2-embedding network $N$ with embedding dimension $k$ computes $\varphi ( x , y )$ if there is an index $0 \leq j < k$ such that the pair $\langle u , v \rangle \in \mathcal { A } ^ { \varphi }$ iff $\pmb { f } ( \langle u , v \rangle ) _ { j } = 1$ , where $\pmb { f } ( \langle u , v \rangle )$ is the embedding for $\langle u , v \rangle$ produced by $N$ on input $\mathcal { A }$ . Likewise, such a network $N$ computes a collection $\mathcal { D }$ of relational joins if $N$ computes each join $\varphi ( x , y )$ in $\mathcal { D }$ .

Theorem 2 (Computation of $C _ { 3 }$ -Relational Joins). Let σ be a relational language, and let $\mathcal { D }$ be a finite collection of $C _ { 3 }$ - relational joins. Then, there is a tuple of parameters $\langle t , k , L \rangle$ and network $N$ in $R \cdot G N N [ \sigma , t , k , L ]$ that computes $\mathcal { D }$ .

The parameters $\langle t , k , L \rangle$ are determined by the joins in $\mathcal { D }$ . The index $t$ that defines the nesting depth of the $\Delta$ atoms is the maximum quantifier depth over (the joins in) $\mathcal { D }$ . On the other hand, the embedding dimension $k$ and the number of layers $L$ are bounded by the sum and maximum, respectively, of the number of subformulas of the joins in $\mathcal { D }$ .

To illustrate the capabilities of the proposed architecture, let us consider the Navig-xy domain from above for which $\sigma$ contains the relations SUCC-X, SUCC-Y, AT, $\operatorname { A T } _ { g }$ , BLOCKED, and CELL. We want to show that $\mathcal { I } _ { 3 }$ contains the predicate $\varphi _ { k } ( x , y )$ that tells when the cell $\langle x , y \rangle$ is at $k$ steps from the goal cell. Indeed, $\varphi _ { 0 } ( x , y ) = \mathrm { A T } _ { g } ( x , y )$ is in $\mathcal { I } _ { 3 }$ . Likewise,

$$
\begin{array} { r l } & { \mathrm { A D J - X } ( x , x ^ { \prime } ) = \mathrm { S U C C - X } ( x , x ^ { \prime } ) \vee \mathrm { S U C C - X } ( x ^ { \prime } , x ) , } \\ & { \mathrm { A D J - Y } ( y , y ^ { \prime } ) = \mathrm { S U C C - Y } ( y , y ^ { \prime } ) \vee \mathrm { S U C C - Y } ( y ^ { \prime } , y ) } \end{array}
$$

belong to $\mathcal { I } _ { 3 }$ . Then, the following also belong to $\mathcal { I } _ { 3 }$ :

$$
\begin{array} { r l } & { \phi _ { k + 1 } ^ { \mathrm { X } } ( x , y ) = \exists z [ \varphi _ { k } ( z , y ) \land \mathrm { A D J - X } ( x , z ) ] , } \\ & { \phi _ { k + 1 } ^ { \mathrm { Y } } ( x , y ) = \exists z [ \varphi _ { k } ( x , z ) \land \mathrm { A D J - Y } ( y , z ) ] , } \\ & { \phi _ { k + 1 } ( x , y ) = \phi _ { k + 1 } ^ { \mathrm { X } } ( x , y ) \lor \phi _ { k + 1 } ^ { \mathrm { Y } } ( x , y ) , } \\ & { \varphi _ { k + 1 } ( x , y ) = \lnot \mathrm { B L O C K E D } ( x , y ) \land \phi _ { k + 1 } ( x , y ) . } \end{array}
$$

Hence, for any state $S$ in an instance of Navig-xy, $V ^ { * } ( S ) =$ $k$ iff $S \models \mathrm { D I S T } _ { k }$ where $\mathrm { D I S T } _ { k } = \exists x y [ \mathrm { A T } ( x , y ) \land \varphi _ { k } ( x , y ) ]$ is a sentence in $\mathcal { J } _ { 3 }$ . Therefore, for a class of instances of bounded $x$ and $y$ dimensions, there is an embedding dimension $k$ , a number $L$ of layers, and a network $N$ in $\mathrm { R - G N N } [ \sigma , 1 , k , L ]$ that computes $V ^ { * }$ for the states $S$ in such instances.

# Conclusions

The paper presents a novel approach for extending the expressive power of Relational Graph Neural Networks (RGNNs) in the classical planning setting by just adding a set of atoms $A _ { t }$ to the state, in a domain-independent manner that depends on the $t$ parameter and the pairs of objects that interact in an atom true in the state. The resulting “architecture” $\mathbf { R - G N N } [ t ]$ appears to produce the necessary $C _ { 3 }$ features in a practical manner, without the memory and time overhead of 3-GNNs, and with much better generalization ability than Edge Transformers, which have the expressiveness of 3-GNNs, but with much less overhead. Interestingly, for all of the domains we considered, we did not see any improvement using $t > 1$ . This is exploited by $\mathbf { R - G N N } [ t ]$ , as far fewer compositions need to be considered, resulting in much faster inference and models that generalize better than the baselines that consider all possible compositions.

It remains to be studied whether the full power of $C _ { 3 }$ is needed to handle most planning domains. The expressivity results from Horc´ık and S´ır (2024) and Drexler et al. (2024) suggest that the expressive power of $C _ { 3 }$ is sufficient but not necessary. Indeed, there is ample room in the middle, between $C _ { 2 }$ and $C _ { 3 }$ , which the $\mathbf { R - G N N } [ t ]$ architecture exploits, in contrast with $\mathbf { R } { \mathbf { - G N N _ { 2 } } }$ and ETs. Approaches that aim to extend representations with new unary predicates by considering cycles in the state graphs may yield an acceptable tradeoff between expressivity and efficiency, without the need to embed pairs or higher tuples of objects at all. This is left for future work.