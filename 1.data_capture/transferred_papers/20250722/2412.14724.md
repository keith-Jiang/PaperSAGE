# FROC: Building Fair ROC from a Trained Classifier

Avyukta Manjunatha Vummintala, Shantanu Das, Sujit Gujar

International Institute of Information Technology, Hyderabad avyukta.v@research.iiit.ac.in, shantanu.das31@gmail.com, sujit.gujar@iiit.ac.in

# Abstract

This paper considers the problem of fair probabilistic binary classification with binary protected groups. The classifier assigns scores, and a practitioner predicts labels using a certain cut-off threshold based on the desired trade-off between false positives vs. false negatives. It derives these thresholds from the ROC of the classifier. The resultant classifier may be unfair to one of the two protected groups in the dataset. It is desirable that no matter what threshold the practitioner uses, the classifier should be fair to both the protected groups; that is, the $\mathcal { L } _ { p }$ norm between FPRs and TPRs of both the protected groups should be at most $\varepsilon$ . We call such fairness on ROCs of both the protected attributes $\varepsilon _ { p }$ -Equalized ROC. Given a classifier not satisfying $\varepsilon _ { 1 }$ -Equalized ROC, we aim to design a postprocessing method to transform the given (potentially unfair) classifier’s output (score) to a suitable randomized yet fair classifier. That is, the resultant classifier must satisfy $\varepsilon _ { 1 }$ -Equalized ROC. First, we introduce a threshold query model on the ROC curves for each protected group. The resulting classifier is bound to face a reduction in AUC. With the proposed query model, we provide a rigorous theoretical analysis of the minimal AUC loss to achieve $\varepsilon _ { 1 }$ -Equalized ROC. To achieve this, we design a linear time algorithm, namely FROC, to transform a given classifier’s output to a probabilistic classifier that satisfies $\varepsilon _ { 1 }$ -Equalized ROC. We prove that under certain theoretical conditions, FROC achieves the theoretical optimal guarantees. We also study the performance of our FROC on multiple real-world datasets with many trained classifiers.

Extended version — https://arxiv.org/abs/2412.14724 Code and Miscellaneous — https://github.com/magnetar-iiith/FROC/tree/main

# 1 Introduction

The use of Machine Learning based Models (MLM) in decision-making is prevalent today. Practitioners use MLMs’ predictions in college admissions, credit scores, recidivism, employment, recommender systems, etc. (Portugal, Alencar, and Cowan 2018; Berger, Frame, and Miller 2005). However, there have been several reports of such MLMs discriminating against individuals belonging to certain groups based on protected attribute such as gender, age, race, color, and religion. E.g., in Angwin et al. (2022), predictive models are found to be biased against the black population, or the Amazon recruitment team has to stop using the AI tool for shortlisting candidates as it was biased against females Dastin (2022). Bickel, Hammel, and O’Connell (1975); Berger, Frame, and Miller (2005); Zhao et al. (2018) show that many of such predictive models are unfair to females. Such unfair instances have driven researchers toward building a fair MLM.

An MLM that achieves fairness with the least possible compromise on traditional performance guarantees such as accuracy is desirable MLM. Building a desirable MLM involves two main steps: a) formalizing and quantifying a fairness measure and b) designing algorithms to train MLM for quantified fairness. Researchers proposed many fairness measures, majorly belonging to two categories: (i) individual fairness Dwork et al. (2012) – individuals with similar input features receive similar decision treatment irrespective of their protected attribute. (ii) Group fairness – a particular statistical property must be similar across each protected group, e.g., Disparate Impact (DI),Equalized odds (EO) (Madras et al. 2018).

Building Fair MLM Fair machine learning models (MLMs) can be developed by targeting different stages of the model training cycle. Approaches include: (i) Pre-processing methods, which act on input data to eliminate bias (Feldman et al. 2015; Zemel et al. 2013). (ii) In-processing algorithms, which intervene during training to incorporate fairness as a constraint or within the learning objective (Padala and Gujar 2020). (iii) Post-processing methods, which adjust the outputs of trained MLMs to produce fair results, requiring access to sensitive attributes.

In-processing and pre-processing methods are tailored to specific fairness criteria and models, necessitating retraining for each new fairness definition. Post-processing methods, in contrast, are model-agnostic and do not depend on the training process, making them suitable for domain experts with limited MLM knowledge (Sleeman et al. 1995). These methods are especially favored when retraining is infeasible, such as in large-scale systems like recommender systems (Nandy et al. 2022).

Given a potentially biased scoring function, this paper addresses the challenge of constructing a fair probabilistic binary classifier with a binary-protected attribute. The goal is to ensure fairness without retraining the MLM, minimizing performance loss.

Fairness and Performance Trade-offs For classification, one of the desired characteristics of an MLM is calibration (Kleinberg, Mullainathan, and Raghavan 2017). Suppose a classifier predicts that a given input is accepted $( Y = 1 )$ ) with probability $p$ , then calibration demands that the fraction of the accepted population, with the same features, is $p$ . Kleinberg, Mullainathan, and Raghavan (2017); Chouldechova (2017) have shown that calibration and equalized odds cannot be satisfied simultaneously except for highly constrained cases. Hence, researchers have been focusing on building classifiers (MLMs) with an appropriate approximate version of fairness (Madras et al. 2018). When it comes to practitioners, they focus on Receiver Operator Characteristics (ROC) for evaluating a classifier as it best describes the classifiers. ROC measures the relative scores of the positive versus negative instances. The area under ROC-curve (AUC) is an appropriate performance metric to measure the predictive quality of such classifiers and to segregate positive and negative samples through ranking (Huang and Ling (2005); Clémençon, Lugosi, and Vayatis (2008); Zehlike, Yang, and Stoyanovich (2021)). AUC is particularly beneficial when the classifier is expected to segregate positive and negative labels, and the predictions must be fair across all threshold scores.

To make the practitioner’s job effortless, we introduce a novel fairness measure, namely $\varepsilon _ { p }$ -Equalized ROC – no matter what threshold it uses for classification, the classifier is approximately fair, i.e., for all possible thresholds, the distance between the corresponding points of the ROC curves for both the protected group should be withing $\varepsilon$ distance in the $\mathcal { L } _ { p }$ norm. We aim to build a new probabilistic classifier that satisfies $\varepsilon _ { 1 }$ -Equalized ROC with the minimal loss in AUC w.r.t. to the scoring function $s$ .

Our Approach: We assume query access to the ROC of $s$ First, we make sufficiently large $k$ queries to the ROC for the protected groups and make a piece-wise linear approximation of the ROC curves of both the protected groups. Next, we transport ROCs within $\varepsilon$ distance of each other to minimize the loss in AUC of the resultant ROC. We can achieve such transportation by randomizing scores across certain feasible classifiers for the given ROC curve. We call the space of these classifiers as ROC Space of $s$ . The resultant classifier from such randomization across the ROC Space is a convex combination of these classifiers. In a nutshell, we transform the given $s$ to a fair scoring function by such ROC transport. We refer to this procedure of ROC transport as FROC. We then geometrically prove that under certain conditions, FROC is optimal.

# Our Contributions:

• We introduce a novel group fairness notion $\varepsilon _ { p }$ -Equalized ROC, enforcing fairness over all thresholds in a scorebased classification, which is extremely useful for practitioners. • Next, we model a post-processing problem as a problem of finding an optimal transformation $\mathcal { H }$ on a given scoring function $s$ to minimize the performance loss due to transformation while ensuring $\varepsilon _ { 1 }$ -Equalized ROC. • To achieve $\varepsilon _ { 1 }$ -Equalized ROC, we propose a ROC transport, FROC, a post-processing algorithm (Algorithm 1).

Thus, it avoids re-training the existing MLM, which might not be fair. It also helps in explaining the decisions.

• We perform rigorous theoretical analysis. We prove that (under some conditions) FROC is optimal in terms of AUC loss. (Theorem 4.2).   
• Finally, we demonstrate the efficacy of FROC via experiments.

# 1.1 Related Work

Fairness in Binary Classification and Ranking Demographic Parity (DP), Disparate Impact (DI), and Equalized Odds (EO) are widely studied group fairness notions. DP (Dwork et al. 2012) and DI (Feldman et al. 2015) ensure that the fraction of positive outcomes is identical across all sensitive groups. Barocas and Selbst (2016) introduced the $8 0 \%$ rule, requiring that the positive outcome rate for a minority group must be at least $4 / 5$ of that for the majority group. EO (Hardt, Price, and Srebro 2016) ensures similar distributions of error rates, specifically false positives and false negatives (Verma and Rubin 2018). Techniques to achieve fair MLMs include those discussed by Padala and Gujar (2020). Group fairness has been shown to be inadequate for score-based classifiers, which classify across all thresholds (Gorantla, Deshpande, and Louis 2021). Consequently, researchers have proposed fairness notions based on the area under the curve (AUC). Examples include intra-group pairwise AUC fairness (Beutel et al. 2019), BNSP (Borkan et al. 2019), and inter-group pairwise AUC (xAUC) fairness (Kallus and Zhou 2019). Yang et al. (2023) present a minimax learning and bias mitigation framework that integrates intra-group and inter-group AUC metrics to address algorithmic bias. Vogel, Bellet, and Clémençon (2021) examine fairness in ranking problems, developing a general class of AUC-based fairness notions. They demonstrate that AUC-based fairness notions do not capture all forms of bias, as AUC summarizes classifier performance. They propose a stronger notion called point wise ROC-based fairness and design an in-processing algorithm for this purpose.

Our fairness definition $\dot { \varepsilon } _ { p }$ -Equalized ROC) is inspired by equalized odds for all thresholds in ranking-based classification and is suitable for post-processing algorithms. It generalizes the approach of Chen and Wu (2020), which uses the Manhattan distance as its norm. We later demonstrate the equivalency of both fairness notions (ours $\varepsilon _ { 1 }$ ). Note that the notion in (Chen and $\mathrm { \sf W u } 2 0 2 0 \$ ) is not motivated by the same error rates at all thresholds, and also, ours is more of a geometric approach from ROC curves, and theirs is an algebraic approach; ours is more general.

Post-processing for fair classification Post-processing techniques range from simple adjustments, such as thresholding or re-scaling, to complex methods like re-weighting or resampling. Hardt, Price, and Srebro (2016) argue that many existing fairness criteria are too restrictive, leading to suboptimal solutions. They propose a fairness notion allowing some variation in prediction outcomes, defined by “equality of opportunity” constraints, ensuring the classifier is unbiased regarding the sensitive attribute. Their approach involves adjusting prediction thresholds for different groups based on their base rates to equalize false positive and false negative rates across groups. However, it does not involve transporting ROC curves. Wei, Ramamurthy, and Calmon (2020) examine post-processing from the perspective of transformers, defining fairness as the expectation of scores and bounding the differences between true positive rates (TPRs) and false positive rates (FPRs) across protected groups. Cui et al. (2021) propose a model-agnostic post-processing framework for balancing fairness in bipartite ranking scenarios. Zhao (2024) introduces a novel approach using Wasserstein barycenters to quantify and address the cost of fairness, demonstrating that the complexity of learning an optimal fair predictor is comparable to learning the Bayes predictor. ¸Tifrea et al. (2024) propose a framework that transforms any regularized in-processing method into a post-processing approach, extending its applicability across a broader range of problem settings. Cruz and Hardt (2023) identifies two key methodological errors in prior work through empirical analysis: comparing methods with different unconstrained base models and differing levels of constraint relaxation. Jang, Shi, and Wang (2022) introduce a method to optimize multiple fairness constraints through group-aware threshold adaptation, learning classification thresholds for each demographic group by optimizing the confusion matrix estimated from the model’s probability distribution. Unlike Jang, Shi, and Wang (2022), our approach starts with the fairness notion that differences between TPRs and FPRs of different groups must be bounded. Mishler, Kennedy, and Chouldechova (2021) use the bounded difference of counterfactual TPRs and FPRs as their fairness criterion, which differs from our $\varepsilon _ { p }$ -Equalized ROC definition. Our $\varepsilon _ { p }$ -Equalized ROC focuses on the bounded difference between TPRs and FPRs of different groups as the fairness criterion.

# 2 Preliminaries

Consider a practitioner interested in binary classification, each data point having a binary-protected attribute. He/she is equipped with a scoring-based classifier trained on dataset $D = \{ ( x _ { i } , a _ { i } , y _ { i } ) _ { i \in 1 : n } \}$ . Here, for ith data sample, $x _ { i } \in$ $\mathcal { X } \subset \mathbb { R } ^ { d }$ denotes features, $y _ { i } \in \{ 0 , 1 \}$ denotes the binary label, and $a _ { i } \in \mathcal { A } = \{ 0 , 1 \}$ denotes its binary protected attribute. We consider all these three as drawn from random variables $X , A , Y$ , respectively. There could be two scenarios - when the protected attribute is included or excluded from training (Wei, Ramamurthy, and Calmon (2020))—our postprocessing works for both cases as long as protected attributes are accessible during post-processing.

The random variables $X , A , Y$ are jointly distributed according to an unknown probability distribution over $( x _ { i } , a _ { i } , y _ { i } )$ . The cumulative conditional distributions on $X \mid$ $\mathbf { \boldsymbol { Y } } = \mathbf { \boldsymbol { 1 } } )$ and $X ~ \mid ~ ( Y ~ = ~ 0 )$ are denoted by $G , H$ , respectively. $G ^ { a } , H ^ { a }$ are the corresponding distributions conditioned on $A \ = \ a$ (i.e. $G ^ { a }$ denotes the distribution of $X \mid ( Y = 1 , A = a ) $ )

# 2.1 Probabilistic Binary Classification

Probabilistic Binary Classifier is equipped with a scoring function $s : \mathcal { X } \times \mathcal { A } \to \mathbb { R }$ mapping the feature space to a score. A deterministic classifier returns $s ( X ) \in \{ 0 , 1 \}$ and a randomized one returns $s ( X ) \in [ 0 , 1 ]$ . The higher the score $s ( x )$ , the higher the chance of the corresponding label $y = 1$ . The model prediction $\widehat { Y }$ , based on certain threshold $t \in [ 0 , 1 ]$ , is given by ${ \widehat { Y } } = \mathbb { I } ( s ( X ) \geq t ) .$ $s$ denotes the space of such scoring functbions.

The practitioner decides the threshold $t$ depending on the corresponding true positive rate $( T P R )$ and false positive rate $( F P R )$ (Provost (2000); Zhou and Liu (2005)). For deciding $t$ , he is supplied with ROC – receiver operator characteristic curve for $s$ . The ROC depicts the relation between TPR $( G _ { s } ( t ) )$ and FPR $( H _ { s } ( t ) )$ for $s$ at all possible thresholds $t$ .

We define $G _ { s } ( t ) \triangleq \mathbb { P } ( s ( X ) \geq t \mid Y = 1 )$ and $H _ { s } ( t )$ ≜ $\mathbb { P } ( s ( X ) \geq t \mid Y = 0 )$ . Furthermore, we define $G _ { s } ^ { a } ( t )$ ≜ $\mathbb { P } ( s ( X ) \ge t \mid Y = 1 , A = a )$ and $H _ { s } ^ { a } ( t ) \triangleq \mathbb { P } ( s ( X ) \geq t \mid$ $Y = 0 , A = a ,$ ).

# 2.2 ROC Curve and AUC

The plot of a ROC-curve (Definition (2.1)) is used to visualize homogeneity between two cumulative distributions (Vogel, Bellet, and Clémençon (2021)). The ROC curve is defined as:

Definition 2.1 (ROC-Curve). For any two cumulative distributions $g _ { 1 } , g _ { 2 }$ defined over the set $\mathbb { R }$ , the ROC-curve is defined as the plot of $R O C _ { g _ { 1 } , g _ { 2 } } ( \alpha ) \triangleq 1 - g _ { 1 } \circ g _ { 2 } ^ { - 1 } ( 1 - \alpha )$ with domain $\alpha \in [ 0 , 1 ]$ .

The area under ROC-curve, $A U C$ , represents a summary of point-wise dissimilarity between the concerned distributions. Formally, let $S , S ^ { \prime }$ be two independent random variables distributed according to $g _ { 1 } , g _ { 2 }$ respectively, then $\begin{array} { r } { A U C _ { g _ { 1 } , g _ { 2 } } = \mathbb { P } ( S ^ { \prime } > S ) + \frac { 1 } { 2 } \mathbb { P } ( S ^ { \prime } = \overset { \vartriangle } { S } ) } \end{array}$ .

For a given scoring function $s$ , we get two RVs, $G _ { s }$ and $H _ { s }$ , by varying decision thresholds. We call the corresponding ROC curve $\mathsf { R O C } _ { s }$ . The area under $\mathsf { R O C } _ { s }$ , i.e., $\mathtt { A U C } _ { s } = A U C _ { H _ { s } , G _ { s } }$ , is used to measure the ranking performance of a score function $s ( . )$ (Cortes and Mohri (2003); Clé- mençon, Lugosi, and Vayatis (2008)). For a perfect classifier, $\mathtt { A U C } _ { s } = 1$ , but such a classifier does not exist. Therefore, the optimal scoring function $s ^ { * }$ maximizes the $\mathbb { A } \mathbb { U } \mathbb { C } _ { s }$ amongst a certain subset of ${ \mathcal { S } } ^ { \prime } \subset { \mathcal { S } }$ . Formally, $s ^ { * } \in \arg \operatorname* { m a x } _ { s \in \mathcal { S } ^ { \prime } } \mathbb { A } \mathrm { U C } _ { s }$ . In section 3.4, we illustrate how a sub-optimal score function with lower TPRs can be achieved by randomizing outputs of $s ( \cdot )$ . This process is crucial in ensuring fairness. Let $\left. S \right| _ { s }$ be the space of possible scoring functions through such randomization. We call it ROC-space of $s$ . Before designing our fair classifier, we formally define our notion of fairness in the next section.

# 2.3 Fairness in Classification

The typical group fairness notions in binary classifiers such as Demographic Parity (DP) and Equalized Odds (EO) are defined on deterministic predictions, i.e., in score-based classification, they work with a single threshold on scoring function $s$ . Let $t ^ { * }$ be the threshold set by the practitioner. The resultant classifier is said to satisfy DP if $G _ { s } ^ { 0 } \dot { ( } t ^ { * } ) + H _ { s } ^ { 0 } ( t ^ { * } ) =$ $G _ { s } ^ { 1 } ( t ^ { * } ) + H _ { s } ^ { 1 } ( t ^ { * } )$ . It satisfies the equivalence of acceptance rates across groups. Similarly, EO enforces equality of positive and negative error rates across protected groups, $\bar { 1 } - G _ { s } ^ { 0 } ( t ^ { * } ) = 1 - G _ { s } ^ { 1 } ( t ^ { * } )$ and $H _ { s } ^ { 0 } ( t ^ { * } ) = \dot { H } _ { s } ^ { 1 } ( t ^ { * } )$ .

$\varepsilon _ { p }$ -Equalized ROC As discussed earlier, all group fairness notions are characterized by equality of a particular statistic across both the protected groups. In scoring-based probabilistic classifiers, these fairness notions depend on the selected threshold. To achieve fairness across all thresholds, the practitioner can choose to retrain the model and achieve the right trade-offs between TPR and FNR. However, retraining is expensive. Therefore, a desirable solution is To offer fair treatment to both protected groups using the pre-trained classifier. However, this leads to invoking the post-processing technique every time the practitioner needs to update the threshold $t ^ { * }$ . Instead, we propose a novel fairness measure to simplify the practitioner’s job. We perform post-processing on the given classifier once, and it ensures that no matter what threshold $t ^ { * }$ they choose to make decisions, the classifier offers similar treatment to both the protected groups. That is, the individual ROCs (Here on, we shall denote the ROCs of the protected groups, i.e., $R O C _ { H _ { s } ^ { 0 } , G _ { s } ^ { 0 } }$ and $R O C _ { H _ { s } ^ { 1 } , G _ { s } ^ { 1 } }$ by $\mathsf { R O C } _ { s } ^ { 0 }$ and $\mathsf { R O C } _ { s } ^ { 1 }$ respectively) should be within $\varepsilon$ distance $\mathcal { L } _ { p }$ norm) of each other. We call it $\varepsilon _ { p }$ -Equalized ROC. More formally,

Definition 2.2 ( $\dot { \varepsilon } _ { p }$ -Equalized ROC). A scoring function for binary classification s with label prediction $\widehat { Y } = \mathbb { I } ( s ( x ) \geq t )$ is said to satisfy -Equalized ROC if for a lb $\alpha \in ( 0 , 1 )$ the following holds:

$$
| | \ R O C _ { s } ^ { 1 } ( \alpha ) - R O C _ { s } ^ { 0 } ( \alpha ) \ | | _ { p } \leq \varepsilon
$$

In $\varepsilon _ { p }$ -Equalized ROC, we utilize standard metrics (i.e. $\mathcal { L } _ { p }$ norms) as the fairness statistic to quantify fairness. Thus, $\varepsilon _ { p }$ -Equalized ROC is feasible for post-processing algorithms.

Furthermore, if FROC is effective for $\mathcal { L } _ { 1 }$ , it necessarily extends to all $p$ -norms. This conclusion follows from the inequality:

$$
| a | ^ { p } + | b | ^ { p } \leq | a | + | b | , \quad \forall p \geq 1 , a , b \in [ 0 , 1 ] .
$$

However, while FROC ensures fairness, it does not guarantee optimality for $p > 1$ .

Next, we formulate the problem of fair post-processing. Note: $\varepsilon _ { 1 }$ -Equalized ROC is a generalization of Equalized Odds to all the given thresholds of the scoring function. The proofs and detailed discussion are in Appendix B.

# 2.4 Problem Formulation

Given $s \in \mathcal S$ , we would like to find $h \in S | _ { s } = \mathcal { H } ( s ) - \mathfrak { a }$ transformation of a given scoring function such that $h$ satisfies $\varepsilon _ { 1 }$ - Equalized ROC. Additionally, we want the loss in AUC due to transformation $\mathcal { H }$ minimal. That is, $\mathcal { L } _ { F } = \tt A U C _ { \it s } - A U C _ { \it h }$ must be minimal to retain the maximum performance guarantee of $s$ . Thus, our goal is to get transformation $\mathcal { H }$ that solves the following optimization problem and returns the optimal transformed score $h ^ { * }$ :

$$
h ^ { * } \in \underset { h \in \cal S | _ { s } } { \arg \operatorname* { m a x } } \ \mathbb { A U C } _ { h }
$$

$$
\| \mathsf { R O C } _ { h } { } ^ { 0 } ( \alpha ) - \mathsf { R O C } _ { h } { } ^ { 1 } ( \alpha ) \| _ { 1 } \leq \varepsilon , \forall \alpha \in [ 0 , 1 ]
$$

![](images/892cbe33b39e394bd3b1b6c0436610e6b9614caca9a4e87c8ac35f20953ee5e5.jpg)  
Figure 1: Shaded Area indicates $\mathcal { L } _ { P L A }$

# 3 Our Approach

First, we explain query access to $\mathsf { R O C } _ { s }$ to sample from the desired statistic at various thresholds and its piece-wise linear approximation in Section 3.1 and Section 3.2, respectively. Since we cannot sample a continuum of thresholds, our ${ \mathrm { R O C } } _ { s }$ will be discrete. In Section 3.3, we describe the transport of ROCs. Finally, we summarize our transformation as FROC in Section 3.4.

# 3.1 Query Model

Let $\mathcal { T } = \{ t _ { 1 } , \ldots t _ { k } \}$ be the set of thresholds at which we sample $\mathsf { R O C } _ { s }$ for each sensitive group $\begin{array} { r } { ( t _ { i } = \frac { i } { k } ) } \end{array}$ . Let ${ { \mathcal Q } ^ { a } } ( t _ { i } )$ denote the query output at threshold $t _ { i }$ for sensitive group $A = a$ on the $\mathsf { R O C } _ { s } ^ { a }$ . $\mathcal { Q } ^ { a } ( t _ { i } ) \triangleq R O C _ { H _ { \mathrm { e } } ^ { a } , G _ { \mathrm { e } } ^ { a } } ( t _ { i } )$ .

Abusing notations, we use $\mathcal { Q } ^ { a } ( t _ { i } )$ and ${ \bar { \mathcal { Q } } } _ { i } ^ { a }$ interchangeably. Let $\mathcal { Q } ^ { a } = ( \mathcal { Q } _ { 1 } ^ { a } , \ldots , \mathcal { Q } _ { k } ^ { a } )$ be the sequence of all query outputs for group $a$ . In the next section, we construct the piece-wise linear approximation of the group-wise ROC curves using the group-wise query outputs ${ \mathcal { Q } } ^ { a }$ .

# 3.2 Piece-wise Linear Approximation (PLA) of ROC-curves

To obtain the piece-wise linear approximation (PLA), we sample $k$ points from ROC and construct a straight line from $\mathcal { Q } _ { i } ^ { a }$ to $\mathcal { Q } _ { i + 1 } ^ { a }$ for all $i = 1 \dots k - 1$ . Lastly, we join $( 0 , 0 )$ to ${ \mathcal { Q } } _ { 1 } ^ { a }$ (see Figure 1). Following these steps on the query sets ${ \mathcal { Q } } ^ { a }$ will generate the PLAs for protected groups $\bar { a } \in \{ 0 , 1 \}$ . We denote by ${ \widehat { G _ { s } ^ { a } } } , { \widehat { H _ { s } ^ { a } } }$ , the cumulative distributions induced by the linear apcproxcimation of the ROC-curve on $s$ .

Due to PLA, we incur a loss $\mathcal { L } _ { L P A }$ in $A U C _ { H _ { s } , G _ { s } }$ (shaded region in Figure (1)). $\mathcal { L } _ { L P A }$ is inversely proportional to the number of queries $k$ , see Section 4.1 for bounds on this loss. Hence, we shall ignore this loss in our fairness analysis as it can be brought arbitrarily close to 0 by increasing $k$ .

# 3.3 Transporting ROCs for $\varepsilon _ { 1 }$ -Equalized ROC

Since we are using post-processing technique to ensure fairness, it is impossible to shift any ROC above its current position, i.e., build a classifier corresponding to any point in the epigraph (the points above the ROC curve) of $\mathsf { R O C } _ { s }$ just with the help of $s$ . Interestingly, a classifier representing a point in the hypograph (points below the curve) of $s \cap { \mathcal { S } }$ can be obtained through randomization on the predicted scores (see Chapter 3 in Barocas, Hardt, and Narayanan (2023)).

![](images/3d0cfc445c717982a11213ca768f0d81dc1825b94da2e18b7003b9f16df81be7.jpg)  
Figure 2: Norm Boundary

The key idea involves abstracting out the convex hull formed by the three points $( 0 , 0 )$ , $( 1 , 1 )$ and $\mathcal { Q } _ { i } ^ { u p }$ , and sampling outcomes from classifiers representing $( 0 , 0 )$ , $( 1 , 1 ) ^ { 1 }$ and $\mathcal { Q } _ { i } ^ { u p }$ with specific probabilities. By taking convex combinations of the three aforementioned points in the ROC space, we can represent any point lying in their convex hull. The exact convex combinations are described in C2. We leverage this property to achieve $\varepsilon _ { 1 }$ -Equalized ROC. We denote this space as $R O C$ -space of $\boldsymbol { s } - \boldsymbol { S } | _ { s }$ . Each point in $\left. S \right| _ { s }$ represents a binary classifier in terms of its performance at a certain threshold $t$ . Each point is of the form $( F P R ( t ) , T P R ( t ) )$ . This method is discussed in detail in the Appendix.

In the realm of binary classification, it is a common occurrence for one group to be subject to discrimination. Specifically, if we plot $\bar { \mathsf { R O C } } _ { s } ^ { 0 }$ , $\mathsf { R O C } _ { s } ^ { \mathrm { 1 } }$ , we will find that one of the ROCs is notably situated below the other. For this study, the ROC predominantly above the other will be designated as $R O C _ { u p }$ , while the other ROC will be referred to as $R O C _ { d o w n }$ . We believe this is a reasonable assumption because we observed that in most classifiers (for which present the results and others we explored on the datasets mentioned in Section E3) the ROCs don’t intersect or intersect at regions where $F P R \leq 0 . 2$ or $T P R \ge 0 . 5$ . Typically, no practitioner will work in those areas of ROCs. We leave for future work to address intersecting ROCs.

Let ${ \mathcal { Q } } ^ { u p }$ , $\mathcal { Q } ^ { d o w n }$ be the corresponding set of query points for $\mathtt { R O C } _ { u p }$ , $\mathsf { R O C } _ { d o w n }$ respectively. We also denote their fair counterparts by up, down.

Algorithm Definitions We need to transport $\mathtt { R O C } _ { u p }$ towards $\mathtt { R O C } _ { d o w n }$ such that the new ROCs are within $\varepsilon$ distance of each other. Our approach is geometric. We need to identify certain points/curves in the epigraph of $\mathsf { R O C } _ { d o w n }$ as follows.

Definition 3.1 (Norm Boundary). The set of all points within $\varepsilon$ distance $\ell _ { 1 }$ norm) from $\mathcal { Q } _ { i } ^ { d \bar { o } w n }$ is known as the norm set ${ \mathfrak { C } } _ { i }$ . Formally, we have

$$
\mathfrak { C } _ { i } \triangleq \{ x : x \in [ 0 , 1 ] ^ { 2 } , | | x - Q _ { i } ^ { d o w n } | | _ { 1 } \leq \varepsilon \}
$$

The set of all points exactly $\varepsilon$ distance (in $\mathcal { L } _ { 1 }$ norm) from $\mathcal { Q } _ { i } ^ { a }$ is known as Norm Boundary $\mathfrak { B } _ { i }$ . Formally,

$$
\mathfrak { B } _ { i } \triangleq \{ x : x \in [ 0 , 1 ] ^ { 2 } , | | x - \mathcal { Q } _ { i } ^ { d o w n } | | _ { 1 } = \varepsilon \}
$$

Additionally, we denote the vertices of the Norm Boundary Rhombus (starting from the top most point and moving clockwise) as $U _ { i } , R _ { i }$ , $D _ { i }$ , and $L _ { i }$ .

We say that an index $i \in [ 1 , 2 , \ldots , k ]$ is a Boundary Cut index when $R O C _ { u p }$ intersects the Norm Boundary $\mathfrak { B } _ { i }$ . Formally,

Definition 3.2 (Boundary Cut). Index $i \in [ 1 , 2 , \ldots , k ]$ is $a$ Boundary Cut index when $\mathfrak { B } _ { i } \cap R O C _ { u p } \neq \phi$ .

We now define the three kinds of shifts that will be used in our Algorithm: For a given $i \in [ 1 , 2 , \ldots , k ]$ , Upshift is the transportation of $\mathcal { Q } _ { i } ^ { u p }$ to the point $U _ { i }$ .

Definition 3.3 (UpShift). For a given $i \in [ 1 , 2 , \ldots , k ]$ , Upshift is the transportation of $\mathcal { Q } _ { i } ^ { u p }$ to the point $U _ { i }$ . Formally, UpShift can be defined as the function that returns a fair threshold ${ \widetilde { \mathcal { Q } } } _ { i } ^ { u p }$ (i.e. $U _ { i , \mathbf { \lambda } }$ ) by taking the $\mathcal { Q } _ { i } ^ { d o w n }$ and $\varepsilon$ as the argument

For a given $i \in [ 1 , 2 , \ldots , k ]$ , Leftshift is the transportation of $\mathcal { Q } _ { i } ^ { u p }$ to the point $L _ { i }$ . Formally,

Definition 3.4 (LeftShift). LeftShift is a function that returns $a$ fair threshold $\widetilde { \mathcal { Q } } _ { i } ^ { u p } \left( i . e . \ L _ { i } \right)$ by taking the $\mathcal { Q } _ { i } ^ { d o w n }$ and $\varepsilon$ as the arguments.

Definition 3.5 (CutShift). For a given $i \in [ 1 , 2 , \ldots , k ]$ (representing the index of the $R O C _ { d o w n } ,$ ), we run through all the points of the $R O C _ { u p }$ and return the set of all points that intersect the Norm Boundary $\mathfrak { B } _ { \mathrm { i } }$ . Formally, we define Cutshift as a function that takes $\mathcal { Q } _ { i } ^ { d o w n }$ and $\varepsilon$ as the arguments and returns $R O C _ { u p } \cap \mathfrak { B } _ { i }$ . The set $R O C _ { u p } \cap \mathfrak { B } _ { i }$ can be represented as $\{ p _ { l e f t } , \stackrel { \cdot } { p } _ { r i g h t } \}$ denoting the points at the intersection of $R O C _ { u p }$ at the left-side of the Norm Boundary and the right-side of the Norm Boundary respectively.

Now, we elaborate on the above procedure to transport points from $R O C _ { u p }$ towards $R O C _ { d o w n }$ .

Algorithm for ROC Transport We provide a geometric algorithm that returns a classifier equivalent to the scoring function $h ^ { * }$ in $\left. S \right| _ { s }$ .

Note that, Algorithm 1 treats $R O C _ { d o w n }$ as implicitly fair. Also, by $A r e a ( \square A B C D )$ , we denote the area of the quadrilateral whose vertices are $A , B , C$ , and $D$ . This area is easily found in this context by splitting $\square A B C D$ into two disjoint triangles- $\Delta A B C$ and $\Delta A C D$ and using the Herons formula (Kendig 2000) on each triangle.

For example, consider $\bar { A r e a } ( \Delta \mathcal { Q } _ { i } ^ { u p } \mathcal { Q } _ { i - 1 } ^ { u p } L _ { i } )$ . Let $\textit { a } =$ $| | \mathcal { Q } _ { i } ^ { u p } \mathcal { Q } _ { i - 1 } ^ { u p } | | _ { 2 }$ , $b = | | \mathcal { Q } _ { i } ^ { u p } L _ { i } | | _ { 2 }$ and $c = | | \mathcal { Q } _ { i - 1 } ^ { u p } L _ { i } | | _ { 2 }$ . Additionally, we define $\textstyle s = { \frac { a + b + c } { 2 } }$ . Then, it is true that:

$$
A r e a ( \Delta \mathcal { Q } _ { i } ^ { u p } \mathcal { Q } _ { i - 1 } ^ { u p } L _ { i } ) = \sqrt { s ( s - a ) ( s - b ) ( s - c ) }
$$

# 3.4 Obtaining Fair Classifier from the Updated ROCs

The algorithm described in the previous subsection returns the fair ROC curves according to $\varepsilon _ { 1 }$ -Equalized ROC. As a final step, we need to find the transformed classifier. We call it ConstructClassifier(FairROCup,FairROCdown , $\mathrm { . R O C } _ { s } ^ { 0 } , \mathrm { R O C } _ { s } ^ { 1 } )$ which returns a probabilistic binary classifier representing $h = \mathcal { H } ( s )$ such that it represents the FairROCs. We construct one using the procedure explained in Section 3.3. Now, we establish the optimality of our solution within specific assumptions.

Require: $R O C _ { u p }$ , $R O C _ { d o w n }$ , $\varepsilon$   
Ensure: F airROCup, F airROCdown   
1: Initialize $i \gets 1$ , $\hat { k } \gets \mathrm { l e n g t h } ( R O C _ { u p } )$   
2: F air $R O C _ { u p } \gets \emptyset$ , $F a i r R O C _ { d o w n } \gets R O C _ { d o w n }$   
3: while $i < k - 1$ do   
4: $i \gets i + 1$   
5: if BOUNDA $\scriptstyle \mathrm { 3 Y C U T } ( i , \varepsilon ) = = \mathrm { T R U E }$ then   
6: $p _ { l e f t } , p _ { r i g h t }$   
$\mathrm { C U T S H I F T } \{ i , R O C _ { u p } , R O C _ { d o w n } \}$   
7: if $F P R ( \mathcal { Q } _ { i } ^ { u p } ) \geq F P R ( \mathcal { Q } _ { i } ^ { d o w n } )$ then   
8: $\widetilde { \mathcal { Q } } _ { i } ^ { u p } \gets p _ { r i g h t }$   
9: else   
10: $\widetilde { \mathcal { Q } } _ { i } ^ { u p } \gets p _ { l e f t }$   
11: end ief   
12: else if $\mathcal { Q } _ { i } ^ { u p } \in \mathrm { H Y P O G R A P H } ( R O C _ { d o w n } )$ then   
13: $\widetilde { \mathcal { Q } } _ { i } ^ { u p }  \mathcal { Q } _ { i } ^ { u p }$   
14: ceontinue   
15: else   
16: if Area(□Qiu+p1Qi Qiup1Li) ≥   
$\mathbf { A r e a } ( \bigtriangledown \mathcal { Q } _ { i + 1 } ^ { u p } \mathcal { Q } _ { i } ^ { u p } \mathcal { Q } _ { i - 1 } ^ { u p } U _ { i } )$ then   
17: up U   
18: else   
19: $\widetilde { \mathcal { Q } } _ { i } ^ { u p }  L _ { i }$   
20: end ief   
21: end if   
22: $F a i r R O C _ { u p } \gets \mathrm { A P P E N D } \big ( \widetilde { \mathcal { Q } } _ { i } ^ { u p } \big )$   
23: end while

# 4 Theoretical Analysis

As described in Section (3.2), we work with PLA of the ROC curves $R O C _ { H _ { s } ^ { a } , G _ { s } ^ { a } }$ , $a \in \{ 0 , 1 \}$ . This causes a loss in area under ROC. We denote this loss by $\mathcal { L } _ { P L A }$ and is quantified as the difference in AUCs of ROCHsa ,Gsa and ROCHa,Ga .

In Section 3.3, transporting the ROC query pointds, ${ \mathcal { Q } } ^ { u p }$ introduces a decrease of the area under the ROC curve due to the transformation of scoring function $s$ to $h$ . We denote this loss by $\mathcal { L } _ { A U C }$ . This loss can be quantified as the difference in AUCs of $R O C _ { widehat { H _ { s } ^ { a } } , \widehat { G _ { s } ^ { a } } }$ and $R O C _ { H _ { h } ^ { a } , G _ { h } ^ { a } }$ The total loss in AUC, $\mathcal { L }$ , induced by FdRO cC is given by: $\mathcal { L } = \mathcal { L } _ { P L A } + \mathcal { L } _ { A U C }$

# 4.1 PLA Loss analysis

We start our analysis by making a few standard assumptions regarding the continuity and differentiability of the cumulative distributions on the family of scoring functions $s$ . We adopt a less stringent assumption than that presented in (Vogel, Bellet, and Clémençon 2021), as we impose only an upper bound on the slopes. This contrasts with the approach in (Vogel, Bellet, and Clémençon 2021), which necessitates both an upper and lower bound on the slopes.

Assumption 4.1. We assume that the rate of change (with respect to the thresholds $t$ ) of the T P Rs and F P Rs are upper bounded. I.e. we assume that $\exists u _ { T } , u _ { F } \in \mathbb { R }$ such that $\begin{array} { r } { \frac { d ^ { \ } \hat { T } P R } { d t } \leq u _ { T } } \end{array}$ and $\begin{array} { r } { \frac { d \ F P R } { d t } \leq u _ { F } } \end{array}$ .

Theorem 4.1. Let $R O C _ { \widehat { H _ { s } ^ { a } } , \widehat { G _ { s } ^ { a } } }$ be the PLA of $R O C _ { H _ { s } ^ { a } , G _ { s } ^ { a } }$ over the query set of $k$ eqdui dcistant thresholds, $\mathcal { T } = \{ t _ { i } \ |$ $t _ { i } = i / k { \bar { \forall } } i \in [ k ] \} .$ . The corresponding $\mathcal { L } _ { P L A }$ is bounded as: $\begin{array} { r } { \mathcal { L } _ { P L A } \leq \frac { 1 } { 2 } \frac { u _ { T } u _ { F } } { k } } \end{array}$

# 4.2 AUC Loss analysis

We start our analysis by making a few assumptions regarding the spacing of the ROC thresholds and the ROC curve.

Assumption 4.2. We have two assumptions: • $\forall i \ \bar { \in } \ \{ 1 , 2 , \ldots , k \}$ , we assume that $F P R ( \mathcal { Q } _ { i - 1 } ^ { d o w n } ) \ \leq$ F P R(Qi ) ≤ F P R(Qid+o1w ). • We assume that the $R O C _ { u p }$ can intersect any Norm boundary (i.e. $( \mathfrak { B } _ { i } ) _ { i \in \{ 1 , 2 , . . . , \dot { k } \} } )$ at most 2 times.

We note that even if Assumption 4.2 does not hold, FROC remains operational and continues to produce outputs that are $\varepsilon _ { 1 }$ -Equalized ROC fair. However, under these conditions, the optimality with respect to AUC is not guaranteed, as Theo$\mathrm { r e m } 4 . 4$ no longer applies. The necessity of these assumptions is discussed in greater detail in the extended version of this paper.

Theorem 4.2. If a given classifier s is piece-wise linear and satisfies assumption 4.2, the ROCs returned by FROC represent the classifier solving optimization problem 2.

# 4.3 Optimally Fair points and Norm Boundary

This section proves that all optimally fair points must lie on some Norm Boundary. We do this by establishing that the performance of any point in the Norm Set can be improved by appropriate transportation to a point on the Norm Boundary.

Theorem 4.3. (Norm Boundary) $\boldsymbol { \mathscr { f } } ( \widetilde { \mathcal { Q } } _ { i } ^ { u p } ) _ { i \in \{ 1 , 2 , . . . , k \} }$ is the set of optimal fair (points that maximieze the AUC and also satisfy the $\varepsilon _ { 1 }$ -Equalized ROC) thresholds must necessarily be a subset of (Bi)i 1,2,...,k .

Theorem 4.4. (CutShift) If index $i$ is a Boundary cut point, then the CutShift operation must be performed. Of the 2 points $( p _ { l e f t }$ and $p _ { r i g h t . }$ ) returned by the Cutshift operation, the point that is closer to $\mathcal { Q } _ { i } ^ { u p }$ must be chosen $\therefore e . { \widetilde { \mathcal { Q } } } _ { i } ^ { u p } =$ $a r g m i n _ { p \in \{ p _ { l e f t } , p _ { r i g h t } \} } | F P R ( \mathcal { Q } _ { i } ^ { u p } ) - F P R ( p ) |$

Theorem 4.5. (UpShift) If index $i$ is not a Boundary cut point and if $\cdot A r e a ( \sqcap \mathscr { Q } _ { i + 1 } \mathscr { Q } _ { i } \mathscr { Q } _ { i - 1 } L _ { i } \geq A r e a ( \sqcap \mathscr { Q } _ { i + 1 } \mathscr { Q } _ { i } \mathscr { Q } _ { i - 1 } U _ { i } ) ,$ , then UpShift operation must be performed. The resulting point $( U _ { i } )$ is the new fair point ${ \widetilde { \mathcal { Q } } } _ { i } ^ { u p }$ . Otherwise, the LeftShift operation must be performed. Tehe resulting point $( L _ { i } )$ is the new fair point Qi .

The proofs oef all the above theorems are given in the appendix. However, the following is brief sketch of the proof:

Step 1: We prove that all optimally fair points $\overline { { ( \widetilde { \mathcal { Q } } _ { i } ^ { u p } ) _ { i \in \{ 1 , 2 , . . . , k \} } } }$ must lie on the Norm Boundaries of the corr∈e{spondin}g $\mathcal { Q } _ { i } ^ { d o w n }$ . (i.e. $( \mathfrak { B } _ { i } ) _ { i \in \{ 1 , 2 , . . . , k \} } )$ Step 2: We then prove that if $\mathfrak { B } _ { i } \cap R O C _ { u p } \ne \phi$ , then the CutShift transportation is the optimal transportation. Step 3: We then prove that if $\mathfrak { B } _ { i } \cap R O C _ { u p } = \phi$ , then, based on the Cover and aforementioned area condition, the UpShift or the LeftShift transportation is the optimal transportation.

In the next section, we experimentally analyze FROC.

![](images/5ec4cee991f3e0747352a80866bf384e05a23e742c29e7598978e98e65bd47ca.jpg)  
Figure 3: Comparison of different methods: (a) C1 vs. C1-FROC, (b) C3-Fair Fair vs. C3-FROC, and (c) C2 Before and Afte FROC.

# 5 Empirical Analysis

# 5.1 Experimental Setup

Datasets: We train different classifiers on the widely-used ADULT (Becker and Kohavi 1996) and COMPAS (Angwin et al. 2022) benchmark datasets, selecting MALE and FEMALE as protected groups in ADULT, and BLACK and OTHERS in COMPAS. ROCs are generated, with additional experiments on datasets like CelebA in Appendix E and F.

Classifiers: We test FROC on ROCs from the following classifiers: 2. C1: FNNC( Padala and Gujar (2020)): This is a neural network-based classifier with a target parameter for fairness. C2: Logistic Regression and C3: Random Forest We used the code from the author’s GitHub for C1 and sklearn implementations for C2 and C3.

Post-Processing methods: We compare FROC against the following baselines: B1: FairProjection-CE and FairProjection-KL (Alghamdi et al. 2022): Transforms the score to achieve mean equalized odds fairness through information projection.

# 5.2 Experiments

We train C1 on both datasets, C2 and C3 on the Adult dataset, and generate their ROCs for all the protected groups. FNNC, we train by ignoring its fairness components in the loss function and then generate ROC. We then invoke FROC for different $\varepsilon$ values and check the best possible threshold for accuracy. We refer to the new classifier as C1-C3-FROC.

Baseline Post-Processing Method: We evaluate FROC, and the baselines B1 on ADULT dataset against the fairness metric mean equalized odds(B2) (Alghamdi et al. 2022) in Figs. 3(b). For consistent comparison, we adopt the training parameters for base classifiers from (Alghamdi et al. 2022) and keep it identical across all experiments.

# 5.3 Results

We show the results on the COMPAS and Adult dataset (using FNNC and FROC) here, along with a comparison with existing post-processing baselines. The remaining experimental observations are detailed in the supplementary. Figure

3(c) displays the ROC curves (Before and After FROC) for both males and females, on the ADULT dataset for C2. The female ROC consistently occupies the higher position, indicating a positive bias for males. This establishes $R O C _ { 0 }$ as our counterpart to $R O C _ { d o w n }$ . Thus, we apply FROC to the alternate curve, $R O C _ { 1 }$ , showcased in the figure. Before FROC, the maximum difference between Male ROC and Female ROC is 0.08. However, after post-processing with FROC, the loss in accuracy is $< 0 . 1 \%$ for $\varepsilon = 0 . 0 5$ . In general, across all experiments (more experiments in Appendix), we observe a $7 . 8 \%$ improvement in fairness, FROC incurs at most a $2 \%$ drop in accuracy. As seen in Figure 3(a) and Figure $\mathbf { \boldsymbol { 3 } } ( \mathbf { \boldsymbol { b } } )$ for smaller values of $\varepsilon$ , we also observe the performance may beat FNNC and the post-processing methods. We assign it to the fact that FNNC (and the other methods) may overachieve the target fairness for smaller values of $\varepsilon$ (Evident from Table 2 (Padala and Gujar 2020)). FROC drops AUC minimally to achieve target fairness.

# 6 Conclusion

In this work, we addressed the problem of practitioners aiming to achieve fair classification without retraining MLMs. Specifically, we provide a post-processing framework that takes a potentially unfair classification score function and returns a probabilistic fair classifier. The practitioner need not worry about fairness across different thresholds, so we proposed a new notion $\varepsilon _ { 1 }$ -Equalized ROC (Definition 2.2), which ensures fairness for all thresholds. To achieve $\varepsilon _ { 1 }$ - Equalized ROC, we proposed FROC (Algorithm 1), which transports the ROC for each sensitive group within $\epsilon$ distance while minimizing the loss in AUC of the resultant ROC. We geometrically proved its optimality conditions (Theorem 4.2) and bounds under certain technical assumptions. We observed empirically that its performance might differ at most by $2 \%$ compared to an in-processing technique while ensuring stronger fairness and avoiding retraining. We leave it for future work to explore the possibility of different distance metrics for fairness and optimizing for different performance measures.