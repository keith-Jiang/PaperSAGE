# QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography

Hao Fang, Graduate Student member, IEEE, Sihao Teng, Graduate Student member, IEEE, Hao Yu, Member, IEEE, Siyi Yuan, Huaiwu He, Zhe Liu, Member, IEEE, Yunjie Yang, Senior Member, IEEE

Abstract—Electrical Impedance Tomography (EIT) is a noninvasive, low-cost bedside imaging modality with high temporal resolution, making it suitable for bedside monitoring. However, its inherently ill-posed inverse problem poses significant challenges for accurate image reconstruction. Deep learning (DL)-based approaches have shown promise but often rely on complex network architectures with a large number of parameters, limiting efficiency and scalability. Here, we propose an UltraLightweight Quantum-Assisted Inference (QuantEIT) framework for EIT image reconstruction. QuantEIT leverages a QuantumAssisted Network (QA-Net), combining parallel 2-qubit quantum circuits to generate expressive latent representations that serve as implicit nonlinear priors, followed by a single linear layer for conductivity reconstruction. This design drastically reduces model complexity and parameter number. Uniquely, QuantEIT operates in an unsupervised, training-data-free manner and represents the first integration of quantum circuits into EIT image reconstruction. Extensive experiments on simulated and real-world 2D and 3D EIT lung imaging data demonstrate that QuantEIT outperforms conventional methods, achieving comparable or superior reconstruction accuracy using only $0 . 2 \%$ of the parameters, with enhanced robustness to noise.

Index Terms—Electrical Impedance Tomography, QuantumAssisted Inference, Inverse Problems, Hybrid Quantum-Classical Models, Lightweight Networks

# I. INTRODUCTION

E iLnEvaCsiTvRe CimAaLgiInmg etedcahnnciequTe mthoagt rpehcyon(stErIuTc)t  pa inaollnyresolved conductivity distributions by injecting small electrical currents and measuring the resulting boundary voltages [1], [2]. Due to its non-ionizing nature, low cost, and high temporal resolution, EIT has been widely applied in medical imaging (e.g., pulmonary monitoring [3]–[5] and brain function imaging [6]–[8]) and industrial process monitoring [9], [10]. However, the inherently ill-posed nature of EIT fundamentally limits its spatial resolution and image quality, posing substantial challenges for accurate and robust image reconstruction.

Hao Fang, Sihao Teng, Hao Yu, Zhe Liu and Yunjie Yang are with the SMART Group, Institute for Imaging, Data and Communications (IDCOM), School of Engineering, The University of Edinburgh, Edinburgh, UK. (Correspondence authors: Yunjie Yang and Zhe Liu; Email: y.yang@ed.ac.uk and zz.liu@ed.ac.uk).

Siyi Yuan and Huaiwu He are with the State Key Laboratory of Complex Severe and Rare Diseases, Department of Critical Care Medicine, Peking Union Medical College, Peking Union Medical College Hospital, Chinese Academy of Medical Sciences, Beijing, China.

This work was supported in part by Noncommunicable Chronic DiseasesNational Science and Technology Major Project (2024ZD0522700), and in part by Prunus Medical-Edinburgh joint research grant.

To address such issues, traditional reconstruction methods have relied on handcrafted regularization techniques such as Tikhonov [11], Newton’s One-Step Error Reconstructor (Noser) [12], $\ell _ { 1 }$ norms [13], and Total Variation (TV) regularization [14]. While these approaches help stabilize the inversion process, they often require careful parameter tuning and tend to perform poorly in severely ill-posed or noisy scenarios. In the past decade, supervised deep learning (DL)- based methods [15]–[18] have been extensively explored for inverse problems in imaging, including EIT. Compared to handcrafted priors, these methods, including convolutional neural networks (CNNs) [19]–[21], variational autoencoders (VAEs) [22], and generative adversarial networks (GANs) [23], have demonstrated notable improvements by learning complex features and data-driven priors from large labeled datasets. However, such approaches heavily rely on the availability of large-scale, high-quality labeled datasets, which can be difficult and costly to obtain in practical EIT settings. Moreover, these models are typically task-specific and often exhibit limited generalization to unseen structures, patterns, or imaging conditions [24], [25].

To overcome the limitations of supervised learning, unsupervised DL-based methods, exemplified by Deep Image Prior (DIP) [26], have attracted attention for their trainingdata-free nature and strong generalization capability. These approaches use untrained neural networks (UNNs) as implicit regularizers, representing the reconstructed conductivity distribution directly as the output of the network. Leveraging the implicit regularization of the network itself, reconstruction is performed by iteratively updating its parameters. By optimizing the network parameters using only the measurement data, these methods avoid the need for pretraining on large datasets. D. Liu et al. [27] introduced DIP to EIT by employing a U-Net as an implicit regularizer, reformulating the reconstruction as a neural network parameter optimization problem and achieving stable and high-quality 2D EIT reconstructions. Later, Z. Liu et al. [28] proposed Regularized Shallow Image Prior (RSIP), incorporating handcrafted regularization into a shallow three-layer multilayer perceptron (MLP), achieving robust reconstruction in both 2D and 3D settings. Fang et al. [24], on the other hand, presented Multi-Branch Attention Image Prior (MAIP), an unsupervised framework enhancing generalization and enabling robust 2D multifrequency EIT reconstruction.

However, these unsupervised methods still rely on conventional neural networks, which approximate complex nonlinear mappings through stacked layers of linear transformations and nonlinear activations, typically requiring carefully designed architectures with numerous parameters. As a result, these models can be computationally intensive, prone to overfitting, and difficult to generalize across imaging scenarios. Moreover, the need for extensive tuning and high memory usage poses challenges for real-time or lightweight deployment.

To address these challenges, recent studies have explored integrating quantum circuits [29] into neural architectures to form hybrid quantum–classical models. Quantum circuits inherently offer high expressive power with surprisingly few parameters, enabled by uniquely quantum phenomena like superposition and entanglement [30], [31]. These capabilities allow quantum-assisted models to represent complex nonlinear mappings more compactly and efficiently than conventional deep neural networks. For example, quantum convolutional neural networks (QCNNs) have achieved high imageclassification accuracy despite using only a limited number of trainable parameters, highlighting their capacity to capture rich feature representations with a compact model size [32].

These advantages open up new possibilities for building lightweight, generalizable quantum-assisted inference frameworks to tackle ill-posed inverse problems like EIT, particularly under data-scarce or resource-constrained scenarios. In particular, quantum models have demonstrated promising generalization from remarkably small training sets. One theoretical analysis guarantees, for instance, that a QCNN with only $O ( \log n )$ parameters can learn to classify quantum states using just $O ( ( \log n ) ^ { 2 } )$ training samples, suggesting robust performance even in severely data-limited scenarios. Here, $n$ denotes the number of qubits representing the input state, and the logarithmic scaling indicates that both the parameter count and the sample complexity grow slowly with system size [33].

Here, we propose an Ultra-Lightweight Quantum-Assisted Iterative Inference (QuantEIT) framework for EIT image reconstruction. We introduce parallel quantum circuits composed of parameterized single-qubit rotation gates and two-qubit entanglement gates to generate compact latent representations for EIT image reconstruction. By leveraging the expressive power of quantum circuits, our method requires only a single linear mapping layer to achieve high-quality 2D and 3D reconstructions. This design effectively avoids designing and tuning complex network architectures while significantly reducing the number of model parameters. In terms of reconstruction performance, the framework also exhibits strong robustness to measurement noise and generalizes effectively across different anatomical structures and imaging conditions.

Our main contributions are summarized as follows:

• We propose QuantEIT, a novel ultra-lightweight quantum-assisted iterative inference framework that integrates parallel quantum circuits into EIT reconstruction, drastically reducing model complexity for efficient inference. QuantEIT enables high-quality 2D and 3D reconstructions in an unsupervised manner. It employs a compact Quantum-Assisted Network (QA-Net) that implicitly generates latent representations from fixed trainable quantum parameters. This module, composed of two parallel 2-qubit circuits and a single linear layer, serves as a lightweight implicit nonlinear prior for the inverse mapping.

Comprehensive experiments on simulated and real-world data show that QuantEIT outperforms state-of-the-art classical models, achieving superior reconstruction quality with only $0 . 2 \%$ of the parameters and enhanced robustness to noise.

# II. METHODOLOGY

Fig. 1 shows the hybrid quantum–classical framework for chest impedance imaging. Currents are first injected into the body through an electrode belt, and boundary voltages are measured by the data acquisition system. The recorded voltages are then processed on a classical computer, which by default interfaces with quantum circuits simulated locally using the PennyLane [34] framework. Alternatively, these circuits can also be executed on a quantum backend. The quantum circuits generate expressive latent representations that are mapped to conductivity distributions.

# A. EIT image reconstruction

EIT image reconstruction is a typical inverse problem that aims to reconstruct 2D or 3D conductivity distributions from voltage measurements, typically subject to noise. The EIT forward model, which characterizes the nonlinear relationship between internal conductivity changes and boundary voltage responses, can be linearized around a known reference conductivity, yielding:

$$
\Delta { \bf v } = { \bf J } \Delta \sigma ,
$$

where $\Delta \mathbf { v } = ( \mathbf { v _ { o } } - \mathbf { v _ { r } } ) \oslash \mathbf { v _ { r } } \in \mathbb { R } ^ { m }$ and $\Delta \sigma = - ( \sigma _ { \mathrm { o } } - \sigma _ { \mathrm { r } } ) \bigcirc$ $\pmb { \sigma _ { r } } \in \mathbb { R } ^ { n }$ denote the normalized voltage measurements and conductivity distributions, respectively. $\mathbf { J } \in \mathbb { R } ^ { m \times n }$ represents the Jacobian (or sensitivity) tensor. Here, $m$ is the number of independent voltage measurements, and $n$ is the number of elements (pixels or voxels).

Due to the ill-posed nature of EIT, directly solving (1) is highly underdetermined and noise-sensitive. To mitigate this issue, we reformulate the reconstruction problem as a regularized optimization task. Specifically, the normalized conductivity change $\Delta \sigma ^ { * }$ is estimated by solving:

$$
\begin{array} { r l } { \Delta \pmb { \sigma } ^ { * } = \arg \operatorname* { m i n } _ { \Delta \pmb { \sigma } } } & { { } \big | \Delta \mathbf { v } - \mathbf { J } \Delta \pmb { \sigma } \big | + \lambda ^ { \top } \pmb { \mathcal { R } } \big ( \Delta \pmb { \sigma } \big ) , } \end{array}
$$

where $| \cdot |$ denotes the selected data fidelity norm (e.g., $\ell _ { 1 }$ or $\ell _ { 2 } ^ { \cdot }$ ). $\mathcal { R } ( \cdot )$ is a vector of handcrafted regularization terms imposing different prior constraints on the solution, and $\lambda ^ { \top }$ is the corresponding vector of regularization weights that control the influence of each prior term.

# B. Quantum Circuit

A quantum bit (qubit) resides in a 2D complex Hilbert space [35]. The standard computational basis vectors are denoted as:

$$
| 0 \rangle = { \binom { 1 } { 0 } } , \quad | 1 \rangle = { \binom { 0 } { 1 } } ,
$$

![](images/faeb2e7089e8273f20ddb7b4f1a671a5fef72230c2b36c6fc9f57195604b2b03.jpg)  
Fig. 1. Overview of the hybrid quantum-classical framework for EIT imaging

For a system of $n _ { q } = 2$ qubits, the total Hilbert space is $\mathcal { H } = \mathbb { C } ^ { 2 ^ { n _ { q } } } = \mathbb { C } ^ { 4 }$ , with the standard basis spanning states like:

$$
\{ \left| 0 0 \right. , \left| 0 1 \right. , \left| 1 0 \right. , \left| 1 1 \right. \} ,
$$

A valid quantum state $| \psi \rangle \in { \mathcal { H } }$ must satisfy the normalization condition:

$$
\langle \psi | \psi \rangle = 1 ,
$$

which ensures that the total probability of all possible measurement outcomes is one.

The first stage of circuit evolution applies parameterized single-qubit rotation gates around the Y-axis, described by the matrix:

$$
R _ { Y } ( \alpha ) = \exp \left( - i { \frac { \alpha } { 2 } } Y \right) = { \binom { \cos { \frac { \alpha } { 2 } } } { \sin { \frac { \alpha } { 2 } } } } \quad { \stackrel { - \sin { \frac { \alpha } { 2 } } } { \cos { \frac { \alpha } { 2 } } } } \quad ,
$$

The Pauli- $\cdot \mathrm { Y }$ operator is defined as:

$$
Y = { \binom { 0 } { i } } \quad { \binom { - i } { 0 } } .
$$

Applying $R _ { Y } ( \alpha )$ to the ground state $| 0 \rangle$ yields:

$$
R _ { Y } ( \alpha ) \left| 0 \right. = \cos \frac { \alpha } { 2 } \left| 0 \right. + \sin \frac { \alpha } { 2 } \left| 1 \right. .
$$

This unitary and real-valued transformation maps each qubit into a continuously differentiable superposition, enabling analytic gradient computation via the parameter-shift rule.

To introduce entanglement, a chain of Controlled-NOT (CNOT) gates is applied. A CNOT gate acts on two qubits (control $c$ , target $t$ ) and transforms the joint state as:

$$
| c , t \rangle \mapsto | c \rangle \otimes | t \oplus c \rangle ,
$$

A CNOT gate flips the target qubit if and only if the control qubit is $| 1 \rangle$ . The standard 2-qubit CNOT matrix is:

$$
\mathrm { C N O T } = \left( \begin{array} { l l l l } { 1 } & { 0 } & { 0 } & { 0 } \\ { 0 } & { 1 } & { 0 } & { 0 } \\ { 0 } & { 0 } & { 0 } & { 1 } \\ { 0 } & { 0 } & { 1 } & { 0 } \end{array} \right) .
$$

This layer induces entanglement between adjacent qubits, significantly enhancing the expressive power of the circuit.

After rotations and entanglement, the final quantum state $| \psi ( \phi ) \rangle$ is measured. For each qubit $k$ , the expectation value of the Pauli-Z operator is computed as:

$$
\begin{array} { r l } & { f _ { k } ( \phi ) = \langle \psi ( \phi ) | Z _ { k } | \psi ( \phi ) \rangle , } \\ & { \quad Z _ { k } = I ^ { \otimes k } \otimes Z \otimes I ^ { \otimes ( n _ { q } - k - 1 ) } , Z = \binom { 1 } { 0 } \quad \overset { ( ) } { - } 1 ) . } \end{array}
$$

This corresponds to measuring the $k$ -th qubit in the computational basis, assigning $+ 1$ to $| 0 \rangle$ and $- 1$ to $| 1 \rangle$ .

For an independent quantum circuit with $n _ { q }$ qubits indexed by $i$ , this results in a real-valued feature vector:

$$
\mathbf { f } ^ { ( i ) } = [ f _ { 0 } ^ { ( i ) } , f _ { 1 } ^ { ( i ) } , \ldots , f _ { n _ { q } - 1 } ^ { ( i ) } ] ^ { \top } \in \mathbb { R } ^ { n _ { q } } .
$$

This vector encodes the response of the quantum circuit to the parameterized gates.

To scale this mechanism, multiple independent quantum circuits (indexed by $i = 1 , \ldots , n _ { c } )$ are instantiated in parallel. Each circuit has its own parameters $\pmb { \phi } ^ { ( i ) }$ and produces a feature vector $\mathbf { f } ^ { ( i ) } \in \mathbb { R } ^ { n _ { q } }$ . These are concatenated to yield a unified feature:

$$
\mathbf { F } = [ \mathbf { f } ^ { ( 1 ) } , \mathbf { f } ^ { ( 2 ) } , \ldots , \mathbf { f } ^ { ( n _ { c } ) } ] ^ { \top } \in \mathbb { R } ^ { n _ { q } \cdot n _ { c } } .
$$

This compact and expressive vector serves as the input to a subsequent classical neural network layer. During training, all parameters $\pmb { \phi } ^ { ( i ) }$ are differentiable, and their gradients ∂fk can be computed using automatic differentiation frameworks such as PennyLane [34], enabling seamless integration into classical backpropagation pipelines. Gradient descent optimization, such as Adam [36], is used to update parameters across all circuits in a unified training loop.

# C. QA-Net for Implicit Latent Generation

The $Q A$ -Net consists of $n _ { c }$ parallel quantum circuits, each operating on $n _ { q }$ qubits, followed by a classical linear mapping layer. It defines a function $\Psi : \phi \to \mathbb { R } ^ { n }$ , where $\phi \in \mathbb { R } ^ { n _ { c } \cdot n _ { q } }$ denotes the set of trainable quantum parameters. Increasing $n _ { q }$ enhances the expressive power of each circuit by expanding its entangled Hilbert space, while increasing $n _ { c }$ augments the overall latent dimension, enabling the model to represent a broader class of solutions with greater structural diversity. In this study, we set $n _ { q } = 2 , n _ { c } = 2$ to form a minimal quantumassisted module, balancing expressivity with hardware efficiency, as illustrated in Fig. 1. These circuits do not require explicit input but instead operate through parameterized quantum gates to produce a compact latent representation $\mathbf { F } \in \mathbb { R } ^ { 4 }$ . This latent vector is then passed to a classical linear layer, which maps it to the one-dimensional conductivity distribution $\Delta \sigma \in \mathbb { R } ^ { n }$ . The mapping is defined as:

$$
\Delta \pmb { \sigma } = \mathrm { S i g m o i d } ( \pmb { W } \mathbf { F } + \pmb { b } ) ,
$$

where $\pmb { W } \in \mathbb { R } ^ { n \times 4 }$ and $\pmb { b } \in \mathbb { R } ^ { n }$ are learnable parameters, and Sigmoid( ) denotes the element-wise logistic activation function, ensuring that the output values of $\Delta \sigma$ lie within the normalized range $[ 0 , 1 ]$ .

In this hybrid architecture, the quantum circuits act as expressive nonlinear mappings that implicitly regularize the reconstruction, enabling lightweight, training-free inference for solving ill-posed inverse problems such as EIT.

# D. QuantEIT for EIT image reconstruction

Within our QuantEIT framework, the unknown conductivity distribution is expressed as the output of the proposed hybrid quantum-classical $Q A$ -Net, denoted as $\Psi ( \pmb \theta )$ , where $\pmb \theta = ( \phi , W , \pmb b )$ , i.e.,

$$
\Delta \pmb { \sigma } ^ { ( k ) } = \Psi \left( \phi ^ { ( k ) } , W ^ { ( k ) } , \pmb { b } ^ { ( k ) } \right) = \Psi \left( \pmb { \theta } ^ { ( k ) } \right) ,
$$

where $k$ denotes the optimization step in the iterative reconstruction process. To fit the predicted voltages to the measured ones, the parameters $\pmb \theta$ are optimized by minimizing the following regularized loss:

$$
\begin{array} { r } { \mathcal { L } ( \pmb { \theta } ) = \| \Delta \mathbf { v } - \mathbf { J } \Psi ( \pmb { \theta } ) \| ^ { 2 } + \lambda ^ { \top } \mathcal { R } \big ( \Psi ( \pmb { \theta } ) \big ) , } \end{array}
$$

In our experiments, to further mitigate the ill-posedness inherent in EIT, we selected three commonly used and complementary handcrafted regularization terms—Laplacian smoothing [37], Total Variation (TV) [38], and $\ell _ { 1 }$ norm [13]. These regularizers provide synergistic constraints on different structural features, enhancing the robustness of our unsupervised reconstruction method under uncertainty. Accordingly, the regularization weight vector and the regularization function vector are defined as:

$$
\lambda = \left[ \begin{array} { c } { \lambda _ { \mathrm { L a p l a c i a n } } } \\ { \lambda _ { \mathrm { T V } } } \\ { \lambda _ { \ell _ { 1 } } } \end{array} \right] , \quad \pmb { \mathcal { R } } \big ( \boldsymbol { \Psi } ( \pmb { \theta } ) \big ) = \left[ \begin{array} { c } { \mathcal { R } _ { \mathrm { L a p l a c i a n } } \big ( \boldsymbol { \Psi } ( \pmb { \theta } ) \big ) } \\ { \mathcal { R } _ { \mathrm { T V } } \big ( \boldsymbol { \Psi } ( \pmb { \theta } ) \big ) } \\ { \mathcal { R } _ { \ell _ { 1 } } \big ( \boldsymbol { \Psi } ( \pmb { \theta } ) \big ) } \end{array} \right] .
$$

Accordingly, the model parameters at each iteration are updated as:

$$
\pmb \theta ^ { ( k + 1 ) } = \arg \operatorname* { m i n } _ { \pmb \theta } \mathcal L ( \pmb \theta ) ,
$$

where the optimization is performed using the Adam optimizer, which adaptively adjusts learning rates based on the first and second moments of the gradients.

After $N$ iterations, the final conductivity distribution is obtained by evaluating the model at the last parameter state:

$$
\Delta \sigma ^ { * } = \Psi ( \pmb { \theta } ^ { ( N ) } ) .
$$

![](images/8d15c28415cca5992879f0cea282256290ddb1dd09d82bcad924896947083ebb.jpg)  
Fig. 2. Illustration of the 2D and 3D simulation setups. The left shows the 2D thoracic cross-section with embedded lung regions and boundary electrodes. The right depicts the 3D thoracic model with two circumferential electrode layers and the internal lung structures.

![](images/b685ddf0d299cf5da9520117e1d1e505ef73a10668e10ff5c4db94874d3f0679.jpg)  
Fig. 3. Illustration of the lung phantom experiment setup.

![](images/c4f4a9bc724ed6f2af79ebb0ca765675a47ca028e0f4e19cfd42a935c8158c9e.jpg)  
Fig. 4. CT scans of Participant 2. (a) Sagittal view, (b) Axial view, and (c) Coronal view. The red boxes indicate dorsal lung volume loss consistent with posterior atelectasis.   
Fig. 5. Global impedance dynamics and thoracic CT images from Participant 3. (a) The impedance curve shows ventilation, breath hold, and perfusion phases. Key events—including the start of breath-hold, saline injection (reference), selected perfusion frames, and perfusion end—are marked with dots. (b) Representative axial CT slices.

a Global impedance Inhalation Exhalation Saline injection (reference) Start breath-hold Selected frames Perfusion End (frame 7) Ventilation Breath-hold Perfusion experiment   
b 00

Algorithm 1 QuantEIT for EIT Reconstruction   

<html><body><table><tr><td>Reconstruction Require: Normalized voltage △v, sensitivity matrix J, regu</td></tr><tr><td>larization weights入,number of iterations N 1: Initialize model parameters 0(O)= (𝜙(O),W(O),b(0))</td></tr><tr><td>2:for k=O to N-1 do 3: Compute conductivity update:△g(k)= 亚(0(k)) Compute loss:</td></tr><tr><td>4: L(0(k)）=△v-J△σ(k) +λTR(△σ(k))</td></tr><tr><td></td></tr><tr><td>5: Update parameters via Adam: 0(k+1) = Adam(0(k),Vθ L(0(𝑘)))</td></tr><tr><td></td></tr><tr><td>6: end for Ensure: Reconstructed conductivity distribution △g* 亚(0(N))</td></tr></table></body></html>

# III. EXPERIMENTAL SETUP

# A. Simulation Data Generation

We employed COMSOL Multiphysics (v6.1) to simulate 2D and 3D EIT measurements using anatomically realistic thoracic models derived from CT scans, as illustrated in Fig. 2. In the 2D setup, 16 electrodes were uniformly arranged along the boundary of the thoracic cross-section, with the lung regions positioned centrally. In the 3D setup, 32 electrodes were evenly distributed in two circumferential layers enclosing the 3D lung geometry.

The background conductivity was set to $0 . 2 4 ~ \mathrm { S / m }$ in both the 2D and 3D simulation cases. In the 2D model, the left lung conductivity was assigned $0 . 1 7 ~ \mathrm { S / m }$ and the right lung $0 . 1 4 ~ \mathrm { S / m }$ , simulating a scenario of left lung ventilation impairment. This configuration was designed to evaluate whether different reconstruction methods can accurately distinguish multiple objects with varying conductivity levels within the same imaging domain. In the 3D model, both lungs were set to $0 . 2 0 \mathrm { S } / \mathrm { m }$ , representing the early phase of inhalation, to assess the capability of each method to reconstruct subtle conductivity changes. A total of 104 boundary voltage measurements were generated for the 2D case and 328 measurements for the 3D case, following the measurement protocol in [28].

# B. Lung Phantom Experiment Setup

Fig. 3 shows the lung phantom experiment setup. A customdesigned thoracic phantom was built to emulate lung ventilation dynamics, consisting of two inflatable lung sacs enclosed within a cylindrical housing and surrounded by evenly distributed electrodes. Air inlets on the top enable independent control of inflation via an external ventilator. Fig. 3(b) shows the real-world experimental setup, including a commercial mechanical ventilator, an artificial lung model, and an EIT system (Shenzhen Yuanlu Inc., EIT V100).

We simulated unilateral pulmonary atelectasis by ventilating only the left lung sac while keeping the right sac uninflated. Voltage measurements were acquired using the same measurement paradigm as in the 3D simulation. The frame prior to ventilation was selected as the reference, while the frame captured at the onset of left lung inflation—when the left sac just begins to expand—was used as the observation. This setup offers a controlled yet realistic scenario to evaluate the reconstruction performance of different algorithms. Specifically, the reference-to-observation transition involves only minor conductivity changes, simulating a weak signal condition that challenges the algorithm’s ability to detect subtle physiological variations under realistic noise and uncertainties.

# C. Clinical Data Acquisition

Clinical data were acquired through real-world experiments. The study protocol was approved by the Institutional Review Board (IRB) of Peking Union Medical College Hospital (approval number: I-24PJ1732). Prior to any data collection, written informed consent was obtained from participants using an IRB-approved consent form (version 2.0, dated July 22, 2024). All procedures complied with the Declaration of Helsinki and national ethical regulations. Participant data were anonymized to ensure confidentiality.

Three participants were enrolled. Participant 1 underwent 2D measurements using a 16-electrode belt. This participant had left lung ventilation impairment, consistent with the 2D simulation condition. Participants 2 and 3 underwent 3D EIT measurements using a dual-layer 32-electrode belt. Participants 1 and 2 underwent ventilation-only experiments, while Participant 3 underwent both ventilation and perfusion procedures. Throughout all procedures, participants remained in a semi-recumbent position and followed a controlled breathing protocol. All EIT voltage data were acquired using commercial systems (Shenzhen Yuanlu Inc.; V100 for 2D, V200 for 3D) following the same protocol as used in the simulation experiments. CT scans were also acquired for Participant 2 and Participant 3 to provide anatomical references for subsequent analysis (see Fig. 4 and Fig. 5b).

For Participants 1 and 2, the voltage measurements acquired at the start of inhalation were used as the reference. For Participant 1, the observation voltage was taken at the end of inhalation, capturing the full ventilation-induced conductivity change. For Participant 2, the observation voltage corresponded to the early phase of the breathing cycle, when the lungs had just begun to expand.

For Participant 3, the reference voltage was selected at the onset of pulmonary perfusion, as shown in Fig. 5a. Prior to the experiment, standard pre-checks were performed to confirm the patency of the central venous catheter, and a $5 \%$ hypertonic saline solution was prepared by mixing $1 0 \mathrm { m l }$ of sterile water with $1 0 \mathrm { m l }$ of $10 \%$ NaCl. During the procedure, an end-expiratory breath-hold maneuver was initiated under deep sedation to suppress spontaneous respiration (breathhold duration $< 8 s \dot { }$ ). Once a stable plateau appeared in the global impedance waveform, $1 0 \mathrm { m l }$ of the prepared saline was rapidly injected via the central line within 2 seconds. EIT data acquisition was simultaneously triggered to capture the impedance dynamics during the first-pass circulation of the contrast agent. A sequence of seven consecutive voltage frames was then selected to span the entire perfusion process for time-sequence reconstruction.

# D. Comparison Methods

We compare QuantEIT with two baselines. The first is Newton’s One-Step Error Reconstructor (Noser) [12], commonly used in clinical settings [39]. The second is Regularized Shallow Image Prior (R-SIP) [28], the state-of-the-art unsupervised learning approach for 2D and 3D EIT. R-SIP combines handcrafted regularization with shallow neural networks to enhance reconstruction robustness and performance. We set the Noser parameter $\mu$ to 20 based on trial and error. For RSIP, we adopted the optimal parameter configurations reported in [28] to ensure fair comparisons.

# E. Implementation Details

We set both $n _ { q }$ (the number of qubits per circuit) and $n _ { c }$ (the number of parallel quantum circuits) to 2 to construct an ultra-lightweight quantum-assisted network. Notably, choosing $n _ { q } ~ = ~ 2$ corresponds to the minimal configuration required to introduce entanglement between qubits. This configuration provides a compact yet expressive latent space while maintaining compatibility with near-term quantum hardware.

For all simulation and real-world experiments, the number of optimization iterations was fixed to 1000. The learning rate was set to 0.05 for the 2D simulation and real-world experiments, while a higher value of 0.1 was employed for the 3D simulation and real-world experiments based on convergence curve analysis under different learning rates. For the 2D simulation and real-world experiments, the regularization weight vector $\lambda ^ { \top }$ was set to [0.03, 0.002, 0.01] and [0.05, 0.03, 0.1], respectively, based on trial and error. For the 3D simulation and real-world experiments, $\lambda ^ { \top }$ was fixed at [0.001, 0.001, 0.001].

# IV. RESULTS AND DISCUSSION

# A. Simulation Experiments

1) Convergence and Noise Resistance: We evaluated the convergence behavior of QuantEIT using both 2D and 3D simulation measurements (see Figure 6a). Specifically, we performed identical reconstruction tasks under different learning rates and plotted the loss curves over iterations to identify the optimal learning rates. We observed that excessively large learning rates led to oscillations in the loss, while overly small learning rates resulted in slow convergence. Based on the convergence curves, we determined that a learning rate of 0.05 for the 2D scenario and 0.1 for the 3D scenario yielded the fastest and smoothest convergence.

We further investigated the robustness of QuantEIT to measurement noise using 2D simulation data. We introduced additive Gaussian noise to the voltage inputs to simulate signal-to-noise ratios (SNRs) ranging from 10 dB to $6 0 ~ \mathrm { d B }$ . As shown in Figure 6b, the left panel plots the loss curves during optimization, which converge smoothly across all SNR levels. The right panel presents four quantitative metrics as functions of SNR: Correlation Coefficient (CC), Peak Signalto-Noise Ratio (PSNR), Relative Error (ERR) [28], and Mean Structural Similarity Index (MSSIM) [40]. The results indicate that QuantEIT maintains high reconstruction quality for SNRs above $3 0 ~ \mathrm { d B }$ . Even under strong noise conditions $( 1 0 – 2 0 \mathrm { d B } )$ , the performance degradation remains within approximately $10 \%$ , demonstrating the strong noise resilience of our method.

![](images/03987ef220ceee3041c2a210b22c28e89d821fab545a0050582a0b3f4ec6c555.jpg)  
Fig. 6. Convergence and robustness analysis of QuantEIT. (a) Convergence under different learning rates for 2D (left) and 3D (right) simulations. (b) Effect of noise level on 2D simulation: loss curves under different SNRs (left), and quantitative metrics (CC, PSNR, ERR, MSSIM) versus SNR (right).

2) Qualitative and Quantitative Reconstruction Results: To comprehensively evaluate the reconstruction performance, we adopted two protocols commonly used in EIT studies. For 2D simulations, max normalization was applied to the reconstructed conductivity distributions to emphasize the relative contrast and spatial variation, which is particularly relevant given the inherent scaling ambiguity in 2D inverse problems. In contrast, for 3D simulations, raw (unnormalized) reconstructions were assessed as a complementary analysis to evaluate the capability of each method to recover the magnitude of conductivity changes.

Fig. 7 presents qualitative reconstruction results for both simulation scenarios. In the 2D case (Fig. 7a), all three methods correctly reconstructed distinguishable bilateral lung contours and accurately captured the conductivity differences reflecting the non-ventilation condition in the left lung. However, Noser exhibited limited fidelity in recovering the detailed lung structures, while both R-SIP and QuantEIT produced clearer boundary delineation. Notably, QuantEIT achieved superior structure preservation, along with a cleaner background and reduced artifacts. For the 3D case (Fig. 7b), volumetric reconstructions and representative slices along the x-, y-, and z-axes are displayed. All three methods successfully reconstructed distinguishable bilateral lung regions. Compared to Noser, R-SIP yielded better structural delineation but suffered from pronounced spurious noise and less accurate conductivity values. QuantEIT achieved the most accurate and visually coherent reconstruction, exhibiting the clearest lung contours, the most faithful conductivity levels, and substantially cleaner background with fewer artifacts.

![](images/d11d0c8c847a072f520b13dceb9fd48e2b98ada6792fe7423bf0158ec37f0a8a.jpg)  
Fig. 7. Qualitative comparison of 2D (a) and 3D (b) EIT simulation reconstruction results across different algorithms. Red boxes highlight regions with apparent artifacts.   
Fig. 8. Quantitative comparison of 2D (a) and 3D (b) EIT simulation reconstruction results across different algorithms.

![](images/1f9266ee3c5383a5638f0b39067cf34e661196dc46d2b244d224f28027faced8.jpg)  
Fig. 9. Ablation study of the proposed QuantEIT on 3D simulation.

Quantitative evaluations are summarized in Fig. 8. For 2D simulations (Fig. 8a), QuantEIT achieved the highest CC (0.87), PSNR (18.56 dB), and MSSIM (0.93), as well as the lowest ERR (0.54), outperforming Noser and R-SIP across all metrics. In 3D simulations (Fig. 8b), QuantEIT again exhibited superior quantitative performance with a CC of 0.80, PSNR of 29.84 dB, and MSSIM of 0.81, alongside a markedly lower error of 0.56 compared to other methods. These improvements indicate that QuantEIT not only enhances relative spatial contrast but also achieves more accurate absolute conductivity reconstruction in 3D volumes.

![](images/9af4eeb04e644e3a82c79b7fc807a3be9ccb2f8291a0370c6893ad11c8356f3c.jpg)

TABLE I COMPUTATIONAL COMPLEXITY AND INFERENCE TIME COMPARISON   

<html><body><table><tr><td>Method</td><td>Task</td><td>#Parameters</td><td>FLOPs</td></tr><tr><td>QuantEIT</td><td>2D</td><td>20,484</td><td>Negligible</td></tr><tr><td>QuantEIT</td><td>3D</td><td>204,804</td><td>Negligible</td></tr><tr><td>R-SIP</td><td>2D</td><td>8,854,096</td><td>17.72M</td></tr><tr><td>R-SIP</td><td>3D</td><td>82,618,960</td><td>165.24M</td></tr></table></body></html>

Overall, the assessments consistently demonstrate the effectiveness of QuantEIT in recovering both the structural and numerical characteristics of 2D and 3D chest conductivity distributions.

3) Ablation Study: To further assess the contribution of the quantum-assisted latent embedding, we conducted an ablation study on the 3D simulation. The outputs of the quantum circuits were removed and replaced with vectors of the same dimensionality. We considered two variants: (i) constant vectors filled with ones and (ii) learnable latent vectors initialized randomly and optimized during training. As shown in Fig. 9, both configurations without quantum assistance failed to reconstruct any meaningful 3D structures, regardless of whether the latent representation was fixed or learned. In contrast, the proposed QuantEIT model, which employs quantum circuits to generate expressive non-linear latent inputs, successfully recovered the anatomical regions of the bilateral lungs with clear contours and consistent conductivity values closely matching the ground truth. These results demonstrate that the inherent entanglement and non-linearity of the quantum-assisted latent space provide essential prior information that cannot be substituted by either static or trainable embeddings.

4) Computational Complexity and Inference Time: We quantitatively compared the computational complexity and inference time of the proposed QuantEIT and the baseline RSIP across 2D and 3D reconstruction tasks. Table I summarizes the computational complexity of QuantEIT and R-SIP under different reconstruction scenarios. As summarized in Table I, QuantEIT exhibits a substantially smaller number of learnable parameters due to the use of a compact quantum-assisted latent representation and a single linear mapping layer. Specifically, QuantEIT contains only 0.02M parameters for 2D reconstruction and 0.20M parameters for 3D reconstruction, while R-SIP requires $8 . 8 5 \mathrm { M }$ and 82.62M parameters, respectively.

In terms of floating-point operations (FLOPs), R-SIP involves 17.72 million FLOPs for 2D reconstruction and 165.24 million FLOPs for 3D reconstruction. In contrast, QuantEIT does not rely on deep feedforward layers and therefore has negligible FLOPs in the classical computation path, aside from the single linear projection.

![](images/09c7097493b3933400826a393c103124183ea413bee74e0261a9c67f7fcd758a.jpg)  
Fig. 10. Scalability of inference time with respect to the number of pixels/voxels (log scale).

Despite its lightweight architecture, the inference time of QuantEIT is primarily bottlenecked by the CPU-based simulation of quantum circuits. As shown in Fig. 10, QuantEIT achieves nearly constant runtime across increasing output dimensions—18.14 seconds for 2D tasks $( 6 4 \times 6 4 )$ and 19.05 seconds for 3D tasks $( 3 2 \times 3 2 \times 4 0 )$ . This stability stems from its fixed-size quantum circuit, whose simulation cost dominates but does not scale with the number of pixels or voxels. In contrast, R-SIP is faster in 2D (5.02 seconds) but suffers from rapidly increasing inference time at higher resolutions, reaching 32.33 seconds in 3D and nearly 90 seconds at the highest tested resolution. This degradation is attributed to its fully connected layers, whose computational complexity scales poorly in high-dimensional settings.

These results highlight QuantEIT’s strong scalability and resolution-agnostic inference characteristics, making it particularly suitable for high-dimensional EIT tasks. All experiments were conducted on a laptop with an Intel Core i9-14900HX CPU and NVIDIA RTX 4090 GPU, using PennyLane to simulate quantum circuits in CPU mode.

Notably, further acceleration is possible if quantum simulation is offloaded to GPU or executed on quantum hardware. As PennyLane currently performs simulation on the CPU by default, particularly on standard Windows machines, future support for GPU backends such as those available on Linux systems with NVIDIA cuQuantum, or support for native quantum execution, could significantly reduce runtime.

# B. Phantom Experiments

Fig. 11b presents the 3D reconstruction results on the phantom dataset. The traditional Noser algorithm produces noisy and spatially diffuse structures, making it difficult to localize the ventilated region. R-SIP, limited by its shallow network architecture, fails to recover meaningful conductivity changes, resulting in a nearly blank reconstruction. In contrast, the proposed QuantEIT successfully reconstructs a compact and localized region of conductivity increase, which aligns with the left lung sac being ventilated. This demonstrates its superior capability in detecting subtle conductivity variations under weak signal conditions in real-world scenarios.

![](images/2b25fe0a7caf289dc8e8a7ebf882fa88e9079650fc911e910ca52e584ece403b.jpg)  
Fig. 11. Qualitative comparison of EIT reconstruction results across different algorithms on (a) 2D clinical data (Participant 1), (b) 3D phantom data, and (c) 3D clinical data (Participant 2).

# C. Clinical Experiments

To further evaluate the clinical applicability of the proposed approach, we conducted experiments on real patient data. Fig. 11a illustrates the 2D reconstruction results of Participant 1. The proposed QuantEIT clearly reveals the non-ventilation region in the left lung, which is consistent with the clinical reference provided by the widely used Noser algorithm. Both R-SIP and QuantEIT produce sharper contour boundaries compared to Noser; however, QuantEIT demonstrates superior noise robustness and a cleaner background.

Fig.11c shows the 3D reconstruction results for Participant 2. To provide anatomical reference, a CT scan was performed, as shown in Fig.4. Specifically, Fig.4a and Fig.4b reveal partial posterior lung volume loss (highlighted by red boxes), while the anterior lung regions remain structurally intact, indicating localized dorsal lung collapse. This clinically confirmed abnormality serves as a radiological benchmark for evaluating reconstruction performance. Among the three methods, R-SIP struggles to capture subtle conductivity variations due to its shallow MLP architecture, resulting in sparse and anatomically implausible reconstructions. Noser roughly indicates the left posterior defect but suffers from noise artifacts and lacks spatial continuity. In contrast, the proposed QuantEIT achieves the most faithful reconstruction: as highlighted by the red boxes in Fig. 11c, it accurately delineates the bilateral lung contours and clearly recovers the posterior ventilation defects, closely matching the CT findings. These results demonstrate that QuantEIT provides both robust noise suppression and anatomically consistent reconstruction under clinically realistic conditions.

![](images/a0d34acf65904721fbe614d5d038918601481f51b7f95eacaf9fa1041702c3b0.jpg)  
Fig. 12. Qualitative comparison of EIT reconstruction results across different algorithms on 3D clinical data from participant 3.

Fig. 12 presents a qualitative comparison of 3D EIT reconstruction results from Participant 3 during the pulmonary perfusion phase (Frame 1 to Frame 7), across three algorithms. At Frame 1 (perfusion onset), impedance changes first appear near the cardiac region. The injected saline then gradually diffuses into both lungs by Frame 7. Noser captures early changes but produces blurry results. R-SIP shows weaker conductivity variation at Frame 1 and almost fails to reconstruct the perfusion signal at Frame 3. QuantEIT yields the most consistent and anatomically coherent results across all frames, accurately tracking the spatiotemporal perfusion process.

# V. CONCLUSION

We proposed QuantEIT, an ultra-lightweight quantumassisted inference framework for EIT reconstruction. By combining parallel 2-qubit quantum circuits with a single linear mapping layer, QuantEIT significantly reduces model complexity while maintaining high reconstruction quality. Extensive experiments on simulated and clinical 2D and 3D EIT lung imaging data demonstrated that QuantEIT consistently outperforms both traditional methods, such as Noser, and SOTA unsupervised approaches like R-SIP, achieving superior structural fidelity and noise robustness with only $0 . 2 \%$ of the parameters. These results underline the potential of hybrid quantum–classical models as practical and efficient solutions for ill-posed inverse problems. Importantly, the proposed approach can be readily deployed on conventional hardware via quantum simulation and provides a clear pathway for future extension to quantum hardware implementations. Future research will focus on scaling the approach to other reconstruction tasks such as CT and Positron Emission Tomography, exploring richer quantum circuit designs, and validating clinical applicability across broader scenarios.