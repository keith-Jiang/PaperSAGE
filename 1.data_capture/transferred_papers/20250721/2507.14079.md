# DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits

Garapati Keerthana, Manik Gupta

Abstract— Progress notes are among the most clinically meaningful artifacts in an Electronic Health Record (EHR), offering temporally grounded insights into a patient’s evolving condition, treatments, and care decisions. Despite their importance, they are severely underrepresented in largescale EHR datasets. For instance, in the widely used Medical Information Mart for Intensive Care III (MIMIC-III) dataset, only about $8 . 5 6 \%$ of hospital visits include progress notes, leaving gaps in longitudinal patient narratives. In contrast, the dataset contains a diverse array of other note types, each capturing different aspects of care.

We present DENSE (Documenting Evolving Progress Notes from Scattered Evidence), a system designed to align with clinical documentation workflows by simulating how physicians reference past encounters while drafting progress notes. The system introduces a fine-grained note categorization and a temporal alignment mechanism that organizes heterogeneous notes across visits into structured, chronological inputs. At its core, DENSE leverages a clinically informed retrieval strategy to identify temporally and semantically relevant content from both current and prior visits. This retrieved evidence is used to prompt a large language model (LLM) to generate clinically coherent and temporally aware progress notes.

We evaluate DENSE on a curated cohort of patients with multiple visits and complete progress note documentation. The generated notes demonstrate strong longitudinal fidelity, achieving a temporal alignment ratio of 1.089, surpassing the continuity observed in original notes. By restoring narrative coherence across fragmented documentation, our system supports improved downstream tasks such as summarization, predictive modeling, and clinical decision support, offering a scalable solution for LLM-driven note synthesis in real-world healthcare settings.

Index Terms— Electronic Health Records, Progress Notes, Longitudinal Modeling, Large Language Models, Clinical Text, MIMIC-III

# I. INTRODUCTION

C hLeIaNltIhCcAarLe sdyosctuemes.ntIat roen lrides aat tehnet hiesatrot eosf cmliondiecranl findings, diagnostic results, interventions, and care decisions throughout a hospital stay. Among these, progress notes,

Garapati Keerthana and Manik Gupta are with the Department of Computer Science and Information Systems, Birla Institute of Technology and Science, Pilani, Hyderabad Campus, Jawahar Nagar, Kapra Mandal, Medchal District, Telangana 500078, India (email: p20240505@hyderabad.bits-pilani.ac.in; manik@hyderabad.bitspilani.ac.in). ORCID: 0009-0009-5116-1553 (G.K.); 0000-0002-4977- 4299 (M.G.).

written daily by physicians and typically structured using the SOAP format (Subjective, Objective, Assessment, Plan), are essential. They capture a patient’s day-to-day evolution in health status and treatment response and serve as a shared reference for care team members [1]–[3]. Beyond bedside care, progress notes are foundational to secondary tasks such as clinical summarization, cohort analysis, billing, clinical natural language processing (NLP), and predictive modeling [4]–[8].

However, in real-world electronic health record (EHR) systems, progress notes are often missing, inconsistently documented, or copied forward across days with minimal updates potentially compromising both care quality and downstream data utility [9]–[11]. For instance, in the widely used MIMICIII critical care dataset, only about $8 . 5 6 \%$ of hospital visits include any progress notes [12]. The result is a striking narrative gap: although numerous clinical events take place during hospitalization, there is often no unified document that tells the full story of what transpired each day.

# A. Clinical data is fragmented across multiple note types

Despite the scarcity of progress notes, hospitals collect a wide array of other documentation. A single patient’s visit may include admission notes, radiology reports, nursing assessments, medication reconciliation logs, surgical summaries, consult notes, and discharge planning documents. Each note captures a partial view of care, yet no single note offers a complete narrative.

Table I summarizes the most common note types in MIMICIII. Collectively, they offer rich and complementary perspectives. For example, a radiology report may describe a chest X-ray finding of pneumonia, a nursing note may mention increased respiratory rate, and a pharmacy note may document antibiotic initiation. Yet, in the absence of a synthesized progress note, reconstructing the full clinical picture is left to human readers or to automated systems often ill-equipped to handle such heterogeneity.

# B. Granular challenges in generating progress notes from scattered evidence

Generating high-quality progress notes from diverse source notes is not a simple extraction task - it requires selection, interpretation, abstraction, and temporal alignment. Several core challenges arise:

TABLE I: Common MIMIC-III clinical note types with descriptions and typical sections.   

<html><body><table><tr><td>Note Type</td><td>Description</td><td>Common Sections</td></tr><tr><td>Admission note</td><td>Documents the patient's reason for hospital- ization and initial exam</td><td>Chief Complaint, History of Previous Ilness (HPI), Physical Exam</td></tr><tr><td>Consultation note</td><td>Specialist review and recommendations</td><td>Reason for Consultation,Assessment, Plan</td></tr><tr><td>Discharge planning</td><td>Coordination and preparation for patient</td><td>Education,Home Needs,Follow-up</td></tr><tr><td>Discharge summary</td><td>discharge Final narrative summary of the hospital stay</td><td>Hospital Course,Discharge Medications</td></tr><tr><td>ECG report</td><td>Interpretation of electrocardiogram results</td><td>Findings,Rhythm Analysis</td></tr><tr><td>Echo report</td><td>Interpretation of echocardiographic imaging</td><td>Ejection Fraction,Valve Assessment</td></tr><tr><td>Event note</td><td>Description of significant clinical events</td><td>Event Description, Clinical Response</td></tr><tr><td>Miscellaneous note</td><td>Informal or uncategorized documentation</td><td>Free-text</td></tr><tr><td>Nursing other</td><td>Observational notes not tied to shift transi-</td><td>Fluid Balance,Pain Assessment</td></tr><tr><td>Nursing shift</td><td>tions Shift-to-shift handoff documentation</td><td>Physical Assessment, Interventions</td></tr><tr><td>Nutrition note</td><td>Assessment of dietary needs and intake</td><td>Diet,Weight,Recommendations</td></tr><tr><td>Pharmacy note</td><td>Medication history and reconciliation</td><td>Medication List,Dose,Route</td></tr><tr><td>Procedure note</td><td>Details about performed clinical procedures</td><td>Technique, Complications</td></tr><tr><td>Progress note</td><td>Daily summary of clinical reasoning and</td><td>Subjective, Objective,Assessment, Plan</td></tr><tr><td>Radiology report</td><td>patient trajectory Diagnostic interpretation of imaging studies</td><td>Impression, Findings</td></tr><tr><td>Transfer note</td><td>Documentation of movement between hos- pital units</td><td>Status,Destination Unit</td></tr></table></body></html>

1) Data sparsity and label inconsistency: Few visits in public EHR datasets such as MIMIC-III contain progress notes, limiting supervised training. Even when present, progress notes may be labeled inconsistently (e.g., “Progress note - MICU” vs. “Daily note” vs. “SOAP”), with occasional misspellings like “Dischaarge Plan” or “Nursong Note,” complicating systematic parsing.

2) Semantic ambiguity and redundancy: Note titles are often ambiguous. A document labeled “Report” may contain radiology findings, nursing assessments, or other content. Similarly, notes titled “DC Plan” and “Discharge Planning” may contain duplicate text, leading to redundancy during input processing [13].

3) Lack of temporal linkage across documents: Notes are timestamped individually, but lack explicit linkage across a hospital course. This complicates the construction of a coherent chronological timeline especially when timestamps are inconsistent or missing altogether.

4) Length variability and computational bottlenecks: Note lengths vary dramatically from single-sentence procedure notes to multi-page nursing narratives. This poses challenges for large language models (LLMs) due to input length limits and results in trade-offs between truncation (information loss) and incoherent generation from overly short inputs.

5) Clinical reasoning and abstraction: Progress notes synthesize diverse findings into clinical assessments (e.g., “Tachycardia likely due to sepsis, given fever and leukocytosis”). This abstraction is a key part of physician reasoning but is difficult for generative models to emulate, especially when source inputs are descriptive rather than inferential.

These challenges highlight the inadequacy of single-note summarization or na¨ıve concatenation approaches. A clinically grounded generation method is required.

# C. Problem Statement

This work addresses the problem of automatically generating structured, clinically relevant, and temporally coherent progress notes for each hospital visit even when no such note exists by synthesizing scattered documentation across heterogeneous EHR inputs.

This task entails:

• Normalizing and categorizing noisy real-world notes into consistent formats.   
Structuring data across time to form visit-level context windows.   
Applying a generation framework that mimics clinical workflows and preserves narrative continuity.   
Evaluating output based on both textual fidelity and medical realism.

# D. Contributions

To address these challenges, we introduce DENSE (Documenting Evolving Notes from Scattered Evidence), a modular system for longitudinal progress note generation. Our core contributions are:

1) Unified note taxonomy and temporal alignment: A clinically informed re-categorization of noisy note labels in MIMIC-III into 16 consistent types (Table I), and a temporal segmentation mechanism that organizes notes into structured visit-centric timelines reflecting clinical workflows.   
2) Clinically informed retrieval-augmented generation: Extending retrieval-augmented generation (RAG) using clinically guided chunking and a vector database to retrieve temporally and semantically relevant evidence. This is then passed, along with prior visit summaries, to a LLM for structured generation. The retrieval approach

builds upon the CLI-RAG framework [14], adapted here for longitudinal synthesis across note types and visits.

3) Longitudinal evaluation benchmark: A curated goldstandard set of 56 patients from MIMIC-III, each with 10 to 57 hospital visits and fully documented progress note histories. This allows evaluation of synthetic note trajectories over extended patient timelines.

To our knowledge, this is the first work to (i) temporally align multi-type clinical note data into visit-structured timelines, (ii) generate autoregressive synthetic progress notes using evidence-aware retrieval across visits, and (iii) benchmark note generation in a longitudinal setting.

The remainder of this paper is organized as follows: Section II reviews related work, Section III details dataset curation, Section IV describes our system architecture, Section V presents experimental results, Section VI outlines implications and future directions, and Section VII concludes the paper.

# II. RELATED WORK

Prior research on clinical note generation spans several domains, including structured-to-text generation, single-visit synthesis, synthetic EHR construction, temporal modeling, and clinical evaluation but few, if any, unify these threads to tackle the synthesis of temporally coherent, visit-level progress notes from heterogeneous clinical evidence [15].

Initial efforts focused on translating structured clinical codes (e.g. International Classification of Diseases (ICD), Current Procedural Terminology (CPT) codes into natural language summaries. Melamud et al. [16] trained neural models to generate patient histories from coded sequences, while Tang et al. [17] emphasized learning patient representations from structured EHR timelines to support clinical classification. However, these approaches typically ignore the unstructured, richly contextualized narratives that physicians write such as progress notes and therefore fall short in replicating the depth of clinical reasoning.

More recently, attention has shifted to using large language models (LLMs) for note synthesis, particularly within single hospital encounters. Soni et al. [18] employed prompt-based generation over structured tabular data to synthesize progress notes, and Biswas et al. [19] applied similar models to simulated provider-patient dialogues. Lu et al.’s ClinicalT5 [20] adapted T5 for clinical summarization tasks by fine-tuning on discharge and radiology note pairs, showing strong results on individual-document generation. However, none of these systems model longitudinal context or integrate information across disparate note types and hospital days. Similarly, Palm et al. [21] focused on encounter-level documentation quality using the PDQI-9 rubric, but did not address how notes evolve over time.

Synthetic EHR generators such as Synthea [22], EMRBots [23], and medGAN [24] simulate patient-level data for benchmarking and experimentation. These tools are valuable for population-level modeling and data augmentation, yet primarily generate structured outputs like diagnosis codes and encounter sequences. They do not attempt to simulate the narrative, physician-authored documentation that underpins clinical decision-making. Representation models like ClinicalBERT [25] and Asclepius [26] have enabled downstream prediction tasks by improving contextual embeddings of EHR notes, but were not designed for generative tasks.

Longitudinal modeling in clinical NLP has been explored through topic models and dynamic embeddings. For instance, Dynamic Embedded Topic Models (DETM) [27] and Embedded Topic Models (ETM) [28] capture evolving disease themes over time by learning topic distributions from patient histories. Such models have been applied to patient trajectory clustering and outcome forecasting [29], but they are not used to generate fluent clinical narratives. In our work, we leverage these thematic frameworks not for generation, but as part of our evaluation: measuring whether the generated progress notes reflect plausible topical shifts over time.

Evaluation of clinical text generation remains an open challenge. Traditional metrics like BLEU and ROUGE offer limited insight into clinical fidelity due to their lexical surfacelevel comparison [30]. Palm et al. [21] introduced PDQI-9 to assess documentation on clinical dimensions such as completeness, organization, and plausibility, offering a more rigorous alternative. More recently, GPT-based evaluators have been used for realism and coherence assessments, but few works explicitly quantify longitudinal consistency across generated notes. Our evaluation suite extends prior efforts by incorporating semantic similarity, thematic alignment, and GPT-based realism across entire hospitalization trajectories.

Despite this rich body of work, key gaps remain. Existing systems rarely model autoregressive note generation over time, almost never integrate multiple note types (e.g., discharge summaries, consults, and nursing notes), and seldom leverage retrieval-augmented methods tailored to clinical tasks. Furthermore, evaluation remains focused on static text similarity or note-level realism, ignoring how well notes cohere over time.

Our framework, DENSE, bridges these gaps by synthesizing visit-level progress notes that are temporally coherent and clinically grounded. Built on a retrieval-augmented architecture inspired by CLI-RAG [14], DENSE aligns evidence across time and sources, generates notes autoregressively at each visit, and evaluates them for narrative continuity and medical plausibility advancing the frontier of generative modeling in real-world EHR systems.

# III. DATA EXPLORATION AND NOTE CATEGORIZATION

Electronic Health Records (EHRs) are composed of diverse, free-text clinical notes serving various roles throughout a patient’s care journey. The NOTEEVENTS table in the MIMICIII database [12] is a rich source of such documentation, spanning admission notes, radiology reports, ECG interpretations, physician notes, discharge summaries, and nursing observations. These are broadly classified using two metadata fields: CATEGORY and DESCRIPTION, which aim to represent the note type and purpose. However, the structure is highly inconsistent, characterized by extreme lexical variation, semantic ambiguity, and inconsistent labeling, posing challenges for downstream analysis.

Table II outlines the typical clinical significance of the most common note types found in MIMIC-III, informed by the original schema and prior literature

TABLE II: Common Note Categories and Their Clinical Relevance in MIMIC-III   

<html><body><table><tr><td>Note Category</td><td>Primary Clinical Content</td></tr><tr><td>Nursing/Other</td><td>Generic，unstructured care notes (e.g., "Report")；may include vitals,observa- tions,shift details.</td></tr><tr><td>Radiology</td><td>Imaging reports (CT,X-ray，MRI)，in- cludes anatomical observations,impres-</td></tr><tr><td>Discharge Summary</td><td>sions. High-level summary of diagnosis,inter- ventions,outcome,and follow-up.</td></tr><tr><td>Echo /ECG</td><td>Specialized test interpretations (cardiac function,electrical activity).</td></tr><tr><td>Nutrition /Pharmacy</td><td>Dietician assessments,medication admin- istration plans,sedation protocols.</td></tr><tr><td>Physician/ Progress Notes</td><td>Physician reasoning，status updates,re- sponse to treatment, ongoing plan.</td></tr><tr><td>Consult /Rehab</td><td>Specialist evaluations,therapy plans (e.g., PT, OT).</td></tr><tr><td>General ／Social Work /Case Management</td><td>Miscellaneous notes-often sparse,ambigu- ous,or duplicated.</td></tr></table></body></html>

Despite this broad categorization, the actual content and metadata within CATEGORY and DESCRIPTION fields display significant inconsistencies. For instance, under CATEGORY $\cdot = \prime$ Physician’, more than 800 distinct DESCRIPTION entries are found, including variants such as ”Physician Resident Progress Note”, ”Progress Note”, ”MICU Resident Progres Note”, and misspellings like ”Physican”. Similarly, the term “Report” appears under multiple categories including Nursing/Other, ECG, Radiology, and Echo, demonstrating both syntactic variability and semantic ambiguity.

A detailed audit of these fields across 2.4 million notes revealed several structural issues:

1) Syntactic Variability: Descriptions differ in case, punctuation, and phrasing (e.g., ”progress note”, ”Progress Note”, ”Progress note - MICU”).   
2) Semantic Ambiguity: Notes labeled under ”Generic Note” or ”Report” span nursing, radiology, and nutrition without meaningful distinction.   
3) Misspellings and Typos: Examples include ”Dischaarge Planning Update”, ”Nursong Progress Note”, ”Dishcarge”.   
4) Sparse Custom Labels: Long-tail of single-instance note types that defy categorization, such as ”Flumazenil Challenge”, ”Death Note”, ”Phone call to wife”.   
5) Ambiguity and Overloading: Categories such as General and Physician include an eclectic mix of note types including procedure notes, progress notes, and event records. This impedes downstream classification or modeling tasks.   
6) Redundancy and Noise: There are numerous nearduplicate or inconsistent labels within DESCRIPTION. For example, “DC Plan”, “Discharge Plan”, and “Dischaarge Planning Update” all refer to the same semantic construct but are logged separately.   
7) Sparse Documentation: Only about $8 . 5 6 \%$ of all visits in MIMIC-III include progress notes, making it difficult to use them as the primary narrative source for temporal modeling.   
8) Lack of Temporal Structuring: The existing schema does not explicitly encode time-aligned sequences of visits or notes across the patient timeline, nor does it link follow-up notes with prior events, despite being essential for longitudinal analysis [31]–[33].

Figure 1 shows the distribution of notes across the top 10 broad categories, revealing significant class imbalance. Note: “Nursing/other” refers to miscellaneous nursing documentation (e.g., vital signs, interventions) that does not fall under standardized nursing note templates, whereas “Nursing” includes structured nursing progress notes.

![](images/f65bf510b78ea41bc18f818406a976cf0b1c5765a7d92f2604bdd109f14a5230.jpg)  
Fig. 1: Distribution of Notes Across Broad Categories in MIMIC-III (Top 10).

# A. Reclassification Strategy

To resolve these issues, we applied a deterministic remapping function that uses regular expressions and semantic pattern matching over cleaned DESCRIPTION fields, with fallback logic using the original CATEGORY when needed. For instance, entries with “progress note” or shift-time patterns were mapped to progress notes or nursing shift notes, respectively, while vague or erroneous labels (e.g., “–error–”) were assigned to misc notes. This approach reorganized semantically overlapping or inconsistent labels into 16 coherent and clinically meaningful types (as seen in Table III), improving consistency while preserving original coverage.

Figure 2 shows the percentage of ICU stays covered by each reclassified note category. Notably, fewer than $9 \%$ of stays contain true physician-authored progress notes, highlighting a key motivation for synthetic note generation.

TABLE III: Granular Issues in Original MIMIC-III Note Categories and Their Resolution via Semantic Reassignment   

<html><body><table><tr><td>Original Issue</td><td>Examples</td><td>Resolved Category</td></tr><tr><td rowspan="3">Overloaded “Nursing/other” Sparseorambiguous “Physician”descriptions Multiple “Discharge</td><td>All 822K entries labeled only“Report”</td><td>nursing_other_notes</td></tr><tr><td>"Progress Note”, "Attending PN” “DCPlan”，“Discharge</td><td>Parsed by regex, e.g. progress notes with time stamps to progress_notes</td></tr><tr><td>Plan Note","Hospice Re- ferral" Consult",</td><td>Mapped to discharge_planning</td></tr><tr><td rowspan="3">"Consult”spread across categories like“Consult", "General","Physician” Ambiguous event types under “General” or "Physician” Short notes or error tags</td><td>"Cardiology “GI Consult”,“Critical Care Consult"</td><td>Consolidated to consult_notes</td></tr><tr><td>“Family Meeting", "Code Discussion", “Death Note”</td><td>Grouped under event_notes</td></tr><tr><td>"-error-”, "Generic Note", blank strings e.g."thoracentesis","in- tubation”in description</td><td>Mapped to fallback category misc_notes Mapped to procedure_notes</td></tr></table></body></html>

![](images/370682df5f2827b07dd86eb8634a2ea771313cdc804a58123df4796f7047c504.jpg)  
Fig. 2: Coverage of Each Note Category Across ICU Stays ( $\%$ of Patients)

This refined note taxonomy enables robust downstream applications, including semantic filtering, prompt conditioning, and longitudinal modeling, as described in Section IV.

# IV. METHODOLOGY

We present DENSE (Documenting Evolving Progress Notes from Scattered Evidence), a modular pipeline for generating SOAP-style progress notes that are temporally coherent and clinically grounded across patient visits. DENSE combines structured note-type reclassification, visit-level data pivoting, domain-specific preprocessing, hierarchical chunking, semantically filtered retrieval, and LLM-based generation as shown in Figure 3

# A. Data Processing and Visit-Level Construction

Note-Type Reclassification: We use over 2.4 million notes from the NOTEEVENTS table in MIMIC-III [12].

These are inconsistently labeled across broad categories (e.g., “Physician”, “Nursing”) and varied subcategories. To resolve this, we apply regular-expression heuristics and manual curation to standardize notes into 16 clinically meaningful types (e.g., progress notes, radiology reports, consult notes, nursing shift notes). This reclassification mitigates syntactic variability, semantic ambiguity, and category overload, providing a reliable basis for downstream tasks.

Visit-Level Pivoting: Using the harmonized note types, we construct a visit-centric dataset. Each row corresponds to a unique hospital admission indexed by SUBJECT ID and HADM ID, with columns for CHARTDATE and each of the 16 note types containing concatenated content from that visit. This structure supports longitudinal alignment and retrieval across time.

# B. Note-Type-Specific Preprocessing

Custom Cleaning Pipelines. Raw clinical notes are highly variable. To normalize content while preserving clinical semantics, we apply note-type-specific preprocessing. This includes standardizing section headers (e.g., History of Present Illness, Assessment and Plan), removing boilerplate templates, normalizing punctuation and spacing, and converting bulleted/tabular data to natural language.

Generic Preprocessing: We apply shared cleaning steps across all notes: Unicode normalization, de-identification (e.g., replacing $[ { ^ { * * } } , . . . ^ { * } { ^ { * } } ] { ^ { 3 } } )$ , bullet-to-paragraph conversion, and keyvalue consolidation. However, different note types (e.g., radiology vs. nursing) undergo tailored processing pipelines based on structure and clinical intent. Header templates are defined in a NOTE HEADERS dictionary, ensuring section-level integrity for downstream chunking.

# C. Evidence Retrieval with CLI-RAG

DENSE incorporates the CLI-RAG [14] retrieval framework to surface semantically relevant evidence for note generation.

Hierarchical Chunking: Each preprocessed note is first segmented by clinical headers using curated templates. Long sections are recursively split into overlapping windows (approx. 3000 characters, 300-character overlap). Each chunk is embedded using Sentence-BERT (all-MiniLM-L6-v2) into 384-dimensional vectors and indexed in ChromaDB with metadata (note type, section, visit ID, etc.).

Retrieval Strategy: Retrieval operates in two modes:

Global retrieval: Semantic search across all indexed chunks using SOAP-aligned queries (e.g., “What treatments were provided?”).   
Local retrieval: Targeted search within specific note types using refined prompts.

Retrieved evidence is deduplicated, filtered by recency and section relevance, and chronologically ordered. This step ensures that generated content reflects both thematic and temporal coherence.

![](images/1ea2f29b7cc710fea5130918a292601018a277a16b3091e84334d714fa996e80.jpg)  
Fig. 3: DENSE pipeline for generating structured SOAP-style progress notes. Annotated modules indicate where Clinically informed RAG is integrated as a retrieval component.

# D. Progress Note Generation via LLMs

Once semantically relevant chunks are retrieved for a given hospital visit, we construct structured prompts to guide large language models (LLMs) in generating high-quality, SOAPstyle progress notes. These prompts are carefully engineered to integrate multiple sources of information while maintaining clinical fidelity and narrative coherence.

For each visit, the prompting process begins with a preprocessing phase where the retrieved chunks are parsed and summarized to remove redundancy and noise. These chunks originating from up to 16 diverse note types (e.g., radiology, nursing, consults, etc.) are cleaned, section-tagged, and chronologically ordered to reflect the flow of clinical events during the visit. This step produces a synthesized prompt summary capturing the most salient clinical evidence across modalities.

In visits beyond the patient’s first, we incorporate a longitudinal aspect by referencing the previously generated progress note from the immediately preceding visit. Instead of simply appending the full earlier note, we produce a concise, clinically meaningful summary of that note, focusing on elements like ongoing problems, treatments, and follow-up plans. This temporal linkage allows the model to simulate the behavior of human clinicians who routinely reference prior notes to maintain continuity of care.

The prompting is carried out in two distinct modes: enrichment and temporal. In the enrichment mode, used exclusively for a patient’s first recorded visit, the LLM prompt is composed solely of the semantically relevant evidence chunks gathered via retrieval techniques. These chunks are drawn from whatever subset of the 16 note types is available for that visit and are designed to provide broad, diverse clinical context for note synthesis. In contrast, the temporal mode applied to all subsequent visits augments this enrichment mode prompt with a summary of the previous visit’s progress note, enabling longitudinal reasoning and coherence over time. This dualmode prompting structure is central to DENSE’s ability to replicate how clinicians integrate both current evidence and patient history when documenting care.

# E. Summary and Relation to Prior Work

DENSE advances the state of clinical note generation by integrating longitudinal reasoning into the generation process, something prior systems like CLI-RAG [14] do not explicitly support. While CLI-RAG serves as a powerful retrieval backbone for surfacing semantically relevant evidence, its design centers around single-visit summarization. In contrast, DENSE builds on this foundation to support multi-visit narrative construction, modeling how clinicians document a patient’s evolving story over time.

This is achieved through several innovations. First, visitlevel note aggregation enables the construction of temporally localized document corpora for each care episode. Second, MIMIC-III notes analysis-based preprocessing allow for consistent semantic segmentation of diverse clinical texts. Third, prompt engineering incorporates both enrichment and temporal components, mirroring the dual inputs clinicians rely on current evidence and prior context. Most crucially, by integrating previous synthetic notes into the prompt construction process, DENSE simulates continuity-aware documentation, enabling LLMs to generate progress notes that not only summarize the current visit, but also reflect the broader trajectory of the patient’s care.

In doing so, DENSE fills a key gap in the literature by enabling structured, temporally conditioned progress note generation across multiple visits. This capability marks a methodological shift from isolated note synthesis to coherent, longitudinal clinical storytelling.

# V. EXPERIMENTAL SETUP AND EVALUATION

This section details the empirical evaluation of the DENSE framework, focusing on its ability to produce clinically meaningful, temporally consistent progress notes across longitudinal patient trajectories. We describe the cohort selection, evaluation methodology, and provide a comprehensive analysis of results supported by quantitative metrics and visualizations.

# A. Dataset and Cohort Selection

To assess longitudinal note generation, we constructed a cohort of 56 patients from MIMIC-III, each with 10 to 57 documented hospital visits, resulting in a total of over 1,100 encounters. For every visit, DENSE generated a synthetic progress note, simulating what a clinician might document based on available clinical context.

For the first encounter of each patient, only concurrent clinical evidence from various note types was used to simulate documentation from a single point in time. For all subsequent visits, DENSE incorporated both current visit evidence and a summary of the previous visit’s note. This design mimics the natural behavior of clinicians, who reference past documentation to maintain continuity and adapt to a patient’s evolving condition.

The data was structured in a pivoted format where each row represented one visit, indexed by SUBJECT ID, HADM ID, CHARTDATE, and included 16 standardized clinical note types (e.g., discharge summaries, radiology reports, lab results, etc.) that served as potential sources of contextual information.

# B. Evaluation Metrics

We used a comprehensive suite of evaluation metrics to capture performance across lexical, semantic, structural, and temporal dimensions.

Lexical overlap was measured via BLEU and ROUGE scores. BLEU was predictably low (mean $= 0 . 0 1 1 6$ ), reflecting DENSE’s tendency to paraphrase and reframe information rather than match exact wording. ROUGE-1 (0.2738) and ROUGE-L (0.1102) showed reasonable token and sequencelevel similarity, indicating that key medical terms and phrases were preserved.

Semantic similarity was assessed using cosine similarity computed from ‘all-mpnet-base-v2‘ sentence embeddings, yielding a strong average score of 0.7398. This suggests that DENSE-generated notes remain faithful to the core meaning of clinician-authored notes.

SOAP structural completeness was evaluated manually for each note, with all generated notes receiving a perfect $4 . 0 / 4 . 0$ score for including the Subjective, Objective, Assessment, and Plan sections.

Length ratio (1.1975) indicated that generated notes were slightly longer on average than gold-standard notes, but remained within a reasonable margin providing additional context without excessive verbosity.

Importantly, to assess longitudinal quality, we introduced a temporal alignment metric. To compute the temporal alignment metric, we measure how semantically coherent a patient’s progress notes are across successive hospital visits. Specifically, for each patient, we compute the average pairwise cosine similarity between adjacent generated progress notes using embeddings from a Sentence-BERT model $( \mathsf { a } \mathsf { 1 } \mathsf { 1 } - \mathsf { m p n e t - b a s e - v } 2 )$ . This produces a temporal consistency score for the generated notes. We repeat this procedure on the original (gold) notes from MIMIC-III to obtain a baseline consistency score. The final temporal alignment ratio is computed as the quotient of the generated score over the gold score:

Mean Pairwise Similaritygenerated Temporal Alignment Ratio $\ b =$ Mean Pairwise Similaritygold (1)

This ratio captures how well the generated notes maintain longitudinal coherence compared to real clinician-authored notes. A score greater than 1 indicates higher temporal consistency in the synthetic notes. While this is a novel adaptation tailored for our longitudinal setting, it draws conceptually from prior work on semantic similarity and discourse coherence modeling [34], [35], but applies it specifically to clinical progress notes over time.

This measured how well adjacent progress notes remained semantically aligned over time, simulating a coherent patient journey. DENSE outperformed the original notes with a mean generated temporal consistency of 0.877 vs. 0.807, yielding an alignment ratio of 1.089 as shown in Table IV. Patientlevel alignment scores with respective generated temporal consistency and gold temporal consistency is shown in Fig 4

TABLE IV: Aggregate Evaluation Metrics Across 56 Patients (1,100 Visits)   

<html><body><table><tr><td>Metric</td><td>Mean Score</td><td>Interpretation</td></tr><tr><td>BLEU</td><td>0.0116</td><td>Low n-gram match,expected due to paraphrasing</td></tr><tr><td>ROUGE-1</td><td>0.2738</td><td>Reasonable unigram overlap</td></tr><tr><td>ROUGE-2</td><td>0.0743</td><td>Limited bigram match,re- flects stylistic variation</td></tr><tr><td>ROUGE-L</td><td>0.1102</td><td>Moderate longest common subsequence</td></tr><tr><td>Semantic Similarity</td><td>0.7398</td><td>Strong content-level align- ment</td></tr><tr><td>SOAP Structure Score</td><td>4.0 / 4.0</td><td>All sections present in gener- ated notes</td></tr><tr><td>Length Ratio</td><td>1.1975</td><td>Slightly more verbose,within acceptable range</td></tr><tr><td>Temporal Consistency (Gold)</td><td>0.807</td><td>Ground truth note consis- tency</td></tr><tr><td>Temporal Consistency(Gen-</td><td>0.877</td><td>Better than gold,high longi-</td></tr><tr><td>erated) Alignment Ratio (Gen/Gold)</td><td>1.089</td><td>tudinal fidelity Improved narrative stability</td></tr></table></body></html>

![](images/2ed1f932c7485315e0c5be9589d0597dcefd92ec62425c82610a0dc9b9892071.jpg)  
Fig. 4: Patient-level temporal alignment scores. Higher values reflect better semantic consistency over time. Values above 1.0 indicate higher longitudinal coherence in DENSE-generated notes compared to real notes.

# C. Summary

DENSE demonstrates strong potential for real-world use in longitudinal clinical documentation. Its generated notes maintain semantic fidelity, structural consistency, and most critically temporal continuity, outperforming even gold-standard notes in maintaining coherent clinical narratives across visits. This makes DENSE a valuable foundation for future EHR-integrated generative systems aimed at improving both provider efficiency and care quality.

# VI. DISCUSSION

The evaluation confirms that DENSE produces high-fidelity progress notes that are both semantically accurate and temporally coherent. Its design combining structured evidence retrieval with longitudinal conditioning enables continuity across visits, a key challenge in multi-encounter clinical documentation. The strong temporal alignment scores indicate that the system not only captures current clinical context, but also meaningfully integrates prior patient information, improving narrative stability over time.

By framing retrieval around note-type-specific inputs and summarizing past documentation, DENSE shifts generation from surface-level text modeling to grounded clinical synthesis. This behavior is especially valuable for maintaining SOAP structure and preserving clinical intent, even in the presence of paraphrasing and stylistic variation.

# A. Clinical and Research Implications

The ability to generate synthetic, high-quality longitudinal notes has immediate utility in both clinical and research settings - Data augmentation for longitudinal NLP tasks, such as prognosis modeling and phenotyping, Filling documentation gaps in incomplete or fragmented patient records and Building intelligent tools for real-time summarization, scribing, or audit support. These capabilities align with broader efforts to reduce clinician burden, while improving EHR data quality and downstream model performance [36].

# B. Future Directions

To further advance this work, future efforts should explore integration of clinician feedback for iterative refinement and alignment with documentation standards, extension to MIMICIV and real-world EHR systems for external validation, use of generated notes to enhance performance on low-resource or longitudinal prediction tasks and embedding safeguards to detect and mitigate hallucinations in generated content.

# VII. CONCLUSIONS

We introduce DENSE, a framework for generating temporally grounded and clinically faithful progress notes by combining structured multi-note retrieval with longitudinal prompt design. Unlike prior methods focused on single-visit summarization, our system incorporates past visit summaries to capture clinical evolution across time, improving coherence and fidelity in multi-visit narratives.

Our evaluation shows that DENSE-generated notes maintain SOAP structure, exhibit strong semantic overlap with reference notes, and outperform ground truth in temporal consistency, demonstrating its utility in modeling continuity of care.

Future work will focus on scaling DENSE to broader patient populations and specialties, integrating multimodal signals such as labs and vitals, and incorporating real-world physician feedback. With robust generalization and potential for downstream utility, DENSE represents a step forward in clinically aligned, AI-assisted documentation.