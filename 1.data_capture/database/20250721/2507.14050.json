{
    "source": "ArXiv (Semantic Scholar未收录)",
    "arxiv_id": "2507.14050",
    "link": "https://arxiv.org/abs/2507.14050",
    "pdf_link": "https://arxiv.org/pdf/2507.14050.pdf",
    "title": "Foundation Models as Class-Incremental Learners for Dermatological Image Classification",
    "authors": [
        "Mohamed Elkhayat",
        "Mohamed Mahmoud",
        "Jamil Fayyad",
        "Nourhan Bayasi"
    ],
    "categories": [
        "cs.CV"
    ],
    "publication_date": "未找到提交日期",
    "venue": "暂未录入Semantic Scholar",
    "fields_of_study": "暂未录入Semantic Scholar",
    "citation_count": "暂未录入Semantic Scholar",
    "influential_citation_count": "暂未录入Semantic Scholar",
    "institutions": [
        "Cairo University",
        "University of Victoria",
        "University of British Columbia"
    ],
    "paper_content": "# Foundation Models as Class-Incremental Learners for Dermatological Image Classification\n\nMohamed Elkhayat $^ 1$ \\*, Mohamed Mahmoud $^ 1$ \\*, Jamil Fayyad $^ { 2 \\dagger }$ †, and Nourhan Bayasi $^ 3$ †\n\n1 Cairo University, Giza, Egypt 2 University of Victoria, Victoria, BC, Canada 3 University of British Columbia, Vancouver, BC, Canada {Mohammed.Khayyat02, muhammad.mahmoud01}@eng-st.cu.edu.eg\n\nAbstract. Class-Incremental Learning (CIL) aims to learn new classes over time without forgetting previously acquired knowledge. The emergence of foundation models (FM) pretrained on large datasets presents new opportunities for CIL by offering rich, transferable representations. However, their potential for enabling incremental learning in dermatology remains largely unexplored. In this paper, we systematically evaluate frozen FMs pretrained on large-scale skin lesion datasets for CIL in dermatological disease classification. We propose a simple yet effective approach where the backbone remains frozen, and a lightweight MLP is trained incrementally for each task. This setup achieves state-of-the-art performance without forgetting, outperforming regularization, replay, and architecture-based methods. To further explore the capabilities of frozen FMs, we examine zero-training scenarios using nearest-mean classifiers with prototypes derived from their embeddings. Through extensive ablation studies, we demonstrate that this prototype-based variant can also achieve competitive results. Our findings highlight the strength of frozen FMs for continual learning in dermatology and support their broader adoption in real-world medical applications. Our code and datasets are available here.\n\nKeywords: Class-Incremental Learning · Continual Learning · Foundation Models · Dermatological Image Classification · Dermatology\n\n# 1 Introduction\n\nReal-world clinical applications rarely offer the luxury of independent and identically distributed (i.i.d.) data [15]. In dermatology, new disease classes or imaging variations may appear gradually as data is collected over time from different sources. Conventional models trained in a static setting often fail under these changing conditions [16], showing a sharp drop in performance on previously learned tasks when updated with new data; a problem known as catastrophic forgetting [26,4]. Continual learning (CL) aims to address this challenge by allowing models to learn new information while preserving past knowledge. Several setups within CL include Class-Incremental Learning (CIL) is one of the most challenging. In CIL, new classes are introduced over time, and the model must learn them without access to data from earlier tasks, making this a relevant setting in clinical workflows where storing or replaying patient data is often restricted due to privacy and ethical concerns.\n\nTo avoid forgetting without storing or replaying old patient data [11], researchers have explored regularization- and architecture-based strategies. Regularization methods penalize changes to important parameters [32], while architecturebased approaches expand the model or allocate task-specific components [36,5,10]. While effective in controlled settings, these methods face key limitations in clinical practice: regularization requires reliable importance estimates, which are often difficult to obtain in data-scarce environments, and architecture-based techniques introduce complexity and memory overhead. In contrast, foundation models (FM) trained on large-scale datasets have reshaped the landscape of CIL, offering robust, transferable features that generalize well with minimal finetuning [12]. Recent work in natural image domains shows that simply leveraging frozen FMs can significantly boost performance and reduce forgetting [19,20].\n\nMotivated by these findings, we turn to dermatology and ask: Can frozen FMs pretrained on large-scale dermatological data support CIL for skin lesion classification, or are specialized CL methods still necessary? To answer this, we present the first comprehensive evaluation of frozen dermatology FMs for continual skin lesion classification. Our setup is deliberately simple: the backbone remains frozen, and a lightweight MLP classifier is incrementally trained for each task. Surprisingly, this approach outperforms prior CIL methods, including regularization, replay, and architectural techniques, without requiring any finetuning. We also explore zero-training setups using prototype-based classifiers derived from FM embeddings, and through extensive ablation studies, demonstrate that variations of this method can significantly outperform existing approaches. Our results suggest that future dermatology-based CL research should start with FMs, rather than designing methods from scratch.\n\n# 2 Related Work\n\nClass-Incremental Learning for Medical Imaging. CIL has recently received growing attention in medical imaging, driven by the need for models that can learn new disease categories without forgetting prior knowledge, all while preserving patient privacy. This has spurred data-free methods that synthesize prior class representations instead of storing raw images. For example, Ayromlou et al. [1] use gradient inversion and novel loss functions to preserve class discriminability. Bayasi et al. [7,6,9] introduce a pruning-based approach that builds independent subnetworks to eliminate forgetting and support fair and generalizable CL. Others rely on regularization: Chee et al. [13] expand network capacity while retaining prior knowledge, and Chen et al. [14] use contrastive learning and distillation for class- and domain-incremental segmentation.\n\nFoundation Models in Continual Learning. Traditional CL methods often train feature extractors from scratch, making them vulnerable to catastrophic forgetting. Recent work has shown that leveraging frozen FMs can improve both stability and efficiency. In vision, methods like DualPrompt [30] and L2P [31] use prompt tuning on frozen backbones, while Janson et al. [19] showed that simple classifiers on frozen features can rival or outperform complex methods. In medical imaging, Yang et al. [34] used fixed encoders with Gaussian mixtures, Zhang et al. [35] introduced adapter modules, and Bayasi et al. [8] leveraged frozen model ensembles. Yet, the role of FMs in continual dermatology classification remains unexplored, leaving an important gap in the field.\n\n# 3 Methodology\n\n# 3.1 Problem Setup\n\nLet $\\mathcal { D } = \\{ ( \\mathbf { x } _ { i } , y _ { i } ) \\} _ { i = 1 } ^ { N }$ denote a dataset of skin lesion images, where $\\mathbf { x } _ { i } \\in \\mathbb { R } ^ { H \\times W \\times C }$ is an input image and $y _ { i } \\in \\{ 1 , 2 , \\ldots , C \\}$ is its corresponding class label. In the class-incremental learning (CIL) setup, the complete set of classes ${ \\mathcal { C } } =$ $\\{ 1 , 2 , . . . , C \\}$ is partitioned into $T$ disjoint subsets, ${ \\mathcal { C } } _ { 1 } , { \\mathcal { C } } _ { 2 } , . . . , { \\mathcal { C } } _ { T }$ , such that new classes are introduced sequentially over $T$ tasks. At each time step $t \\in \\{ 1 , \\ldots , T \\}$ , the model receives access only to a task-specific dataset $\\mathcal { D } _ { t } = \\{ ( \\mathbf { x } _ { i } , y _ { i } ) \\mid y _ { i } \\in \\mathcal { C } _ { t } \\}$ . No access is granted to prior task data $\\mathcal { D } _ { < t }$ , and storage of past examples is not allowed. The model must update its classification capabilities to accommodate new classes in $\\mathit { \\check { C } } _ { t }$ while preserving performance on all previously learned classes $\\textstyle { \\mathcal { C } } _ { < t } = \\bigcup _ { j = 1 } ^ { t - 1 } { \\mathcal { C } } _ { j }$ .\n\nLet $\\mathcal { F } _ { \\theta }$ be a dermatology FM with frozen parameters $\\theta$ , pretrained on a largescale skin lesion images. The parameters $\\theta$ remain fixed and are never updated during the continual learning (CL) process. For an input image $\\mathbf { x }$ , the model produces a feature embedding:\n\n$$\n\\mathbf { z } = \\mathcal { F } _ { \\boldsymbol { \\theta } } ( \\mathbf { x } ) \\in \\mathbb { R } ^ { d } .\n$$\n\nOur goal is to evaluate two CL baselines built on top of these frozen embeddings. The first one uses an MLP-based classifier, where a lightweight multi-layer perceptron is incrementally trained on top of the frozen embeddings for each new task. The second one adopts a prototype-based nearest-mean classifier (NMC), which requires no training. Instead, it computes a mean feature vector (prototype) for each class using the frozen features of the labeled training samples.\n\n# 3.2 Baseline 1: MLP-Based Class-Incremental Learning\n\nIn this baseline, we keep the FM frozen and train a lightweight MLP classifier incrementally across tasks.\n\n3.2.1. Training Phase. At each task $t$ , a new MLP head $h _ { t } : \\mathbb { R } ^ { d }  \\mathbb { R } ^ { | \\mathcal { C } _ { t } | }$ is trained on the frozen embeddings from $\\mathcal { D } _ { t }$ . The MLP has two hidden layers with ReLU activation and a softmax output:\n\n$$\nh _ { t } ( { \\bf z } ) = \\mathrm { S o f t m a x } \\left( W _ { 3 } \\cdot \\mathrm { R e L U } \\left( W _ { 2 } \\cdot \\mathrm { R e L U } ( W _ { 1 } { \\bf z } + { \\bf b } _ { 1 } ) + { \\bf b } _ { 2 } \\right) + { \\bf b } _ { 3 } \\right) ~ .\n$$\n\nTo support all seen classes, we concatenate the outputs of all MLPs learned up to task $t$ : $h ( \\mathbf { z } ) = \\operatorname { C o n c a t } ( h _ { 1 } ( \\mathbf { z } ) , \\dots , h _ { t } ( \\mathbf { z } ) )$ .\n\n3.2.2. Inference Phase. At test time, input image $\\mathbf { x }$ is passed through the frozen encoder and all MLP heads. The final prediction is made by taking the class with the highest probability across all tasks: $\\hat { y } = \\arg \\operatorname* { m a x } _ { c \\in \\mathcal { C } _ { \\leq t } } h ( \\mathcal { F } _ { \\theta } ( \\mathbf { x } ) ) _ { c }$ .\n\n# 3.3 Baseline 2: Prototype-Based Nearest Mean Classifier (NMC)\n\nThis baseline avoids training by using class-wise mean embeddings (prototypes) computed from frozen features.\n\n3.3.1. Training Phase. For each class $c \\in { \\mathcal { C } } _ { t }$ , we compute a class prototype $\\mu _ { c }$ by averaging the frozen embeddings of all class-wise training samples in $\\mathcal { D } _ { t }$ :\n\n$$\n\\mu _ { c } = \\frac { 1 } { | \\mathcal { D } _ { c } | } \\sum _ { ( \\mathbf { x } _ { i } , y _ { i } ) \\in \\mathcal { D } _ { t } , y _ { i } = c } \\mathcal { F } _ { \\theta } ( \\mathbf { x } _ { i } ) .\n$$\n\nThese prototypes are stored in a memory bank: $\\mathcal { M } _ { t } = \\{ \\mu _ { c } \\ | \\ c \\in \\mathcal { C } _ { t } \\}$ .\n\n3.3.2. Inference Phase. Given a test image $\\mathbf { x }$ , we extract its embedding $\\mathbf { z } =$ $\\mathcal { F } _ { \\boldsymbol { \\theta } } ( \\mathbf { x } )$ , then classify it by assigning the label of the nearest prototype across all seen classes: $\\begin{array} { r } { \\hat { y } = \\arg \\operatorname* { m i n } _ { c \\in \\mathcal { C } _ { \\leq t } } \\| \\mathbf { z } - \\mu _ { c } \\| _ { 2 } } \\end{array}$ .\n\n# 4 Experiments and Results\n\nWe evaluate our two FM-based CL baselines on the task of skin lesion classification under the CIL setting, where new sets of classes are introduced sequentially without access to previous data. Details are given next.\n\n# 4.1 Experimental Setup\n\nDatasets. Our experiments are conducted on three publicly available dermatology datasets: HAM10000 (HAM) [28], Dermofit (DMF) [2], and Derm7pt (D7P) [21], comprising 10,015 1,211, and 963 dermoscopic images, respectively. These datasets were collected from diverse clinical sources and span a subset of seven skin lesion classes. To simulate a CIL scenario, each dataset is partitioned into $T$ tasks with mutually exclusive class labels. We adopt the dataset splits and experimental protocol from [8] to ensure fair and consistent comparison.\n\nImplementation Details. We evaluate our baselines using two dermatologybased FMs: the Google Derm model [18], a publicly released FM trained on over 400 skin conditions, and PanDerm [33], a large-scale FM pre-trained on millions of clinical and dermoscopic dermatology images. Both models are used as frozen feature extractors throughout the continual learning process, with no fine-tuning. The MLP-based classifier is trained using the Adam optimizer (learning rate 0.001, batch size 200) with cross-entropy loss. Training runs for up to 200 epochs per task, with early stopping based on validation accuracy to mitigate overfitting. Reference Methods and Competitors. We compare our baselines with three standard reference methods: SINGLE, which trains separate models for different tasks and deploys a specific model for each task during inference; JOINT, which aggregates the data from all tasks as a consolidated dataset to jointly train a single model (aka. multitask learning); and SeqFT, which fine-tunes a single model on the current task, without any countermeasure to forgetting. We compare against several CL competitors, including two regularization-based methods: EWC [22] and LwF [23]; two generative-based method: DGM [25] and BIR [29]; two replay-based method: iCaRL [27] and RM [3] and a frozen pretrained model-based method: Continual-Zoo [8].\n\nEvaluation Metrics. We report the balanced accuracy (BAAC), which accounts for class imbalance by averaging the recall across all classes, ensuring that each class contributes equally to the final score. Also, we report the forgetting measure $( \\mathbf { F } )$ , which quantifies how much the model forgets previously learned tasks: $\\begin{array} { r } { { \\bf F } = \\frac { 1 } { T - 1 } \\sum _ { i = 1 } ^ { T - 1 } \\operatorname* { m a x } _ { k \\in \\{ 1 , \\dots , T - 1 \\} } a _ { k , i } - a _ { T , i } } \\end{array}$ , where $a _ { k , i }$ is the accuracy on task $i$ after training on task $k$ , and $\\boldsymbol { a } _ { T , i }$ is the final accuracy on task $i$ after training on all $T$ tasks. A higher value of $\\mathbf { F }$ indicates more forgetting.\n\n# 4.2 Results and Analysis\n\nMain Results. Table 1 summarizes the performance of our two FM-based baselines across three skin lesion benchmarks. Our MLP-based models (Google Derm and PanDerm) consistently achieve state-of-the-art balanced accuracy (BAAC) while exhibiting zero forgetting ( $\\mathbf { F } = 0$ ), outperforming all existing CL methods including regularization, replay, and architecture-based approaches. On the HAM dataset, PanDerm with MLP achieves a BAAC of $9 2 . 2 5 \\%$ , surpassing even the upper-bound SINGLE model $( 8 8 . 3 5 \\%$ ) and strongly outperforming replaybased methods like RM. Similar trends are observed on DMF, where PanDerm with MLP reaches $9 3 . 1 1 \\%$ , exceeding the best non-foundation continual learning method, Continual-Zoo, by over 20 percentage points. On the D7P dataset, PanDerm again leads with a BAAC of $7 7 . 8 0 \\%$ , outperforming all methods.\n\nInterestingly, our NMC-based FM baselines, particularly with Google Derm, achieve comparable, and sometimes superior, results relative to other competing techniques. For example, NMC with Google Derm on D7P surpasses all CL methods and even JOINT. However, their performance lag behind their MLP counterparts, reflecting their inability to adapt to complex or overlapping class boundaries typical of medical imaging and skin lesion data. By contrast, MLPs can learn more flexible decision boundaries in the embedding space, better leveraging the rich features of the frozen FM. These results suggest that the choice of classifier plays an important role in realizing the full potential of frozen foundation features in the CIL setting. Motivated by this, we explore enhancements for NMC-based models in the subsequent ablation studies.\n\nTable 1. Performance evaluation of our FM-based baselines and existing methods on three skin lesion classification benchmarks in the CIL setting. Numbers in parentheses next to replay- or generative-based methods indicate the number of stored or generated samples per old class, respectively. Green and blue cells denote the best and secondbest results, respectively.   \n\n<html><body><table><tr><td rowspan=\"2\">Method</td><td colspan=\"2\">HAM</td><td colspan=\"2\">DMF</td><td colspan=\"2\">D7P</td></tr><tr><td>BAAC (↑)</td><td>F (↓)</td><td>BAAC (↑)</td><td>F(↓)</td><td>BAAC (↑)</td><td>F(↓）</td></tr><tr><td colspan=\"7\">ReferenceMethods</td></tr><tr><td>SINGLE</td><td>88.35</td><td>-</td><td>85.01</td><td>1</td><td>73.74</td><td></td></tr><tr><td>JOINT</td><td>82.13</td><td>=</td><td>80.66</td><td></td><td>68.32</td><td></td></tr><tr><td>SeqFT</td><td>51.54</td><td>50.76</td><td>37.21</td><td>55.25</td><td>36.51</td><td>52.18</td></tr><tr><td colspan=\"7\">CompetingMethods</td></tr><tr><td>EWC LWF DGM BIR</td><td>59.84 61.22 75.97</td><td>32.29 33.70 19.27 17.85</td><td>50.86 49.87 64.99 61.47</td><td>43.72 40.69 25.47</td><td>42.73 40.67 61.24</td><td>38.51 35.66 22.38</td></tr><tr><td>iCaRL (50) iCaRL (100)</td><td>74.39 70.80 73.27</td><td>18.44 14.97</td><td>64.32 68.49</td><td>19.18 20.17 18.27</td><td>62.90 60.84</td><td>19.65 24.78</td></tr><tr><td>RM (50)</td><td>73.61</td><td>16.83</td><td>63.73</td><td>16.73</td><td>63.72 63.05</td><td>19.28 22.57</td></tr><tr><td>RM (100)</td><td>76.32 78.15</td><td>15.92 11.09</td><td>70.14 72.51</td><td>15.22 14.21</td><td>65.87 68.04</td><td>20.17 17.58</td></tr><tr><td colspan=\"7\">Continual-Zoo Ours (Baseline1:FMwith MLP)</td></tr><tr><td>Google Derm</td><td>89.26</td><td>0</td><td>91.35</td><td>0</td><td></td><td></td></tr><tr><td>PanDerm</td><td>92.25</td><td>0</td><td>93.11</td><td>0</td><td>74.59 77.80</td><td>0 0</td></tr><tr><td colspan=\"7\">Ours (Baseline 2: FM with NMC)</td></tr><tr><td>Google Derm PanDerm</td><td>64.75 57.95</td><td>0 0</td><td>67.56 49.27</td><td>0 0</td><td>68.74 44.51</td><td>0 0</td></tr></table></body></html>\n\nAblation Studies. We conduct ablation studies to understand design choices in our approach: (1) exploring variants of the NMC classifier, and (2) evaluating the impact of replacing dermatology-specific FMs with general-purpose alternatives.\n\n1. NMC Classifier Variants. Table 2 reports the performance of several variants of the base NMC evaluated on HAM, DMF and D7P benchmarks. We begin with a straightforward yet effective enhancement: applying $\\ell _ { 2 }$ normalization to embeddings prior to centroid computation. This standardization consistently improves accuracy by better aligning the embedding space for distance-based decisions. For example, on DMF with Google Derm, accuracy increases from $6 7 . 5 6 \\%$ to $6 9 . 4 6 \\%$ . Next, we explore projection-based variants that transform embeddings before classification. Random projection [24] into a higher-dimensional Euclidean space yields limited gains; however, when combined with normalization, modest improvements are observed; for instance, PanDerm accuracy on DMF increases from $4 9 . 5 7 \\%$ to $5 4 . 3 8 \\%$ . The most substantial improvements arise from our learnable hyperbolic projection [17], which maps embeddings onto a hyperbolic manifold whose parameters are optimized during training. This projection explicitly captures hierarchical and relational structures among classes, adapting the embedding geometry to improve clustering and distance-based decision boundaries. The impact is significant: on HAM, accuracy rises from 64.75% to $8 1 . 4 1 \\%$ with the Google Derm model and from 57.95% to $8 0 . 2 4 \\%$ with PanDerm. Further, combining the hyperbolic projection with normalization boosts\n\nTable 2. Performance evaluation (balanced accuracy $\\%$ ) of different variations of the NMC classifier across three skin lesion classification benchmarks. Green cells denote the best results.   \n\n<html><body><table><tr><td rowspan=\"2\">Method</td><td colspan=\"2\">HAM</td><td colspan=\"2\">DMF</td><td colspan=\"2\">D7P</td></tr><tr><td>Derm</td><td>PanDerm</td><td>Derm</td><td>PanDerm</td><td>Derm</td><td>PanDerm</td></tr><tr><td>Base NMC (from Table1)</td><td>64.75</td><td>57.95</td><td>67.56</td><td>49.27</td><td>68.74</td><td>44.51</td></tr><tr><td>Base NMC+ Norm.</td><td>66.60</td><td>61.03</td><td>69.46</td><td>54.89</td><td>66.43</td><td>47.94</td></tr><tr><td>Random Projection</td><td>67.29</td><td>57.43</td><td>66.99</td><td>49.57</td><td>68.74</td><td>40.72</td></tr><tr><td>Random Projection + Norm.</td><td>66.11</td><td>62.06</td><td>66.20</td><td>54.38</td><td>68.46</td><td>47.27</td></tr><tr><td>Hyperbolic Projection</td><td>81.41</td><td>80.24</td><td>63.79</td><td>43.21</td><td>65.28</td><td>59.59</td></tr><tr><td>Hyperbolic Projection + Norm.</td><td>80.15</td><td>80.15</td><td>60.08</td><td>53.91</td><td>64.77</td><td>63.73</td></tr><tr><td>PCA</td><td>64.75</td><td>56.67</td><td>67.26</td><td>50.23</td><td>68.74</td><td>44.51</td></tr><tr><td>PCA+ Norm.</td><td>66.60</td><td>59.96</td><td>69.46</td><td>54.89</td><td>66.10</td><td>47.94</td></tr><tr><td>LDA</td><td>51.88</td><td>78.91</td><td>69.38</td><td>37.12</td><td>45.23</td><td>38.56</td></tr></table></body></html>\n\nTable 3. Performance evaluation (balanced accuracy $\\%$ ) of our FM-based baselines using a general-purpose foundation model (CLIP ViT-L/14). Green and blue cells denote the best and second-best results, respectively.   \n\n<html><body><table><tr><td>Method</td><td>HAM</td><td>DMF</td><td>一 D7P</td></tr><tr><td colspan=\"4\">OurBaselines</td></tr><tr><td>FMwithMLP</td><td>88.38</td><td>90.43</td><td>71.19</td></tr><tr><td>FM with NMC</td><td>53.53</td><td>70.13</td><td>46.01</td></tr><tr><td></td><td>NMC Classifier Variants</td><td></td><td></td></tr><tr><td>Base NMC + Norm. RandomProjection</td><td>55.11 52.15</td><td>71.26 69.99</td><td>46.52 43.79</td></tr><tr><td>Random Projection + Norm.</td><td>51.56</td><td>69.87</td><td>43.63</td></tr><tr><td>Hyperbolic Projection</td><td>80.05</td><td>53.50</td><td>59.59</td></tr><tr><td>Hyperbolic Projection + Norm.</td><td>80.05</td><td>57.20</td><td>60.10</td></tr><tr><td>PCA</td><td>53.53</td><td>70.13</td><td>45.86</td></tr><tr><td>PCA_+ Norm.</td><td>55.10</td><td>71.25</td><td>46.37</td></tr><tr><td>LDA</td><td>73.04</td><td></td><td></td></tr><tr><td></td><td></td><td>61.82</td><td>28.57</td></tr></table></body></html>\n\nPanDerm accuracy on D7P from $4 4 . 5 1 \\%$ to $6 3 . 7 3 \\%$ , yielding the strongest NMC results overall. While both the hyperbolic projection and the MLP classifier involve learnable parameters, they differ fundamentally. The MLP learns flexible, general mappings from embeddings to class predictions, requiring more extensive training. In contrast, the hyperbolic projection embeds data in a geometric space that models hierarchies, enhancing clustering and interpretability with fewer parameters and less risk of overfitting. We finally assess classical dimensionality reduction techniques. Principal component analysis (PCA), which preserves variance without explicitly optimizing class separability, does not improve performance, whereas Linear discriminant analysis (LDA), designed to maximize between-class variance, delivers mixed, unstable results: while it achieves $7 8 . 9 1 \\%$ on HAM with PanDerm, its performance deteriorates on other datasets due to the high intra-class variance. In summary, we conclude that normalization (as a non-learnable enhancement) and the hyperbolic projection (as a learnable enhancement) provide the most effective improvements to the NMC, each helping to narrow the gap to the MLP classifiers reported in Table 1 on different datasets. 2. General-Purpose vs. Domain-Specific FMs. To assess the importance of domain specialization, we repeat our experiments using a general-purpose FM—CLIP ViT-L/14 pretrained on natural images, replacing the dermatologyspecific model. Results are shown in Table 3. Despite lacking domain-specific pretraining, CLIP embeddings remain highly effective for parametric classifiers: the MLP achieves $8 8 . 3 8 \\%$ , $9 0 . 4 3 \\%$ , and 71.19% on HAM, DMF, and D7P, respectively, outperforming all prior CL methods. This supports our central claim: strong, transferable FM features, regardless of domain, can improve performance in CIL. In contrast, NMC variants suffer significant degradation. The base NMC achieves only $5 3 . 5 3 \\%$ on HAM and $4 6 . 0 1 \\%$ on D7P, far below its dermatologyinitialized counterpart. Interestingly, while normalization and hyperbolic projection again improve performance (e.g., HAM jumps from $5 3 . 5 3 \\%$ to $8 0 . 0 5 \\%$ ), they cannot fully bridge the gap, and their gains are inconsistent across datasets. Hyperbolic projection $^ +$ normalization achieves a strong $6 0 . 1 0 \\%$ on D7P but still trails the MLP by more than $1 1 \\%$ . LDA continues to show erratic behavior: while it produces $7 3 . 0 4 \\%$ on HAM (competitive with more structured NMC variants), it collapses entirely on D7P (28.57%), underscoring its sensitivity to class imbalance and feature distributions. Overall, these findings reinforce two observations: (1) parametric models like MLPs can extract meaningful decision boundaries from general-purpose FMs, making them highly effective for CIL; and (2) for other approaches like NMC that lack task-specific adaptation, alignment between the pretraining and target domain remains crucial.\n\n# 5 Conclusions\n\nThis work demonstrates the clear advantage of leveraging frozen foundation models as class-incremental learners in dermatological image classification. Through systematic evaluation across three skin lesion benchmarks, we show that a simple approach, which is training a lightweight MLP on top of a frozen dermatologyspecific backbone, can surpass upper-bound reference methods, without requiring complex regularization, replay, or architectural modifications. Remarkably, this MLP-based strategy maintains strong performance when built on generalpurpose models like CLIP ViT-L/14, further reinforcing the value of rich, pretrained features in CL for medical applications. These findings yield three key insights. First, foundation models should be considered the default starting point for future research in CL. Second, nearest-mean classifiers still benefit substantially from domain-specific pretraining due to their limited representational flexibility. Third, our results emphasize the importance of aligning model design with the geometric properties of the embedding space. Specifically, incorporating inductive biases, such as learnable hyperbolic projections, can significantly close the gap between simple prototype-based classifiers and other learnable models while offering greater simplicity and interpretability. Taken together, we hope this work encourages the community to rethink the foundations of CL; i.e., shifting from building methods from scratch toward designing smarter, lighter learning systems that build on the strengths of powerful pretrained models. A promising future direction is to explore dynamic backbone adaptation and taskaware prompt tuning to further improve flexibility while retaining the benefits of strong pretrained representations.",
    "summary": "```json\n{\n  \"core_summary\": \"### 🎯 核心概要\\n\\n> **问题定义 (Problem Definition)**\\n> *   论文解决的核心问题是皮肤病变分类中的类增量学习（Class-Incremental Learning, CIL）问题，即在不断引入新疾病类别的同时，避免对已学习知识的遗忘。\\n> *   该问题在临床应用中至关重要，因为现实中的皮肤病数据往往是动态增加的，且由于隐私和伦理限制，无法存储或重放旧患者数据。\\n\\n> **方法概述 (Method Overview)**\\n> *   论文提出了一种简单而有效的方法：使用预训练的基础模型（Foundation Model, FM）作为冻结的特征提取器，并在其上增量训练一个轻量级MLP分类器或使用原型分类器（NMC）。\\n\\n> **主要贡献与效果 (Contributions & Results)**\\n> *   **创新贡献点1：** 展示了冻结的基础模型在皮肤病变分类的CIL任务中可以达到最先进的性能，无需复杂的正则化或重放机制。\\n>     *   关键数据：在HAM10000数据集上，PanDerm+MLP的平衡准确率（BAAC）达到92.25%，显著优于所有基线方法。\\n> *   **创新贡献点2：** 探索了零训练的原型分类器（NMC），并通过归一化和双曲投影等改进，使其性能接近MLP分类器。\\n>     *   关键数据：在HAM10000数据集上，双曲投影+NMC的BAAC从57.95%提升到80.24%。\\n> *   **创新贡献点3：** 验证了通用基础模型（如CLIP）在缺乏领域特定预训练的情况下，仍能通过MLP分类器实现高性能。\\n>     *   关键数据：CLIP+MLP在HAM10000数据集上的BAAC为88.38%，优于大多数基线方法。\\n> *   **创新贡献点4：** 通过消融实验，证明了归一化和双曲投影对NMC性能的提升作用。\\n>     *   关键数据：在DMF数据集上，Google Derm+NMC的BAAC从67.56%提升到69.46%通过归一化。\",\n  \"algorithm_details\": \"### ⚙️ 算法/方案详解\\n\\n> **核心思想 (Core Idea)**\\n> *   论文的核心思想是利用预训练的基础模型（FM）提供的强大且通用的特征表示能力，通过冻结其参数避免灾难性遗忘，并在其基础上增量学习轻量级分类器。\\n> *   这种方法有效的原因是FM在大型数据集上预训练后，已经学习到了丰富的特征表示，能够泛化到新的类别和任务。\\n\\n> **创新点 (Innovations)**\\n> *   **与先前工作的对比：** 传统的CIL方法通常需要复杂的正则化、重放或架构扩展，而这些方法在临床环境中可能不切实际或效率低下。\\n> *   **本文的改进：** 本文提出了一种极简的方法，仅需冻结FM并增量训练一个轻量级MLP或使用原型分类器，避免了存储旧数据或设计复杂机制的需求。\\n\\n> **具体实现步骤 (Implementation Steps)**\\n> 1.  **特征提取：** 使用预训练的FM（如Google Derm或PanDerm）作为冻结的特征提取器，输入图像$x$得到嵌入$z = F_\\\\theta(x)$。\\n> 2.  **MLP分类器训练：** 对于每个新任务$t$，训练一个轻量级MLP分类器$h_t$，其输出为$h_t(z) = \\\\text{Softmax}(W_3 \\\\cdot \\\\text{ReLU}(W_2 \\\\cdot \\\\text{ReLU}(W_1 z + b_1) + b_2) + b_3)$。\\n> 3.  **原型分类器（NMC）：** 对于每个新类别$c$，计算其原型$\\\\mu_c$作为该类所有训练样本嵌入的平均值，分类时选择最近的原型$\\\\hat{y} = \\\\arg\\\\min_{c} \\\\|z - \\\\mu_c\\\\|_2$。\\n> 4.  **改进NMC：** 通过嵌入归一化、随机投影或双曲投影等技巧提升NMC的性能。\\n\\n> **案例解析 (Case Study)**\\n> *   论文未明确提供此部分信息。\",\n  \"comparative_analysis\": \"### 📊 对比实验分析\\n\\n> **基线模型 (Baselines)**\\n> *   论文对比了多种基线方法，包括SINGLE（每个任务单独训练模型）、JOINT（多任务联合训练）、SeqFT（顺序微调）、正则化方法（EWC、LwF）、生成方法（DGM、BIR）、重放方法（iCaRL、RM）以及Continual-Zoo（基于冻结模型的集成方法）。\\n\\n> **性能对比 (Performance Comparison)**\\n> *   **在平衡准确率（BAAC）上：** 本文方法（PanDerm+MLP）在HAM10000数据集上达到了92.25%，显著优于最佳基线Continual-Zoo（78.15%）和重放方法RM（76.32%）。与表现最佳的基线相比，提升了14.1个百分点。\\n> *   **在遗忘度量（F）上：** 本文方法（PanDerm+MLP）的遗忘度量为0，表明完全没有遗忘，而正则化方法EWC的遗忘度量为32.29，重放方法RM的遗忘度量为15.92。\\n> *   **在零训练场景下：** 本文的NMC+双曲投影在HAM数据集上达到了81.41%的BAAC，优于随机投影 (67.29%) 和PCA (64.75%)。\\n> *   **在通用基础模型上：** CLIP+MLP在HAM10000数据集上的BAAC为88.38%，优于大多数基线方法。\",\n  \"keywords\": \"### 🔑 关键词\\n\\n*   类增量学习 (Class-Incremental Learning, CIL)\\n*   持续学习 (Continual Learning, CL)\\n*   基础模型 (Foundation Model, FM)\\n*   皮肤病变分类 (Dermatological Image Classification, N/A)\\n*   原型分类器 (Nearest-Mean Classifier, NMC)\\n*   双曲投影 (Hyperbolic Projection, N/A)\\n*   医疗影像分析 (Medical Image Analysis, N/A)\\n*   归一化 (Normalization, N/A)\"\n}\n```"
}