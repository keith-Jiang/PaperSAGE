{
    "source": "ArXiv (Semantic Scholar未收录)",
    "arxiv_id": "2507.14077",
    "link": "https://arxiv.org/abs/2507.14077",
    "pdf_link": "https://arxiv.org/pdf/2507.14077.pdf",
    "title": "Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions",
    "authors": [
        "Temiloluwa Prioleau",
        "Baiying Lu",
        "Yanjun Cui"
    ],
    "categories": [
        "cs.AI",
        "cs.LG"
    ],
    "publication_date": "未找到提交日期",
    "venue": "暂未录入Semantic Scholar",
    "fields_of_study": "暂未录入Semantic Scholar",
    "citation_count": "暂未录入Semantic Scholar",
    "influential_citation_count": "暂未录入Semantic Scholar",
    "institutions": [
        "Emory University",
        "Dartmouth College"
    ],
    "paper_content": "# Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions\n\nTemiloluwa Prioleau∗   \nDepartment of Computer Science   \nEmory University   \nAtlanta, GA 30322   \ntpriole@emory.edu Baiying Lu †   \nDepartment of Computer Science Dartmouth College Hanover, NH 03755   \nbaiying.lu.gr@dartmouth.edu Yanjun Cui †   \nDepartment of Computer Science Dartmouth College   \nyanjun.cui.gr@dartmouth.edu\n\n# Abstract\n\nArtificial intelligence (AI) algorithms are a critical part of state-of-the-art digital health technology for diabetes management. Yet, access to large high-quality datasets is creating barriers that impede development of robust AI solutions. To accelerate development of transparent, reproducible, and robust AI solutions, we present Glucose-ML, a collection of 10 publicly available diabetes datasets, released within the last 7 years (i.e., $2 0 1 8 \\textrm { - } 2 0 2 5 )$ . The Glucose-ML collection comprises over 300,000 days of continuous glucose monitor (CGM) data with a total of 38 million glucose samples collected from $2 5 0 0 +$ people across 4 countries. Participants include persons living with type 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support researchers and innovators with using this rich collection of diabetes datasets, we present a comparative analysis to guide algorithm developers with data selection. Additionally, we conduct a case study for the task of blood glucose prediction - one of the most common AI tasks within the field. Through this case study, we provide a benchmark for shortterm blood glucose prediction across all 10 publicly available diabetes datasets within the Glucose-ML collection. We show that the same algorithm can have significantly different prediction results when developed/evaluated with different datasets. Findings from this study are then used to inform recommendations for developing robust AI solutions within the diabetes or broader health domain. We provide direct links to each longitudinal diabetes dataset in the Glucose-ML collection and openly provide our code: https://anonymous.4open.science/r/ GlucoseML_Diabetes_Datasets_NeurIPS2025-F5FC/.\n\n# 1 Introduction\n\nAn artificial intelligence (AI) algorithm is only as good as the data used for development and evaluation. As a result, access to high-quality datasets is a precursor for building robust AI algorithms. This fundamental principle motivates the growing effort to increase access to high-quality datasets and in so doing increase the transparency, reproducibility, generalizability, fairness, and robustness of\n\nAI algorithms, especially in human-centered domains like healthcare [91, 85, 79, 18, 71]. Yet, access to large high-quality datasets is a challenge in many health domains where a patients’ privacy and security is critical. This challenge motivates the target goal of making large volumes of health-relevant data accessible for research while minimizing potential risks and threats [55, 111, 83].\n\nDiabetes is an exemplar health domain in which AI algorithms are a critical part of state-of-the-art technology (e.g. for screening, decision-support, and management [41, 22, 30, 37, 102, 81]). The prevalence of digital health technology, such as wearable continuous glucose monitors (CGMs), insulin pumps, and activity trackers, is creating large volumes of longitudinal diabetes-relevant data that is critical to develop and evaluate transformational AI-driven solutions. However, progress within the field is hampered by the highly regulated nature of the healthcare industry, low interoperability across technology, and a fragmented research community. Consequently, data-centric researchers and innovators have limited or no access to large high-quality datasets for developing robust AI solutions.\n\nTo bridge this gap, we present Glucose-ML - a collection of longitudinal diabetes-relevant datasets to accelerate development and evaluation of transparent, reproducible, and robust AI solutions that can revolutionize the field. This study focuses on recent diabetes datasets that are publicly available through open or controlled access, and released within the last 7 years (2018 - 2025). All datasets in the Glucose-ML collection include real-world glucose data collected using clinically-validated CGMs across populations of people living with type 1 diabetes (T1D), type 2 diabetes (T2D), pre-diabetes (PreD), and people without diabetes. The key contributions of this work are:\n\n• We curate and present Glucose-ML - a collection of 10 publicly-available, diabetes-relevant datasets comprising longitudinal glucose data from over 2500 people across 4 countries, to support robust development and evaluation of AI-driven algorithms, models, and tools. Glucose-ML includes over 300,000 days of CGM data and a total of 38 million blood glucose samples.   \n• We present a comparative analysis of individual datasets within the Glucose-ML collection to highlight strengths and weaknesses of each dataset, and to guide algorithm developers with the dataset selection process when seeking to develop AI solutions.   \n• We present a case study for the common machine learning (ML) task of blood glucose prediction. Through this analysis, we characterize and compare the performance of two naïve prediction algorithms across 10 publicly available diabetes datasets. Additionally, we show that the same model can have significant performance differences for predicting glucose when developed/evaluated on different datasets.\n\nFindings from this study serve as a basis for recommendations to practitioners developing AI solutions for diabetes and within the broader health domain, especially as it relates to data selection, model design, and model evaluation.\n\n# 2 Background & Related Work\n\nWearable CGMs are minimally-invasive sensors for continuous monitoring of glucose trends [10]. Based on today’s technology, CGMs provide real-time glucose readings based on sensor measurements from the interstitial fluid [53]. Most CGMs record one glucose sample every 5 - 15 minutes depending on the manufacturer, and have a lifespan of 10 - 14 days [53]. CGMs are considered to be the standard of care for people living with T1D, and increasing evidence shows the benefit and effectiveness of CGM use in populations of people living with T2D [7, 65, 103]. Additionally, in recent years, CGM use is becoming more popular in populations of people with prediabetes, people without diabetes, and in sports [14, 47, 51, 54]. Other diabetes-relevant wearable devices that monitor and record longitudinal data include insulin pumps used for administering insulin (the hormone needed to metabolize glucose), and activity trackers used for monitoring relevant behavioral and physiological factors, such as physical activity, sedentary behavior, heart rate, body temperature, and sleep metrics [36, 97]. User-generated data from these digital health technologies is foundational for understanding diabetes management in outpatient settings and developing novel AI solutions to support care [104, 82, 24, 41, 51, 66, 9, 94].\n\nWhile there are existing efforts to increase access to and availability of high quality data in the diabetes domain, the fragmented nature of this interdisciplinary field has created silos between various stakeholders, including data creators and algorithm developers. For example, the Jaeb Center for Health Research (JCHR) - a nonprofit research center that conducts world class clinical trials with a core focus on T1D - provides public access to rich datasets from their studies [33]. However, the majority of these datasets are not leveraged within the AI and ML community for algorithmic innovation as evident from several literature reviews [31, 113, 116]. The most widely used publicly accessible datasets used for diabetes-relevant AI and ML tasks include: the Pima Indian Diabetes Dataset [116, 17, 78], UVA/Padova simulated dataset for T1D [67, 108], and OhioT1DM [68].\n\nThe Pima Indian Diabetes Dataset (PIDD) was originally collected by the National Institutes of Diabetes and Digestive and Kidney Diseases (NIDDK) and hosted on the UCI Machine Learning Database. This relatively small and static PIDD dataset that includes 8 distinct attributes from 768 Pima-Indian women (e.g. age, plasma glucose from a 2-hour oral glucose test, and diastolic blood pressure) has been used for ML research since year 2007 (18 years ago) and is still being used in year 2025 [86, 92, 101]. Conversely, the UVA/Pavoda Type 1 Diabetes simulator has been released in three versions (S2008 [56], S2013 [67], and S2017 [108]) each of which includes virtual T1D subjects (adults, adolescents, and children). The UVA/Pavoda simulated T1D datasets have been used extensively for AI and ML research toward automated insulin delivery systems for closed-loop blood glucose control (also known as an artificial pancreas) [35, 61]. While simulated datasets are critical for developing control algorithms, best practice guidelines show the need for AI/ML algorithms to also be evaluated on real-world data because algorithms evaluated on simulated data can perform poorly in real-world settings [48].\n\nAmongst the publicly-available, real-world, and diabetes-relevant datasets released in the last 10 years, the OhioT1DM dataset is the most widely in the AI and ML community [68, 31, 48]. The OhioT1DM dataset was originally published in 2018 and then updated in 2020. In total, this dataset comprises 8-weeks of time-matched CGM and insulin pump data from 12 people with T1D, as well as physiological data from a fitness band/activity tracker. The OhioT1DM dataset has been used extensively for developing and evaluating AI algorithms for blood glucose prediction [122, 123, 70, 117, 40]. While the OhioT1DM dataset has served as a good benchmark for developing and evaluating AI algorithms, it is limited by the small sample size and limited heterogeneity (e.g., all participants had T1D and used an insulin pump for diabetes management). Given this, it is expected that AI algorithms developed on such a small dataset could performed differently on a larger and more heterogeneous cohort with greater glycemic variability. To bridge the data challenge that stifles development and evaluation of robust AI solutions for diabetes and other time series modeling tasks [110], we present a collection of publicly-available longitudinal datasets from over 2500 people across multiple countries, including persons with T1D, T2D, pre-diabetes, and no diabetes.\n\n# 3 GlucoseML Overview\n\nOur collection of diabetes datasets - GlucoseML - includes 10 publicly available datasets with longitudinal data from wearable devices, including CGMs, from populations with diabetes (i.e., T1D and T2D) and populations without diabetes (i.e., prediabetes or no diabetes). This collection prioritizes recent datasets, released between year 2018 and 2025, from observational studies and/or retrospective data collections that are not influenced by a clinical intervention. The majority of datasets included in this collection are in alignment with the well-known FAIR data principles, such that each dataset is findable, accessible, interoperable, and reusable [112]. Additionally, all datasets include associated documentation that describe the dataset (e.g. through a publication or publicly accessible protocol).\n\nTable 1 provides an overview of the Glucose-ML collection which includes longitudinal glucose data from OhioT1DM [68, 69], T1DEXI [94], BIG IDEAs [13, 20], DiaTrend [89, 88], ShanghaiT1DM [119, 120], ShanghaiT2DM [119, 120], T1DiabetesGranada [95, 96], AI-READI [21, 6], UCHTT1DM [57, 58], and CGMacros [43]. From Table 1, we can observe the collection includes diabetes datasets collected in the U.S. $( 6 0 \\% )$ , China $( 2 0 \\% )$ , Spain $( 1 0 \\% )$ , and Chile $( 1 0 \\% )$ . There are a total of 2559 participants across the collection of datasets, between $1 2 \\cdot 1 0 6 7$ participants in each dataset, and a duration of 2 - 1907 days of glucose data per participant. Across the collection of datasets, there is a total of 313,043 days with at least 1 glucose reading from a wearable CGM and a total of 38,008,810 (i.e., over 38 million) glucose readings. More details about the population breakdown, age, hemoglobin A1C, and summary statistics on glycemic control for each individual dataset is presented in Appendix Table 3 and 4.\n\nTable 1: Overview of the Glucose-ML collection comprising 10 public diabetes datasets available for development of robust AI solutions.   \n\n<html><body><table><tr><td rowspan=\"2\">Pubicts ailable</td><td rowspan=\"2\">Accessibility</td><td rowspan=\"2\">Year</td><td rowspan=\"2\">Country</td><td rowspan=\"2\">Person</td><td colspan=\"2\">Man/Person</td><td rowspan=\"2\">Total Glucose</td></tr><tr><td></td><td></td></tr><tr><td>OhioT1DM [69,68]</td><td>Controlled</td><td>20201</td><td>US</td><td>12</td><td>54</td><td>48-57</td><td>166,533</td></tr><tr><td>T1DEXI [49, 94]</td><td>Controlled</td><td>2022</td><td>US</td><td>497</td><td>27</td><td>3-28</td><td>3,785,253</td></tr><tr><td>BIG IDEAs [20,13]</td><td>Open</td><td>2023</td><td>US</td><td>16</td><td>9.38</td><td>8-11</td><td>36,898</td></tr><tr><td>DiaTrend [88,89]</td><td>Controlled</td><td>2023</td><td>US</td><td>54</td><td>512</td><td>31-1907</td><td>7,680,740</td></tr><tr><td>ShanghaiT1DM[120,119]</td><td>Open</td><td>2023</td><td>China</td><td>12</td><td>15</td><td>7-42</td><td>15,695</td></tr><tr><td>ShanghaiT2DM[120,119]</td><td>Open</td><td>2023</td><td>China</td><td>100</td><td>13</td><td>4-41</td><td>112,475</td></tr><tr><td>T1DiabetesGranada [96,95]</td><td>Controlled</td><td>2024</td><td>Spain</td><td>736</td><td>350</td><td>8-1463</td><td>22,671,708</td></tr><tr><td>AI-READI² [6,21]</td><td>Controlled</td><td>2024</td><td>US</td><td>1067</td><td>11</td><td>2-13</td><td>2,880,509</td></tr><tr><td>UCHTT1DM [58, 57]</td><td>Open</td><td>2024</td><td>Chile</td><td>20</td><td>6</td><td>3-8</td><td>29,174</td></tr><tr><td>CGMacros [43]</td><td>Open</td><td>2025</td><td>US</td><td>45</td><td>11</td><td>8-20</td><td>629,825</td></tr><tr><td colspan=\"2\">Glucose-ML Total</td><td></td><td></td><td>2,559</td><td></td><td></td><td>38,008,810</td></tr></table></body></html>\n\nOhioT1DM was initially released in year 2018, then it was updated to the current version released in year 20   \n2This study leverages $\\mathbf { v } 2 . 0 . 0$ of the AI-READI dataset comprising data from 1067 participants that was collected between July 19, 2023 and July 31, 2024. 3The CGMacros dataset includes glucose values from both Dexcom and Freestyle Libre CGMs for each participant. This study leverages glucose values from only the Dexcom CGMs for analysis.\n\nThe specific sensors used for collecting glucose data across all datasets include CGMs manufactured by Medtronic (i.e. Medtronic Enlite and Guardian) [73], Dexcom (i.e., Dexcom G5, G6, and Pro) [27] and Abbott (i.e., FreeStyle Libre 1, 2 and Pro) [4]. In general, CGM sensors by Medtronic and Dexcom repeatedly measure glucose every 5 minutes, and have a lifespan of up to 7 days and up to 10 days respectively, after which the sensor should be replaced. Meanwhile, Freestyle Libre CGMs by Abbott measure glucose every 15 minutes and have a lifespan of up to 14 days after which the sensor should be replaced. These CGMs are clinically-validated and FDA-approved sensors that report glucose readings between the range of $4 0 - 4 0 0 \\mathrm { m g / d L }$ [25, 11].\n\n# 3.1 Dataset accessibility\n\nTable 1 shows that each individual dataset within the Glucose-ML collection is publicly available either through open or controlled access. The individual datasets are hosted on several hosting sites, including dedicated institutional sites [69], Vivli [109], Physionet [84, 39], Synapse [98], Figshare [44], Zenodo [3], FAIRhub [1], and Github [2].\n\n# 3.2 Ethics and fairness\n\nAll datasets within the Glucose-ML collection are reported to be obtained in accordance with the relevant ethical guidelines, including approval by an appropriate institutional review board (IRB) and all participants provided informed consent. These datasets are fully de-identified such that they do not contain personally identifiable data. Additionally, a data use agreement (DUA) is required for datasets released via controlled access. Conversely, the majority of open access datasets are released with an appropriate license, such as the Open Data Commons Attribution License and the Creative Commons Attribution-NonCommercial License. The three exceptions are the UCHTT1DM [58] and ShanghaiT1DM & ShanghaiT2DM [120] datasets which are released openly on Github and Figshare, but do not include an associated license.\n\n# 4 Comparative analysis of diabetes datasets\n\nIn this study, we conducted comparative analysis across all 10 publicly-available datasets within the Glucose-ML collection to elicit unique strengths and weaknesses of each dataset. Our comparative analysis can also guide in the process of selecting diabetes-relevant datasets to support development of robust AI solutions. While the majority of our analysis focuses on glucose data from CGMs, it is important to note that these datasets also include diabetes-relevant data from other sources such as insulin delivery systems, activity trackers, user logs/mobile apps, questionnaires/surveys, and medical\n\n# Glucose-ML Collection\n\nOhioT1DM: G, I, A, S, Q T1DEXI: G, I, A, S, Q, M BIG IDEAs: G, A, Q, M DiaTrend: G, I, Q, M ShanghaiT1DM: G, S, Q, M   \nShanghaiT2DM: G, S, Q, M T1DiabetesGranada: G, Q, M AI-READI: G, A, Q, M UCHTT1DM: G, I, A, S CGMacros: G, A, S, Q, M   \nContinuous Glucose Insulin Delivery Activity Self-Report / Questionnaire / Medical Record / Clinical Monitor (G) System (I) Tracker (A) Mobile App (S) Survey (Q) Measurement (M) 0 E 血 。 000 口 □ Glucose Insulin doses Heart rate User logs Carbohydrate input Step count (e.g. meal, exercise, Lab measurements Sleep metrics medication, life Demographic data (e.g. oral glucose Skin temperature events) (e.g. age, sex/gender, test, hemoglobin Accelerometry data diabetes duration, A1C, cholesterol, Galvanic skin response race/ethnicity, etc.) triglycerides, etc.)\n\nrecord/clinical measurements. Fig. 1 presents a comparative overview of various data sources and data types across individual datasets in the Glucose-ML collection. From this figure, we can observe that the T1DEXI dataset is potentially the most comprehensive dataset as it includes glucose data, insulin-related data (e.g. insulin doses and carbohydrate input), activity tracker data (e.g. heart rate, step count, sleep metrics), user logs (e.g., meals, exercise), demographic data (e.g. age, sex/gender, diabetes duration), and lab measurements (e.g. hemoglobin A1C). However, T1DEXI comprise a population of people with T1D only, and mean data duration is 27 days/person as shown in Table 1.\n\nFig. 2A presents a comparison of the populations and sample size represented in each individual dataset within the Glucose-ML collection. From this figure, we can observe that there are between 12 - 1067 participants in each individual dataset. Five out of the ten datasets are solely from cohorts with T1D $( 5 0 \\% )$ , one dataset is solely from a cohort with T2D $( 1 0 \\% )$ , while the remaining four datasets include participants with T2D, prediabetes, and no diabetes $( 2 0 \\% )$ , T1D and no diabetes $( 1 0 \\% )$ and prediabetes and no diabetes $( 1 0 \\% )$ . From Fig. 2B, we see that there are between 127 - 257,782 days of CGM data in each dataset. The majority of longitudinal diabetes datasets $( 8 0 \\% )$ include short durations of glucose data per participant (i.e., less than 60 days). Only DiaTrend [89] and T1DiabetesGranada [96] include long durations of glucose data per participant (i.e., more than 6 months, and in many cases, multiple years of longitudinal glucose data).\n\nGiven that glucose data in these longitudinal diabetes datasets is collected via wearable CGMs, missing data is not uncommon. Clinical consensus guidelines recommend the availability of more than $70 \\%$ of possible CGM readings to provide adequate glucose data for evaluating diabetes management [11, 25]. Therefore, in this study we leverage insights from prior work to identify missing CGM data when glucose readings are not present for more than three times the expected sampling rate of the distinct CGM used within each dataset (i.e., Dexcom, Medtronic, or FreeStyle Libre CGMs) [23, 32, 107]. For example, a Dexcom G6 CGM generally records glucose data every 5 minutes. Therefore, a period of missing data is identified when the difference between two consecutive timestamps of glucose readings has a duration of 15 minutes or more. Fig. 2C presents an overview of the percentage of CGM days with adequate (i.e., $\\geq 7 0 \\%$ ) versus inadequate glucose data for each dataset. From this figure, we can observe that all datasets included in our collection have sufficient glucose data (i.e., $< 2 5 \\%$ missing data) within the data collection period of each study.\n\nFinally, we compared the blood glucose dynamics of participants within each dataset using clinicallyvalidated metrics, namely time in glucose ranges [11]. These metrics quantify the percentage of glucose readings that are within the target/normal range of $7 0 - 1 8 0 \\mathrm { m g / d L }$ (TIR), below the target range (TBR), and above the target range (TAR). Fig. 2D presents an overview of the percentage of blood glucose values within the five clinically-relevant target ranges for each dataset. It is important to note that we only calculate the time in various glucose ranges on days with adequate glucose data (i.e., $> 7 0 \\%$ of CGM data available). From Fig. 2D, we can observe that DiaTrend [89] has the lowest TIR of $51 \\%$ , whereas the clinical recommendation for persons with T1D is to maintain a target TIR of greater than $70 \\%$ [11]. This significant difference between real-world blood glucose control in DiaTrend and the clinical recommendation shows that the DiaTrend dataset is the most dynamic and potentially the most challenging dataset to be used for developing and evaluating robust AI algorithms for populations with T1D. Conversely, the BIG IDEAs dataset [13, 20] which was collected from a population with prediabetes and no diabetes has the highest TIR of $9 7 . 6 \\%$ . This observation shows that BIG IDEAs dataset comprises more stable and in-range glucose dynamics so AI algorithms developed and evaluated solely on this dataset will likely report better performance due to the less challenging context.\n\n![](images/4dc1e418c11bd175ef3e898faa08775eb431e42173474c1676332565d65fdfc6.jpg)  \nFigure 2: Comparative analysis of sample size and population (A), longitudinal glucose duration (B), data quality and sufficiency (C), and glucose dynamics (D) across 10 public diabetes datasets.\n\n# 5 Case study: Blood glucose prediction\n\nInformed by several literature reviews within the field, we observed that blood glucose prediction is one of the most common task for which AI/ML algorithms are developed within the diabetes domain [5, 22, 31, 38, 41, 48, 113, 114]. This is a classic time-series prediction problem for which statistical, traditional, and deep learning methods have been used to solve in prior literature. Given this, we conduct a case study for the task of predicting blood glucose 30-minutes ahead using two naïve baseline methods recommended to serve as benchmarks for comparison with new and more advanced AI algorithms. The objective of this case study is not to present a novel AI algorithm for the task, but to characterize and compare the performance of naïve prediction algorithms across 10 publicly available diabetes datasets within the GlucoseML collection.\n\n# 5.1 Naïve Baseline Algorithms\n\nBuilding on best practice guidelines [48], we implement two naïve models, including 1) a zero-order hold predictor, and 2) a simple linear regression predictor, for the task of blood glucose prediction.\n\n• Zero-hold predictor (also known as a persistent baseline) simply assumes the predicted value will not change in the future. Therefore, when using a zero-hold predictor for blood glucose prediction 30-mins ahead, we simply use the exact glucose value 30 minutes prior as the prediction 30 minutes ahead. This baseline implementation is described as linear extrapolation in the work by Fox et al. [34].   \nSimple linear regression predictor fits a regression line across the most recent history of a given duration $( H )$ , then uses this regression line to predict blood glucose 30 minutes ahead [48]. In our implementation of a simple linear regression predictor, we used a history of between $1 0 \\textmd { - } 3 0$ minutes based on the sampling frequency of the specific CGM used for data collection within each dataset. For studies that used a Dexcom or Medtronic CGM, both of which record approximately one glucose reading every 5 minutes, we used a history duration of 10 minutes with the goal of having three consecutive glucose readings at $t$ , $t = 5 m i n s$ , and $t + 1 0 m i n s$ as the basis for fitting a regression line. Conversely, for studies that used a FreeStyle Libre CGM (i.e., ShanghaiT1DM & ShanghaiT2DM [119], and T1DiabetesGranada [95]), we used a history duration of 30 minutes with the similar goal of having three consecutive glucose readings $t$ , $t = 1 5 m i n s$ , $t + 3 0$ mins as the basis for fitting a regression line.\n\n# 5.2 Data Cleaning\n\nToward the goal of predicting blood glucose 30 minutes ahead using the aforementioned naïve baseline algorithms, we started by conducting simple data cleaning steps to remove unrealistic glucose readings within individual datasets in the GlucoseML collection. Our first data cleaning step included removing non-numeric glucose readings and glucose readings that are not within the standard CGM range of $4 0 - 4 0 0 \\mathrm { m g / d L }$ . Examples of excluded glucose recordings include recordings of \"LOW\" and \"HIGH\" in place of an actual glucose value in the AI-READI dataset. Following this, we removed consecutive glucose recordings with an unrealistic rate of change. Informed by the paper by DeSalvo and Buckingham, we removed consecutive glucose readings that were less than 30 seconds apart and/or that had a rate of change greater than $2 0 \\mathrm { m g / d L / m i n }$ , which is 5 times the reported rate of change for detecting missed meal boluses [26]. Table 5 in the Appendix provides a summary of the total glucose recordings in each dataset before the data cleaning steps, number of recordings excluded, and total glucose samples after data cleaning.\n\n# 5.3 Algorithm Implementation, Handling Missing Data, and Performance Evaluation\n\nSince our two naïve baseline algorithms have minimal or no parameters that need to be learned from a training dataset, our implementation of these methods was run on the full data duration of participants within the individual datasets (except for OhioT1DM). In the case of OhioT1DM [68] where a train/test split was provided by the original data creators, we evaluated the naïve algorithms on the apportioned test set only. However, our implementation did not require splitting the other datasets into a training, validation, and/or test set. Informed by best practice guidelines, we excluded periods of missing data from our analysis to avoid interpolation or extrapolation approaches that can introduce errors into the prediction model and reported accuracy [48]. Finally, to facilitate easy comparison of the performance of naïve prediction algorithms across 10 publicly available diabetes datasets, we report the accuracy of each prediction method using root mean squared error (RMSE) [46, 48]. A lower RMSE equates to less prediction error, while a higher RMSE equates to more prediction error and thus worse prediction performance.\n\nComputing Resources: All experiments were conducted on a MacBook Air (Apple M2 CPU, 8 GB and 16GB RAM), and run using CPUs only. The total estimated preprocessing time is $\\approx 7 0$ seconds. The runtime varied depending on the dataset duration, ranging from $\\approx 1$ minute to 4 hours per dataset. Per Table 1 and Appendix Table 5, we see that T1DiabetesGranada [95, 96] has the largest number of glucose samples (22.6 million) with an average of 1 year of glucose data per participant, and up to 4 years of glucose data across individual participants. As a result, this dataset required the longest runtime. The total estimated storage required for analysis in this study is $\\approx 8$ GB.\n\n![](images/17f64d0b05d838cd3a1c4ba4e653fa5550fae1bcb2839695886e782a90c6931a.jpg)  \nFigure 3: Performance overview for two naïve baseline algorithms, zero-order hold and simple linear regression, predicting blood glucose 30 minutes ahead using 10 publicly available diabetes datasets.\n\n# 5.4 Results for Blood Glucose Prediction\n\nFig. 3 and Table 2 present the results for predicting blood glucose 30 minutes ahead using the aforementioned naïve baseline methods. From Fig. 3, we observe that the zero-order hold predictor performed better as evident by the lower RMSE compared to the simple linear regression predictor in all 10 diabetes datasets. Given this, we will focus the rest of our analysis on the results from the zero-order predictor for assessing the performance difference across datasets. From Table 2, we observe that the zero-order hold predictor achieved the lowest RMSE of $1 6 . 1 \\pm 2 . 7 2 \\mathrm { m g / d L }$ on BIG IDEAs, meanwhile the same method achieved the highest RMSE of $2 8 . 1 4 \\pm 4 . 9 6 \\mathrm { { m g / d L } }$ on DiaTrend. A Mann-Whitney U test [72] was performed to compare the glucose prediction performance of the zero-order hold predictor on the BIG IDEAs and DiaTrend datasets. We found that there is a statistically significant difference in the glucose prediction performance of the same method on the BIG IDEAs dataset and the DiaTrend dataset; U-statistic $= 8$ , $Z = - 5 . 9 2$ , $p = 3 . 1 6 \\mathrm { e } { - 9 }$ . These findings suggest that the dataset used for developing a blood glucose prediction algorithm significantly affects the performance obtained.\n\nTo ensure a more fair comparison of blood glucose prediction performance across datasets, we identified diabetes datasets with T2D, preD, and ND for comparison, and diabetes datasets with T1D only for comparison. We performed a Mann-Whitney U test to compare the glucose prediction performance on the BIG IDEAs and CGMacros datasets, both of which are more comparable in the represented population. Similarly, we found that there is a statistically significant difference in the glucose prediction performance on these two groups; U-statistic $= 1 8 5$ , $Z { = } - 2 . 8 6$ , $p = 0 . 0 0 4$ . To also compare the prediction performance across T1D only datasets, we observed that the zero-order hold predictor achieved the lowest RMSE of $2 0 . 5 8 \\pm 3 . 3 9 \\mathrm { m g / d L }$ on the ShanghaiT1DM dataset and the highest RMSE of $2 8 . 1 4 \\pm 4 . 9 6 ~ \\mathrm { m g / d L }$ on the DiaTrend dataset - see Table 2. We also performed a Mann-Whitney U test to compare the glucose prediction performance on DiaTrend and ShanghaiT1DM datasets; both solely from T1D populations. We found that there is a statistically significant difference in the glucose prediction performance on these two groups; U-statistic $= 5 8 4$ , $\\scriptstyle { Z = 4 . 3 3 }$ , $p = 1 . 6 \\mathrm { e } { - 5 }$ . These results further support that the dataset used for developing and evaluating a blood glucose prediction algorithm significantly affects the prediction performance obtained.\n\n# 6 Discussion\n\nIn this paper, we present Glucose-ML - a collection of 10 publicly available diabetes datasets to accelerate development and evaluation of transparent, reproducible, and robust AI solutions. This collection comprises longitudinal glucose and other data from $2 5 0 0 +$ people living with diabetes (i.e., T1D and T2D) and people living without diabetes (i.e., prediabetes and no diabetes). The Glucose-ML collection includes over 300,000 days with CGM data and a total of 38 million glucose samples across all individual diabetes datasets. To our knowledge, the Glucose-ML collection is the largest and most comprehensive in literature to date. In addition to providing a review of recent publicly available diabetes dataset, this study includes comparative analysis of each dataset and a case study for blood glucose predicting using these datasets. Our results provide a benchmark for predicting blood glucose using each dataset within the Glucose-ML collection. Furthermore, our results show that the same AI algorithm can have significantly different results when developed and evaluated on different datasets.\n\nTable 2: Mean RMSE (std) for predicting blood glucose 30-minutes ahead using two naïve baselines. Lower RMSE means less prediction error while higher RMSE means more prediction error.   \n\n<html><body><table><tr><td rowspan=\"2\">PubliclyAvailable Diabetes Datasets</td><td colspan=\"2\">Mean RMSE (std) mg/dL</td></tr><tr><td>Zero-order Hold</td><td>Simple Linear Regression</td></tr><tr><td>OhioT1DM[68,69]</td><td>23.27 (2.92)</td><td>28.08 (4.80)</td></tr><tr><td>T1DEXI [94,49]</td><td>24.03 (5.38)</td><td>29.80 (6.28)</td></tr><tr><td>BIG IDEAs [13,20]</td><td>16.11 (2.72)</td><td>23.86 (3.91)</td></tr><tr><td>DiaTrend [89,88]</td><td>28.14 (4.96)</td><td>35.00 (5.29)</td></tr><tr><td>ShanghaiT1DM[119,120]</td><td>20.58 (3.39)</td><td>21.70 (3.20)</td></tr><tr><td>ShanghaiT2DM[119,120]</td><td>17.51 (4.04)</td><td>19.82 (4.48)</td></tr><tr><td>T1DiabetesGranada [95,96]</td><td>24.81 (5.17)</td><td>28.08 (5.70)</td></tr><tr><td>AI-READI [21, 6]</td><td>19.16 (4.96)</td><td>30.67 (7.06)</td></tr><tr><td>UCHTT1DM[57, 58]</td><td>19.28 (7.10)</td><td>30.41 (4.00)</td></tr><tr><td>CGMacros [43]</td><td>19.90 (4.68)</td><td>30.59 (5.64)</td></tr></table></body></html>\n\nAlthough this study did not include all public diabetes datasets available to facilitate AI development, we provide a more comprehensive review and analysis compared what has been presented in prior work. For example, Jacobs et al. [48] present a review of current real-world diabetes datasets, but only include three datasets, namely OhioT1DM [68], T1DEXI [94], and Tidepool Big Data Donation [105]. The Tidepool Big Data Donation dataset has been used for data-centric analysis in a few studies [9, 12, 77, 76, 87], however, this dataset is not publicly available so it was not included in the Glucose-ML collection. Some examples of other open diabetes datasets include OpenAPS [74], REPLACE-BG [8] and Maastricht study [99, 106]. The OpenAPS dataset has been used for data-centric analysis and developing AI solutions in prior work [45, 100]. However, this dataset is collected from a highly selective, technology-adept population of individuals with T1D who use a fully-closed loop automated insulin delivery (AID) system for diabetes management so it was not included in the Glucose-ML collection [74]. Meanwhile, the REPLACE-BG [8] (collected in year 2015 - 2016) and Maastricht study [99, 106] (initially reported in 2014) datasets were not included in the Glucose-ML collection because they are not recent and were collected/released before year 2018.\n\n# 6.1 Recommendations for developing robust AI solutions for diabetes and beyond\n\nComprehensive recommendation on developing robust AI algorithms is beyond the scope of this work, so we refer readers to related work [42, 48, 63]. Here, we present three recommendations that build on findings from this study.\n\n• Data Selection: A best practice guideline for AI development and evaluation is to leverage multiple datasets with representative subgroups and representative variability for the target population and task. For diabetes-centered AI solutions, the selected datasets should include individuals with representative variation in glycemic control, hemoglobin A1C, age groups, geographical locations, racial/ethnic groups, gender, and more - see Table 1, 3 and 4. • Model Design: Newly proposed AI models should always be compared with a naïve baseline model. Several studies in literature do not include a baseline (e.g. [62, 90, 15, 115]) or only include regression-based baselines or other more advanced baselines (e.g. [45, 40, 121, 123]). A best practice guideline is to include a zero-order hold predictor as a naïve baseline for blood glucose prediction tasks in addition to any other baselines. This is especially critical when a private dataset is used for AI development and evaluation. • Model Evaluation: To enable comparison with related work, it is critical for newly proposed AI solutions to not only be developed with simulated and/or private datasets (e.g. [59, 75, 52,\n\n64]). A best practice guideline is to develop and evaluate AI solutions on publicly available datasets, in addition to any private datasets. Additionally, models should not be evaluated on test sets that have been smoothed or that include interpolation of missing data [48]. These common pitfalls can lead to invalid estimates of accuracy.\n\n# 6.2 Ethical considerations\n\nRepresentation across the Glucose-ML collection: We assess representation of the Glucose-ML collection across three dimensions: sex/gender, age, and race/ethnicity. With regard to sex/gender, Table 3 in the Appendix shows that the Glucose-ML collection includes a fair representation across sex/gender (total: 1077 males $(42 \\% )$ and 1482 females $( 5 8 \\% ) )$ . With regards to age, the Glucose-ML collection does not include representation of children and/or adolescents - see Table 3. However, T1D and increasing incidences of prediabetes and T2D are not uncommon in pediatric populations [60, 80, 118]. With regard to race/ethnicity, research shows that diabetes is more prevalent across certain racial/ethnic groups [19]. For example, in US adults, diabetes is more prevalent amongst American Indian and Alaska Native adults, followed by non-Hispanic Black adults, and adults of Hispanic origin [16]. However, data on race/ethnicity is only reported in a few datasets (i.e., T1DEXI [49], DiaTrend [88], AI-READI [6], and CGMacros [43]. Of the four datasets $( 4 0 \\% )$ that report race/ethnicity, T1DEXI [94, 49] and DiaTrend [89, 88] have a large representation of non-Hispanic Whites/Caucasians; $87 \\%$ and $89 \\%$ , respectively. CGMacros has a large representation of Hispanics/Latinos $( 7 5 . 5 \\% )$ [43]. While AI-READI has a more balanced representation of persons from Hispanic $( 2 1 \\% )$ , Asian $( 2 3 \\% )$ , Black $( 2 7 \\% )$ , and White $( 2 9 \\% )$ race/ethnic groups [6].\n\nIntended Data Use: The Glucose-ML collection has been curated to accelerate research and development of AI solutions for diabetes and beyond. It is imperative to respect the privacy of participants who have openly shared their data with qualified researchers/innovators. As a result, data users should not attempt to re-identify participants, including for re-identification theory research.\n\n# 6.3 Limitations\n\nAlbeit the strengths of this work, there are some limitations that should be acknowledged. Firstly, this paper focuses solely on evaluating longitudinal glucose data from publicly available diabetes datasets. Hence, we did not delve into other longitudinal/diabetes-related data streams within each dataset, such as insulin-related data (e.g. insulin and carbohydrate input), activity tracker data (e.g. heart rate, step count, and sleep metrics), user logs (e.g. medication, meals, and life events), and clinical measurements (e.g. hemoglobin A1C and cholesterol). Secondly, despite our faithful attempt to provide a review and comparative analysis of recent open diabetes datasets, there is a chance that we unintentionally omitted some relevant datasets. For example, two recent T1D datasets, D1NAMO [29, 28] and T1DEXIP [50, 93], were not included in the Glucose-ML collection. When writing this manuscript, the authors were awaiting access to T1DEXIP and had not discovered D1NAMO.",
    "summary": "```json\n{\n  \"core_summary\": \"### 🎯 核心概要\\n\\n> **问题定义 (Problem Definition)**\\n> *   论文旨在解决糖尿病管理中AI算法开发面临的高质量数据集获取难题。现有数据集存在规模小、异构性不足、访问受限等问题，阻碍了鲁棒AI解决方案的开发。\\n> *   该问题在糖尿病数字健康技术（如血糖预测、决策支持）中具有关键价值，直接影响AI模型的透明度、可重复性和泛化能力。\\n\\n> **方法概述 (Method Overview)**\\n> *   论文提出Glucose-ML——一个包含10个公开糖尿病数据集的集合，涵盖2500+参与者、38M血糖样本，支持跨数据集算法开发与评估。\\n\\n> **主要贡献与效果 (Contributions & Results)**\\n> *   **数据集整合：** 整合10个2018-2025年发布的公开数据集，覆盖T1D/T2D/PreD/ND人群，总时长超30万天CGM数据。\\n> *   **基准分析：** 通过血糖预测案例研究，证明同一算法在不同数据集上性能差异显著（如零阶保持预测器RMSE从16.1±2.72到28.14±4.96 mg/dL）。\\n> *   **实践指南：** 提出数据选择、模型设计和评估的具体建议，如优先选择代表性子群和变异性的数据集。\",\n  \"algorithm_details\": \"### ⚙️ 算法/方案详解\\n\\n> **核心思想 (Core Idea)**\\n> *   通过整合多源异构糖尿病数据集，构建标准化评估框架，揭示数据特性对算法性能的影响机制。\\n> *   设计哲学：数据多样性（人群、设备、时长）和临床相关性（血糖动态范围）是鲁棒AI开发的关键。\\n\\n> **创新点 (Innovations)**\\n> *   **先前局限：** 现有研究多依赖单一数据集（如OhioT1DM），样本量小（如12人）、人群单一（仅T1D）。\\n> *   **本文改进：** 1) 跨国家/疾病阶段数据集整合；2) 提出基于临床指标（如TIR/TBR/TAR）的数据质量评估框架；3) 开源代码与标准化预处理流程。\\n\\n> **具体实现步骤 (Implementation Steps)**\\n> 1.  **数据收集：** 筛选2018-2025年公开数据集，要求包含CGM数据且符合FAIR原则。\\n> 2.  **数据清洗：** 剔除异常值（如<40或>400 mg/dL）、非数值记录（如\\\"LOW\\\"）、不合理变化率（>20 mg/dL/min）。\\n> 3.  **基准算法：** 实现零阶保持预测器（直接延用30分钟前血糖值）和简单线性回归预测器（基于10-30分钟历史数据拟合）。\\n> 4.  **评估协议：** 使用RMSE指标，排除缺失数据段（>3倍采样间隔的缺失）。\\n\\n> **案例解析 (Case Study)**\\n> *   以DiaTrend数据集为例：其TIR仅51%（临床推荐>70%），导致零阶预测器RMSE达28.14±4.96 mg/dL，显著高于BIG IDEAs数据集（TIR=97.6%，RMSE=16.11±2.72 mg/dL）。\",\n  \"comparative_analysis\": \"### 📊 对比实验分析\\n\\n> **基线模型 (Baselines)**\\n> *   零阶保持预测器（Zero-order Hold）\\n> *   简单线性回归预测器（Simple Linear Regression）\\n\\n> **性能对比 (Performance Comparison)**\\n> *   **在血糖预测误差（RMSE）上：** 零阶预测器在BIG IDEAs数据集上达到**16.11±2.72 mg/dL**，显著优于DiaTrend数据集（28.14±4.96 mg/dL）。与后者相比，误差降低42.7%。\\n> *   **在算法稳定性上：** 零阶预测器在所有10个数据集上均优于线性回归，后者RMSE普遍高出3.8-11.5 mg/dL（如OhioT1DM上28.08 vs 23.27 mg/dL）。\\n> *   **在数据异质性影响上：** T1D数据集（如DiaTrend）平均RMSE比T2D/ND数据集（如ShanghaiT2DM）高53.8%，证实人群差异对算法性能的关键影响。\",\n  \"keywords\": \"### 🔑 关键词\\n\\n*   连续血糖监测 (Continuous Glucose Monitoring, CGM)\\n*   糖尿病管理 (Diabetes Management, N/A)\\n*   人工智能基准测试 (AI Benchmarking, N/A)\\n*   时间序列预测 (Time Series Prediction, TSP)\\n*   医疗数据集 (Medical Datasets, N/A)\\n*   鲁棒性评估 (Robustness Evaluation, N/A)\\n*   开源科学 (Open Science, N/A)\\n*   数据质量指标 (Data Quality Metrics, DQM)\"\n}\n```"
}