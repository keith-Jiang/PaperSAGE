{
    "source": "ArXiv (Semantic Scholar未收录)",
    "arxiv_id": "2507.14088",
    "link": "https://arxiv.org/abs/2507.14088",
    "pdf_link": "https://arxiv.org/pdf/2507.14088.pdf",
    "title": "DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration",
    "authors": [
        "Xiyun Li",
        "Yining Ding",
        "Yuhua Jiang",
        "Yunlong Zhao",
        "Runpeng Xie",
        "Shuang Xu",
        "Yuanhua Ni",
        "Yiqin Yang",
        "Bo Xu"
    ],
    "categories": [
        "cs.LG"
    ],
    "publication_date": "未找到提交日期",
    "venue": "暂未录入Semantic Scholar",
    "fields_of_study": "暂未录入Semantic Scholar",
    "citation_count": "暂未录入Semantic Scholar",
    "influential_citation_count": "暂未录入Semantic Scholar",
    "institutions": [
        "The Key Laboratory of Cognition and Decision Intelligence for Complex Systems",
        "Institute of Automation",
        "Chinese Academy of Sciences",
        "School of Future Technology",
        "University of Chinese Academy of Sciences",
        "Nankai University",
        "Tsinghua University"
    ],
    "paper_content": "# DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration\n\nXiyun Li (lixiyun $\\pmb { 2 0 2 0 } \\textcircled { a }$ ia.ac.cn) 1,2,Yining Ding3,Yuhua Jiang4,Yunlong Zhao1, Runpeng Xie1, Shuang ${ \\bf { X } } { \\bf { u } } ^ { 1 }$ ,Yuanhua $\\mathbf { N i } ^ { 3 }$ , Yiqin Yang (yiqin.yang $@$ ia.ac.cn)1\\*,Bo Xu (xubo@ia.ac.cn)1,2\\*\n\n1The Key Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China 2School of Future Technology, University of Chinese Academy of Sciences, Beijing, 101408, China 3Nankai University, Tianjin, 300350, China 4Tsinghua University, Beijing, 100084, China \\*Corresponding author\n\n# Abstract\n\nReal-time human-artificial intelligence (AI) collaboration is crucial yet challenging, especially when AI agents must adapt to diverse and unseen human behaviors in dynamic scenarios. Existing large language model (LLM) agents often fail to accurately model the complex human mental characteristics such as domain intentions, especially in the absence of direct communication. To address this limitation, we propose a novel dual process multi-scale theory of mind (DPMT) framework, drawing inspiration from cognitive science’s dual process theory. Our DPMT framework incorporates a multi-scale theory of mind (ToM) module to facilitate robust human partner modeling through mental characteristic reasoning. Experimental results demonstrate that DPMT significantly enhances humanAI collaboration, and ablation studies further validate the contributions of our multi-scale ToM in the slow system.\n\nKeywords: theory of mind; human-AI collaboration; dual process theory; intelligent agents; large language model\n\n# Introduction\n\nIn recent years, large language models (LLMs) have achieved expert-level performance across various domains, including conversational question-answering assistants (Achiam et al., 2023) and code generation (Chen et al., 2021; R. Li et al., 2023). Building on the exceptional perception, comprehension, and reasoning capabilities of LLMs, LLM agents have rapidly emerged, attracting widespread attention. By integrating mechanisms such as memory and reflection, these agents demonstrate general-purpose abilities and robust generalization across tasks like operating system command execution (Deng et al., 2024; He et al., 2024), mobile assistance (J. Wang et al., 2024; C. Zhang et al., 2023), creative exploration in Minecraft (G. Wang et al., 2023), and embodied intelligence scenarios (Brohan et al., 2023).\n\nHowever, achieving effective adaptation in complex collaborative tasks remains a significant challenge, which is critical for the broader application of LLM agents. Unlike tasks that an LLM agent can perform independently, collaborative tasks like Overcooked (Ghost Town Games, 2016) require the agent to work with diverse partners, including humans, to efficiently complete a series of complex sub-tasks—such as retrieving ingredients, cooking, and serving dishes within a limited time. The task list in Overcooked is too intricate for a single agent to handle alone. Furthermore, human collaborators, constrained by bounded rationality, may lack complete domain knowledge, introducing additional instability and uncertainty in human-artificial intelligence (AI) collaboration.\n\nThus, effectively modeling human cognition is key to improving adaptation and collaboration.\n\nRecent research has focused on improving the adaptability and decision-making capabilities of LLM agents by facilitating communication between human players and AI agents in environments with diverse human partners (Liu et al., 2023; S. Zhang et al., 2024). Leveraging their advanced natural language understanding, LLM agents can interpret human commands and formulate subsequent action plans (Liu et al., 2023). By adjusting their collaboration strategies through mutual communication with human partners, LLM agents significantly improve the overall collaboration performance of human-AI teams (S. Zhang et al., 2024).\n\nHowever, the improved communication alone does not fully address the challenges of real-time scenarios. Current LLM agents lack the human-like cognitive ability known as “theory of mind” (ToM), which allows humans to understand and predict others’ mental beliefs based on observed behaviors in social environment (Astington & Jenkins, 1995). This ability facilitates efficient collaboration in tasks without direct communication. The absence of ToM hinders LLM agents’ performance in complex, real-time human-AI collaborative tasks. Although recent studies have explored ToM modeling to improve agent prediction (Rabinowitz et al., 2018; X. Li et al., 2023), these approaches rely on highquality trajectories and prior knowledge of partners. As a result, their interpretability and generalization are limited, restricting their applicability in real collaborative scenarios.\n\nInspired by dual process theory (Vaisey, 2009; Lizardo et al., 2016), we propose a cognitive dual process multi-scale theory of mind (DPMT) to improve the interpretability and efficiency of human partner modeling in real-time human-AI collaboration. Our DPMT framework distinguishes between two decision-making systems for real-time human-AI collaboration: a fast system for automatic decisions and a slow system for modeling higher-level cognitive abilities. The core contribution of this work is the development of a multi-scale theory of mind module to simulate the slow system for understanding human partners’ behavioral trajectories and reasoning about their mental characteristics, facilitating more effective collaboration. This ToM process follows a three-tiered reasoning process, which progresses from domain knowledge to cognitive style, and ultimately to domain intention, as illustrated in Figure 1. Experimental results from collaborative\n\n出心 出子   \noCnhiopnpsehdercea.bTbwagoeusragnendt Agent Human hBiassdeedtaoinlehdisotrdaejrectory, Agent Human   \norders are both Cathy. knowledge is incorrect   \nHuman partner is due to mixing an off-list ?   \nchopping onions now. soup, so I will focus on □ □□ the mixing action. □ □□ 000 o0e Step 1. Observing Step 2. Partner domain knowledge Reasoning 之花 □ T 7   \niMnygrpeadritenetr-pisretphaeration- oriented style, preparing Agent AgentHuman Human oAfntieorncs,hompypipnagrttnher’s long-term intention is Agent Human   \namlilxiensgtrheedime intnstofitrhset,pthote.n 日 Ic hwoilplpilnagcteotmomataoteose,sso 1 □□ in the center. □ □□ 000 000\n\nFigure 1: A four-step example of cognitive ToM modeling for human partners in the collaborative task Overcooked. In Step 1, the agent observes the environment and the human partner’s recent behaviors. In Step 2, the agent understands the human trajectory and predicts the partner’s domain knowledge. In Step 3, the agent analyzes the partner’s behavioral preferences and categorizes his cognitive style based on the inferred domain knowledge. In Step 4, the agent infers the partner’s domain intention for effective disicion-making.\n\ntasks in Overcooked demonstrate the effectiveness of DPMT in improving real-time human-AI collaboration.\n\n# Related Work\n\nLLM agent. Human-AI collaboration (Puig et al., 2020; Gao et al., 2020) constitutes a highly challenging research direction, motivating extensive investigations into strategies for enhancing the effectiveness, efficiency, and adaptability of human-AI systems. Compared to traditional agents, LLMbased agents contain an inherent world model, making them highly effective in reasoning and facilitating interpretable interaction for complex tasks, such as human-AI collaboration (Wu et al., 2024; Liu et al., 2023). Recent research (C. Zhang et al., 2024) designs the LLM agent framework with a verifier on the Overcooked environment, with knowledge and state as prompts to guide action planning. Recent work by (H. Zhang et al., 2023) proposes a modular framework that enables embodied agents to communicate and collaborate effectively, facilitating the efficient accomplishment of multi-agent long-term collaboration tasks.\n\nTheory of Mind (ToM) refers to the ability of individuals to understand and predict others’ mental states, including their intentions and goals for optimal decision-making and efficient social collaboration. Recent work introduces the ToM module in single-agent scenarios to predict an agent’s future actions based on its historical trajectory (Rabinowitz et al., 2018). A ToM-based multi-agent communication method incorporates an additional ToM module to select optimal communication partners based on historical trajectories in multiagent systems (Y. Wang, Xu, Wang, et al., 2021). The mutual ToM process, introduced in recent work (S. Zhang et al., 2024), enhances human-AI collaboration by improving reasoning and communication.\n\nPartner modeling. In multi-agent reinforcement learning (MARL) tasks, partners often exhibit dynamic and diverse strategies, introducing significant challenges in nonstationarity and generalization. To address these challenges in multi-agent collaboration, several studies (Carroll et al., 2019; Shih & Sawhney, 2021) have explored partner modeling to predict partners’ behaviors for enhancing efficient collaboration in complex MARL scenarios. Other approaches construct additional behavioral models (X. Li et al., 2023; Jiang et al., 2024) to simulate human partners and characterize their behavior styles. However, these methods focus on the accuracy of behavioral policy modeling, neglecting the simulation of partners’ mental characteristics. Our work focuses on human partner’s multi-scale ToM modeling for partner knowledge, cognitive styles, and domain intentions.\n\n# DPMT: Dual Process Multi-scale Theory of Mind Framework\n\n# Overview\n\nAs illustrated in Figure 2, our DPMT method comprises several components: the information extractor, the slow reasoning system, the fast intuitive system, and the action decoding module. The information extractor transforms environmental observation $o _ { t }$ and the human partner’s trajectory $c _ { t - 1 }$ into the language state, represented as the system cue $p _ { t } ^ { \\mathrm { s y s t e m } }$ pt . ystem encodes textual information about the environment and serves as the input for both the fast and slow systems.\n\nThe fast system focuses on the quick intuitive decisionmaking for each step, making macro-action $m _ { t }$ from a predefined macro-action set. In contrast, the slow system emphasizes cognitive multi-scale ToM reasoning, modeling the partner’s mental characteristics $k _ { t } , y _ { t } , n _ { t }$ to assist the fast system in making macro-action decisions.\n\nThe action decoding module decomposes the current macro-action $m _ { t }$ into atomic actions $a _ { t }$ and executes them at a much higher frequency until $m _ { t }$ is completed. Once $m _ { t }$ is finished, the fast system determines the subsequent $m _ { t + 1 }$ based on the multi-scale partner reasoning $k _ { t } , y _ { t } , n _ { t }$ from the slow reasoning system. This hierarchical approach ensures a seamless integration of intuitive decision-making and cognitive reasoning for efficient human-AI collaboration.\n\n# Slow System\n\nAs illustrated in Figure 3, we propose a multi-scale mental characteristics system for human-AI collaboration, drawing inspiration from social psychology research on human decision-making (Hauser, 2019; Santos, 2008). These studies categorize various mental characteristics that influence individual behavior into three key dimensions: domain knowledge, cognitive style, and domain intention (Zhao & Smil\n\nobservation 0t Domain Knowledge Corpus ToM Cue IngredientTomato:1.Itneeds5stepstochop tomato.The tomatopositionis (0.3)... System info: Ct-1 ToolPot:1.If thesoupinthepot exceedsfivesteps,the soupwillcatch fire.. Game Scenario: As an AI Information extractor OrderAlice:1.Toprepare theAlicesoup,theseingredientsneed tocook10steps.. assistant with Theory of Caai Cognitive Style Corpus mindabilityinasimplified Overcooked game,...   \n信 language state psystem Personalitystyle:FieldIndependent,Fieldependent GameGuidelines:To make J Behavioralstrategystyle:Ingredient-preparation-oriented,stable,random.. soup:   \n00\\*\\*0 ToMknowledge pkowt. Current soup orders:...   \nEnvironment Fast domain knowledge k Human ToM Reasoning System: Human Domain knowledge Domain knowledge   \natomic action a, Macro0- maker ToMstyle cognitvesie ya pintention D HumanCognitive style asedosegardes Parinectoe Cognitive style corpus:..   \nAction decoding ToMintention Mredtl is il a Partnerstyle prediction nt-1,k,yt domainintention n, Human Domain intention Domainintention   \nmacro action m, SlowSystem:Multi-scaleToM Afterchopping theonions,mypartner's next long-termintention is Portner itention $U P$ soIwillace prediction examples:...\n\nlie, 2015; Bostan, 2009). This system organizes these mental characteristics into a hierarchical architecture, with domain knowledge forming the foundation and domain intentions at the top, progressively enhancing interpretability. Building on this, we propose a multi-scale ToM model as our slow system, simulating the slow cognitive process in the dual process theory. This ToM model comprises multiple stages of human partner mental characteristic reasoning: the human domain knowledge reasoning stage $\\mathrm { T o M } _ { \\mathrm { k n o w l e d g e } }$ , the human cognitive style reasoning stage $\\mathrm { T o M _ { s t y l e } }$ , and the human domain intention reasoning stage ToMintention.\n\nSmall models face significant limitations in interpretability and general knowledge, making it challenging to construct an efficient and interpretable ToM model capable of effectively capturing partner styles and inferring domain intentions from partner trajectories. To overcome these challenges, we leverage LLMs as the foundation for the ToM model, leveraging their strengths in interpretability and extensive world knowledge to enhance human partner ToM modeling.\n\nDomain knowledge reasoning stage Domain knowledge in the Overcooked includes ingredient knowledge, order knowledge, and tool knowledge. Since these types of knowledge are not directly provided in the environmental state, they are typically accumulated from the human partner’s experiences. Predicting human partners’ domain knowledge serves as the foundation for further predictions of their cognitive styles and domain intentions, forming a critical basis for higher-level ToM reasoning.\n\nIn our framework, the partner domain knowledge reasoning stage $\\mathrm { T o M } _ { \\mathrm { k n o w l e d g e } }$ takes the knowledge cue $p _ { t } ^ { . . }$ nowledge as input, which integrates information from the language state $p _ { t } ^ { \\mathrm { s y s t e m } }$ , the human partner’s trajectory context $c _ { t - 1 }$ , additional partner domain knowledge reasoning cases, and a customized domain knowledge corpus. The domain knowledge corpus comprises knowledge from three categories, such as ingredient tomato under ingredient knowledge, order Bob under order knowledge. The output of $\\mathrm { T o M _ { k } }$ nowledge is the human partner domain knowledge $k _ { t }$ , which includes insights such as whether the human partner understands the current task rules or the required order preparation sequences.\n\n![](images/387f84c03a1fd2580c4581e78ae86f595f8568a3c07923a1c85a40ad759ed6bb.jpg)  \nFigure 2: As shown in the figure above, our proposed DPMT framework is inspired by the dual process theory, comprising an information extractor module, an action decoding module, a fast system for macro-action decision-making and a slow system for human partner modeling with a multi-scale ToM module. The ToM module consists of three stages: domain knowledge reasoning $\\mathrm { T o M } _ { \\mathrm { k n o w l e d g e } }$ , cognitive style reasoning $\\mathrm { T o M _ { \\mathrm { s t y l e } } }$ , and domain intention reasoning $\\mathbf { T o M } _ { \\mathrm { i n t e n t i o n } }$ . By emulating the cognitive structure, our framework can effectively reason about the human partner and achieve efficient collaboration.   \nFigure 3: Our proposed multi-scale mental characteristics system includes domain knowledge, cognitive style, and domain intention. Domain knowledge includes ingredient knowledge, order knowledge, and tool knowledge. Cognitive style represents the partner’s personality trait and behavioral style. Domain intention consists of long-term and short-term goals, representing the partner’s decision-making process.\n\nCognitive style reasoning stage The cognitive style reflects a human partner’s mental characteristic for decisionmaking preferences based on the domain knowledge, including personality traits, behavioral strategy preferences, and risk preferences. From the perspective of personality traits, cognitive style can be categorized into field-independent, who prefer to complete an entire order independently, and fielddependent, who tend to collaborate by dividing order tasks into sub-tasks to complete an order. In field-dependent players, cognitive styles can be further categorized based on the behavioral strategy, which defines different task tendencies. For example, an ingredient-preparation-oriented style focuses primarily on retrieving and processing various ingredients. This style can also be divided into stable (consistently following a fixed strategy) and random according to the behavioral strategy. Accurate classification of cognitive styles is crucial for effective partner intention modeling.\n\nIn the partner style reasoning stage $\\mathrm { T o M _ { \\mathrm { s t y l e } } }$ , the cognitive style cue $p _ { t } ^ { \\mathrm { s t y l e } }$ comprises ptknowledge, the previous cognitive style prediction $y _ { t - 1 }$ , and the partner domain knowledge prediction $k _ { t }$ . This stage also incorporates an additional partner style corpus to predict the human partner’s cognitive style $y _ { t }$ . In the partner style corpus, we design various partner cognitive styles based on behavioral strategies and personality traits observed in human behavioral experiments. These partner styles are stored in a structured format consisting of a name, a descriptive paragraph, and representative cases.\n\nDomain intentions reasoning stage Building upon the cognitive style and the current domain state, domain intentions include both short-term and long-term intentions of the human partner, which are crucial for achieving efficient human-AI collaboration. Short-term intention reasoning involves atomic action prediction, determining the human partner’s current action, such as UP, DOWN, LEFT, RIGHT. In contrast, long-term intention reasoning focuses on predicting the human partner’s macro-action, specifying their primary goal for the current phase, such as Chop Tomato, Prepare Bob Ingredients, Cook Alice Soup, Plate David Soup. Based on the $k _ { t }$ and $y _ { t }$ , the domain intention reasoning stage ToMintention incorporates a short-term intention cases and long-term intention reasoning corpus in domain intention cue $p _ { t } ^ { \\mathrm i }$ ntention to output the human partner’s predicted intentions $n _ { t }$\n\n# Fast System\n\nTo enable more real-time human-AI collaboration, our DPMT incorporates a fast system that simulates the quick decision-making system in the dual process theory. While powerful large models like GPT-4o demonstrate superior reasoning ability, their high latency makes them unsuitable for the fast system. Instead, our fast system in DPMT leverages a smaller-scale LLM, such as llama-13B, to reduce latency in macro-action decision-making and achieve real-time collaboration, using the environmental language state ptsystem, the fast system prompt, and currently available actions as input.\n\nAs illustrated in Figure 4, the fast system calculates macroaction probabilities by computing token probabilities, similar to recent works (Liu et al., 2023; Tan et al., 2024). Each macro-action is represented as a sequence of tokens. The LLM evaluates the probability of token sequences based on the human ToM reasoning from the slow system. These probabilities are then normalized to form the macro-action probability distribution at step t. The fast system selects the macroaction $m _ { t }$ with the highest probability from this distribution.\n\n![](images/9d8dd8846dee2a8e91e5771c6a3c1c2b5a3ef9841770a78fad60c1394e66964a.jpg)  \nFigure 4: Overview of our fast system in our proposed DPMT. The fast system first computes token probabilities for every macro-action, then derives the probability distribution of available macro-actions, selecting the one with the highest probability as the output.\n\nAlthough smaller models may make suboptimal decisions, our fast system compensates for this by leveraging accurate partner reasoning from the slow system. These two systems are implemented using multi-threading, where the slow system’s reasoning for partner modeling operates at a longer time scale than the fast system’s macro-action decisions. This design allows the fast system to run more frequently, enabling efficient real-time human-AI collaboration.\n\n# Experiments\n\n# Experimental Environment\n\nOur experimental environment is Overcooked (Ghost Town Games, 2016; Liu et al., 2023), a primary human-AI collaboration benchmark. We have conducted experiments on three maps based on the recent work (Liu et al., 2023), which introduced an expanded version of the traditional Overcooked environment for human-AI collaboration. In this environment, the agent and the human player work together to complete cooking tasks as quickly as possible to achieve a higher reward within a limited time. As shown in Figure 5, the environment includes three maps: Ring, Bottleneck, and Quick, each with varying levels of difficulty. Among them, the Quick and Bottleneck maps are more challenging. As shown in Figure 5, completing an order requires following a specific sequence of steps. The agent and human player must retrieve the necessary ingredients, chop them, combine them according to the different recipes, cook them for the required duration to make a dish, plate the dish before it overcooks, and serve the dish to the designated position. Once the dish is served, the player receives a reward (for example, 15 points), while failing to submit a dish results in a penalty (for example, -5 points). Players can choose and execute one action simultaneously from the following options: UP, DOWN, LEFT, or RIGHT, using the directional arrow keys. This environment designs a macro-action set with 21 predefined macro actions for the LLM agent, such as Cook Alice Soup.\n\n![](images/1ee7f8e679553a74c46a14ad92b8f2cc7ba1fef30bc20c987f68483ae0bf7d86.jpg)  \nFigure 5: The left part shows our Overcooked environments. The maps from top to bottom are Ring, Bottleneck, and Quick. The right part shows the detailed layout description of the bottleneck environment.\n\n# Human Experiment 1: Collaborating with Human Partners with Specific Strategies\n\nExperimental Setup. In the human-AI collaboration experiment, similar to HLAgent (Liu et al., 2023), the human player followed the fixed strategy to control the partner agent and interact with objects using the arrow keys like ’up,’ and ’down.’ In our human experiments, baseline methods included our DPMT with Qwen, our DPMT without the multiscale ToM (MsToM) and the HLAgent. Since communication between agents was not allowed in our task setting, we used the 0-command HLAgent as our baseline. To ensure experimental fairness, we established a stopping criterion that terminated LLM agent executions once the trajectory length reached 500 steps. In this part of the experiment, we used game scores to measure human-AI collaboration efficiency. The experiments were conducted on three maps and repeated five times under consistent conditions. The average humanAI collaboration scores are shown in Table 1.\n\nMain Results. As shown in Table 1, our proposed DPMT method consistently achieved the highest collaboration performance when paired with fixed-strategy human partners across all three maps: Ring, Quick, and Bottleneck, highlighting the effectiveness of our DPMT framework. Compared to the baseline methods, the introduction of the multi-scale mental characteristic ToM reasoning module (MsToM) in our\n\nTable 1: Score comparison between baseline methods and our DPMT method across all three maps in the human experiment 1. Standard deviations are shown in parentheses.   \n\n<html><body><table><tr><td>Methods</td><td>Ring</td><td>Bottleneck</td><td>Quick</td></tr><tr><td>OurDPMT</td><td>121 (±13.56)</td><td>101 (±13.56)</td><td>104 (±16.73)</td></tr><tr><td>Our DPMT w Qwen</td><td>100 (±15.17)</td><td>95 (±22.80)</td><td>105 (±18.71)</td></tr><tr><td>OurDPMTw/oMsToM</td><td>44 (±22.23)</td><td>23 (±22.93)</td><td>9 (±19.34)</td></tr><tr><td>HLAgent</td><td>99 (±18.81)</td><td>60 (±20.74)</td><td>87 (±16.00)</td></tr></table></body></html>\n\nDPMT framework led to a higher success rate in serving soups, a lower obstruction rate, and a lower incidence of dish fires by accurately predicting human partners’ mental characteristics, such as domain intentions. In contrast, the lack of ToM reasoning in DPMT w/o MsToM often resulted in ineffective collaboration, including redundant actions, route blockages, overcooked dishes, and frequent task repetition, ultimately incurring performance penalties.\n\n![](images/50552974e231f77a60cafedbef7d212cc9a10760ffa5864628e0e191daed48c5.jpg)  \nFigure 6: Score results of ablation experiments for different mental characteristics in human experiment 1. The black line denotes the standard deviation.\n\nAdditionally, compared to the HLAgent baseline, our method achieved superior and more stable performance, particularly on complex maps such as Bottleneck. The Bottleneck map has a more complex structure with a narrow passage, resulting in a higher blockage rate. This highlights the critical role of accurate ToM reasoning in achieving efficient human-AI collaboration. Furthermore, substituting the GPT4o API with Qwen-72B as the base model for mental characteristic reasoning resulted in slight improvements in collaboration performance on the Quick map. This enhancement is likely attributed to minor fluctuations in real-time experimental results caused by latency.\n\nAblation Results. We conducted ablation experiments to analyze the effectiveness of our DPMT method further. As shown in Figure 6, we compared the complete DPMT method with its ablated versions, where specific mental characteristic reasoning stages (w/o knowledge, w/o style, and w/o intention) were removed. Our method consistently outperformed the ablated versions across all maps (Ring, Quick, and Bottleneck), especially on more complex maps, where effective ToM reasoning plays a crucial role in coordination. For example, removing the intention reasoning layer led to a significant performance drop on the Quick map, while omitting the style layer caused notable declines on the Bottleneck map. These results indicate the importance of each ToM characteristic and demonstrate the necessity of hierarchical ToM modeling for effective partner reasoning and improved collaboration.\n\n# Questionnaire for Subjective Judgment in Human Experiment 2\n\n1 Game Ability “Can the AI agent efficiently utilize time to complete as many effective tasks as possible based on the order situation?\"   \n2 Human-AI Collaboration Fluidity “Can the AI agent accurately perceive the current order requirements and your actions, adapt its own actions accordingly, and collaborate efficiently with you avoiding redundant work?\"   \n3 Theory of mind (ToM) Ability “To what extent do you feel that your AI agent understands your intentions? Can the AI agent effectively avoid conflicts with your operations, such as not taking over kitchen equipment, interrupting, or obstructing your actions?\" \"Do you feel comfortable collaborating with the AI agent? Can it adapt to your movement habits and coordinate effectively to minimize idleness or delays, accelerating order completion? Can it adjust its path to avoid congestion in narrow passages by observing your movement?” Do you trust the AI agent? Can it adapt its behavior to align with the common goal in high-pressure or emergency situations (e.g., time shortages or fire)?\n\n# Human Experiment 2: Collaborating with Human Partners with Diverse Strategies\n\nExperiment Setup. An ideal AI agent should not only cooperate seamlessly with fixed-strategy human players but also collaborate efficiently with unseen human partners who employ diverse strategies. To further analyze the effectiveness and the human preference of our proposed DPMT framework, we conducted additional behavioral experiments for human studies. These experiments were performed across three maps with 30 participants (26 male, 4 female, ages 20–50). As shown in Figure 7, we designed a 5-point Likert scale questionnaire for each map, consisting of several questions (Hoffman, 2019; S. Zhang et al., 2024). This experiment followed a within-subject design, where each participant collaborated with both the DPMT and three baseline agents (A-D). To ensure fairness and validity, we randomized the order of partner agents (’ABCD’ or ’DBCA’) for each participant. Additionally, to evaluate the AI agent’s performance more effectively, we extended the game duration to 90 seconds, longer than in previous human experiment 1.\n\nAll participants were required to review the informed consent form and game rules before starting. To familiarize themselves with the task environment and rules, they first collaborated with rule-based agents across three maps. After completing the collaboration task on each map, they filled out a corresponding questionnaire, rating different agents based on their level of agreement with each statement.\n\nResults. In our collaboration experiments with diverse human participants, we evaluated performance using two key metrics: average collaboration scores within a fixed time limit and subjective judgments from the participants. As shown in\n\n![](images/091788c1078b84764096a5beaa385faabc9b099276ec4815aa6d742ee2580aba.jpg)  \nFigure 7: Our proposed questionnaire for subjective judgment metric with 5-point Likert scales was used in our human experiment 2. The questionnaire includes three parts: game ability, human-AI collaboration fluidity, and ToM ability. Different questionnaires were designed for different maps.   \nFigure 8: Average collaboration score comparison between baseline methods and our proposed DPMT when paired with diverse participants in the human experiment 2.\n\nFigure 8, our DPMT method consistently outperformed baseline methods across all three maps, exhibiting a result trend similar to the main result of human experiment 1, demonstrating its ability to adapt to both specific strategies and diverse unseen human collaborators. For the subjective judgment scores, we computed the average scores based on our proposed questionnaire, with a maximum score of 5, as shown in Table 2. Notably, our method achieved higher subjective scores, further highlighting its superior ToM reasoning capability for effective partner modeling.\n\nTable 2: The average subjective judgment when paired with diverse unseen participants in human experiment 2 ranges from 0 to 5. Standard deviations are shown in parentheses.   \n\n<html><body><table><tr><td>Methods</td><td>Ring</td><td>Bottleneck</td><td>Quick</td></tr><tr><td>Our DPMT</td><td>4.07 (±0.53)</td><td>4.02 (±0.45)</td><td>4.02 (±0.61)</td></tr><tr><td>Our DPMTwQwen</td><td>3.51 (±0.58)</td><td>3.73 (±0.47)</td><td>3.89 (±0.68)</td></tr><tr><td>OurDPMTw/o MsToM</td><td>2.20 (±0.70)</td><td>2.16 (±0.67)</td><td>2.04 (±0.60)</td></tr><tr><td>HLAgent</td><td>3.09 (±0.30)</td><td>2.78 (±0.59)</td><td>3.22 (±0.69)</td></tr></table></body></html>\n\n# Conclusion\n\nDrawing inspiration from the dual process theory, we introduce a cognitive dual process multi-scale ToM (DPMT) framework, which simulates both the fast system for quick decision-making and the slow system for ToM reasoning. The slow system in DPMT employs a three-stage ToM reasoning process—partner domain knowledge, cognitive style, and domain intention—to improve the interpretability and generalization of partner ToM modeling. Additionally, it integrates a structured corpus of mental characteristics and a memory module that stores partner trajectories and ToM reasoning predictions. Our DPMT outperforms baseline methods in human-AI collaboration experiments, demonstrating superior adaptability and ToM ability. Ablation studies further validate the contribution of different reasoning stages. Notably, our method achieves significantly stronger results on complex maps, highlighting its potential for tackling more intricate human-AI collaborative tasks.",
    "summary": "```json\n{\n  \"core_summary\": \"### 🎯 核心概要\\n\\n> **问题定义 (Problem Definition)**\\n> *   论文针对实时人机协作中AI代理难以准确建模复杂人类心理特征（如领域意图）的问题，特别是在缺乏直接沟通的情况下。这一问题在动态场景中尤为关键，因为现有的大型语言模型（LLM）代理往往无法有效适应多样且未见的人类行为。\\n> *   该问题的重要性在于，解决它能够显著提升人机协作的效率和应用范围，特别是在需要实时决策和协作的复杂任务中（如游戏《Overcooked》）。\\n\\n> **方法概述 (Method Overview)**\\n> *   论文提出了一种新颖的双过程多尺度心智理论（DPMT）框架，结合了认知科学中的双过程理论和多尺度心智理论（ToM）模块，以通过心理特征推理实现鲁棒的人类伙伴建模。\\n\\n> **主要贡献与效果 (Contributions & Results)**\\n> *   **创新贡献点1：** 提出了多尺度ToM模块，通过三个阶段（领域知识推理、认知风格推理和领域意图推理）实现人类伙伴心理特征的建模。实验结果显示，该方法在《Overcooked》任务中显著提升了协作效率。\\n> *   **创新贡献点2：** 设计了双过程系统（快速系统和慢速系统），分别负责快速决策和认知推理，实现了实时协作。实验表明，该方法在复杂地图（如Bottleneck）上的协作得分比基线方法提升了约68%。\\n> *   **创新贡献点3：** 引入了结构化心理特征语料库和记忆模块，增强了ToM推理的准确性和泛化能力。主观评价显示，用户对DPMT的协作流畅性和ToM能力的评分显著高于基线方法（平均评分4.07 vs. 3.09）。\",\n  \"algorithm_details\": \"### ⚙️ 算法/方案详解\\n\\n> **核心思想 (Core Idea)**\\n> *   DPMT框架的核心思想是模拟人类认知的双过程理论，通过快速系统实现直觉决策，通过慢速系统实现多尺度ToM推理。这种设计能够同时满足实时性和准确性需求，从而提升人机协作的效率。\\n> *   该方法之所以有效，是因为它通过分层推理（从领域知识到认知风格再到领域意图）逐步增强对人类伙伴的理解，从而做出更准确的协作决策。\\n\\n> **创新点 (Innovations)**\\n> *   **与先前工作的对比：** 现有LLM代理缺乏ToM能力，难以在缺乏直接沟通的情况下预测人类伙伴的行为。此外，传统方法依赖于高质量轨迹和先验知识，泛化性和可解释性有限。\\n> *   **本文的改进：** DPMT通过多尺度ToM模块和结构化语料库，实现了对伙伴心理特征的动态推理。快速系统使用轻量级LLM（如llama-13B）降低延迟，慢速系统则利用大型LLM（如GPT-4o）提升推理能力。\\n\\n> **具体实现步骤 (Implementation Steps)**\\n> *   1. **信息提取器**：将环境观察和人类伙伴轨迹转换为语言状态，作为快速和慢速系统的输入。\\n> *   2. **慢速系统**：执行多尺度ToM推理，包括：\\n>       - **领域知识推理**：预测伙伴的领域知识（如任务规则和准备顺序）。\\n>       - **认知风格推理**：分类伙伴的决策偏好（如场独立或场依赖风格）。\\n>       - **领域意图推理**：预测伙伴的短期和长期意图（如切番茄或准备汤）。\\n> *   3. **快速系统**：基于慢速系统的推理结果，选择概率最高的宏动作（如Cook Alice Soup）。\\n> *   4. **动作解码模块**：将宏动作分解为原子动作并执行。\\n\\n> **案例解析 (Case Study)**\\n> *   论文提供了一个四步示例（如图1所示）：\\n>       - **步骤1**：代理观察环境和伙伴行为。\\n>       - **步骤2**：代理预测伙伴的领域知识（如伙伴是否理解任务规则）。\\n>       - **步骤3**：代理分析伙伴的认知风格（如原料准备导向风格）。\\n>       - **步骤4**：代理推断伙伴的领域意图（如长期意图是准备番茄汤），并据此调整自身行为。\",\n  \"comparative_analysis\": \"### 📊 对比实验分析\\n\\n> **基线模型 (Baselines)**\\n> *   HLAgent：一种基于LLM的代理框架，支持人机协作但缺乏ToM能力。\\n> *   DPMT w/o MsToM：DPMT的变体，移除了多尺度ToM模块。\\n> *   DPMT w Qwen：使用Qwen-72B作为基础模型的DPMT版本。\\n\\n> **性能对比 (Performance Comparison)**\\n> *   **在协作得分上：** 在《Overcooked》的Bottleneck地图上，DPMT的平均得分为101（±13.56），显著优于HLAgent（60 ±20.74）和DPMT w/o MsToM（23 ±22.93）。与表现最佳的基线相比，提升了约68%。\\n> *   **在主观评价上：** 用户对DPMT的ToM能力评分为4.02（±0.45），远高于HLAgent的2.78（±0.59）。特别是在协作流畅性方面，DPMT的评分比基线高出30%以上。\\n> *   **在实时性上：** DPMT的快速系统使用llama-13B实现了低延迟决策，同时慢速系统的推理频率与快速系统解耦，确保了实时协作的效率。\",\n  \"keywords\": \"### 🔑 关键词\\n\\n*   心智理论 (Theory of Mind, ToM)\\n*   人机协作 (Human-AI Collaboration, N/A)\\n*   双过程理论 (Dual Process Theory, N/A)\\n*   大型语言模型 (Large Language Model, LLM)\\n*   认知风格 (Cognitive Style, N/A)\\n*   领域意图 (Domain Intention, N/A)\\n*   实时决策 (Real-time Decision Making, N/A)\\n*   智能代理 (Intelligent Agents, N/A)\"\n}\n```"
}