{
    "source": "ArXiv (Semantic Scholaræœªæ”¶å½•)",
    "arxiv_id": "2507.14059",
    "link": "https://arxiv.org/abs/2507.14059",
    "pdf_link": "https://arxiv.org/pdf/2507.14059.pdf",
    "title": "Design of a Modular Mobile Inspection and Maintenance Robot for an Orbital Servicing Hub",
    "authors": [
        "Tianyuan Wang",
        "Mark A Post",
        "Mathieu Deremetz"
    ],
    "categories": [
        "cs.RO"
    ],
    "publication_date": "æœªæ‰¾åˆ°æäº¤æ—¥æœŸ",
    "venue": "æš‚æœªå½•å…¥Semantic Scholar",
    "fields_of_study": "æš‚æœªå½•å…¥Semantic Scholar",
    "citation_count": "æš‚æœªå½•å…¥Semantic Scholar",
    "influential_citation_count": "æš‚æœªå½•å…¥Semantic Scholar",
    "institutions": [
        "University of York",
        "Space Applications Services NV/SA"
    ],
    "paper_content": "# Design of a Modular Mobile Inspection and Maintenance Robot for an Orbital Servicing Hub\n\nTianyuan Wang1[0000âˆ’0003âˆ’3545âˆ’4937], Mark A Post1[0000âˆ’0002âˆ’1925âˆ’7039], and Mathieu Deremetz $^ 2$\n\n$^ { 1 }$ University of York, Heslington, York, England, YO10 5DD {tianyuan.wang,mark.post}@york.ac.uk https://www.york.ac.uk/physics-engineering-technology/ 2 Space Applications Services NV/SA, Leuvensesteenweg 325, 1932 Sint-Stevens-Woluwe, Belgium mathieu.deremetz@spaceapplications.com https://www.spaceapplications.com/\n\nAbstract. The use of autonomous robots in space is an essential part of the â€œNew Spaceâ€ commercial ecosystem of assembly and re-use of space hardware components in Earth orbit and beyond. The STARFAB project aims to create a ground demonstration of an orbital automated warehouse as a hub for sustainable commercial operations and servicing. A critical part of this fully-autonomous robotic facility will be the capability to monitor, inspect, and assess the condition of both the components stored in the warehouse, and the STARFAB facility itself. This paper introduces ongoing work on the STARFAB Mobile Inspection Module (MIM). The MIM uses Standard Interconnects (SI) so that it can be carried by Walking Manipulators (WM) as an independently-mobile robot, and multiple MIMs can be stored and retrieved as needed for operations on STARFAB. The MIM carries high-resolution cameras, a 3D profilometer, and a thermal imaging sensor, with the capability to add other modular sensors. A grasping tool and torque wrench are stored within the modular body for use by an attached WM for maintenance operations. Implementation and testing is still ongoing at the time of writing. This paper details the concept of operations for the MIM as an on-orbit autonomous inspection and maintenance system, the mechanical and electronic design of the MIM, and the sensors package used for non-destructive testing.\n\nKeywords: Space Robotics Â· Servicing Â· Maintenance Â· Inspection Â· Non-Destructive Testing\n\n# 1 Introduction\n\nOuter space has become easier to access than ever before with the advent of low-cost commercial launch technologies and improvements in space technology, communications and robotics. However, the current practice of simply launching single-use bespoke missions from Earth is not economical and sustainable, and the development of In-space Service, Assembly and Maintenance (ISAM) technologies has taken priority to facilitate this new ecosystem. The â€œNew Spaceâ€\n\nor â€œBig Spaceâ€ model that is now evolving envisions the use of modular space technologies with universal interoperability that can be assembled, deployed, retrieved, and maintained fully or partly autonomously through the use of robotics in Earth orbit and beyond. With this model comes the need for in-space robotic storage and handling of required items and resources, which we propose can be fulfilled in the form of an â€œOrbital Hubâ€ that serves as a unified warehousing, assembly, and maintenance facility to which servicer spacecraft could dock and launch carrying with them satellites composed of modular components that can be serviced and reconfigured. To this end, the project â€œA Space Warehouse Concept and Ecosystem to Energize European ISAM (STARFAB)â€ [5] introduces a novel concept, the Orbital Automated Warehouse Unit (also known as the Orbital Depot), which serves as a backbone and enabler for sustainable ISAM commercial activities [2]. The introduction of capability to warehouse, reconfigure, and redeploy modular spacecraft components on-orbit brings with it the necessity to regularly inspect and maintain components remotely and at least semi-autonomously. The Inspection and Maintenance (I&M) capabilities within STARFAB focus on the detection, diagnosis, and reporting of malfunction or damage to facilities, systems, and contents. Non-destructive testing (NDT) methods provide the lifecycle analysis with failure prediction and diagnosis capability needed to plan the deployment and operation of modular spacecraft. STARFAB also needs the capability to carry out light maintenance interventions robotically and on demand, to implement planned or unplanned maintenance of the facilities. Complex interventions are not considered at present due to the high fundamental complexity of robotic maintenance activities on-orbit. The Inspection and Maintenance robot for STARFAB is designed as a self-contained spacecraft module called the Mobile Inspection Module (MIM). The MIM uses HOTDOCK (HD) Standard Interconnects (SI) so that it can be carried by Walking Manipulators (WM) and other mobile subsystems [4]. It also operates like any other self-contained modular element in the system with independent power and processing resources, and multiple MIMs can be stored and retrieved as needed for operations on STARFAB.\n\n# 2 System Design\n\nRequirements Table 1 summarizes the Inspection and Maintenance requirements for STARFAB. The main inspection and maintenance challenges for STARFAB are due to requiring autonomous operation in a minimally-controlled vacuum and irradiated environment with extremes of temperature. This limits feasible NDT techniques at present to remotely-deployable optical sensing methods applicable to inspecting a wide range of materials and parts. Based on this set of requirements, the MIM is designed to carry a high-resolution machine vision camera with encircling illumination unit, optical 3D scanner, and thermal imaging camera. Maintenance activities are accomplished by using an additional WM to attach and manipulate a grasping tool and torque wrench.\n\nConcept of Operations The primary use case for the MIM is the inspection of modular spacecraft components known as Orbital Replacement Units (ORUs) and components while they are on route to or from the primary structure. The\n\nTable 1: Inspection and Maintenance Requirements   \n\n<html><body><table><tr><td>Element</td><td>Requirement</td></tr><tr><td>Payloads</td><td>Automated NDT is possible for all payloads on all external surfaces.</td></tr><tr><td>Spacecraft</td><td>Hosted spacecraft shall be inspected externally without disassembly.</td></tr><tr><td>Profilometry</td><td>Scratch/deformationdamage detected fromdebris larger than O.3mm.</td></tr><tr><td>Resolution</td><td>Debris impact damage detectable down to O.6mm diametric size.</td></tr><tr><td>Reliability</td><td>Damage features detected with 9O% probability to confidence of 95%.</td></tr><tr><td>Range</td><td>Inspection within a range of O.2m to 2m from the sensor array.</td></tr><tr><td>Thermal</td><td>Inspection distinguishes localized temperatures of-40C to 150C.</td></tr><tr><td>Illumination</td><td>Ring-topology visible spectrum illumination source is carried for vision.</td></tr><tr><td>Handling</td><td>Replacement partshandled and placedusing dedicated robotic tools.</td></tr><tr><td>Grasping</td><td>Gripper tool can grasp objects with dimensions from O.5cm to 10cm.</td></tr><tr><td>Torque</td><td>Torque tool compatible to NASA PGT tool one;2.7Nm to 30Nm.</td></tr></table></body></html>\n\nMIM must be capable of being positioned at any stage of the ORUâ€™s movement, while aiming to keep the primary structure unobstructed. The secondary use case for the MIM is inspection of the structural integrity of STARFAB itself, from both interior and exterior positions, and that of docked servicer spacecraft. The MIM can be be positioned by â€œwalkingâ€ over designated fixture points on the structure with WMs, transported by attaching via a WM to a shuttle system, or attached in place to a fixture point via a WM as an â€œeye in handâ€ sensor.\n\n![](images/735da146e77a6f269f1ab05931f7549d13cd98069155d99f17bd7ee152c289a6.jpg)  \nFig. 1: Operations of the MIM performing I&M inside and outside STARFAB.\n\n# 3 Mechanical Design\n\nForm Factor The form factor of the MIM is based on the Multi-Arms Robot (MAR) developed for on-orbit large telescope assembly [1]. Design underwent three major iterations with careful consideration given to the I&M requirements, as well as ensuring compatibility with the STARFABâ€™s existing system, which eventually led to a final iteration that aligned with the MAR form factor, shown in Figure 2, to achieve several objectives. First, adopting the MAR torsoâ€™s form factor allows the MIM to utilize the same kinematic configuration, ensuring seamless integration with the existing system. Second, the evenly distributed three HDs, when paired with the WM, provide enhanced flexibility, where the third HD can be positioned as needed to interface with tools. The MAR torsoâ€™s top view features a hexagonal shape with unequal sides. The MIMâ€™s sensor components are mounted on one of the longer sides within a cylindrical-like enclosure capable of tilt movement. When the sensor interface is oriented forward, two WMs are mounted on the left and rear HDs, allowing for autonomous movement, while the HD on the right side is reserved for an additional robotic arm, either a WM or a lighter alternative, for tool retrieval, manipulation, and storage. This configuration enables the MIM to interact with tools through an independent robotic arm, providing greater degrees of freedom. The tools are stored within the open-sided compartments on the two sides of the MIM main body under the lid. These compartments take space both internally and externally to the original MAR torso profile to achieve a balance between the WM-to-tool interference and the tool carrying capacity.\n\n![](images/17ca3619bd9d318b087e0e3026e8493dcbc72d975d0839b0207a3154aa47102e.jpg)  \nFig. 2: Mechanical design of the MIM. (a) An overview of the MIM with HDs attached. (d) An exploded view of the main constituent parts of the MIM.\n\nInterfacing The three HDs at the corners of the MIM chassis interface to WMs, payloads, and other modular components. Specifications including quantity and placements of the HDs depend on the configuration of how the MIM is to be integrated with other STARFAB modular systems. As a modular system, the MIM is designed to be flexible enough to fulfil many different roles, as shown in Figure 3. These include, for example, when operating as an independent robot, it will have two WMs attached, which operate as â€œlegsâ€, to walk across infrastructureâ€™s attachment points. This allows it to reach external locations on the warehouse unit and areas not easily within reach of manipulators. When operating as a payload for the WM, with the WM mounted on a shuttle or fixed attachment point, the MIM can be flexibly positioned for inspection using one WM. When operating as a payload for the external Large Arm of STARFAB, the MIM is held by the grapple fixture and positioned above the area to be inspected. The manipulation of tools is accomplished by attaching a WM to an unused HD on the MIM to access tools in the tool storage. Tools are then used by the WM with a camera integrated within the WM operating as an â€œeye-in-handâ€ sensor and within the view of the MIMâ€™s sensor package, which then operates as an â€œeye-to-handâ€ sensor.\n\nPower Given the constraints on mass and energy consumption inherent in space applications, the internal electronics of the MIM are designed to be minimalistic, operating at 24V with a power consumption of approximately 5W per unit, except for the on-board computer (OBC) and illumination source. Mass reduction remains a primary concern, as the flight version of the MIM is larger and heavier than ground applications. The power bus on the robotic arm operates at 48V, allowing for more efficient power distribution with a current limitation of around 14A for the entire robot.\n\n![](images/ff0ffac71dd99fddf759e4aff3374f749a930aa57928f8d38c282e964bd29176.jpg)  \nFig. 3: Example configurations of the MIM. From (a) to (d): walking configuration, externally mounted configuration, large arm mounted configuration, and maintenance MIM Configuration.\n\n![](images/5d12b01fe40cff247a5e95fafe11851757fe399aba1db6b2cefb4a09f99a236b.jpg)  \nFig. 4: Block diagram of MIM systems with interfacing to external systems.\n\n# 4 Sensor and Processing Hardware Selection\n\nOn-Board Computing The computing hardware for the MIM must have the capacity to run image and signal processing algorithms in real time for I&M purposes. While future flight hardware and software will be significantly different, for terrestrial testing an OBC running Linux is used to facilitate experimentation with algorithms from the OpenCV machine vision library, Point Cloud Library (PCL), and the InFuse Space Robotics Common Data Fusion Framework (CDFF) [3]. The central OBC on the MIM is an Nvidia Jetson Orin Nano developer board, which has sensor hardware acceleration in Linux and uses ROS2 over Ethernet as a system bus to other components.\n\n![](images/8ae66e77891bf2db3e985e2dd49b5538278c449e12d282ee877597d38c35d8c1.jpg)  \nFig. 5: Prototype of the sensor enclosure and containing perception electronics. From (a) to (c): the 3D, front, and top view of the enclosure and electronics.\n\n![](images/2ac7a09fd20ab7df0ad2208941b7230415977c0941bdb68e65085662594eb5a6.jpg)  \nFig. 6: Initial data from the MIMâ€™s onboard sensors. (a) 3D scanner generated mesh model. (b) Sensor readout visualized on the rviz2 interface.\n\nPerception Sensors To fulfil the I&M requirements, the sensors in the MIM primarily cover RGB, depth, point cloud, and thermal imaging domains. A block diagram of the system framework and the prototype of the sensor enclosure are shown in Figure 4 and 5, respectively. For RGB images, to ensure the sharpness of objects captured at different distances, camera with a zoom lens and local image processing capability is preferred. For better compatibility with the OBCs and ROS2 communication middleware, the Raspberry Pi 5 with Pi Camera 3 sensors was selected. They are mounted at the four corners of the sensor enclosureâ€™s front panel, providing a wide field of view around potential obstructions. Although these cameras are expected to be sufficient for depth imaging, capacity for an accelerated ZED X stereo camera is included for testing purposes. For sub-millimetre surface profiling, most LIDAR units have insufficient point cloud density, so a Matter And Form THREE 3D structured light camera system is used to achieve sufficient surface resolution while internally handling additional processing overheads. Coarse resolution thermal imaging is used to detect the presence of operational anomalies that cause lack of activity or overheating. For appropriate dynamic range with a small footprint, a Waveshare Long-wave IR Thermal Imaging Camera with 80 $\\times$ 62 resolution is used.\n\n# 5 Conclusions\n\nThe STARFAB Mobile Inspection Module represents a novel modular approach to inspection and maintenance, suitable for the flexible ecosystems of space hardware components needed to achieve sustainable autonomous operations in Earth orbit and beyond. The next steps in MIM development are to test the complete prototype in identifying and profiling ORUs and STARFAB structural elements as a platform for algorithm development to achieve the I&M performance requirements. Following verification activities, a MIM with aluminium chassis and near-flight capable components will perform autonomous inspection and maintenance as part of the STARFAB project demonstration in mid-2026.",
    "summary": "```json\n{\n  \"core_summary\": \"### ğŸ¯ æ ¸å¿ƒæ¦‚è¦\\n\\n> **é—®é¢˜å®šä¹‰ (Problem Definition)**\\n> *   è®ºæ–‡é’ˆå¯¹åœ¨è½¨æœåŠ¡ä¸ç»´æŠ¤ï¼ˆISAMï¼‰ä¸­è‡ªä¸»æ£€æµ‹ä¸ç»´æŠ¤ï¼ˆI&Mï¼‰çš„éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§æ¨¡å—åŒ–ç§»åŠ¨æ£€æµ‹ä¸ç»´æŠ¤æœºå™¨äººï¼ˆMIMï¼‰çš„è®¾è®¡æ–¹æ¡ˆã€‚è¯¥é—®é¢˜çš„é‡è¦æ€§åœ¨äºï¼Œéšç€å•†ä¸šèˆªå¤©çš„å‘å±•ï¼Œä¼ ç»Ÿçš„å•æ¬¡ä½¿ç”¨ä»»åŠ¡æ¨¡å¼å·²ä¸ç»æµä¸”ä¸å¯æŒç»­ï¼Œè€Œæ¨¡å—åŒ–ç©ºé—´æŠ€æœ¯çš„è‡ªä¸»ç»„è£…ã€éƒ¨ç½²å’Œç»´æŠ¤æˆä¸ºå…³é”®ã€‚\\n> *   è¯¥é—®é¢˜å…‹æœäº†ç°æœ‰æ–¹æ³•ä¸­ç¼ºä¹é«˜æ•ˆã€è‡ªä¸»çš„æ£€æµ‹ä¸ç»´æŠ¤èƒ½åŠ›çš„ç“¶é¢ˆï¼Œåœ¨è½¨é“ä»“åº“ï¼ˆå¦‚STARFABï¼‰ä¸­å…·æœ‰å…³é”®ä»·å€¼ï¼Œèƒ½å¤Ÿå®ç°æ¨¡å—åŒ–èˆªå¤©ç»„ä»¶çš„è¿œç¨‹æ£€æµ‹å’Œè½»é‡ç»´æŠ¤ã€‚\\n\\n> **æ–¹æ³•æ¦‚è¿° (Method Overview)**\\n> *   è®ºæ–‡æå‡ºäº†ä¸€ç§æ¨¡å—åŒ–ç§»åŠ¨æ£€æµ‹æ¨¡å—ï¼ˆMIMï¼‰ï¼Œé‡‡ç”¨æ ‡å‡†æ¥å£ï¼ˆSIï¼‰è®¾è®¡ï¼Œå¯è¢«è¡Œèµ°æœºæ¢°è‡‚ï¼ˆWMï¼‰æºå¸¦ï¼Œå¹¶é…å¤‡é«˜åˆ†è¾¨ç‡æ‘„åƒå¤´ã€3Dè½®å»“ä»ªå’Œçƒ­æˆåƒä¼ æ„Ÿå™¨ï¼Œæ”¯æŒéç ´åæ€§æ£€æµ‹ï¼ˆNDTï¼‰å’Œè½»é‡ç»´æŠ¤æ“ä½œã€‚\\n\\n> **ä¸»è¦è´¡çŒ®ä¸æ•ˆæœ (Contributions & Results)**\\n> *   **æ¨¡å—åŒ–è®¾è®¡**ï¼šMIMé‡‡ç”¨æ ‡å‡†æ¥å£ï¼ˆHOTDOCK SIï¼‰ï¼Œå¯ä¸è¡Œèµ°æœºæ¢°è‡‚ï¼ˆWMï¼‰æ— ç¼é›†æˆï¼Œå®ç°çµæ´»ç§»åŠ¨å’Œå¤šä»»åŠ¡é…ç½®ã€‚\\n> *   **å¤šä¼ æ„Ÿå™¨é›†æˆ**ï¼šé…å¤‡é«˜åˆ†è¾¨ç‡æ‘„åƒå¤´ï¼ˆRaspberry Pi 5 + Pi Camera 3ï¼‰ã€3Dç»“æ„å…‰ç›¸æœºï¼ˆMatter And Form THREEï¼‰å’Œçƒ­æˆåƒç›¸æœºï¼ˆWaveshareï¼‰ï¼Œæ”¯æŒéç ´åæ€§æ£€æµ‹ï¼ˆNDTï¼‰ï¼Œæ£€æµ‹ç²¾åº¦è¾¾0.3mmï¼ˆè¡¨é¢æŸä¼¤ï¼‰å’Œ0.6mmï¼ˆç¢ç‰‡å†²å‡»ï¼‰ã€‚\\n> *   **è½»é‡ç»´æŠ¤èƒ½åŠ›**ï¼šå†…ç½®æŠ“å–å·¥å…·å’Œæ‰­çŸ©æ‰³æ‰‹ï¼Œæ”¯æŒç”±WMæ“ä½œçš„è½»é‡ç»´æŠ¤ä»»åŠ¡ï¼Œæ‰­çŸ©èŒƒå›´è¦†ç›–2.7Nmè‡³30Nmã€‚\\n> *   **è®¡ç®—ä¸é€šä¿¡**ï¼šé‡‡ç”¨Nvidia Jetson Orin Nanoä½œä¸ºä¸»æ§æ¿ï¼Œè¿è¡ŒROS2ä¸­é—´ä»¶ï¼Œæ”¯æŒå®æ—¶å›¾åƒå’Œä¿¡å·å¤„ç†ç®—æ³•ã€‚\",\n  \"algorithm_details\": \"### âš™ï¸ ç®—æ³•/æ–¹æ¡ˆè¯¦è§£\\n\\n> **æ ¸å¿ƒæ€æƒ³ (Core Idea)**\\n> *   MIMçš„æ ¸å¿ƒè®¾è®¡æ€æƒ³æ˜¯é€šè¿‡æ¨¡å—åŒ–å’Œæ ‡å‡†åŒ–æ¥å£ï¼ˆSIï¼‰å®ç°çµæ´»çš„å¤šä»»åŠ¡é…ç½®ï¼ŒåŒæ—¶é›†æˆå¤šä¼ æ„Ÿå™¨å’Œè½»é‡ç»´æŠ¤å·¥å…·ï¼Œæ»¡è¶³è½¨é“ä»“åº“ï¼ˆSTARFABï¼‰çš„è‡ªä¸»æ£€æµ‹ä¸ç»´æŠ¤éœ€æ±‚ã€‚å…¶æœ‰æ•ˆæ€§åœ¨äºæ¨¡å—åŒ–è®¾è®¡èƒ½å¤Ÿé€‚åº”å¤šç§æ“ä½œåœºæ™¯ï¼ˆå¦‚è¡Œèµ°ã€å¤–éƒ¨å®‰è£…ã€å¤§å‹æœºæ¢°è‡‚æºå¸¦ï¼‰ï¼Œè€Œå¤šä¼ æ„Ÿå™¨ç»„åˆæä¾›äº†å…¨é¢çš„éç ´åæ€§æ£€æµ‹èƒ½åŠ›ã€‚\\n\\n> **åˆ›æ–°ç‚¹ (Innovations)**\\n> *   **ä¸å…ˆå‰å·¥ä½œçš„å¯¹æ¯”**ï¼šä¼ ç»Ÿè½¨é“ç»´æŠ¤ä¾èµ–å•ä¸€åŠŸèƒ½æœºå™¨äººæˆ–èˆªå¤©å‘˜æ“ä½œï¼Œç¼ºä¹çµæ´»æ€§å’Œè‡ªä¸»æ€§ã€‚\\n> *   **æœ¬æ–‡çš„æ”¹è¿›**ï¼šMIMé€šè¿‡æ ‡å‡†æ¥å£ï¼ˆSIï¼‰å’Œæ¨¡å—åŒ–è®¾è®¡ï¼Œå®ç°äº†ä¸è¡Œèµ°æœºæ¢°è‡‚ï¼ˆWMï¼‰çš„æ— ç¼é›†æˆï¼Œæ”¯æŒå¤šç§æ“ä½œæ¨¡å¼ï¼ˆå¦‚è¡Œèµ°ã€å·¥å…·æ“ä½œï¼‰ï¼Œå¹¶é›†æˆå¤šä¼ æ„Ÿå™¨å’Œè½»é‡ç»´æŠ¤å·¥å…·ï¼Œæå‡äº†æ£€æµ‹å’Œç»´æŠ¤çš„çµæ´»æ€§ä¸æ•ˆç‡ã€‚\\n\\n> **å…·ä½“å®ç°æ­¥éª¤ (Implementation Steps)**\\n> *   1. **æœºæ¢°è®¾è®¡**ï¼šåŸºäºå¤šè‡‚æœºå™¨äººï¼ˆMARï¼‰çš„èº¯å¹²å½¢å¼ï¼Œé‡‡ç”¨å…­è¾¹å½¢ä¸å¯¹ç§°è®¾è®¡ï¼Œé…å¤‡ä¸‰ä¸ªæ ‡å‡†æ¥å£ï¼ˆHDï¼‰å’Œä¼ æ„Ÿå™¨èˆ±ï¼ˆå¯å€¾æ–œï¼‰ã€‚\\n> *   2. **ä¼ æ„Ÿå™¨é›†æˆ**ï¼šåœ¨ä¼ æ„Ÿå™¨èˆ±å†…å®‰è£…é«˜åˆ†è¾¨ç‡æ‘„åƒå¤´ï¼ˆRaspberry Pi 5 + Pi Camera 3ï¼‰ã€3Dç»“æ„å…‰ç›¸æœºï¼ˆMatter And Form THREEï¼‰å’Œçƒ­æˆåƒç›¸æœºï¼ˆWaveshareï¼‰ã€‚\\n> *   3. **å·¥å…·å­˜å‚¨ä¸æ“ä½œ**ï¼šå·¥å…·å­˜å‚¨åœ¨æœºèº«ä¸¤ä¾§çš„å¼€æ”¾å¼éš”é—´ä¸­ï¼Œç”±WMé€šè¿‡æœªä½¿ç”¨çš„HDæ¥å£æ“ä½œã€‚\\n> *   4. **è®¡ç®—ä¸é€šä¿¡**ï¼šé‡‡ç”¨Nvidia Jetson Orin Nanoä½œä¸ºä¸»æ§æ¿ï¼Œè¿è¡ŒROS2ä¸­é—´ä»¶ï¼Œæ”¯æŒå®æ—¶å›¾åƒå’Œä¿¡å·å¤„ç†ç®—æ³•ã€‚\\n\\n> **æ¡ˆä¾‹è§£æ (Case Study)**\\n> *   è®ºæ–‡æœªæ˜ç¡®æä¾›æ­¤éƒ¨åˆ†ä¿¡æ¯ã€‚\",\n  \"comparative_analysis\": \"### ğŸ“Š å¯¹æ¯”å®éªŒåˆ†æ\\n\\n> **åŸºçº¿æ¨¡å‹ (Baselines)**\\n> *   è®ºæ–‡æœªæ˜ç¡®æä¾›ä¸å…¶ä»–åŸºçº¿æ¨¡å‹çš„å¯¹æ¯”å®éªŒã€‚\\n\\n> **æ€§èƒ½å¯¹æ¯” (Performance Comparison)**\\n> *   **åœ¨æ£€æµ‹ç²¾åº¦ä¸Š**ï¼šMIMçš„3Dè½®å»“ä»ªå¯æ£€æµ‹0.3mmçš„è¡¨é¢åˆ’ç—•æˆ–å˜å½¢ï¼Œçƒ­æˆåƒç›¸æœºå¯åŒºåˆ†-40Â°Cè‡³150Â°Cçš„å±€éƒ¨æ¸©åº¦ã€‚\\n> *   **åœ¨æ“ä½œçµæ´»æ€§ä¸Š**ï¼šMIMæ”¯æŒä¸‰ç§é…ç½®æ¨¡å¼ï¼ˆè¡Œèµ°ã€å¤–éƒ¨å®‰è£…ã€å¤§å‹æœºæ¢°è‡‚æºå¸¦ï¼‰ï¼Œèƒ½å¤Ÿé€‚åº”å¤šç§æ£€æµ‹å’Œç»´æŠ¤åœºæ™¯ã€‚\\n> *   **åœ¨åŠŸè€—ä¸Š**ï¼šMIMçš„åŠŸè€—çº¦ä¸º5Wï¼ˆä¸åŒ…æ‹¬ä¸»æ§æ¿å’Œç…§æ˜æºï¼‰ï¼Œé€‚ç”¨äºç©ºé—´åº”ç”¨çš„ä½åŠŸè€—éœ€æ±‚ã€‚\",\n  \"keywords\": \"### ğŸ”‘ å…³é”®è¯\\n\\n*   ç©ºé—´æœºå™¨äºº (Space Robotics, N/A)\\n*   åœ¨è½¨æœåŠ¡ (Orbital Servicing, N/A)\\n*   éç ´åæ€§æ£€æµ‹ (Non-Destructive Testing, NDT)\\n*   æ¨¡å—åŒ–æœºå™¨äºº (Modular Robotics, N/A)\\n*   è¡Œèµ°æœºæ¢°è‡‚ (Walking Manipulator, WM)\\n*   æ ‡å‡†æ¥å£ (Standard Interconnect, SI)\\n*   è½¨é“ä»“åº“ (Orbital Depot, N/A)\\n*   è‡ªä¸»æ£€æµ‹ (Autonomous Inspection, N/A)\"\n}\n```"
}