{
    "link": "https://arxiv.org/abs/2403.18435",
    "pdf_link": "https://arxiv.org/pdf/2403.18435",
    "title": "DELTA: Pre-train a Discriminative Encoder for Legal Case Retrieval via Structural Word Alignment",
    "authors": [
        "Haitao Li",
        "Qingyao Ai",
        "Xinyan Han",
        "Jia Chen",
        "Qian Dong",
        "Yiqun Liu",
        "Chong Chen",
        "Qi Tian"
    ],
    "publication_date": "2024-03-27",
    "venue": "arXiv.org",
    "fields_of_study": [
        "Computer Science"
    ],
    "citation_count": 8,
    "influential_citation_count": 0,
    "paper_content": "# DELTA: Pre-Train a Discriminative Encoder for Legal Case Retrieval via Structural Word Alignment\n\nHaitao $\\mathbf { L I } ^ { 1 , 2 }$ Qingyao ${ \\bf A } { \\bf I } ^ { 1 , 2 }$ Xinyan $\\mathbf { H A N } ^ { 1 , 2 }$ , Jia CHEN3, Qian DONG1,2, Yiqun $\\mathbf { L I U } ^ { 1 , 2 * }$\n\n1Department of Computer Science and Technology, Tsinghua University, Beijing, China 2 Institute for Internet Judiciary, Tsinghua University, Beijing, China 3 Xiaohongshu Inc liht22@mails.tsinghua.edu.cn\n\n# Abstract\n\nRecent research demonstrates the effectiveness of using pretrained language models for legal case retrieval. Most of the existing works focus on improving the representation ability for the contextualized embedding of the $\\left[ C L S \\right]$ token and calculate relevance using textual semantic similarity. However, in the legal domain, textual semantic similarity does not always imply that the cases are relevant enough. Instead, relevance in legal cases primarily depends on the similarity of key facts that impact the final judgment. Without proper treatments, the discriminative ability of learned representations could be limited since legal cases are lengthy and contain numerous non-key facts. To this end, we introduce DELTA, a discriminative model designed for legal case retrieval. The basic idea involves pinpointing key facts in legal cases and pulling the contextualized embedding of the $\\ [ C L S ]$ token closer to the key facts while pushing away from the non-key facts, which can warm up the case embedding space in an unsupervised manner. To be specific, this study brings the word alignment mechanism to the contextual masked auto-encoder. First, we leverage shallow decoders to create information bottlenecks, aiming to enhance the representation ability. Second, we employ the deep decoder to enable “translation” between different structures, with the goal of pinpointing key facts to enhance discriminative ability. Comprehensive experiments conducted on publicly available legal benchmarks show that our approach can outperform existing state-of-theart methods in legal case retrieval. It provides a new perspective on the in-depth understanding and processing of legal case documents.\n\n# Code — https://github.com/CSHaitao/DELTA\n\n# Introduction\n\nLegal case retrieval, which focuses on retrieving relevant cases for a query case, is essential for supporting legal reasoning and decision-making (Shao et al. 2020; Li et al. 2023a,b). In recent years, neural retrieval models constructed with pre-trained language models (PLM), which are capable of capturing the latent semantics of text documents, have attracted significant attention in the field of legal case retrieval (Su et al. 2024). For instance, Xiao et al (Xiao et al.\n\n2021) propose Lawformer based on Longformer. Li et al. (Li et al. 2023a) developed a structure-aware framework named SAILER which utilizes structural information in legal cases to better pretrain the text encoder.\n\nDespite their success, existing pre-trained retrieval models for legal case retrieval are far from being perfect due to several problems. One particularly significant issue is their incapability of discriminating key legal facts, which are crucial for determining case relevance, from other texts that simply describe case background and unimportant facts. As highlighted in prior research (Ma et al. 2021; Shao et al. 2023), the relevance determination in legal case retrieval is complex and fundamentally different from general search relevance. Unlike open-domain retrieval which mostly relies on keyword matching or text semantic similarity, legal case relevance focuses more on the identification of key facts that are crucial for case decisions. Existing pre-trained models focus on constructing better representations that capture the text semantics of individual case documents. However, in the legal domain, better semantic representation vectors do not always lead to better discrimination of legal relevance if the representations focus on capturing facts that are unimportant from legal perspectives.\n\nTo address this issue, we propose a novel framework called DELTA, which stands for Pre-training a Discriminative Encoder for Legal Case ReTrieval via Structural Word Alignment. Inspired by SAILER, we further delve into the knowledge implied between different structures of legal case documents to pre-train the encoder. Specifically, DELTA employs an encoder-decoder architecture to achieve an in-depth understanding of legal cases and effective extraction of key information. Besides employing shallow decoders to create a bottleneck for the $\\left[ C L \\bar { S } \\right]$ token and generate high-quality textual representations, DELTA also incorporates the Structural Word Alignment (SWA) task to identify key facts by “translating” the Fact section to the legal analysis and decisions in the Reasoning section. Furthermore, DELTA enhances the alignment between the case representation and its key factual information in the semantic space. This alignment is achieved by pulling the case representation closer to the key facts while simultaneously pushing it away from background information within the case document. The whole algorithm not only enhances the discriminative ability of the representation models from the legal perspective but also helps legal users better track the key facts in retrieved cases, thus making the results more interpretable and trustworthy. To the best of our knowledge, DELTA is the first work to apply word alignment in legal case retrieval, which provides new perspectives for in-depth understanding and processing of legal cases. To validate the effectiveness of our model, we carried out comprehensive experiments on Chinese and English legal benchmarks. Empirical results indicate that DELTA significantly outperforms current state-of-the-art baselines.\n\n# Related Work\n\n# Legal Case Retrieval\n\nLegal case retrieval has attracted considerable attention from both academia and industry. Researchers in legal case retrieval primarily focus on two categories of models: Expert Knowledge-based models (Zeng et al. 2005; Saravanan, Ravindran, and Raman 2009) and Natural Language Processing (NLP) models (Shao et al. 2020; Xiao et al. 2021; Chalkidis et al. 2020; Li et al. 2023a). Expert knowledgebased modeling enhances case representation by extending legal elements (Zeng et al. 2005) or developing ontological frameworks (Saravanan, Ravindran, and Raman 2009), including the introduction of new sub-elements to the legal problem element for a more comprehensive representation of legal cases. On the other hand, Natural Language Processing models employ deep learning techniques such as BERT and its variants to capture semantic similarities between cases at the text level. These models show great potential for legal case retrieval.\n\nRecently, numerous studies have addressed the challenge of long texts in the legal field by segmenting the text into paragraphs or enlarging the inputs for language models. For instance, Shao et al. (Shao et al. 2020) segment legal documents into multiple paragraphs and subsequently aggregate the scores. Tang et al. (Tang et al. 2023) converted the cases into a Text-Attributed Case Graph to better represent legal instruments. Furthermore, many researchers have attempted to enhance performance by pre-training models on extensive legal corpora. For instance, the development of LEGALBERT (Chalkidis et al. 2020) involved collecting a significant array of English legal texts from various domains for pre-training. Li et al. (Li et al. 2023a) employed the specific structure of legal documents to pre-train SAILER, achieving state-of-the-art results on the legal dataset. Despite great success, the primary objective of these models is to enhance representing capabilities. However, in the legal domain, semantic similarity does not always correspond to case relevance. In this paper, our objective is to identify key facts within legal documents, thereby enhancing the discriminative ability of representation vectors.\n\n# Word Alignment in Language Translation\n\nWord Alignment (WA) is a crucial component of statistical machine translation, primarily dedicated on establishing correspondences between words in a sentence pair (Li et al. 2019). This task plays a critical role in comprehending the relationships between languages and facilitating crosslanguage translation. In traditional statistical machine translation (Dyer, Chahuneau, and Smith 2013; Och and Ney 2003), word alignment usually requires an annotated parallel corpus, i.e., correspondences need to be manually created for each word in a sentence. This procedure is both laborintensive and costly.\n\nWith the rapid evolution of Neural Machine Translation, alignment by attention brings a more flexible and efficient solution (Bahdanau, Cho, and Bengio 2014; Chatterjee et al. 2017; Li et al. 2019; Garg et al. 2019; Zenkel, Wuebker, and DeNero 2019; Liu et al. 2016). Neural machine translation can automatically learn word alignment from a corpus without manual annotation. Bahdanau et al. (Bahdanau, Cho, and Bengio 2014) were the first to demonstrate an example of word alignment using attention mechanisms in the RNNSearch model. Subsequently, Liu et al. (Liu et al. 2016) improved attention with the annotation results obtained by the statistical alignment tool, expecting better alignment results. Inspired by this work, we attempt to utilize word alignment between different structures to identify key facts in legal cases.\n\n# Task Description\n\nThe main purpose of legal case retrieval is to identify the relevant cases from the candidate cases for each query case. Formally, for a query $q$ , the legal practitioner needs to find the top- $k$ relevant cases from the candidate set C. In the legal domain, these relevant cases $\\mathbf { C } _ { q } = c _ { 1 } ^ { * } , c _ { 2 } ^ { * } , . . . . . . , c _ { k } ^ { * }$ are known as precedents, referring to historical cases that provide support for the judgment of the query case. In most legal case retrieval scenarios, $q$ only contains the Facts component, while each candidate case containing the complete structure.\n\nGenerally speaking, a legal case usually consists of three parts: Fact, Reasoning, and Decision. The Fact section focuses on the argument, evidence, and basic facts. Since arguments and evidence are not all useful, Fact section usually contains a great deal of non-key facts. The Reasoning section reveals how the court selects and applies the legal rules. The Decision section is the definitive response of the court to the legal dispute. In practice, when legal practitioners draft a legal case document, they first analyze the key facts and subsequently construct the Reasoning section based on their experience. This process can be regarded as “translating” the Fact section into the Reasoning section. Numerous words or phrases within these two sections exhibit correspondences. Understanding the structures in legal cases and learning the correspondence between structures is essential to improve the performance of legal case retrieval.\n\n# Method\n\nThe framework of DELTA is shown as Figure 1. DELTA consists of three components, i.e., fact encoder, shallow decoders for different case sections, and a deep decoder for word alignment. The optimization goal is to make this dense embedding more expressive and distinguishable.\n\n![](images/527b7f2645e8920b0fd061184b775167fa259228e405c74fd5d0536a0951ec9e.jpg)  \nFigure 1: Pre-training designs of DELTA. DELTA creates information bottlenecks with two shallow decoders to improve representing ability of $\\left[ C L S \\right]$ vector. Furthermore, Structural Word Alignment task is employed to identify key facts. DELTA pulls $\\left[ C L S \\right]$ vectors closer to key facts and pushes them away from the non-key facts to enhance discriminative ability.\n\n# Encoder and Shallow Decoder\n\nThe Encoder encodes the Fact section into a high-quality representation vector to perform effective retrieval. In particular, the Fact section $F = [ f _ { 1 } , . . . , f _ { n } ]$ is sampled, and then a portion of its tokens is randomly selected to be replaced with the $[ M A S K ]$ token. To preserve enough information, only a small portion $( 0 - 1 5 \\% )$ of the token is replaced. We define the masked tokens as $m ( F )$ and input the masked fact $F _ { m a s k }$ to the encoder $\\Psi _ { F }$ . We can get the contextualized embeddings of $\\left[ C L S \\right]$ token $h _ { F }$ and other ordinary tokens $H _ { F }$ :\n\n$$\nh _ { F } , H _ { F } = \\Psi _ { F } ( F _ { m a s k } )\n$$\n\nThe masked tokens are predicted using the standard approach of masked language modeling, resulting in the encoder’s loss $L _ { m l m }$ .\n\nAs for decoding, we introduce two shallow decoders i.e., Reasoning Decoder and Decision Decoder. In this process, we concatenate the dense vector $h _ { F }$ with contextual sentence embedding and feed it into shallow decoders for text reconstruction. Specifically, we select some original tokens from the Reasoning section $R = [ r _ { 1 } , r _ { 2 } , . . . , r _ { n } ]$ and the Decision section $D = [ d _ { 1 } , d _ { 2 } , . . . , \\bar { d _ { n } } ]$ and replace them with $[ M A S K ]$ token. Aggressive masking rates $( > = 3 0 \\%$ ) are employed to provide adequate difficulty in reconstruction. Then, the original $\\left[ C L S \\right]$ vectors in the Reasoning and Decision section are replaced with the dense representation $h _ { F }$ from Fact Encoder. The processed texts $m ( R )$ and $m ( D )$ are fed into their respective decoders. The loss for reconstructing the original text is defined as $L _ { d e c }$ . As discussed in previous work (Lu et al. 2021), the shallow decoder has limited capabilities, so $h _ { f }$ is forced to represent more information for text reconstruction.\n\n# Structural Word Alignment\n\nMany studies (Li et al. 2023a; Ma et al. 2023a) have already shown that the rich knowledge embedded in the structure of legal documents can effectively aid in model training. We further extend this spirit to improve the encoder’s discriminative ability by exploiting potential correspondences between the different structures of legal case documents.\n\nSince the Reasoning section discusses and analyzes all the key facts, each of which has a corresponding description, we attempt to identify the key fact tokens in the Fact section through the word alignment mechanism. However, annotated word alignment is challenging and labor-intensive. Instead, there has been some work exploring unsupervised word alignment with neural machine translation, which has proven to be effective (Garg et al. 2019; Zenkel, Wuebker, and DeNero 2019). Inspired by these studies, we propose the Structural Word Alignment (SWA) task in this section.\n\nSpecifically, given a Fact section $\\boldsymbol { F } ~ = ~ [ f _ { 1 } , . . . , f _ { I } ]$ that serves as the source sentence and a Reasoning section $R =$ $\\left[ r _ { 1 } , r _ { 2 } , . . . , r _ { J } \\right]$ as the target sentence, where $I$ and $J$ represent the lengths of Fact and Reasoning section respectively, an alignment $\\Lambda$ is defined as a subset of the Cartesian product of the word positions (Och and Ney 2003):\n\n$$\n\\Lambda \\subseteq \\{ ( i , j ) : i = 1 , . . . , I ; j = 1 , . . . , J \\}\n$$\n\nThe goal of the word alignment task is to establish a discrete alignment, representing a many-to-many mapping of source words to their corresponding translations in the target sentence. To achieve unsupervised word alignment, DELTA introduces another decoder, with sufficiently deep layers to effectively perform the translation process. This decoder is autoregressive and its training objective can be formulated as:\n\n$$\nL _ { T L M } = - \\sum _ { j = 1 } ^ { J } \\log p ( r _ { j } | \\boldsymbol { F } , r _ { < j } , \\boldsymbol { \\theta } )\n$$\n\nwhere $\\theta$ denotes the parameters of the deep decoder. Different from the shallow decoder, all ordinary tokens in the Fact section contribute to decoding the next token. It is also worth noting that this loss function does not optimize the parameters of the encoder to preserve its original encoding capability.\n\nIn this paper, we focus on guiding the cross-attention sublayer in the decoder to obtain the alignment relation. Formally, the representation of the $i ^ { t h }$ target token in the decoder as $q ^ { i } \\in \\mathbb { R } ^ { 1 \\ast d _ { e m b } }$ , where $d _ { e m b }$ denotes the dimension of vectors. The output vectors of all source tokens from the encoder serve as the key matrix $K \\in \\mathbb { R } ^ { I * d _ { e m b } }$ and the value matrix $V \\in \\mathbb { R } ^ { I * d _ { e m b } }$ . It is worth noting that the $K$ and $V$ matrices are identical, which corresponds to the outputs of the encoder. Then, the $N$ heads project the query vector and the key and value matrices into distinct subspaces:\n\n$$\n\\tilde { q } _ { n } ^ { i } = q ^ { i } W _ { n } ^ { Q } , \\tilde { K } _ { n } = K W _ { n } ^ { K } , \\tilde { V } _ { n } = V W _ { n } ^ { V }\n$$\n\n$$\nH _ { n } ^ { i } = A t t e n t i o n ( \\tilde { q } _ { n } ^ { i } , \\tilde { K } _ { n } , \\tilde { V } _ { n } )\n$$\n\n$$\nM ( q ^ { i } , K , V ) = C o n c a t ( H _ { 1 } ^ { i } , . . . , H _ { N } ^ { i } ) W ^ { O }\n$$\n\nwhere $W _ { n } ^ { Q }$ , $W _ { n } ^ { K }$ , $\\boldsymbol { W } _ { n } ^ { V }$ and $W ^ { O }$ are all trainable parameters of the $n ^ { t h }$ head. $C o n c a t ( \\cdot )$ denotes the concatenate of multihead attention. The scaled dot-product attention is employed by each head:\n\n$$\nA t t e n t i o n ( \\tilde { q } _ { n } ^ { i } , \\tilde { K } _ { n } ^ { i } , \\tilde { V } _ { n } ^ { i } ) = a _ { n } ^ { i } \\tilde { V } _ { n }\n$$\n\n$$\na _ { n } ^ { i } = s o f t m a x ( \\frac { \\tilde { q } _ { n } ^ { i } \\tilde { K } _ { n } ^ { T } } { \\sqrt { d _ { e m b } } } )\n$$\n\nwhere $a _ { n } ^ { i }$ represents the attention probabilities for the $i ^ { t h }$ target token across all source tokens in the $n ^ { t h }$ attention head. The multi-head attention mechanism of the transformer generates multiple attention matrices. To gain a deeper insight into the behavior of the encoder-decoder attention, we average the attention matrices across all heads within each layer to get $a ^ { i }$ . The word alignment $\\Lambda$ can be readily extracted from the attention weight $a ^ { i }$ according to the style of maximum a posterior strategy (MAP):\n\n$$\n\\Lambda _ { i , j } = \\left\\{ { \\begin{array} { r l r } { 1 } & { j = \\arg \\operatorname* { m a x } _ { j ^ { ' } } a _ { j ^ { ' } } ^ { i } } \\\\ { 0 } & { \\mathrm { o t h e r w i s e } } \\end{array} } \\right.\n$$\n\nFollowing Garg et al. (Garg et al. 2019), we utilize the attentional probability of the penultimate layer, i.e., $l = L -$ 1, as the alignment result, which is shown to provide the best alignment result in previous studies. Afterward, we group together the vectors ${ \\bar { a } } ^ { i }$ to obtain the attention matrix $A _ { I \\times J }$ .\n\nThe importance of tokens in the Fact section is calculated as follows:\n\n$$\nX _ { i } = \\sum _ { j = 1 } ^ { J } \\Lambda _ { i , j } A _ { i , j }\n$$\n\nAccording to $X _ { i }$ , we choose the top $p \\%$ importance token in the Fact section as the key facts $F _ { k e y }$ , and the others are considered as non-key facts $F _ { n o n - k e y }$ . Then, we employ mean pooling on the embedding of these token to get their representations. In an ideal vector space for legal cases, $\\left[ C L S \\right]$ embeddings are expected to be consistent with representations of key facts while far from non-key facts. Thus, contrastive learning is employed to achieve this objective, where representations of key facts are treated as positive examples $h _ { p }$ and those of non-key facts are negative examples $h _ { n }$ . The loss function $L _ { C O N }$ is formulated as follows:\n\n$$\n L _ { C O N } = - \\log \\frac { e x p ( s i m ( h _ { f } , h _ { p } ) ) } { e x p ( s i m ( h _ { f } , h _ { p } ) ) + e x p ( s i m ( h _ { f } , h _ { n } ) ) }\n$$\n\nwhere $s i m ( \\cdot )$ is the dot-product function. In practice, the in-batch negative technique (Karpukhin et al. 2020) is employed to better utilize positive and negative samples from the same batch. To be specific, given a case $q$ , both positive and negative samples of the other cases in the same batch are considered as negative samples for case $q$ . Notably, all positive and negative examples are obtained unsupervised without any manual annotation. This unsupervised text-level contrastive learning loss can effectively warm up the embedding space and improve the discriminative ability of the DELTA. Finally, the optimization objective of the model is the combination of the above losses, which is formulated as:\n\n$$\nm i n . L _ { m l m } + L _ { d e c } + \\lambda _ { 1 } L _ { T L M } + \\lambda _ { 2 } L _ { C O N }\n$$\n\nwhere $\\lambda _ { 1 }$ and $\\lambda _ { 2 }$ is the hyperparameters.\n\nCompared to SAILER, DELTA cleverly leverages other ordinary tokens to more finely extract the legal knowledge embedded in different structures. The additional information provided by these ordinary tokens can help generate better semantic representations, offering greater potential for practical applications.\n\n# Experiment Setting Datasets and Metrics\n\nIn this paper, we conducted experiments on both Chinese and English legal case retrieval benchmarks. Below, we provide detailed descriptions of these datasets:\n\n- LeCaRD (Ma et al. 2021) is a widely used legal case retrieval dataset under the Chinese legal system. It contains 107 queries and 43,000 candidate case documents. - CAIL2022-LCR is another Chinese legal case retrieval dataset, which has been provided as the test set for the CAIL2022 legal case retrieval competition. This dataset comprises 130 queries and 13,000 candidate cases. - COLIEE2022 (Kim et al. 2022) is an English dataset that serves as the official dataset for COLIEE2022 Task 1. This dataset consists of two parts: the training set and the test set. The training set comprises 898 queries and 3,531 candidate cases, while the test set includes 300 queries and 1,263 candidate cases.\n\n- COLIEE2023 (Goebel et al. 2023) serves as the benchmark for evaluating legal case retrieval techniques in the COLIEE2023 competition. This dataset contains 959 query cases against 4,400 candidate cases for training and 319 query cases against 1,335 candidate cases for testing.\n\nWe follow the official metrics for these datasets to evaluate performance. Specifically, for LeCaRD and CAIL2022- LCR, we employ Precision $\\textcircled { a } 5$ , Recall $\\textcircled { a } 5$ , F1 score, $\\mathrm { N D C G } @ 1 0$ and ${ \\mathrm { N D C G } } \\ @ 3 0 .$ . Furthermore, for the COLIEE datasets, we provide results for Precision $\\textcircled { a } 5$ , Recall $\\textcircled { a } 5$ , F1 score, $\\mathbf { R } @ 1 0 0$ , and $\\mathbf { R } @ 5 0 0$ .\n\nDue to the limited number of queries and the lack of training sets in the Chinese datasets LeCaRD and CAIL2022- LCR, we only conducted zero-shot experiments on these datasets. For detailed statistics on the data, please refer to the Appendix.\n\n# Baselines\n\nWe conduct a comparison of DELTA with four distinct categories of baseline models, including Sparse Retrieval Models, General Pre-trained Models, Dense Retrieval Models, and Legal-oriented Pre-trained Models.\n\nRegarding Sparse Retrieval Models, we consider taking BM25 (Robertson, Zaragoza et al. 2009) and QLD (Zhai 2008) as the baseline models, both of which are classical retrieval models based on lexical matching. Furthermore, General Pre-trained Models include BERT (Devlin et al. 2018) and RoBERTa (Liu et al. 2019), with adaptations for the Chinese dataset using the corresponding Chinese versions of BERT and RoBERTa. We further extend our comparison to include a range of Dense Retrieval models: coCondneser (Gao and Callan 2021), SEED (Lu et al. 2021), COTMAE (Wu et al. 2022). These models have retrieval-oriented optimization objectives and achieve state-of-the-art performance in web search tasks. To ensure equitable comparisons, we pre-train these models on the legal corpus with their optimal parameters.\n\nFinally, we take into account pre-trained language models tailored to legal scenarios. These models comprise BERT xs, Lawformer (Xiao et al. 2021), LEGALBERT (Chalkidis et al. 2020), SAILER (Li et al. 2023a), CaseEncoder (Ma et al. 2023b).\n\nSince our work focuses on dense retrieval in legal scenarios, we did not include more time-consuming methods such as ColBERT (Khattab and Zaharia 2020), CaseGNN (Tang et al. 2023), CaseLink (Tang et al. 2024), and SLC (Ma et al. 2023a) in our baselines.\n\n# Implementation Details\n\nPre-training We initialize the encoder of the English/Chinese version of DELTA separately from bert-baseuncased/chinese-bert-wwm. The decoders are initialized from scratch. In line with Li et al. (Li et al. 2023a), the Chinese pre-training corpus comprises tens of millions of legal case documents, sourced from China Judgment Online 1. We divide the case documents into three parts: Fact, Reasoning, Decision, with regular expression matching. Simple cases with facts less than 50 words are filtered. Similarly, the English pre-training corpus comprises an extensive collection of legal case documents from the U.S. federal and state courts 2. The detailed data processing procedure is in the Appendix.\n\nDuring the pre-training phase, we conduct training for up to 5 epochs using AdamW (Loshchilov and Hutter 2018) optimizer, with a learning rate of 5e-5, and a linear schedule with a warmup ratio of 0.1. The batch size is set to 72. The default mask ratio is set to 0.15 for the encoder and 0.45 for the shallow decoders. The shallow decoder is designed with a single transformer layer, while the deep decoder consists of six transformer layers. The hyperparameters $p$ and is set to 60. A more elegant approach would be to adaptively assign different $p$ values for each case, which we leave for future work. The hyperparameters $\\lambda _ { 1 }$ and $\\lambda _ { 2 }$ are both set to 1.\n\nFine-tuning During the fine-tuning phase, we discard all decoders and solely fine-tune the encoder. The training is performed on the COLIEE training set, employing a contrastive learning loss. For each given query, we employ BM25 to retrieve the top 100 related documents from the entire corpus, where irrelevant documents are treated as negative examples. The ratio of positive to negative examples is maintained at 1:15. We fine-tune the model up to 20 epochs employing the AdamW (Loshchilov and Hutter 2018) optimizer, with a learning rate set at 5e-6, a batch size of 4, and a linear schedule that includes a warmup ratio of 0.1. All experiments presented in this paper are conducted on 8 NVIDIA Tesla A100 GPUs.\n\n# Experiment Result\n\n# Zero-Shot Evaluation\n\nWe conduct zero-shot experiments on four legal benchmarks. The performance comparisons on two Chinese criminal law datasets are shown in Table 1. Due to space constraints, the zero-shot experiments on the English datasets are included in the Appendix. Based on the results in this table, we can derive the following conclusions:\n\n• Without the guidance of training data, BM25 and QLD show competitive performance in legal case retrieval task, which is in line with previous findings (Li et al. 2023b). It shows that sparse retrieval methods are still very robust baselines in legal case retrieval task. • General Pre-trained Models usually show suboptimal performance on legal case retrieval. This can be attributed to that their pre-training objectives are not tailored for similarity-based tasks, especially for legal case retrieval. • Dense Retrieval model enhances their ability for similarity modeling, typically resulting in superior performance compared to General Pre-trained Models. However, even after being retrained on legal corpora, they still fall short in the legal domain due to a lack of understanding of legal cases.\n\nTable 1: Comparisons between DELTA and various baselines on Chinese benchmark on zero-shot setting. $* / * *$ denotes that DELTA performs significantly better than baselines at $p < 0 . 0 5 / 0 . 0 1$ level using the Fisher randomization test (Rubin 1980). Best method in each column is marked bold.   \n\n<html><body><table><tr><td rowspan=\"2\">Model</td><td colspan=\"4\">LeCaRD</td><td rowspan=\"2\"></td><td colspan=\"4\">CAIL2022-LCR</td></tr><tr><td>Precision</td><td>Recall</td><td>F1_score</td><td>NDCG@10 NDCG@30</td><td>Precision</td><td>Recall</td><td>F1_score</td><td>NDCG@10 NDCG@30</td></tr><tr><td>BM25</td><td>0.8916</td><td>0.1748</td><td>0.2922</td><td>0.7115**</td><td>0.8172*</td><td>0.8477**</td><td>0.2018**</td><td>0.3259** 0.7303**</td><td>0.8304*</td></tr><tr><td>QLD</td><td>0.8897</td><td>0.1737</td><td>0.2906</td><td>0.7157**</td><td>0.8373 0.8538**</td><td>0.2004**</td><td>0.3246**</td><td>0.7535**</td><td>0.8545</td></tr><tr><td>Chinese BERT</td><td>0.6654**</td><td>0.1263**</td><td>0.2123**</td><td>0.5252**</td><td>0.5374**</td><td>0.6600** 0.1487**</td><td>0.2427**</td><td>0.5604**</td><td>0.5618**</td></tr><tr><td>Chinese RoBERTa</td><td>0.8841</td><td>0.1778</td><td>0.2960</td><td>0.7438**</td><td>0.7897**</td><td>0.9046 0.2180</td><td>0.3513</td><td>0.8043**</td><td>0.8518</td></tr><tr><td>coCondenser</td><td>0.8411**</td><td>0.1648**</td><td>0.2756**</td><td>0.6719**</td><td>0.7404**</td><td>0.1931** 0.8138**</td><td>0.3121**</td><td>0.7063**</td><td>0.7607**</td></tr><tr><td>SEED</td><td>0.8411**</td><td>0.1575**</td><td>0.2653**</td><td>0.6721**</td><td>0.7330**</td><td>0.8369** 0.1906**</td><td>0.3105**</td><td>0.7365**</td><td>0.7815**</td></tr><tr><td>COT-MAE</td><td>0.8467**</td><td>0.1567**</td><td>0.2644**</td><td>0.6815**</td><td>0.7089**</td><td>0.8446** 0.1996**</td><td>0.3229**</td><td>0.7274**</td><td>0.7311**</td></tr><tr><td>BERT_xs</td><td>0.7159**</td><td>0.1377**</td><td>0.2309**</td><td>0.5695**</td><td>0.5751**</td><td>0.6462** 0.1369**</td><td>0.2259**</td><td>0.5236**</td><td>0.5206**</td></tr><tr><td>SAILER</td><td>0.9028</td><td>0.1902</td><td>0.3142</td><td>0.7979</td><td>0.8485</td><td>0.8938 0.2310</td><td>0.3671</td><td>0.8319</td><td>0.8660</td></tr><tr><td>Lawformer</td><td>0.8056**</td><td>0.1552**</td><td>0.2603**</td><td>0.6216**</td><td>0.6362**</td><td>0.7908** 0.1820**</td><td>0.2935**</td><td>0.6908**</td><td>0.6988**</td></tr><tr><td>CaseEncoder</td><td>0.8926</td><td>0.1879</td><td>0.3104</td><td>0.7850*</td><td>0.8391*</td><td>0.8947 0.2323</td><td>0.3688</td><td>0.8330</td><td>0.8670</td></tr><tr><td>DELTA</td><td>0.9308</td><td>0.1959</td><td>0.3236</td><td>0.8117</td><td>0.8579</td><td>0.9077</td><td>0.2377 0.3767</td><td>0.8379</td><td>0.8709</td></tr></table></body></html>\n\nTable 2: Comparisons between DELTA and various baselines on English benchmark with fine-tuning setting. $^ { * } / { ^ { * * } } { ^ { * } }$ denotes that DELTA performs significantly better than baselines at $p < 0 . 0 5 / 0 . 0 1$ level using the Fisher randomization test (Rubin 1980). Best method in each column is marked bold.   \n\n<html><body><table><tr><td rowspan=\"2\">Model</td><td colspan=\"5\">COLIEE2022</td><td colspan=\"5\">COLIEE2023</td></tr><tr><td>Precison</td><td>Recall</td><td>F1_score</td><td>R@100</td><td>R@200</td><td>Precison</td><td>Recall</td><td>F1_score</td><td>R@100</td><td>R@500</td></tr><tr><td>BM25</td><td>0.1307**</td><td>0.1552**</td><td>0.1418**</td><td>0.5866**</td><td>0.8416**</td><td>0.1222</td><td>0.2270</td><td>0.1589</td><td>0.6612**</td><td>0.8835**</td></tr><tr><td>QLD</td><td>0.1313**</td><td>0.1559**</td><td>0.1426**</td><td>0.6326**</td><td>0.8804**</td><td>0.1191*</td><td>0.2212*</td><td>0.1548*</td><td>0.7113*</td><td>0.9255*</td></tr><tr><td>BERT</td><td>0.1146**</td><td>0.1362**</td><td>0.1245**</td><td>0.5752**</td><td>0.8699**</td><td>0.0959**</td><td>0.1781**</td><td>0.1247**</td><td>0.6419**</td><td>0.9264*</td></tr><tr><td>RoBERTa</td><td>0.1524**</td><td>0.1805**</td><td>0.1650**</td><td>0.7517</td><td>0.9414</td><td>0.1003**</td><td>0.1862**</td><td>0.1303**</td><td>0.6967**</td><td>0.9070**</td></tr><tr><td>coCondenser</td><td>0.2393**</td><td>0.2842**</td><td>0.2598**</td><td>0.7508</td><td>0.9311</td><td>0.1197*</td><td>0.2223*</td><td>0.1556*</td><td>0.7355</td><td>0.9409</td></tr><tr><td>SEED</td><td>0.2266**</td><td>0.2692**</td><td>0.2461**</td><td>0.7527</td><td>0.9391</td><td>0.1223</td><td>0.2270</td><td>0.1589</td><td>0.7182*</td><td>0.9310*</td></tr><tr><td>COT-MAE</td><td>0.2427*</td><td>0.2882**</td><td>0.2634**</td><td>0.7608</td><td>0.9412</td><td>0.1229</td><td>0.2282*</td><td>0.1597</td><td>0.7347</td><td>0.9472</td></tr><tr><td>LEGALBERT</td><td>0.0713**</td><td>0.0847**</td><td>0.0774**</td><td>0.3432**</td><td>0.7123**</td><td>0.0545**</td><td>0.1013**</td><td>0.0709**</td><td>0.4659**</td><td>0.8629**</td></tr><tr><td>SAILER</td><td>0.2540*</td><td>0.3016*</td><td>0.2757*</td><td>0.7364*</td><td>0.9325</td><td>0.1253</td><td>0.2328</td><td>0.1629</td><td>0.7094**</td><td>0.9371*</td></tr><tr><td>DELTA</td><td>0.2707</td><td>0.3214</td><td>0.2938</td><td>0.7636</td><td>0.9493</td><td>0.1316</td><td>0.2444</td><td>0.1711</td><td>0.7493</td><td>0.9502</td></tr></table></body></html>\n\nTable 3: Ablation study on COLIEE2023 under zero-shot setting. Best results are marked bold.   \n\n<html><body><table><tr><td>Method</td><td>Precision</td><td>Recall</td><td>F1_score</td></tr><tr><td>DELTA</td><td>0.0828</td><td>0.1526</td><td>0.1075</td></tr><tr><td>w/o LcON</td><td>0.0639</td><td>0.1187</td><td>0.0831</td></tr><tr><td>W/o LTLM</td><td>0.0557</td><td>0.1036</td><td>0.0725</td></tr><tr><td>w/o Ldec</td><td>0.0608</td><td>0.1129</td><td>0.0790</td></tr><tr><td>w/o Lmlm</td><td>0.0796</td><td>0.1478</td><td>0.1035</td></tr><tr><td>w/o All</td><td>0.0338</td><td>0.0628</td><td>0.0440</td></tr></table></body></html>\n\n• Legal-oriented Pre-trained Models are generally trained on extensive legal texts, which contributes to a better understanding of legal cases. However, the pre-training objectives of both BERT xs and Lawformer do not focus on retrieval tasks, which limits their performance. SAILER, on the other hand, performs better than other pre-trained models, indicating that utilizing structural information in legal cases can lead to more effective case representations.\n\n• Finally, We can observe that DELTA achieves the best performance on all metrics. Furthermore, it’s worth noting that DELTA doesn’t show a significant improvement compared to SAILER. This observation might be attributed to the nature of the Chinese legal system where cases with similar causes are typically considered relevant, rendering the need for discriminative ability less crucial. Nevertheless, by enhancing its discriminative capability, DELTA reaches the state-of-the-art in both Chinese datasets.\n\n# Fine-tuning Evaluation\n\nWe further compare DELTA with baselines on English benchmarks. For a fair comparison, we employ the same set of hyperparameters and fine-tuning data across various pre-trained models. As shown in Table 2, we have the following findings: (1) With the guidance of annotated data, the performance of pre-trained models is further improved. However, the majority of these models still face challenges in achieving satisfactory performance. (2) In comparison to COLIEE2023, pre-trained models a more substantial improvement on the COLIEE2022 dataset. This improvement could be attributed to the greater similarity between the training and testing sets in COLIEE2022. From this, We assume that robust unsupervised training approaches are crucial in legal scenarios where large-scale labeled data are lacking. (3) Overall, DELTA consistently achieves the best results on both datasets under fine-tuned evaluation. Our designed unsupervised pretraining methods warm up the casevector representation space, leading to better performance of DELTA with supervised data. This also indicates that the advantages of DELTA are universal, irrespective of the availability of annotated training data.\n\n# Ablation Studies\n\nTo better illustrate the effectiveness of our model design and pre-training tasks, we conduct ablation studies on COLIEE2023 in the zero-shot setting, which accurately represent the nature of the pre-trained model. The experimental results are presented in Table 3. From these results, we observe: (1) The removal of the $L _ { C O N }$ component results in a significant degradation of performance, suggesting that the proposed contrastive learning loss plays a crucial role in learning discriminative representations. (2) The absence of $L _ { T L M }$ , which is crucial for training the deep decoder to provide accurate alignment, leads to a significant drop in performance. This highlights the importance of key facts in determining the relevance of legal cases. (3) Removal of $L _ { d e c }$ also results in a decrease in model performance. This suggests that shallow decoders can create information bottlenecks, enhancing the representational capabilities of text vectors. (4) Consistent with previous research (Li et al. 2023a), the $L _ { m l m }$ task enhances the model’s text comprehension, further boosting performance. These results demonstrate the effectiveness of our pre-training objectives. Both the representation and discriminative abilities of vectors are crucial for effective legal case retrieval.\n\n# Hyperparameter Analysis\n\nIn this section, we further investigate the impact of various components within the deep decoder. All reported results here are derived from experiments conducted on the COLIEE 2023 dataset in the zero-shot setting.\n\nImpact of deep decoder layers number We initially study the influence of the number of deep decoder layers on performance. As shown in Table 4, performance consistently improves as the number of deep decoder layers increases, up to a point of 6 layers. Notably, a significant decline in performance is observed when the layer count is reduced to 2. We suspect that it is necessary for a certain depth in the decoder to more effectively execute the translation task. Overall, DELTA’s performance in relation to its decoder layers exhibits notable robustness.\n\nImpact of the ratio of key facts Subsequently, we explore the effect of the key fact ratio on performance. Specifically, this experiment involves grid searching the parameter $p$ from $10 \\%$ to $80 \\%$ , in increments of $10 \\%$ . As shown in Table 5. It is evident that the key fact ratio has a significant impact on model performance. At lower $p$ values (e.g., $1 0 \\% , 2 0 \\% )$ , the selected tokens fail to adequately represent the entire case, leading to reduced performance. Conversely, excessively high $p$ values (e.g., $70 \\%$ , $8 0 \\%$ ) may include non-key facts, potentially damaging performance. Overall, DELTA maintains commendable performance across a wide range of key fact ratios, with optimal performance achieved at a $p$ value of $60 \\%$ .\n\nTable 4: The impact of deep decoder layers number on COLIEE2023 under zero-shot setting. Best results are marked bold.   \n\n<html><body><table><tr><td>Decoder Layer</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td></tr><tr><td>Precision</td><td>0.0645</td><td>0.0727</td><td>0.0771</td><td>0.0783</td><td>0.0828</td><td>0.0802</td></tr><tr><td>Recall</td><td>0.1199</td><td>0.1350</td><td>0.1431</td><td>0.1455</td><td>0.1526</td><td>0.1490</td></tr><tr><td>F1_score</td><td>0.0839</td><td>0.0945</td><td>0.1002</td><td>0.1018</td><td>0.1075</td><td>0.1043</td></tr></table></body></html>\n\nTable 5: The impact of the ratio of key facts on COLIEE2023 under zero-shot setting. Best results are marked bold.   \n\n<html><body><table><tr><td>P</td><td>Precision</td><td>Recall F1_score</td></tr><tr><td>10</td><td>0.0307 0.0570</td><td>0.0399</td></tr><tr><td>20</td><td>0.0501</td><td>0.0931 0.0651</td></tr><tr><td>30</td><td>0.0570</td><td>0.1059 0.0741</td></tr><tr><td>40</td><td>0.0658</td><td>0.1222 0.0855</td></tr><tr><td>50</td><td>0.0740</td><td>0.1373 0.0961</td></tr><tr><td>60</td><td>0.0828</td><td>0.1526 0.1075</td></tr><tr><td>70</td><td>0.0752</td><td>0.1397 0.0977</td></tr><tr><td>80</td><td>0.0708</td><td>0.1315 0.0920</td></tr></table></body></html>\n\n# Visual Analysis\n\nWe employed t-SNE to visualize the vector distribution of legal case documents. This analysis was conducted on the COLIEE 2023 dataset in the zero-shot setting. Specifically, we visualized the sampled query and its top 200 candidate cases. The Case Study section in the Appendix presents the results for both SAILER and DELTA. For SAILER, the distribution of positive samples appears almost random, and the vector distribution is concentrated in a specific region. This is attributed to SAILER focus on modeling the representation of individual cases without considering the relationships between them. In contrast, DELTA addresses this limitation by utilizing the Structural Word Alignment task to warm up the vector space. As a result, in the vector space of DELTA, positive cases are more closely aligned with the query, and the overall vector distribution is more uniform. This approach allows DELTA’s vector representation to more accurately reflect the relevance between legal cases. Overall, compared to SAILER, DELTA demonstrates a superior ability to generate discriminative case vectors.\n\n# Conclusion\n\nIn this paper, we present a novel pre-training framework DELTA for legal case retrieval. DELTA skillfully utilizes the translation process between different structures of legal case documents to identify key facts. These key facts are further employed to warm up the vector space, aiming to improve the discriminative ability of textual representations. Experimental results show that our pre-trained objectives contribute significantly to effective retrieval performance. Our method achieves state-of-the-art results on publicly available Chinese and English benchmarks. In the future, we will explore more ways to inject legal knowledge into pre-trained models for deeper understanding and analysis of legal case documents.",
    "institutions": [
        "Department of Computer Science and Technology, Tsinghua University",
        "Institute for Internet Judiciary, Tsinghua University",
        "Xiaohongshu Inc"
    ],
    "summary": "{\n    \"core_summary\": \"### 核心概要\\n\\n**问题定义**\\n现有用于法律案例检索的预训练检索模型难以有效区分关键法律事实，在法律领域，语义相似性并不总是对应案例相关性，这限制了模型的判别能力，而法律案例检索对于支持法律推理和决策至关重要。\\n\\n**方法概述**\\n提出DELTA框架，采用编码器 - 解码器架构，利用浅解码器创建信息瓶颈以提升表示能力，结合结构词对齐（SWA）任务识别关键事实，拉近案例表示与关键事实的距离，推远与背景信息的距离，从而提升模型的判别能力。\\n\\n**主要贡献与效果**\\n- 提出DELTA框架，是首个将词对齐应用于法律案例检索的工作。在公开的中文和英文法律基准测试上取得了最优结果，如在LeCaRD数据集的零样本实验中，DELTA的Precision达到0.9308，高于SAILER的0.9028；在COLIEE2022数据集的微调评估中，DELTA的Precision为0.2707，高于SAILER的0.2540。\\n- 利用结构词对齐任务识别关键事实，通过对比学习增强了表示模型从法律角度的判别能力。消融实验表明，去除对比学习损失$L_{CON}$、$L_{TLM}$、$L_{dec}$、$L_{mlm}$等组件均会导致模型性能下降，证明了各组件对模型性能的重要性。\",\n    \"algorithm_details\": \"### 算法/方案详解\\n\\n**核心思想**\\nDELTA利用法律案例不同结构间的对应关系，通过结构词对齐任务识别关键事实，拉近案例表示与关键事实的距离，推远与背景信息的距离，从而增强表示模型从法律角度的判别能力，使模型能更好地理解法律案例并有效提取关键信息。同时，通过编码器 - 解码器架构深入理解法律案例，利用浅解码器创建信息瓶颈以提高表示能力，利用深度解码器执行结构词对齐任务来识别关键事实，通过对比学习使案例表示更接近关键事实，远离非关键事实。\\n\\n**创新点**\\n先前的工作主要关注提升表示能力，未充分考虑法律领域中语义相似与案例相关性的差异，无法有效区分关键法律事实。DELTA的创新点在于进一步挖掘法律案例文档不同结构间隐含的知识，引入结构词对齐任务，利用普通标记提供的额外信息更精细地提取法律知识，增强了模型的判别能力。与SAILER相比，DELTA更精细地提取法律知识，利用普通标记生成更好的语义表示。\\n\\n**具体实现步骤**\\n1. **编码器和浅解码器**：编码器将事实部分编码为高质量表示向量，对事实部分$F = [ f _ { 1 },..., f _ { n } ]$的标记进行随机掩码，仅替换小部分（0 - 15%）标记为$[MASK]$标记，预测掩码标记得到编码器损失$L_{mlm}$。浅解码器包括推理解码器和决策解码器，对推理和决策部分的标记进行掩码，采用激进的掩码率（>= 30%），用事实编码器的稠密表示$h_{F}$替换相应部分的$[CLS]$向量，重建原始文本得到损失$L_{dec}$。\\n2. **结构词对齐**：定义对齐$\\Lambda$为词位置笛卡尔积的子集，引入深度解码器进行无监督词对齐，其训练目标为$L_{TLM}$。通过多头注意力机制得到注意力矩阵，根据注意力权重提取词对齐$\\Lambda$，计算事实部分标记的重要性$X_i = \\sum _ { j = 1 } ^ { J } \\Lambda _ { i, j } A _ { i, j }$，选择前$p\\%$的标记作为关键事实$F_{key}$，其余为非关键事实$F_{non - key}$，采用对比学习得到损失$L_{CON} = - \\log \\frac { exp ( sim ( h _ { f }, h _ { p } ) ) } { exp ( sim ( h _ { f }, h _ { p } ) ) + exp ( sim ( h _ { f }, h _ { n } ) ) }$。模型的优化目标为$min. L_{mlm} + L_{dec} + \\lambda_1 L_{TLM} + \\lambda_2 L_{CON}$。\\n3. **预训练**：分别从`bert-base-uncased`/`chinese-bert-wwm`初始化编码器，从零初始化解码器。使用AdamW优化器训练5个epoch，学习率为5e - 5，线性调度且热身比例为0.1，批量大小为72。默认编码器掩码率为0.15，浅解码器掩码率为0.45。浅解码器设计为单层变压器层，深度解码器由六层变压器层组成，超参数$p$设为60，$\\lambda_1$和$\\lambda_2$都设为1。\\n4. **微调**：丢弃所有解码器，仅微调编码器，在COLIEE训练集上训练，采用对比学习损失。对于每个查询，用BM25从整个语料库中检索前100个相关文档，无关文档作为负例，正负例比例保持1:15。使用AdamW优化器训练20个epoch，学习率为5e - 6，批量大小为4，线性调度且热身比例为0.1。\\n\\n**案例解析**\\n论文使用t - SNE对COLIEE 2023数据集在零样本设置下的法律案例文档向量分布进行可视化分析。对于SAILER，正样本分布几乎随机，向量分布集中在特定区域，因其只关注单个案例的表示建模，未考虑案例间关系。而DELTA利用结构词对齐任务使向量空间更优，正样本与查询更接近，整体向量分布更均匀，其向量表示能更准确反映法律案例间的相关性，表明DELTA生成判别式案例向量的能力更优。\",\n    \"comparative_analysis\": \"### 对比实验分析\\n\\n**基线模型**\\n- 稀疏检索模型：BM25、QLD。\\n- 通用预训练模型：BERT、RoBERTa（中文数据集使用相应中文版）。\\n- 密集检索模型：coCondenser、SEED、COT - MAE。\\n- 面向法律的预训练模型：BERT xs、Lawformer、LEGALBERT、SAILER、CaseEncoder。\\n\\n**性能对比**\\n*   **在 [Precision] 指标上：** 在LeCaRD数据集的零样本实验中，DELTA达到了 **0.9308**，优于SAILER (0.9028)、BM25 (0.8916) 等多个基线模型；在COLIEE2022数据集的微调评估中，DELTA的Precision为 **0.2707**，高于SAILER (0.2540)、BM25 (0.1307) 等。在CAIL2022 - LCR数据集的零样本实验中，DELTA达到0.9077，优于SAILER的0.8938；在COLIEE2023数据集的微调评估中，DELTA达到0.1316，优于SAILER的0.1253。\\n*   **在 [Recall] 指标上：** 在LeCaRD数据集零样本实验中，DELTA为 **0.1959**，高于部分基线模型；在COLIEE2022数据集微调评估中，DELTA达到 **0.3214**，优于多数基线模型。在CAIL2022 - LCR数据集的零样本实验中，DELTA达到0.2377，优于部分基线模型；在COLIEE2023数据集的微调评估中，DELTA达到0.2444，优于SAILER的0.2328。\\n*   **在 [F1_score] 指标上：** 在LeCaRD数据集零样本实验中，DELTA达到 **0.3236**，优于多个基线模型；在COLIEE2022数据集微调评估中，DELTA为 **0.2938**，高于多数基线模型。在CAIL2022 - LCR数据集的零样本实验中，DELTA达到0.3767，优于SAILER的0.3671；在COLIEE2023数据集的微调评估中，DELTA达到0.1711，优于SAILER的0.1629。\\n*   **在 [NDCG@10] 指标上：** 在LeCaRD数据集零样本实验中，DELTA达到 **0.8117**，优于多数基线模型。在CAIL2022 - LCR数据集的零样本实验中，DELTA达到0.8379，优于SAILER的0.8319。\\n*   **在 [NDCG@30] 指标上：** 在LeCaRD数据集零样本实验中，DELTA达到 **0.8579**，优于多数基线模型。在CAIL2022 - LCR数据集的零样本实验中，DELTA达到0.8709，优于SAILER的0.8660。\\n*   **在 [R@100] 指标上：** 在COLIEE2022数据集微调评估中，DELTA达到 **0.7636**，优于部分基线模型；在COLIEE2023数据集微调评估中，DELTA为 **0.7493**，高于多数基线模型。\\n*   **在 [R@500] 指标上：** 在COLIEE2023数据集微调评估中，DELTA达到 **0.9502**，优于多数基线模型。\",\n    \"keywords\": \"### 关键词\\n\\n- 法律案例检索 (Legal Case Retrieval, N/A)\\n- 判别式编码器预训练 (Pre - training a Discriminative Encoder, N/A)\\n- 结构词对齐 (Structural Word Alignment, SWA)\\n- 编码器 - 解码器架构 (Encoder - Decoder Architecture, N/A)\\n- 预训练模型 (Pre - trained Model, N/A)\"\n}"
}