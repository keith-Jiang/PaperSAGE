{
    "link": "https://arxiv.org/abs/2412.14724",
    "pdf_link": "https://arxiv.org/pdf/2412.14724",
    "title": "FROC: Building Fair ROC from a Trained Classifier",
    "authors": [
        "Avyukta Manjunatha Vummintala",
        "Shantanu Das",
        "Sujit Gujar"
    ],
    "publication_date": "2024-12-19",
    "venue": "arXiv.org",
    "fields_of_study": [
        "Computer Science"
    ],
    "citation_count": 0,
    "influential_citation_count": 0,
    "paper_content": "# FROC: Building Fair ROC from a Trained Classifier\n\nAvyukta Manjunatha Vummintala, Shantanu Das, Sujit Gujar\n\nInternational Institute of Information Technology, Hyderabad avyukta.v@research.iiit.ac.in, shantanu.das31@gmail.com, sujit.gujar@iiit.ac.in\n\n# Abstract\n\nThis paper considers the problem of fair probabilistic binary classification with binary protected groups. The classifier assigns scores, and a practitioner predicts labels using a certain cut-off threshold based on the desired trade-off between false positives vs. false negatives. It derives these thresholds from the ROC of the classifier. The resultant classifier may be unfair to one of the two protected groups in the dataset. It is desirable that no matter what threshold the practitioner uses, the classifier should be fair to both the protected groups; that is, the $\\mathcal { L } _ { p }$ norm between FPRs and TPRs of both the protected groups should be at most $\\varepsilon$ . We call such fairness on ROCs of both the protected attributes $\\varepsilon _ { p }$ -Equalized ROC. Given a classifier not satisfying $\\varepsilon _ { 1 }$ -Equalized ROC, we aim to design a postprocessing method to transform the given (potentially unfair) classifier’s output (score) to a suitable randomized yet fair classifier. That is, the resultant classifier must satisfy $\\varepsilon _ { 1 }$ -Equalized ROC. First, we introduce a threshold query model on the ROC curves for each protected group. The resulting classifier is bound to face a reduction in AUC. With the proposed query model, we provide a rigorous theoretical analysis of the minimal AUC loss to achieve $\\varepsilon _ { 1 }$ -Equalized ROC. To achieve this, we design a linear time algorithm, namely FROC, to transform a given classifier’s output to a probabilistic classifier that satisfies $\\varepsilon _ { 1 }$ -Equalized ROC. We prove that under certain theoretical conditions, FROC achieves the theoretical optimal guarantees. We also study the performance of our FROC on multiple real-world datasets with many trained classifiers.\n\nExtended version — https://arxiv.org/abs/2412.14724 Code and Miscellaneous — https://github.com/magnetar-iiith/FROC/tree/main\n\n# 1 Introduction\n\nThe use of Machine Learning based Models (MLM) in decision-making is prevalent today. Practitioners use MLMs’ predictions in college admissions, credit scores, recidivism, employment, recommender systems, etc. (Portugal, Alencar, and Cowan 2018; Berger, Frame, and Miller 2005). However, there have been several reports of such MLMs discriminating against individuals belonging to certain groups based on protected attribute such as gender, age, race, color, and religion. E.g., in Angwin et al. (2022), predictive models are found to be biased against the black population, or the Amazon recruitment team has to stop using the AI tool for shortlisting candidates as it was biased against females Dastin (2022). Bickel, Hammel, and O’Connell (1975); Berger, Frame, and Miller (2005); Zhao et al. (2018) show that many of such predictive models are unfair to females. Such unfair instances have driven researchers toward building a fair MLM.\n\nAn MLM that achieves fairness with the least possible compromise on traditional performance guarantees such as accuracy is desirable MLM. Building a desirable MLM involves two main steps: a) formalizing and quantifying a fairness measure and b) designing algorithms to train MLM for quantified fairness. Researchers proposed many fairness measures, majorly belonging to two categories: (i) individual fairness Dwork et al. (2012) – individuals with similar input features receive similar decision treatment irrespective of their protected attribute. (ii) Group fairness – a particular statistical property must be similar across each protected group, e.g., Disparate Impact (DI),Equalized odds (EO) (Madras et al. 2018).\n\nBuilding Fair MLM Fair machine learning models (MLMs) can be developed by targeting different stages of the model training cycle. Approaches include: (i) Pre-processing methods, which act on input data to eliminate bias (Feldman et al. 2015; Zemel et al. 2013). (ii) In-processing algorithms, which intervene during training to incorporate fairness as a constraint or within the learning objective (Padala and Gujar 2020). (iii) Post-processing methods, which adjust the outputs of trained MLMs to produce fair results, requiring access to sensitive attributes.\n\nIn-processing and pre-processing methods are tailored to specific fairness criteria and models, necessitating retraining for each new fairness definition. Post-processing methods, in contrast, are model-agnostic and do not depend on the training process, making them suitable for domain experts with limited MLM knowledge (Sleeman et al. 1995). These methods are especially favored when retraining is infeasible, such as in large-scale systems like recommender systems (Nandy et al. 2022).\n\nGiven a potentially biased scoring function, this paper addresses the challenge of constructing a fair probabilistic binary classifier with a binary-protected attribute. The goal is to ensure fairness without retraining the MLM, minimizing performance loss.\n\nFairness and Performance Trade-offs For classification, one of the desired characteristics of an MLM is calibration (Kleinberg, Mullainathan, and Raghavan 2017). Suppose a classifier predicts that a given input is accepted $( Y = 1 )$ ) with probability $p$ , then calibration demands that the fraction of the accepted population, with the same features, is $p$ . Kleinberg, Mullainathan, and Raghavan (2017); Chouldechova (2017) have shown that calibration and equalized odds cannot be satisfied simultaneously except for highly constrained cases. Hence, researchers have been focusing on building classifiers (MLMs) with an appropriate approximate version of fairness (Madras et al. 2018). When it comes to practitioners, they focus on Receiver Operator Characteristics (ROC) for evaluating a classifier as it best describes the classifiers. ROC measures the relative scores of the positive versus negative instances. The area under ROC-curve (AUC) is an appropriate performance metric to measure the predictive quality of such classifiers and to segregate positive and negative samples through ranking (Huang and Ling (2005); Clémençon, Lugosi, and Vayatis (2008); Zehlike, Yang, and Stoyanovich (2021)). AUC is particularly beneficial when the classifier is expected to segregate positive and negative labels, and the predictions must be fair across all threshold scores.\n\nTo make the practitioner’s job effortless, we introduce a novel fairness measure, namely $\\varepsilon _ { p }$ -Equalized ROC – no matter what threshold it uses for classification, the classifier is approximately fair, i.e., for all possible thresholds, the distance between the corresponding points of the ROC curves for both the protected group should be withing $\\varepsilon$ distance in the $\\mathcal { L } _ { p }$ norm. We aim to build a new probabilistic classifier that satisfies $\\varepsilon _ { 1 }$ -Equalized ROC with the minimal loss in AUC w.r.t. to the scoring function $s$ .\n\nOur Approach: We assume query access to the ROC of $s$ First, we make sufficiently large $k$ queries to the ROC for the protected groups and make a piece-wise linear approximation of the ROC curves of both the protected groups. Next, we transport ROCs within $\\varepsilon$ distance of each other to minimize the loss in AUC of the resultant ROC. We can achieve such transportation by randomizing scores across certain feasible classifiers for the given ROC curve. We call the space of these classifiers as ROC Space of $s$ . The resultant classifier from such randomization across the ROC Space is a convex combination of these classifiers. In a nutshell, we transform the given $s$ to a fair scoring function by such ROC transport. We refer to this procedure of ROC transport as FROC. We then geometrically prove that under certain conditions, FROC is optimal.\n\n# Our Contributions:\n\n• We introduce a novel group fairness notion $\\varepsilon _ { p }$ -Equalized ROC, enforcing fairness over all thresholds in a scorebased classification, which is extremely useful for practitioners. • Next, we model a post-processing problem as a problem of finding an optimal transformation $\\mathcal { H }$ on a given scoring function $s$ to minimize the performance loss due to transformation while ensuring $\\varepsilon _ { 1 }$ -Equalized ROC. • To achieve $\\varepsilon _ { 1 }$ -Equalized ROC, we propose a ROC transport, FROC, a post-processing algorithm (Algorithm 1).\n\nThus, it avoids re-training the existing MLM, which might not be fair. It also helps in explaining the decisions.\n\n• We perform rigorous theoretical analysis. We prove that (under some conditions) FROC is optimal in terms of AUC loss. (Theorem 4.2).   \n• Finally, we demonstrate the efficacy of FROC via experiments.\n\n# 1.1 Related Work\n\nFairness in Binary Classification and Ranking Demographic Parity (DP), Disparate Impact (DI), and Equalized Odds (EO) are widely studied group fairness notions. DP (Dwork et al. 2012) and DI (Feldman et al. 2015) ensure that the fraction of positive outcomes is identical across all sensitive groups. Barocas and Selbst (2016) introduced the $8 0 \\%$ rule, requiring that the positive outcome rate for a minority group must be at least $4 / 5$ of that for the majority group. EO (Hardt, Price, and Srebro 2016) ensures similar distributions of error rates, specifically false positives and false negatives (Verma and Rubin 2018). Techniques to achieve fair MLMs include those discussed by Padala and Gujar (2020). Group fairness has been shown to be inadequate for score-based classifiers, which classify across all thresholds (Gorantla, Deshpande, and Louis 2021). Consequently, researchers have proposed fairness notions based on the area under the curve (AUC). Examples include intra-group pairwise AUC fairness (Beutel et al. 2019), BNSP (Borkan et al. 2019), and inter-group pairwise AUC (xAUC) fairness (Kallus and Zhou 2019). Yang et al. (2023) present a minimax learning and bias mitigation framework that integrates intra-group and inter-group AUC metrics to address algorithmic bias. Vogel, Bellet, and Clémençon (2021) examine fairness in ranking problems, developing a general class of AUC-based fairness notions. They demonstrate that AUC-based fairness notions do not capture all forms of bias, as AUC summarizes classifier performance. They propose a stronger notion called point wise ROC-based fairness and design an in-processing algorithm for this purpose.\n\nOur fairness definition $\\dot { \\varepsilon } _ { p }$ -Equalized ROC) is inspired by equalized odds for all thresholds in ranking-based classification and is suitable for post-processing algorithms. It generalizes the approach of Chen and Wu (2020), which uses the Manhattan distance as its norm. We later demonstrate the equivalency of both fairness notions (ours $\\varepsilon _ { 1 }$ ). Note that the notion in (Chen and $\\mathrm { \\sf W u } 2 0 2 0 \\$ ) is not motivated by the same error rates at all thresholds, and also, ours is more of a geometric approach from ROC curves, and theirs is an algebraic approach; ours is more general.\n\nPost-processing for fair classification Post-processing techniques range from simple adjustments, such as thresholding or re-scaling, to complex methods like re-weighting or resampling. Hardt, Price, and Srebro (2016) argue that many existing fairness criteria are too restrictive, leading to suboptimal solutions. They propose a fairness notion allowing some variation in prediction outcomes, defined by “equality of opportunity” constraints, ensuring the classifier is unbiased regarding the sensitive attribute. Their approach involves adjusting prediction thresholds for different groups based on their base rates to equalize false positive and false negative rates across groups. However, it does not involve transporting ROC curves. Wei, Ramamurthy, and Calmon (2020) examine post-processing from the perspective of transformers, defining fairness as the expectation of scores and bounding the differences between true positive rates (TPRs) and false positive rates (FPRs) across protected groups. Cui et al. (2021) propose a model-agnostic post-processing framework for balancing fairness in bipartite ranking scenarios. Zhao (2024) introduces a novel approach using Wasserstein barycenters to quantify and address the cost of fairness, demonstrating that the complexity of learning an optimal fair predictor is comparable to learning the Bayes predictor. ¸Tifrea et al. (2024) propose a framework that transforms any regularized in-processing method into a post-processing approach, extending its applicability across a broader range of problem settings. Cruz and Hardt (2023) identifies two key methodological errors in prior work through empirical analysis: comparing methods with different unconstrained base models and differing levels of constraint relaxation. Jang, Shi, and Wang (2022) introduce a method to optimize multiple fairness constraints through group-aware threshold adaptation, learning classification thresholds for each demographic group by optimizing the confusion matrix estimated from the model’s probability distribution. Unlike Jang, Shi, and Wang (2022), our approach starts with the fairness notion that differences between TPRs and FPRs of different groups must be bounded. Mishler, Kennedy, and Chouldechova (2021) use the bounded difference of counterfactual TPRs and FPRs as their fairness criterion, which differs from our $\\varepsilon _ { p }$ -Equalized ROC definition. Our $\\varepsilon _ { p }$ -Equalized ROC focuses on the bounded difference between TPRs and FPRs of different groups as the fairness criterion.\n\n# 2 Preliminaries\n\nConsider a practitioner interested in binary classification, each data point having a binary-protected attribute. He/she is equipped with a scoring-based classifier trained on dataset $D = \\{ ( x _ { i } , a _ { i } , y _ { i } ) _ { i \\in 1 : n } \\}$ . Here, for ith data sample, $x _ { i } \\in$ $\\mathcal { X } \\subset \\mathbb { R } ^ { d }$ denotes features, $y _ { i } \\in \\{ 0 , 1 \\}$ denotes the binary label, and $a _ { i } \\in \\mathcal { A } = \\{ 0 , 1 \\}$ denotes its binary protected attribute. We consider all these three as drawn from random variables $X , A , Y$ , respectively. There could be two scenarios - when the protected attribute is included or excluded from training (Wei, Ramamurthy, and Calmon (2020))—our postprocessing works for both cases as long as protected attributes are accessible during post-processing.\n\nThe random variables $X , A , Y$ are jointly distributed according to an unknown probability distribution over $( x _ { i } , a _ { i } , y _ { i } )$ . The cumulative conditional distributions on $X \\mid$ $\\mathbf { \\boldsymbol { Y } } = \\mathbf { \\boldsymbol { 1 } } )$ and $X ~ \\mid ~ ( Y ~ = ~ 0 )$ are denoted by $G , H$ , respectively. $G ^ { a } , H ^ { a }$ are the corresponding distributions conditioned on $A \\ = \\ a$ (i.e. $G ^ { a }$ denotes the distribution of $X \\mid ( Y = 1 , A = a ) $ )\n\n# 2.1 Probabilistic Binary Classification\n\nProbabilistic Binary Classifier is equipped with a scoring function $s : \\mathcal { X } \\times \\mathcal { A } \\to \\mathbb { R }$ mapping the feature space to a score. A deterministic classifier returns $s ( X ) \\in \\{ 0 , 1 \\}$ and a randomized one returns $s ( X ) \\in [ 0 , 1 ]$ . The higher the score $s ( x )$ , the higher the chance of the corresponding label $y = 1$ . The model prediction $\\widehat { Y }$ , based on certain threshold $t \\in [ 0 , 1 ]$ , is given by ${ \\widehat { Y } } = \\mathbb { I } ( s ( X ) \\geq t ) .$ $s$ denotes the space of such scoring functbions.\n\nThe practitioner decides the threshold $t$ depending on the corresponding true positive rate $( T P R )$ and false positive rate $( F P R )$ (Provost (2000); Zhou and Liu (2005)). For deciding $t$ , he is supplied with ROC – receiver operator characteristic curve for $s$ . The ROC depicts the relation between TPR $( G _ { s } ( t ) )$ and FPR $( H _ { s } ( t ) )$ for $s$ at all possible thresholds $t$ .\n\nWe define $G _ { s } ( t ) \\triangleq \\mathbb { P } ( s ( X ) \\geq t \\mid Y = 1 )$ and $H _ { s } ( t )$ ≜ $\\mathbb { P } ( s ( X ) \\geq t \\mid Y = 0 )$ . Furthermore, we define $G _ { s } ^ { a } ( t )$ ≜ $\\mathbb { P } ( s ( X ) \\ge t \\mid Y = 1 , A = a )$ and $H _ { s } ^ { a } ( t ) \\triangleq \\mathbb { P } ( s ( X ) \\geq t \\mid$ $Y = 0 , A = a ,$ ).\n\n# 2.2 ROC Curve and AUC\n\nThe plot of a ROC-curve (Definition (2.1)) is used to visualize homogeneity between two cumulative distributions (Vogel, Bellet, and Clémençon (2021)). The ROC curve is defined as:\n\nDefinition 2.1 (ROC-Curve). For any two cumulative distributions $g _ { 1 } , g _ { 2 }$ defined over the set $\\mathbb { R }$ , the ROC-curve is defined as the plot of $R O C _ { g _ { 1 } , g _ { 2 } } ( \\alpha ) \\triangleq 1 - g _ { 1 } \\circ g _ { 2 } ^ { - 1 } ( 1 - \\alpha )$ with domain $\\alpha \\in [ 0 , 1 ]$ .\n\nThe area under ROC-curve, $A U C$ , represents a summary of point-wise dissimilarity between the concerned distributions. Formally, let $S , S ^ { \\prime }$ be two independent random variables distributed according to $g _ { 1 } , g _ { 2 }$ respectively, then $\\begin{array} { r } { A U C _ { g _ { 1 } , g _ { 2 } } = \\mathbb { P } ( S ^ { \\prime } > S ) + \\frac { 1 } { 2 } \\mathbb { P } ( S ^ { \\prime } = \\overset { \\vartriangle } { S } ) } \\end{array}$ .\n\nFor a given scoring function $s$ , we get two RVs, $G _ { s }$ and $H _ { s }$ , by varying decision thresholds. We call the corresponding ROC curve $\\mathsf { R O C } _ { s }$ . The area under $\\mathsf { R O C } _ { s }$ , i.e., $\\mathtt { A U C } _ { s } = A U C _ { H _ { s } , G _ { s } }$ , is used to measure the ranking performance of a score function $s ( . )$ (Cortes and Mohri (2003); Clé- mençon, Lugosi, and Vayatis (2008)). For a perfect classifier, $\\mathtt { A U C } _ { s } = 1$ , but such a classifier does not exist. Therefore, the optimal scoring function $s ^ { * }$ maximizes the $\\mathbb { A } \\mathbb { U } \\mathbb { C } _ { s }$ amongst a certain subset of ${ \\mathcal { S } } ^ { \\prime } \\subset { \\mathcal { S } }$ . Formally, $s ^ { * } \\in \\arg \\operatorname* { m a x } _ { s \\in \\mathcal { S } ^ { \\prime } } \\mathbb { A } \\mathrm { U C } _ { s }$ . In section 3.4, we illustrate how a sub-optimal score function with lower TPRs can be achieved by randomizing outputs of $s ( \\cdot )$ . This process is crucial in ensuring fairness. Let $\\left. S \\right| _ { s }$ be the space of possible scoring functions through such randomization. We call it ROC-space of $s$ . Before designing our fair classifier, we formally define our notion of fairness in the next section.\n\n# 2.3 Fairness in Classification\n\nThe typical group fairness notions in binary classifiers such as Demographic Parity (DP) and Equalized Odds (EO) are defined on deterministic predictions, i.e., in score-based classification, they work with a single threshold on scoring function $s$ . Let $t ^ { * }$ be the threshold set by the practitioner. The resultant classifier is said to satisfy DP if $G _ { s } ^ { 0 } \\dot { ( } t ^ { * } ) + H _ { s } ^ { 0 } ( t ^ { * } ) =$ $G _ { s } ^ { 1 } ( t ^ { * } ) + H _ { s } ^ { 1 } ( t ^ { * } )$ . It satisfies the equivalence of acceptance rates across groups. Similarly, EO enforces equality of positive and negative error rates across protected groups, $\\bar { 1 } - G _ { s } ^ { 0 } ( t ^ { * } ) = 1 - G _ { s } ^ { 1 } ( t ^ { * } )$ and $H _ { s } ^ { 0 } ( t ^ { * } ) = \\dot { H } _ { s } ^ { 1 } ( t ^ { * } )$ .\n\n$\\varepsilon _ { p }$ -Equalized ROC As discussed earlier, all group fairness notions are characterized by equality of a particular statistic across both the protected groups. In scoring-based probabilistic classifiers, these fairness notions depend on the selected threshold. To achieve fairness across all thresholds, the practitioner can choose to retrain the model and achieve the right trade-offs between TPR and FNR. However, retraining is expensive. Therefore, a desirable solution is To offer fair treatment to both protected groups using the pre-trained classifier. However, this leads to invoking the post-processing technique every time the practitioner needs to update the threshold $t ^ { * }$ . Instead, we propose a novel fairness measure to simplify the practitioner’s job. We perform post-processing on the given classifier once, and it ensures that no matter what threshold $t ^ { * }$ they choose to make decisions, the classifier offers similar treatment to both the protected groups. That is, the individual ROCs (Here on, we shall denote the ROCs of the protected groups, i.e., $R O C _ { H _ { s } ^ { 0 } , G _ { s } ^ { 0 } }$ and $R O C _ { H _ { s } ^ { 1 } , G _ { s } ^ { 1 } }$ by $\\mathsf { R O C } _ { s } ^ { 0 }$ and $\\mathsf { R O C } _ { s } ^ { 1 }$ respectively) should be within $\\varepsilon$ distance $\\mathcal { L } _ { p }$ norm) of each other. We call it $\\varepsilon _ { p }$ -Equalized ROC. More formally,\n\nDefinition 2.2 ( $\\dot { \\varepsilon } _ { p }$ -Equalized ROC). A scoring function for binary classification s with label prediction $\\widehat { Y } = \\mathbb { I } ( s ( x ) \\geq t )$ is said to satisfy -Equalized ROC if for a lb $\\alpha \\in ( 0 , 1 )$ the following holds:\n\n$$\n| | \\ R O C _ { s } ^ { 1 } ( \\alpha ) - R O C _ { s } ^ { 0 } ( \\alpha ) \\ | | _ { p } \\leq \\varepsilon\n$$\n\nIn $\\varepsilon _ { p }$ -Equalized ROC, we utilize standard metrics (i.e. $\\mathcal { L } _ { p }$ norms) as the fairness statistic to quantify fairness. Thus, $\\varepsilon _ { p }$ -Equalized ROC is feasible for post-processing algorithms.\n\nFurthermore, if FROC is effective for $\\mathcal { L } _ { 1 }$ , it necessarily extends to all $p$ -norms. This conclusion follows from the inequality:\n\n$$\n| a | ^ { p } + | b | ^ { p } \\leq | a | + | b | , \\quad \\forall p \\geq 1 , a , b \\in [ 0 , 1 ] .\n$$\n\nHowever, while FROC ensures fairness, it does not guarantee optimality for $p > 1$ .\n\nNext, we formulate the problem of fair post-processing. Note: $\\varepsilon _ { 1 }$ -Equalized ROC is a generalization of Equalized Odds to all the given thresholds of the scoring function. The proofs and detailed discussion are in Appendix B.\n\n# 2.4 Problem Formulation\n\nGiven $s \\in \\mathcal S$ , we would like to find $h \\in S | _ { s } = \\mathcal { H } ( s ) - \\mathfrak { a }$ transformation of a given scoring function such that $h$ satisfies $\\varepsilon _ { 1 }$ - Equalized ROC. Additionally, we want the loss in AUC due to transformation $\\mathcal { H }$ minimal. That is, $\\mathcal { L } _ { F } = \\tt A U C _ { \\it s } - A U C _ { \\it h }$ must be minimal to retain the maximum performance guarantee of $s$ . Thus, our goal is to get transformation $\\mathcal { H }$ that solves the following optimization problem and returns the optimal transformed score $h ^ { * }$ :\n\n$$\nh ^ { * } \\in \\underset { h \\in \\cal S | _ { s } } { \\arg \\operatorname* { m a x } } \\ \\mathbb { A U C } _ { h }\n$$\n\n$$\n\\| \\mathsf { R O C } _ { h } { } ^ { 0 } ( \\alpha ) - \\mathsf { R O C } _ { h } { } ^ { 1 } ( \\alpha ) \\| _ { 1 } \\leq \\varepsilon , \\forall \\alpha \\in [ 0 , 1 ]\n$$\n\n![](images/892cbe33b39e394bd3b1b6c0436610e6b9614caca9a4e87c8ac35f20953ee5e5.jpg)  \nFigure 1: Shaded Area indicates $\\mathcal { L } _ { P L A }$\n\n# 3 Our Approach\n\nFirst, we explain query access to $\\mathsf { R O C } _ { s }$ to sample from the desired statistic at various thresholds and its piece-wise linear approximation in Section 3.1 and Section 3.2, respectively. Since we cannot sample a continuum of thresholds, our ${ \\mathrm { R O C } } _ { s }$ will be discrete. In Section 3.3, we describe the transport of ROCs. Finally, we summarize our transformation as FROC in Section 3.4.\n\n# 3.1 Query Model\n\nLet $\\mathcal { T } = \\{ t _ { 1 } , \\ldots t _ { k } \\}$ be the set of thresholds at which we sample $\\mathsf { R O C } _ { s }$ for each sensitive group $\\begin{array} { r } { ( t _ { i } = \\frac { i } { k } ) } \\end{array}$ . Let ${ { \\mathcal Q } ^ { a } } ( t _ { i } )$ denote the query output at threshold $t _ { i }$ for sensitive group $A = a$ on the $\\mathsf { R O C } _ { s } ^ { a }$ . $\\mathcal { Q } ^ { a } ( t _ { i } ) \\triangleq R O C _ { H _ { \\mathrm { e } } ^ { a } , G _ { \\mathrm { e } } ^ { a } } ( t _ { i } )$ .\n\nAbusing notations, we use $\\mathcal { Q } ^ { a } ( t _ { i } )$ and ${ \\bar { \\mathcal { Q } } } _ { i } ^ { a }$ interchangeably. Let $\\mathcal { Q } ^ { a } = ( \\mathcal { Q } _ { 1 } ^ { a } , \\ldots , \\mathcal { Q } _ { k } ^ { a } )$ be the sequence of all query outputs for group $a$ . In the next section, we construct the piece-wise linear approximation of the group-wise ROC curves using the group-wise query outputs ${ \\mathcal { Q } } ^ { a }$ .\n\n# 3.2 Piece-wise Linear Approximation (PLA) of ROC-curves\n\nTo obtain the piece-wise linear approximation (PLA), we sample $k$ points from ROC and construct a straight line from $\\mathcal { Q } _ { i } ^ { a }$ to $\\mathcal { Q } _ { i + 1 } ^ { a }$ for all $i = 1 \\dots k - 1$ . Lastly, we join $( 0 , 0 )$ to ${ \\mathcal { Q } } _ { 1 } ^ { a }$ (see Figure 1). Following these steps on the query sets ${ \\mathcal { Q } } ^ { a }$ will generate the PLAs for protected groups $\\bar { a } \\in \\{ 0 , 1 \\}$ . We denote by ${ \\widehat { G _ { s } ^ { a } } } , { \\widehat { H _ { s } ^ { a } } }$ , the cumulative distributions induced by the linear apcproxcimation of the ROC-curve on $s$ .\n\nDue to PLA, we incur a loss $\\mathcal { L } _ { L P A }$ in $A U C _ { H _ { s } , G _ { s } }$ (shaded region in Figure (1)). $\\mathcal { L } _ { L P A }$ is inversely proportional to the number of queries $k$ , see Section 4.1 for bounds on this loss. Hence, we shall ignore this loss in our fairness analysis as it can be brought arbitrarily close to 0 by increasing $k$ .\n\n# 3.3 Transporting ROCs for $\\varepsilon _ { 1 }$ -Equalized ROC\n\nSince we are using post-processing technique to ensure fairness, it is impossible to shift any ROC above its current position, i.e., build a classifier corresponding to any point in the epigraph (the points above the ROC curve) of $\\mathsf { R O C } _ { s }$ just with the help of $s$ . Interestingly, a classifier representing a point in the hypograph (points below the curve) of $s \\cap { \\mathcal { S } }$ can be obtained through randomization on the predicted scores (see Chapter 3 in Barocas, Hardt, and Narayanan (2023)).\n\n![](images/3d0cfc445c717982a11213ca768f0d81dc1825b94da2e18b7003b9f16df81be7.jpg)  \nFigure 2: Norm Boundary\n\nThe key idea involves abstracting out the convex hull formed by the three points $( 0 , 0 )$ , $( 1 , 1 )$ and $\\mathcal { Q } _ { i } ^ { u p }$ , and sampling outcomes from classifiers representing $( 0 , 0 )$ , $( 1 , 1 ) ^ { 1 }$ and $\\mathcal { Q } _ { i } ^ { u p }$ with specific probabilities. By taking convex combinations of the three aforementioned points in the ROC space, we can represent any point lying in their convex hull. The exact convex combinations are described in C2. We leverage this property to achieve $\\varepsilon _ { 1 }$ -Equalized ROC. We denote this space as $R O C$ -space of $\\boldsymbol { s } - \\boldsymbol { S } | _ { s }$ . Each point in $\\left. S \\right| _ { s }$ represents a binary classifier in terms of its performance at a certain threshold $t$ . Each point is of the form $( F P R ( t ) , T P R ( t ) )$ . This method is discussed in detail in the Appendix.\n\nIn the realm of binary classification, it is a common occurrence for one group to be subject to discrimination. Specifically, if we plot $\\bar { \\mathsf { R O C } } _ { s } ^ { 0 }$ , $\\mathsf { R O C } _ { s } ^ { \\mathrm { 1 } }$ , we will find that one of the ROCs is notably situated below the other. For this study, the ROC predominantly above the other will be designated as $R O C _ { u p }$ , while the other ROC will be referred to as $R O C _ { d o w n }$ . We believe this is a reasonable assumption because we observed that in most classifiers (for which present the results and others we explored on the datasets mentioned in Section E3) the ROCs don’t intersect or intersect at regions where $F P R \\leq 0 . 2$ or $T P R \\ge 0 . 5$ . Typically, no practitioner will work in those areas of ROCs. We leave for future work to address intersecting ROCs.\n\nLet ${ \\mathcal { Q } } ^ { u p }$ , $\\mathcal { Q } ^ { d o w n }$ be the corresponding set of query points for $\\mathtt { R O C } _ { u p }$ , $\\mathsf { R O C } _ { d o w n }$ respectively. We also denote their fair counterparts by up, down.\n\nAlgorithm Definitions We need to transport $\\mathtt { R O C } _ { u p }$ towards $\\mathtt { R O C } _ { d o w n }$ such that the new ROCs are within $\\varepsilon$ distance of each other. Our approach is geometric. We need to identify certain points/curves in the epigraph of $\\mathsf { R O C } _ { d o w n }$ as follows.\n\nDefinition 3.1 (Norm Boundary). The set of all points within $\\varepsilon$ distance $\\ell _ { 1 }$ norm) from $\\mathcal { Q } _ { i } ^ { d \\bar { o } w n }$ is known as the norm set ${ \\mathfrak { C } } _ { i }$ . Formally, we have\n\n$$\n\\mathfrak { C } _ { i } \\triangleq \\{ x : x \\in [ 0 , 1 ] ^ { 2 } , | | x - Q _ { i } ^ { d o w n } | | _ { 1 } \\leq \\varepsilon \\}\n$$\n\nThe set of all points exactly $\\varepsilon$ distance (in $\\mathcal { L } _ { 1 }$ norm) from $\\mathcal { Q } _ { i } ^ { a }$ is known as Norm Boundary $\\mathfrak { B } _ { i }$ . Formally,\n\n$$\n\\mathfrak { B } _ { i } \\triangleq \\{ x : x \\in [ 0 , 1 ] ^ { 2 } , | | x - \\mathcal { Q } _ { i } ^ { d o w n } | | _ { 1 } = \\varepsilon \\}\n$$\n\nAdditionally, we denote the vertices of the Norm Boundary Rhombus (starting from the top most point and moving clockwise) as $U _ { i } , R _ { i }$ , $D _ { i }$ , and $L _ { i }$ .\n\nWe say that an index $i \\in [ 1 , 2 , \\ldots , k ]$ is a Boundary Cut index when $R O C _ { u p }$ intersects the Norm Boundary $\\mathfrak { B } _ { i }$ . Formally,\n\nDefinition 3.2 (Boundary Cut). Index $i \\in [ 1 , 2 , \\ldots , k ]$ is $a$ Boundary Cut index when $\\mathfrak { B } _ { i } \\cap R O C _ { u p } \\neq \\phi$ .\n\nWe now define the three kinds of shifts that will be used in our Algorithm: For a given $i \\in [ 1 , 2 , \\ldots , k ]$ , Upshift is the transportation of $\\mathcal { Q } _ { i } ^ { u p }$ to the point $U _ { i }$ .\n\nDefinition 3.3 (UpShift). For a given $i \\in [ 1 , 2 , \\ldots , k ]$ , Upshift is the transportation of $\\mathcal { Q } _ { i } ^ { u p }$ to the point $U _ { i }$ . Formally, UpShift can be defined as the function that returns a fair threshold ${ \\widetilde { \\mathcal { Q } } } _ { i } ^ { u p }$ (i.e. $U _ { i , \\mathbf { \\lambda } }$ ) by taking the $\\mathcal { Q } _ { i } ^ { d o w n }$ and $\\varepsilon$ as the argument\n\nFor a given $i \\in [ 1 , 2 , \\ldots , k ]$ , Leftshift is the transportation of $\\mathcal { Q } _ { i } ^ { u p }$ to the point $L _ { i }$ . Formally,\n\nDefinition 3.4 (LeftShift). LeftShift is a function that returns $a$ fair threshold $\\widetilde { \\mathcal { Q } } _ { i } ^ { u p } \\left( i . e . \\ L _ { i } \\right)$ by taking the $\\mathcal { Q } _ { i } ^ { d o w n }$ and $\\varepsilon$ as the arguments.\n\nDefinition 3.5 (CutShift). For a given $i \\in [ 1 , 2 , \\ldots , k ]$ (representing the index of the $R O C _ { d o w n } ,$ ), we run through all the points of the $R O C _ { u p }$ and return the set of all points that intersect the Norm Boundary $\\mathfrak { B } _ { \\mathrm { i } }$ . Formally, we define Cutshift as a function that takes $\\mathcal { Q } _ { i } ^ { d o w n }$ and $\\varepsilon$ as the arguments and returns $R O C _ { u p } \\cap \\mathfrak { B } _ { i }$ . The set $R O C _ { u p } \\cap \\mathfrak { B } _ { i }$ can be represented as $\\{ p _ { l e f t } , \\stackrel { \\cdot } { p } _ { r i g h t } \\}$ denoting the points at the intersection of $R O C _ { u p }$ at the left-side of the Norm Boundary and the right-side of the Norm Boundary respectively.\n\nNow, we elaborate on the above procedure to transport points from $R O C _ { u p }$ towards $R O C _ { d o w n }$ .\n\nAlgorithm for ROC Transport We provide a geometric algorithm that returns a classifier equivalent to the scoring function $h ^ { * }$ in $\\left. S \\right| _ { s }$ .\n\nNote that, Algorithm 1 treats $R O C _ { d o w n }$ as implicitly fair. Also, by $A r e a ( \\square A B C D )$ , we denote the area of the quadrilateral whose vertices are $A , B , C$ , and $D$ . This area is easily found in this context by splitting $\\square A B C D$ into two disjoint triangles- $\\Delta A B C$ and $\\Delta A C D$ and using the Herons formula (Kendig 2000) on each triangle.\n\nFor example, consider $\\bar { A r e a } ( \\Delta \\mathcal { Q } _ { i } ^ { u p } \\mathcal { Q } _ { i - 1 } ^ { u p } L _ { i } )$ . Let $\\textit { a } =$ $| | \\mathcal { Q } _ { i } ^ { u p } \\mathcal { Q } _ { i - 1 } ^ { u p } | | _ { 2 }$ , $b = | | \\mathcal { Q } _ { i } ^ { u p } L _ { i } | | _ { 2 }$ and $c = | | \\mathcal { Q } _ { i - 1 } ^ { u p } L _ { i } | | _ { 2 }$ . Additionally, we define $\\textstyle s = { \\frac { a + b + c } { 2 } }$ . Then, it is true that:\n\n$$\nA r e a ( \\Delta \\mathcal { Q } _ { i } ^ { u p } \\mathcal { Q } _ { i - 1 } ^ { u p } L _ { i } ) = \\sqrt { s ( s - a ) ( s - b ) ( s - c ) }\n$$\n\n# 3.4 Obtaining Fair Classifier from the Updated ROCs\n\nThe algorithm described in the previous subsection returns the fair ROC curves according to $\\varepsilon _ { 1 }$ -Equalized ROC. As a final step, we need to find the transformed classifier. We call it ConstructClassifier(FairROCup,FairROCdown , $\\mathrm { . R O C } _ { s } ^ { 0 } , \\mathrm { R O C } _ { s } ^ { 1 } )$ which returns a probabilistic binary classifier representing $h = \\mathcal { H } ( s )$ such that it represents the FairROCs. We construct one using the procedure explained in Section 3.3. Now, we establish the optimality of our solution within specific assumptions.\n\nRequire: $R O C _ { u p }$ , $R O C _ { d o w n }$ , $\\varepsilon$   \nEnsure: F airROCup, F airROCdown   \n1: Initialize $i \\gets 1$ , $\\hat { k } \\gets \\mathrm { l e n g t h } ( R O C _ { u p } )$   \n2: F air $R O C _ { u p } \\gets \\emptyset$ , $F a i r R O C _ { d o w n } \\gets R O C _ { d o w n }$   \n3: while $i < k - 1$ do   \n4: $i \\gets i + 1$   \n5: if BOUNDA $\\scriptstyle \\mathrm { 3 Y C U T } ( i , \\varepsilon ) = = \\mathrm { T R U E }$ then   \n6: $p _ { l e f t } , p _ { r i g h t }$   \n$\\mathrm { C U T S H I F T } \\{ i , R O C _ { u p } , R O C _ { d o w n } \\}$   \n7: if $F P R ( \\mathcal { Q } _ { i } ^ { u p } ) \\geq F P R ( \\mathcal { Q } _ { i } ^ { d o w n } )$ then   \n8: $\\widetilde { \\mathcal { Q } } _ { i } ^ { u p } \\gets p _ { r i g h t }$   \n9: else   \n10: $\\widetilde { \\mathcal { Q } } _ { i } ^ { u p } \\gets p _ { l e f t }$   \n11: end ief   \n12: else if $\\mathcal { Q } _ { i } ^ { u p } \\in \\mathrm { H Y P O G R A P H } ( R O C _ { d o w n } )$ then   \n13: $\\widetilde { \\mathcal { Q } } _ { i } ^ { u p }  \\mathcal { Q } _ { i } ^ { u p }$   \n14: ceontinue   \n15: else   \n16: if Area(□Qiu+p1Qi Qiup1Li) ≥   \n$\\mathbf { A r e a } ( \\bigtriangledown \\mathcal { Q } _ { i + 1 } ^ { u p } \\mathcal { Q } _ { i } ^ { u p } \\mathcal { Q } _ { i - 1 } ^ { u p } U _ { i } )$ then   \n17: up U   \n18: else   \n19: $\\widetilde { \\mathcal { Q } } _ { i } ^ { u p }  L _ { i }$   \n20: end ief   \n21: end if   \n22: $F a i r R O C _ { u p } \\gets \\mathrm { A P P E N D } \\big ( \\widetilde { \\mathcal { Q } } _ { i } ^ { u p } \\big )$   \n23: end while\n\n# 4 Theoretical Analysis\n\nAs described in Section (3.2), we work with PLA of the ROC curves $R O C _ { H _ { s } ^ { a } , G _ { s } ^ { a } }$ , $a \\in \\{ 0 , 1 \\}$ . This causes a loss in area under ROC. We denote this loss by $\\mathcal { L } _ { P L A }$ and is quantified as the difference in AUCs of ROCHsa ,Gsa and ROCHa,Ga .\n\nIn Section 3.3, transporting the ROC query pointds, ${ \\mathcal { Q } } ^ { u p }$ introduces a decrease of the area under the ROC curve due to the transformation of scoring function $s$ to $h$ . We denote this loss by $\\mathcal { L } _ { A U C }$ . This loss can be quantified as the difference in AUCs of $R O C _ { widehat { H _ { s } ^ { a } } , \\widehat { G _ { s } ^ { a } } }$ and $R O C _ { H _ { h } ^ { a } , G _ { h } ^ { a } }$ The total loss in AUC, $\\mathcal { L }$ , induced by FdRO cC is given by: $\\mathcal { L } = \\mathcal { L } _ { P L A } + \\mathcal { L } _ { A U C }$\n\n# 4.1 PLA Loss analysis\n\nWe start our analysis by making a few standard assumptions regarding the continuity and differentiability of the cumulative distributions on the family of scoring functions $s$ . We adopt a less stringent assumption than that presented in (Vogel, Bellet, and Clémençon 2021), as we impose only an upper bound on the slopes. This contrasts with the approach in (Vogel, Bellet, and Clémençon 2021), which necessitates both an upper and lower bound on the slopes.\n\nAssumption 4.1. We assume that the rate of change (with respect to the thresholds $t$ ) of the T P Rs and F P Rs are upper bounded. I.e. we assume that $\\exists u _ { T } , u _ { F } \\in \\mathbb { R }$ such that $\\begin{array} { r } { \\frac { d ^ { \\ } \\hat { T } P R } { d t } \\leq u _ { T } } \\end{array}$ and $\\begin{array} { r } { \\frac { d \\ F P R } { d t } \\leq u _ { F } } \\end{array}$ .\n\nTheorem 4.1. Let $R O C _ { \\widehat { H _ { s } ^ { a } } , \\widehat { G _ { s } ^ { a } } }$ be the PLA of $R O C _ { H _ { s } ^ { a } , G _ { s } ^ { a } }$ over the query set of $k$ eqdui dcistant thresholds, $\\mathcal { T } = \\{ t _ { i } \\ |$ $t _ { i } = i / k { \\bar { \\forall } } i \\in [ k ] \\} .$ . The corresponding $\\mathcal { L } _ { P L A }$ is bounded as: $\\begin{array} { r } { \\mathcal { L } _ { P L A } \\leq \\frac { 1 } { 2 } \\frac { u _ { T } u _ { F } } { k } } \\end{array}$\n\n# 4.2 AUC Loss analysis\n\nWe start our analysis by making a few assumptions regarding the spacing of the ROC thresholds and the ROC curve.\n\nAssumption 4.2. We have two assumptions: • $\\forall i \\ \\bar { \\in } \\ \\{ 1 , 2 , \\ldots , k \\}$ , we assume that $F P R ( \\mathcal { Q } _ { i - 1 } ^ { d o w n } ) \\ \\leq$ F P R(Qi ) ≤ F P R(Qid+o1w ). • We assume that the $R O C _ { u p }$ can intersect any Norm boundary (i.e. $( \\mathfrak { B } _ { i } ) _ { i \\in \\{ 1 , 2 , . . . , \\dot { k } \\} } )$ at most 2 times.\n\nWe note that even if Assumption 4.2 does not hold, FROC remains operational and continues to produce outputs that are $\\varepsilon _ { 1 }$ -Equalized ROC fair. However, under these conditions, the optimality with respect to AUC is not guaranteed, as Theo$\\mathrm { r e m } 4 . 4$ no longer applies. The necessity of these assumptions is discussed in greater detail in the extended version of this paper.\n\nTheorem 4.2. If a given classifier s is piece-wise linear and satisfies assumption 4.2, the ROCs returned by FROC represent the classifier solving optimization problem 2.\n\n# 4.3 Optimally Fair points and Norm Boundary\n\nThis section proves that all optimally fair points must lie on some Norm Boundary. We do this by establishing that the performance of any point in the Norm Set can be improved by appropriate transportation to a point on the Norm Boundary.\n\nTheorem 4.3. (Norm Boundary) $\\boldsymbol { \\mathscr { f } } ( \\widetilde { \\mathcal { Q } } _ { i } ^ { u p } ) _ { i \\in \\{ 1 , 2 , . . . , k \\} }$ is the set of optimal fair (points that maximieze the AUC and also satisfy the $\\varepsilon _ { 1 }$ -Equalized ROC) thresholds must necessarily be a subset of (Bi)i 1,2,...,k .\n\nTheorem 4.4. (CutShift) If index $i$ is a Boundary cut point, then the CutShift operation must be performed. Of the 2 points $( p _ { l e f t }$ and $p _ { r i g h t . }$ ) returned by the Cutshift operation, the point that is closer to $\\mathcal { Q } _ { i } ^ { u p }$ must be chosen $\\therefore e . { \\widetilde { \\mathcal { Q } } } _ { i } ^ { u p } =$ $a r g m i n _ { p \\in \\{ p _ { l e f t } , p _ { r i g h t } \\} } | F P R ( \\mathcal { Q } _ { i } ^ { u p } ) - F P R ( p ) |$\n\nTheorem 4.5. (UpShift) If index $i$ is not a Boundary cut point and if $\\cdot A r e a ( \\sqcap \\mathscr { Q } _ { i + 1 } \\mathscr { Q } _ { i } \\mathscr { Q } _ { i - 1 } L _ { i } \\geq A r e a ( \\sqcap \\mathscr { Q } _ { i + 1 } \\mathscr { Q } _ { i } \\mathscr { Q } _ { i - 1 } U _ { i } ) ,$ , then UpShift operation must be performed. The resulting point $( U _ { i } )$ is the new fair point ${ \\widetilde { \\mathcal { Q } } } _ { i } ^ { u p }$ . Otherwise, the LeftShift operation must be performed. Tehe resulting point $( L _ { i } )$ is the new fair point Qi .\n\nThe proofs oef all the above theorems are given in the appendix. However, the following is brief sketch of the proof:\n\nStep 1: We prove that all optimally fair points $\\overline { { ( \\widetilde { \\mathcal { Q } } _ { i } ^ { u p } ) _ { i \\in \\{ 1 , 2 , . . . , k \\} } } }$ must lie on the Norm Boundaries of the corr∈e{spondin}g $\\mathcal { Q } _ { i } ^ { d o w n }$ . (i.e. $( \\mathfrak { B } _ { i } ) _ { i \\in \\{ 1 , 2 , . . . , k \\} } )$ Step 2: We then prove that if $\\mathfrak { B } _ { i } \\cap R O C _ { u p } \\ne \\phi$ , then the CutShift transportation is the optimal transportation. Step 3: We then prove that if $\\mathfrak { B } _ { i } \\cap R O C _ { u p } = \\phi$ , then, based on the Cover and aforementioned area condition, the UpShift or the LeftShift transportation is the optimal transportation.\n\nIn the next section, we experimentally analyze FROC.\n\n![](images/5ec4cee991f3e0747352a80866bf384e05a23e742c29e7598978e98e65bd47ca.jpg)  \nFigure 3: Comparison of different methods: (a) C1 vs. C1-FROC, (b) C3-Fair Fair vs. C3-FROC, and (c) C2 Before and Afte FROC.\n\n# 5 Empirical Analysis\n\n# 5.1 Experimental Setup\n\nDatasets: We train different classifiers on the widely-used ADULT (Becker and Kohavi 1996) and COMPAS (Angwin et al. 2022) benchmark datasets, selecting MALE and FEMALE as protected groups in ADULT, and BLACK and OTHERS in COMPAS. ROCs are generated, with additional experiments on datasets like CelebA in Appendix E and F.\n\nClassifiers: We test FROC on ROCs from the following classifiers: 2. C1: FNNC( Padala and Gujar (2020)): This is a neural network-based classifier with a target parameter for fairness. C2: Logistic Regression and C3: Random Forest We used the code from the author’s GitHub for C1 and sklearn implementations for C2 and C3.\n\nPost-Processing methods: We compare FROC against the following baselines: B1: FairProjection-CE and FairProjection-KL (Alghamdi et al. 2022): Transforms the score to achieve mean equalized odds fairness through information projection.\n\n# 5.2 Experiments\n\nWe train C1 on both datasets, C2 and C3 on the Adult dataset, and generate their ROCs for all the protected groups. FNNC, we train by ignoring its fairness components in the loss function and then generate ROC. We then invoke FROC for different $\\varepsilon$ values and check the best possible threshold for accuracy. We refer to the new classifier as C1-C3-FROC.\n\nBaseline Post-Processing Method: We evaluate FROC, and the baselines B1 on ADULT dataset against the fairness metric mean equalized odds(B2) (Alghamdi et al. 2022) in Figs. 3(b). For consistent comparison, we adopt the training parameters for base classifiers from (Alghamdi et al. 2022) and keep it identical across all experiments.\n\n# 5.3 Results\n\nWe show the results on the COMPAS and Adult dataset (using FNNC and FROC) here, along with a comparison with existing post-processing baselines. The remaining experimental observations are detailed in the supplementary. Figure\n\n3(c) displays the ROC curves (Before and After FROC) for both males and females, on the ADULT dataset for C2. The female ROC consistently occupies the higher position, indicating a positive bias for males. This establishes $R O C _ { 0 }$ as our counterpart to $R O C _ { d o w n }$ . Thus, we apply FROC to the alternate curve, $R O C _ { 1 }$ , showcased in the figure. Before FROC, the maximum difference between Male ROC and Female ROC is 0.08. However, after post-processing with FROC, the loss in accuracy is $< 0 . 1 \\%$ for $\\varepsilon = 0 . 0 5$ . In general, across all experiments (more experiments in Appendix), we observe a $7 . 8 \\%$ improvement in fairness, FROC incurs at most a $2 \\%$ drop in accuracy. As seen in Figure 3(a) and Figure $\\mathbf { \\boldsymbol { 3 } } ( \\mathbf { \\boldsymbol { b } } )$ for smaller values of $\\varepsilon$ , we also observe the performance may beat FNNC and the post-processing methods. We assign it to the fact that FNNC (and the other methods) may overachieve the target fairness for smaller values of $\\varepsilon$ (Evident from Table 2 (Padala and Gujar 2020)). FROC drops AUC minimally to achieve target fairness.\n\n# 6 Conclusion\n\nIn this work, we addressed the problem of practitioners aiming to achieve fair classification without retraining MLMs. Specifically, we provide a post-processing framework that takes a potentially unfair classification score function and returns a probabilistic fair classifier. The practitioner need not worry about fairness across different thresholds, so we proposed a new notion $\\varepsilon _ { 1 }$ -Equalized ROC (Definition 2.2), which ensures fairness for all thresholds. To achieve $\\varepsilon _ { 1 }$ - Equalized ROC, we proposed FROC (Algorithm 1), which transports the ROC for each sensitive group within $\\epsilon$ distance while minimizing the loss in AUC of the resultant ROC. We geometrically proved its optimality conditions (Theorem 4.2) and bounds under certain technical assumptions. We observed empirically that its performance might differ at most by $2 \\%$ compared to an in-processing technique while ensuring stronger fairness and avoiding retraining. We leave it for future work to explore the possibility of different distance metrics for fairness and optimizing for different performance measures.",
    "institutions": [
        "International Institute of Information Technology, Hyderabad"
    ],
    "summary": "{\n    \"core_summary\": \"### 核心概要\\n\\n**问题定义**\\n论文聚焦于具有二元受保护群体的公平概率二元分类问题。在机器学习模型广泛应用于决策制定（如大学录取、信用评分等）的背景下，存在对特定受保护群体（基于性别、年龄、种族等）的歧视现象。现有公平性度量和方法存在局限性，部分组公平性概念不适用于基于分数的分类器，且许多方法需重新训练模型，成本较高。实现公平分类并尽量减少对传统性能保证（如准确率）的妥协，对实际决策制定至关重要。\\n\\n**方法概述**\\n提出后处理方法FROC，先对每个受保护群体的ROC曲线进行足够多的查询以获取数据，接着进行分段线性近似，再将ROC曲线在$\\varepsilon$距离内进行传输，把给定分类器的输出（分数）转换为满足$\\varepsilon_1$-Equalized ROC的概率分类器，以实现公平性并最小化AUC损失。\\n\\n**主要贡献与效果**\\n- 引入新颖的组公平性概念$\\varepsilon_p$-Equalized ROC，确保基于分数的分类在所有阈值下的公平性，对从业者极为有用。\\n- 提出后处理算法FROC，避免对现有可能不公平的MLM进行重新训练，并在某些理论条件下证明了FROC在AUC损失方面的最优性。\\n- 通过实验验证了FROC的有效性，在多个真实世界数据集上，公平性提升约7.8%，准确率最多下降2%，在ADULT数据集上对于C2分类器，处理后在$\\varepsilon = 0.05$时准确率损失$< 0.1\\%$。\",\n    \"algorithm_details\": \"### 算法/方案详解\\n\\n**核心思想**\\nFROC算法的核心思想是利用后处理技术，在不重新训练模型的前提下，将给定分类器的输出转换为公平的分类器。具体利用ROC曲线的特性，通过对ROC曲线进行分段线性近似和传输操作，使两个受保护群体的ROC曲线在$\\varepsilon$距离内，从而实现$\\varepsilon_1$-Equalized ROC，同时最小化AUC损失。其有效性在于可在不改变模型训练过程的情况下，通过对输出的调整来保证公平性。\\n\\n**创新点**\\n- 提出新的公平性度量$\\varepsilon_p$-Equalized ROC，适用于所有阈值的分数分类，推广了Chen和Wu (2020) 的方法，且是基于ROC曲线的几何方法，更为通用。\\n- FROC作为后处理方法，模型无关且不依赖训练过程，适用于对MLM知识有限的领域专家，尤其在大规模系统（如推荐系统）中，当重新训练不可行时具有优势。\\n\\n**具体实现步骤**\\n1. **查询模型（Query Model）**：设$\\mathcal{T} = \\{ t_1, \\ldots t_k \\}$为采样阈值集合，$t_i = \\frac{i}{k}$，对每个敏感组在$\\mathsf{ROC}_s^a$的阈值$t_i$处进行查询，查询输出记为$\\mathcal{Q}^a(t_i) \\triangleq ROC_{H_{e}^a, G_{e}^a}(t_i)$，用$\\mathcal{Q}^a$表示组$a$的所有查询输出序列。\\n2. **分段线性近似（Piece - wise Linear Approximation）**：从ROC采样$k$个点，对所有$i = 1 \\dots k - 1$，从$\\mathcal{Q}_i^a$到$\\mathcal{Q}_{i + 1}^a$构建直线，最后连接$(0, 0)$到$\\mathcal{Q}_1^a$，得到受保护组的PLA，记由ROC曲线线性近似诱导的累积分布为$\\widehat{G_{s}^{a}}$和$\\widehat{H_{s}^{a}}$。由于PLA会导致AUC损失$\\mathcal{L}_{LPA}$，该损失与查询次数$k$成反比，可通过增加$k$使其接近0。\\n3. **运输ROC曲线（Transporting ROCs）**：为实现$\\varepsilon_1$-Equalized ROC，将$\\mathtt{ROC}_{up}$向$\\mathtt{ROC}_{down}$运输。定义了相关概念和操作：\\n    - **Norm Boundary**：$\\mathfrak{C}_i \\triangleq \\{ x : x \\in [0, 1]^2, || x - \\mathcal{Q}_i^{down} ||_1 \\leq \\varepsilon \\}$为$\\mathcal{Q}_i^{down}$在$\\ell_1$范数下$\\varepsilon$距离内的点集，$\\mathfrak{B}_i \\triangleq \\{ x : x \\in [0, 1]^2, || x - \\mathcal{Q}_i^{down} ||_1 = \\varepsilon \\}$为$\\mathcal{Q}_i^{down}$在$\\ell_1$范数下$\\varepsilon$距离的点集，即Norm Boundary，记其菱形顶点为$U_i, R_i, D_i, L_i$。\\n    - **Boundary Cut**：当$\\mathfrak{B}_i \\cap ROC_{up} \\neq \\phi$时，$i$为Boundary Cut index。\\n    - **UpShift**：将$\\mathcal{Q}_i^{up}$运输到点$U_i$。\\n    - **LeftShift**：将$\\mathcal{Q}_i^{up}$运输到点$L_i$。\\n    - **CutShift**：对给定的$i$，遍历$ROC_{up}$的点，返回与Norm Boundary $\\mathfrak{B}_i$的交点集$ROC_{up} \\cap \\mathfrak{B}_i$，可表示为$\\{ p_{left}, p_{right} \\}$。\\n4. **获得公平分类器（Obtaining Fair Classifier）**：根据运输后的ROC曲线，构建公平分类器$h = \\mathcal{H}(s)$。具体算法如下：\\n   - 初始化$i \\gets 1$，$\\hat{k} \\gets \\mathrm{length}(ROC_{up})$，$FairROC_{up} \\gets \\emptyset$，$FairROC_{down} \\gets ROC_{down}$。\\n   - 当$i < k - 1$时：\\n     - $i \\gets i + 1$。\\n     - 如果$BOUNDA3YCUT(i, \\varepsilon) == \\mathrm{TRUE}$：\\n       - 执行$CUTSHIFT\\{i, ROC_{up}, ROC_{down}\\}$得到$p_{left}$和$p_{right}$。\\n       - 如果$FPR(\\mathcal{Q}_{i}^{up}) \\geq FPR(\\mathcal{Q}_{i}^{down})$，则$\\widetilde{\\mathcal{Q}}_{i}^{up} \\gets p_{right}$；否则，$\\widetilde{\\mathcal{Q}}_{i}^{up} \\gets p_{left}$。\\n     - 否则，如果$\\mathcal{Q}_{i}^{up} \\in \\mathrm{HYPOTHGRAPH}(ROC_{down})$，则$\\widetilde{\\mathcal{Q}}_{i}^{up} \\gets \\mathcal{Q}_{i}^{up}$，继续循环。\\n     - 否则：\\n       - 如果$Area(\\square\\mathcal{Q}_{i}^{up}\\mathcal{Q}_{i - 1}^{up}L_{i}) \\geq Area(\\triangle\\mathcal{Q}_{i + 1}^{up}\\mathcal{Q}_{i}^{up}\\mathcal{Q}_{i - 1}^{up}U_{i})$，则$\\widetilde{\\mathcal{Q}}_{i}^{up} \\gets U_{i}$；否则，$\\widetilde{\\mathcal{Q}}_{i}^{up} \\gets L_{i}$。\\n     - 将$\\widetilde{\\mathcal{Q}}_{i}^{up}$添加到$FairROC_{up}$中。\\n\\n**案例解析**\\n论文未明确提供此部分信息\",\n    \"comparative_analysis\": \"### 对比实验分析\\n\\n**基线模型**\\n- B1: FairProjection - CE和FairProjection - KL (Alghamdi et al. 2022)：通过信息投影将分数转换以实现平均均衡赔率公平性。\\n\\n**性能对比**\\n*   **在 [公平性/mean equalized odds] 指标上：** FROC在ADULT数据集上相较于基线模型B1实现了公平性提升约7.8%，在所有实验中也体现出公平性提升约7.8%，表明FROC在实现公平性方面具有更好的效果。而基线模型未明确提及公平性提升的具体数值。\\n*   **在 [准确率/Accuracy] 指标上：** 在ADULT数据集上，对于C2分类器，FROC处理前男性ROC和女性ROC的最大差异为0.08，处理后在$\\varepsilon = 0.05$时准确率损失$< 0.1\\%$。在所有实验中，FROC导致的准确率下降最多为2%。对于较小的$\\varepsilon$值，FROC的性能可能超过基线模型，因为基线模型可能会过度实现目标公平性，导致在某些情况下性能不如FROC。\",\n    \"keywords\": \"### 关键词\\n\\n- 公平分类 (Fair Classification, N/A)\\n- $\\varepsilon_p$-Equalized ROC ($\\varepsilon_p$-Equalized ROC, N/A)\\n- FROC算法 (FROC Algorithm, N/A)\\n- 后处理方法 (Post - processing Method, N/A)\\n- 二元分类 (Binary Classification, N/A)\\n- ROC曲线 (ROC Curve, N/A)\"\n}"
}