{
    "link": "https://arxiv.org/abs/2403.01875",
    "pdf_link": "https://arxiv.org/pdf/2403.01875",
    "title": "Locally Convex Global Loss Network for Decision-Focused Learning",
    "authors": [
        "Haeun Jeon",
        "Hyun-sool Bae",
        "Minsu Park",
        "Chanyeong Kim",
        "Woo Chang Kim"
    ],
    "publication_date": "2024-03-04",
    "venue": "AAAI Conference on Artificial Intelligence",
    "fields_of_study": [
        "Computer Science"
    ],
    "citation_count": 1,
    "influential_citation_count": 0,
    "paper_content": "# Locally Convex Global Loss Network for Decision-Focused Learning\n\nHaeun Jeon\\*, Hyunglip Bae\\*, Minsu Park, Chanyeong Kim, Woo Chang Kim†\n\nKAIST haeun39, qogudflq, mspark0425, kim.chanyeong, wkim @kaist.ac.kr\n\n# Abstract\n\nIn decision-making problems under uncertainty, predicting unknown parameters is often considered independent of the optimization part. Decision-focused learning (DFL) is a taskoriented framework that integrates prediction and optimization by adapting the predictive model to give better decisions for the corresponding task. Here, an inevitable challenge arises when computing the gradients of the optimal decision with respect to the parameters. Existing research copes with this issue by smoothly reforming surrogate optimization or constructing surrogate loss functions that mimic task loss. However, they are applied to restricted optimization domains. In this paper, we propose Locally Convex Global Loss Network (LCGLN), a global surrogate loss model that can be implemented in a general DFL paradigm. LCGLN learns task loss via a partial input convex neural network which is guaranteed to be convex for chosen inputs while keeping the non-convex global structure for the other inputs. This enables LCGLN to admit general DFL through only a single surrogate loss without any sense for choosing appropriate parametric forms. We confirm the effectiveness and flexibility of LCGLN by evaluating our proposed model with three stochastic decision-making problems.\n\n# 1 Introduction\n\nDecision-making problems under uncertainty arise in various real-world applications such as production optimization, energy planning, and asset liability management (Shiina and Birge 2003; Carino et al. 1994; Fleten and Kristoffersen 2008; Delage and Ye 2010; Garlappi, Uppal, and Wang 2007). These problems involve two main tasks: Prediction and Optimization. The Prediction task aims to create a model for uncertainty and estimate unknown parameters from some input features. This task is often performed using machine learning (ML) techniques such as regression or deep learning. In the Optimization task, the corresponding optimization problem is solved using diverse off-the-shelf solvers with the estimated parameters from the prediction task. For example, in asset liability management, asset returns are estimated in the prediction stage, and the optimal portfolio to repay the liability is obtained in the optimization stage based on these predictions.\n\nPrediction-focused learning (PFL) framework is the most commonly used approach to solve such problems, handling the two tasks in separate and independent steps. PFL first trains the ML model on the input features to produce predictions that closely match the observed parameters. Subsequently, the decision-making problem is defined using the parameters predicted by the trained ML model and is solved to obtain an optimal decision. PFL is based on the underlying belief that accurate predictions will lead to good decisions. However, ML models frequently fail to achieve perfect accuracy, resulting in sub-optimal decisions. Consequently, in many applications, the prediction and optimization tasks are not distinct but are intricately linked and should ideally be considered jointly.\n\nDecision-focused learning (DFL) achieves the above purpose by directly training ML models to make predictions that lead to good decisions. DFL combines prediction and optimization tasks by creating an end-to-end system that aims to minimize task loss directly. Task loss is defined as the quality of decisions derived from the predictive model and therefore, depends on the optimal solution of the associated optimization problem. To train an ML model in this context, differentiating through the optimization problem is required to calculate the gradient of the task loss. This presents a key challenge in integrating prediction and optimization. However, differentiation may be impossible if the decision variable is discrete or the objective function is discontinuous.\n\nWhile surrogate optimization still necessitates differentiation of the optimization problem, efforts have been made to develop solver-free surrogate loss functions that can effectively obtain gradients. We refer to this approach as Surrogate DFL. Recent successful works in Surrogate DFL include SPO (Elmachtoub and Grigas 2022), Contrastive Loss (Mulamba et al. 2020), LTR Loss (Mandi et al. 2022), LODL (Shah et al. 2022), EGL (Shah et al. 2024), LANCER (Zharmagambetov et al. 2024), and TaskMet (Bansal et al. 2024). SPO, Contrastive loss, and LTR loss are specifically designed for linear objectives while LODL can be implemented for general DFL problems. However, LODL creates and trains a surrogate with a specific parametric form for each data instance resulting in expensive computation, with decision quality heavily dependent on the chosen parametric surrogate form. While EGL and LANCER have partially addressed the computational cost issue by extending a local model to a global model, the challenge of selecting an appropriate parametric surrogate form still remains. Alongside the surrogates, TaskMet minimized the prediction error while maintaining the decision quality. We illustrated the model training pipeline for PFL, DFL, and Surrogate DFL in Figure 1.\n\n![](images/8bda06338f2e460cab37432cd5581a6d9ade571c0c56ed235125962def71497e.jpg)  \nFigure 1: A model training pipeline for PFL, DFL, and surrogate DFL. PFL trains the predictive model by minimizing the prediction loss. DFL directly delivers gradients minimizing the task loss. Surrogate DFL first learns a surrogate loss model that follows the true task loss by sampling predictions and its task losses. Then, it trains the predictive model to convey useful gradients derived from the trained surrogate loss model in an end-to-end manner.\n\nNotably, there have been attempts to construct surrogate loss functions using neural networks (Shah et al. 2022). However, these approaches generally performed poorly in experiments because naive MLPs fail to capture the local characteristics of the true underlying loss.\n\nIn this paper, we propose Locally Convex Global Loss Network (LCGLN), which is a global and general surrogate loss for DFL. LCGLN adopts partial input convex neural network (PICNN) (Amos, Xu, and Kolter 2017) as a parametric surrogate form to approximate task loss. With PICNN, we guarantee the surrogate loss function to be convex for the chosen inputs while maintaining the general structure for the others. Furthermore, users are not required to possess an artistic sense for selecting the suitable parametric function form for the task loss. Therefore, LCGLN can handle the general DFL problems using only one surrogate loss, regardless of the number of observed data. In the experiment section, we demonstrate the capability of LCGLN on three stochastic decision-making problems, namely inventory stock problem, budget allocation problem, and portfolio optimization problem. We show that LCGLN learns task loss well with a single surrogate loss.\n\n# 2 Related Works\n\nVarious methodologies based on gradient-based learning in DFL have been developed (Mandi et al. 2023). Some approaches directly differentiate the constrained optimization problem to update the model parameters. For instance, stochastic optimization problems were tackled by directly differentiating convex QPs using KKT optimality conditions and employing Optnet (Amos and Kolter 2017) for efficient differentiation (Donti, Amos, and Kolter 2017). For general convex optimization problems, the differentiable solver Cvxpylayers (Agrawal et al. 2019) were developed.\n\nAlternatively, some works introduce regularization terms to smooth the optimization mapping. For example, the Euclidean norm of the decision variables was added to use quadratic programming methods (Wilder, Dilkina, and Tambe 2019), while the logarithmic barrier term was added to differentiate linear programming problems (Mandi and Guns 2010). Furthermore, entropy terms were incorporated to solve multi-label problems (Martins and Kreutzer 2017; Amos, Koltun, and Kolter 2019), while constrained optimization problems were addressed using the perturband-MAP (Papandreou and Yuille 2011) framework, which added regularization through perturbations (Niepert, Minervini, and Franceschi 2021; Berthet et al. 2020).\n\nRecent works on DFL have focused on constructing differentiable surrogate loss models. Smart ”Predict, Then Optimize” (SPO) (Elmachtoub and Grigas 2022) proposed a convex $\\mathrm { S P O + }$ loss where the loss upper bounds the task loss. To update the predictive model, they obtained a subgradient of their proposed surrogate loss. NCE (Mulamba et al. 2020) used a noise contrastive approach (Gutmann and Hyva¨rinen 2010) to build a family of surrogate loss for linear objectives. LTR (Mandi et al. 2022) applied this approach to ranking problems. SO-EBM (Kong et al. 2022) used an energybased differentiable layer to model the conditional probability of the decision. The energy-based layer acts as a surrogate of the optimization problem. LODL (Shah et al. 2022) used supervised machine learning to locally construct surrogate loss models to represent task loss. They first sampled predictions near true instances for each instance and built a surrogate loss model respectively. They proposed three families for the model (e.g. WeightedMSE, Quadratic) to design parametric surrogate loss models. EGL (Shah et al. 2024) extends LODL to a global surrogate model and LANCER (Zharmagambetov et al. 2024) learns such handcraft global surrogate loss via actor-critic framework.\n\n![](images/10699c07e604bb063ab2b420a199e4294dae7e13ff529101a6dc42cca9f81d05.jpg)  \nFigure 2: A simple example of a knapsack problem. There are two items valued $\\$ 40$ , $\\$ 30$ each, marked with a yellow star. We predict the value of items and choose the higher one. Blue dots and red crosses are predicted values representing good and bad decisions respectively. PFL gives the same prediction loss for every prediction while DFL gives $\\$ 10$ loss in red cross and 0 in blue.\n\n# 3 Preliminaries\n\nIn this section, we motivate the necessity of DFL approach from a simple knapsack example. We also briefly summarize surrogate loss models and input convex neural networks.\n\nComparison on PFL and DFL Prediction-focused learning (PFL) and decision-focused learning (DFL) are two big learning pipelines for decision-making problems under uncertainty as in Figure 1. While PFL learns the predictive model focusing on the prediction from the predictive model, DFL focuses on the objective of the downstream optimization problem, commonly referred to task loss. Starting with\n\nPFL, the model training step is divided into two stages, prediction and optimization. In the prediction stage, PFL learns a predictive model by minimizing the prediction loss such as MSE. In the optimization stage, it solves an optimization problem using the prediction of the predictive model as parameters. By contrast, the predictive model in DFL is trained in an end-to-end manner. It prioritizes learning the model to make good decisions (or actions) by minimizing the task loss, rather than optimizing the prediction loss.\n\nWe introduce a motivating example with a simple knapsack problem in Figure 2 to give motivation in using DFL. Let’s consider two items: item 1 with a value of $\\$ 40$ and item 2 with $\\$ 30$ . Two axes in Figure 2 represent the value of each item. The true optimal value (40, 30) is marked by a yellow star. Assume we can only select one item. Our objective is to predict the value of items by only observing the item features and choosing one with a higher value. If we choose item 1 (the optimal decision), we would be satisfied, earning $\\$ 40$ . Conversely, choosing item 2 would be a suboptimal decision, resulting in a relative loss of $\\$ 10$ . Suppose we predict the values as blue dots and red crosses. From a PFL point of view, the prediction loss is equal to $\\$ 20$ . Any prediction on the gray circle results in the same prediction loss, which is not informative as the blue dots are correct decisions, whereas the red crosses are not. From a DFL standpoint, blue dots return zero task loss while red crosses give task loss of $\\$ 10$ . This example shows that minimizing the prediction loss may not lead to lower task loss.\n\nSurrogate DFL DFL computes task loss gradients with respect to the input parameters by, for example, directly differentiating the optimization problem (or optimizer) (Donti, Amos, and Kolter 2017). However, the optimizer cannot be differentiated easily in most cases. To tackle this, methods using surrogate loss functions were proposed (Elmachtoub and Grigas 2022). Surrogate loss models are differentiable and it approximates the mapping between the prediction and the task loss. Consequently, it can be used to calculate the gradient to update the predictive model efficiently.\n\nGiven dataset $\\boldsymbol { \\mathcal { D } } = \\{ ( x _ { i } , y _ { i } ) \\} _ { i = 1 } ^ { N }$ with $N$ instances, our goal is to minimize the regret $\\mathcal { R }$ for the optimization problem:\n\ns\n\n$$\n\\begin{array} { r l } { \\underset { \\theta } { \\mathrm { m i n } } \\quad } & { \\mathcal { R } ( \\hat { y } , y ) : = \\mathcal { L } _ { t a s k } \\big ( a ^ { * } ( \\hat { y } ) , y \\big ) - \\mathcal { L } _ { t a s k } \\big ( a ^ { * } ( y ) , y \\big ) } \\\\ { \\mathrm { . t . } \\quad } & { \\quad \\hat { y } = \\mathcal { M } _ { \\theta } ( x ) } \\\\ & { \\quad a ^ { * } ( \\hat { y } ) = \\underset { a \\in \\mathcal { A } } { \\mathrm { a r g m i n } } \\mathcal { L } _ { t a s k } \\big ( a , \\hat { y } \\big ) } \\end{array}\n$$\n\nwhere $\\mathcal { L } _ { t a s k }$ is the task loss to be optimized, $\\hat { y }$ is the prediction from the predictive model $\\mathcal { M }$ parameterized by $\\theta$ and $a ^ { * } \\in { \\mathcal { A } }$ is an optimal action (or decision) in a feasible region $\\mathcal { A }$ derived by any off-the-shelf solver. Note that the second term of the objective is nothing but a constant optimal loss, and therefore our objective is equivalent to minimizing $\\mathcal { L } _ { t a s k } ( a ^ { * } ( \\hat { y } ) , y )$ .\n\nTo update the predictive model via gradient descent w.r.t. $\\theta$ , one must find the gradient ${ \\partial \\mathcal { R } } / { \\partial \\theta }$ . Using the chain rule, the gradient can be decomposed into:\n\n$$\n\\begin{array} { r } { \\frac { \\partial \\mathcal { R } ( \\hat { y } , y ) } { \\partial \\theta } = \\frac { \\partial \\mathcal { R } ( \\hat { y } , y ) } { \\partial \\hat { y } } \\cdot \\frac { \\partial \\hat { y } } { \\partial \\theta } } \\\\ { \\approx \\frac { \\partial \\mathcal { L } _ { \\psi } ( \\hat { y } , y ) } { \\partial \\hat { y } } \\cdot \\frac { \\partial \\hat { y } } { \\partial \\theta } } \\end{array}\n$$\n\nwhere $\\mathcal { L } _ { \\psi } ( \\hat { y } , y )$ is the parametric surrogate loss with parameter $\\psi$ that is trained to approximate $\\mathcal { R } ( \\hat { y } , y )$ . The global surrogate loss can be trained to richly approximate the true task loss as:\n\n$$\n\\psi ^ { * } = \\underset { \\psi } { \\arg \\operatorname* { m i n } } \\ \\underset { \\hat { y } , y } { \\mathbb { E } } \\left[ \\left| \\mathcal { L } _ { \\psi } ( \\hat { y } , y ) - \\mathcal { R } ( \\hat { y } , y ) \\right| \\right]\n$$\n\nTraining the predictive model $\\mathcal { M } _ { \\theta }$ can be easily done with backpropagation using the gradient $\\partial \\mathcal { L } _ { \\psi } / \\partial \\theta$ .\n\nPartial Input Convex Neural Network Amos et al. (Amos, Xu, and Kolter 2017) proposed an input convex neural network (PICNN) that ensures convexity with respect to the chosen inputs. PICNN is constructed by introducing additional weights to connect the input layer to each hidden layer. Given this structure, non-decreasing convex activation functions such as softplus and non-negativity of weights connecting between hidden layers are required to guarantee the convexity of PICNN. LCGLN uses PICNN to richly represent the non-convex nature of the true loss mapping, and simultaneously ensure local convexity.\n\n# 4 Locally Convex Global Loss Network\n\nIn various optimization problems, each has its own specific objectives known as task losses. Our goal is to devise a surrogate loss function capable of accurately representing the true task loss across a range of optimization problems. In this paper, we introduce LCGLN, where a single loss representation can replace the true task loss. While DFL methods suffer from differentiating through the optimization solver when the optimization problem is not smooth, our LCGLN is easily differentiable and therefore can be readily backpropagated when updating the predictive model via gradients.\n\nWe now introduce the end-to-end training procedure for LCGLN. The goal is to learn a regret mapping $( { \\hat { y } } , y ) $ $\\mathcal { R } ( \\hat { y } , y )$ to obtain gradient ${ \\partial \\mathcal { R } } / { \\partial \\theta }$ for updating the predictive model $\\mathcal { M } _ { \\theta }$ . The training consists of three main steps: generating samples, learning a global surrogate loss, and training a predictive model.\n\nGenerating Samples To train the LCGLN in a supervised learning manner, we generate $K$ samples for each $N$ instance, i.e. for each instance $y _ { i }$ , we sample $\\tilde { y } _ { i } ^ { ( 1 ) } , \\tilde { y } _ { i } ^ { ( 2 ) } , . . . , \\tilde { y } _ { i } ^ { ( K ) }$ .\n\nSome previous research assumed that predictions $\\tilde { y }$ would closely approximate the true labels $y$ , typically generating sample predictions by simply adding Gaussian noise. However, the Gaussian sampling method may be challenging to apply for two reasons. First, in some cases, the true label $y$ is unknown. For example, in the inventory stock problem used in our experiments, the true $y$ represents the probability vector of each demand occurring. Yet, the observed data only provides a specific demand value realized according to that probability. In such cases, since the true $y$ is unknown, there is no target to which Gaussian noise can be added. Second, even if the true $y$ is known, determining the appropriate standard deviation for sampling around $y$ can be difficult, often requiring repeated tuning.\n\n<html><body><table><tr><td>Dataset: D = {(xi, yi)}=1 1. Generate Samples: Sample set S←@ fori=1,...,Ndo S ← SU(yi, yi,0) end for Initialize sampling model Mε for k=1,...,K-1 do for i=1,...,N do g）=M（mi） m←Update(ε,Vellyk）- yill） (）rgminaCts((y),y). S←SU(g(）,y,R(g）,y）) end for end for 2. Learn LCGLN L : Initialize surrogate loss model L . for(y,y,R(y,y)) inS do ←Update (ψ,VllL(y,y)-R(y,y)ll) end for 3.Train Predictive Model Mθ: Initialize predictive model Mθ . Solve a(</td></tr></table></body></html>\n\nOn account of this, we adopt the model-based sampling (MBS) approach (Shah et al. 2024). MBS involves constructing a sampling model $M _ { \\xi }$ that mirrors the architecture of the predictive model and training within a PFL paradigm using MSE. During the training, we take inferences from the intermediate model and generate samples. Unlike the Gaussian sampling, neither the true $y$ nor the standard deviation for the noise is required for MBS.\n\nLearning Global Surrogate Loss LCGLN Our objective is to learn a mapping $( \\hat { y } , y ) \\ \\to \\ \\mathcal { R }$ for conveying informative gradients of task loss. We propose leverage of partial input convex neural network (PICNN) (Amos, Xu, and Kolter 2017) as our Locally Convex Global Loss Network (LCGLN). Our motivation for using PICNN as a surrogate model for task loss is fourfold:\n\n• Expressiveness: A good surrogate loss model should have a sufficient number of parameters to accurately approximate the true task loss since a lack of expressiveness may lead to under-performance. Amos, Xu, and Kolter (2017) proved that a $k$ -layer PICNN can represent any $k$ -layer feedforward network. Since feedforward neural networks are known as universal approximators (Cybenko 1989; Funahashi 1989; Hornik 1991), this ensures the PICNN can accurately model task loss. • Easily Differentiable: We need to differentiate our loss model with respect to $\\hat { y }$ for gradients training the predictive model. Discontinuous or non-differentiable loss models face significant challenges in such tasks. In contrast, PICNN can be easily differentiated by using built-in backward functions.\n\nTable 1: The table contains normalized test regret $\\mathcal { R } _ { t e s t } / \\mathcal { R } _ { w o r s t }$ with standard error mean (SEM) tested on three stochastic optimization problems. The metric is lower the better with an optimal regret of zero. The best-performing results for each problem are bold-lettered. We evaluate PFL, DFL, local, and global surrogate loss models. We use 32 samples for the surrogate loss models. The global surrogate loss LCGLN outperformed the baselines across all three problems.   \n\n<html><body><table><tr><td rowspan=\"2\">PARADIGM</td><td rowspan=\"2\">METHODS</td><td colspan=\"3\">PROBLEM</td></tr><tr><td>INVENTORY</td><td>BUDGET(500 FAKES)</td><td>PORTFOLIO</td></tr><tr><td>2 STAGE</td><td>PFL</td><td>0.242 ±0.005</td><td>0.513 ± 0.016</td><td>0.189 ±0.002</td></tr><tr><td>EXACT DIFF</td><td>DFL</td><td>0.228 ±0.002</td><td>0.532 ±0.020</td><td>0.187 ±0.002</td></tr><tr><td>LOCAL SURROGATE</td><td>LODL-DQ</td><td>0.378 ±0.007</td><td>0.503 ±0.020</td><td>0.193 ±0.002</td></tr><tr><td rowspan=\"4\">GLOBAL SURROGATE</td><td>LANCER</td><td>0.182 ±0.004</td><td>0.490 ±0.010</td><td>0.246±0.008</td></tr><tr><td>EGL-WMSE</td><td>0.371 ±0.002</td><td>0.510 ± 0.013</td><td>0.187 ±0.001</td></tr><tr><td>EGL-DQ</td><td>0.369 ±0.007</td><td>0.492 ±0.005</td><td>0.256±0.002</td></tr><tr><td>LCGLN</td><td>0.174 ±0.002</td><td>0.468 ± 0.009</td><td>0.185 ±0.000</td></tr></table></body></html>\n\n• Locally Convex, but not Globally: We want the model to capture the highly non-convex structure of the true underlying task loss mapping. Task loss can be expressed as $\\hat { f } ( x ^ { * } ( \\hat { y } ) , y ) - f ( x ^ { * } \\bar { ( y ) } , \\bar { y } )$ , where it achieves its minimum regret zero when $\\hat { y } = y$ . While task loss may not be convex in $\\hat { y }$ for a given $y$ in general, we use PICNN to drive $\\hat { y }$ towards the true value $y$ by eliminating local minima except $y$ . This property enables the model to provide informative gradients for training the predictive model with a small sample size. Furthermore, we induce the local minima by adding $\\{ ( y _ { i } , y _ { i } , 0 ) \\} _ { i = 1 } ^ { N }$ to the dataset for every instance.\n\n• Generality: The adoption of PICNN helps generalize the function approximators and allows the approximation of differentiable optimization. Using PICNN, we can only focus on the overall network architecture and perform a simple hyperparameter search instead of requiring welltrained experts’ efforts in choosing the right parametric function forms for specific problems.\n\nTraining Predictive Model The predictive model $M _ { \\theta }$ learns a mapping $x  y$ . To obtain gradients for the predictive model training, we first generated samples using the MBS approach. For each generated sample, we derived the true task loss in regret form and added the sample, instance, and regret pair to the dataset. Additionally, we included $\\{ ( y _ { i } , y _ { i } , 0 ) \\} _ { i = 1 } ^ { \\setminus }$ into the dataset to induce local minima for every instance $y _ { i }$ . Using this dataset, we trained the global surrogate loss model structured with PICNN.\n\nBuilding on these steps, we now train the predictive model $M _ { \\theta }$ via gradient descent utilizing the gradients provided by the global surrogate loss $\\mathcal { L } _ { \\psi }$ . The entire procedure from generating the dataset to training the predictive model is summarized in Algorithm 1.\n\n# 5 Experiments and Results\n\nWe validate our methodology with three stochastic optimization problems.\n\n# 5.1 Experimental Settings\n\nIn this section, we explain the experimental details and the baselines used to evaluate our method. Each problem is elaborated in two stages: the parameter prediction stage and the optimization stage.\n\nProblem Description We conducted experiments on three different stochastic optimization problems, each presenting unique challenges as explored in previous research (Donti, Amos, and Kolter 2017; Wilder, Dilkina, and Tambe 2019; Shah et al. 2022). Our experiments were built on top of the public codes from previous research (Donti, Amos, and Kolter 2017; Shah et al. 2022). Here we briefly describe each problem. For further problem descriptions, please refer to Appendix B.\n\n• Inventory Stock (Donti, Amos, and Kolter 2017): We decide the order quantity to minimize the cost over the stochastic demand. To simplify the problem, we assume the demands are discrete. Prediction: We predict the discrete probability distribution of the demand. Optimization: With the predicted demand distribution, we decide the order quantity that minimizes the cost.   \n• Budget Allocation (Wilder, Dilkina, and Tambe 2019): We choose websites to advertise based on click-through rates (CTRs) of users among websites. As a variant, we conduct four different experiment settings by concatenating $\\{ 0 , 5 , 5 0 , 5 0 0 \\}$ size of random CTRs (fake targets) to the original CTRs and adjusting the problem difficulty. Prediction: Given the website features, we predict the CTRs. Optimization: With the predicted CTRs, we choose the websites to advertise that maximize the expected number of users who click on the advertisement at least once.\n\n![](images/a3ae67e0c8e8dde45bbfc7a42ac16517466e73a8ff414704b65861528744502a.jpg)  \nFigure 3: A line plot showing the normalized test regret $\\mathcal { R } _ { t e s t } / \\mathcal { R } _ { w o r s t }$ for each methodology and problem setting. The metric is lower the better, with 0 representing the optimal value. We tested sample size of $\\{ 2 , 4 , 8 , 1 6 , 3 2 \\}$ for each problem. The standard error mean for each experiment is detailed in Appendix C.2. Our global surrogate loss LCGLN represented by the red straight line outperforms when 32 samples are used.\n\n• Portfolio Optimization (Shah et al. 2022): We allocate weights for invested stocks to maximize the expected risk-adjusted return.\n\nPrediction: Given the historical daily stock return data, we predict the future stock price. Optimization: Using the predicted stock price, we assign portfolio weights that maximize the expected riskadjusted return, given the covariance matrix.\n\nBaselines We compare our global surrogate loss network LCGLN with the following baselines from previous research. When available, we utilized the hyperparameters specified in previous research for the baselines. In cases where these were not provided, we endeavored to fine-tune them to perform their best.\n\n• PFL: A standard approach that trains a predictive model on the input features to produce predictions that closely match the observed parameters. We use the negative loglikelihood (NLL) loss for the inventory stock problem and the mean squared error (MSE) loss for the other problems.   \n• DFL: A direct approach that differentiates through the solver to derive gradients for training the predictive model. For the inventory stock and the portfolio optimization problems, we use the differentiable QP solver (Donti, Amos, and Kolter 2017). We use multilinear relaxation (Wilder, Dilkina, and Tambe 2019) for the budget allocation problem.   \n• LODL: The local surrogate model (Shah et al. 2022) that learns a surrogate loss locally for each instance, creating total $N$ surrogate loss models. To learn a loss model, LODL generates $K$ number of samples for each $N$ instance and solves for the input of the model. We use directed-quadratic surrogate loss (LODL-DQ) from their paper, the most promising result among the proposed 4 different loss models.   \n• LANCER: The global surrogate model (Zharmagambe\n\ntov et al. 2024) that uses alternating optimization to learn the predictive model and the global surrogate loss model. The prediction samples are sampled from the predictive model and are used to train the surrogate loss. The predictive model is then trained using the gradients from the updated surrogate loss.\n\n• EGL: The global surrogate model (Shah et al. 2024) that learns a global surrogate loss with feature-based parameterization and model-based sampling. We use directedquadratic (EGL-DQ) and weighted-MSE (EGL-WMSE) for the baseline, which showed the best results on the budget allocation and the portfolio optimization problems respectively.\n\nEvaluation Metric We use the normalized test regret $\\mathcal { R } _ { t e s t } / \\mathcal { R } _ { w o r s t }$ as the evaluation metric, where $\\mathcal { R } _ { t e s t }$ is a test regret with regret defined in Equation 1. For the maximization tasks, such as the budget allocation and portfolio optimization problem, regrets are calculated by multiplying the negative sign on the corresponding objective. We calculate the worst case regret $\\mathcal { R } _ { w o r s t }$ for each problem and derive the normalized test regret. For the inventory stock problem, we assumed the worst-case scenario when the company ordered no stock. In the budget allocation problem, the worstcase scenario was assumed when the advertisements were allocated to the lowest predicted CTRs. For the portfolio optimization problem, we considered the worst-case scenario to be when the entire investment was allocated to the stock with the lowest predicted return. Our metric is 0 when optimal and 1 when worst.\n\nWe used a predictive model $\\mathcal { M } _ { \\theta }$ as one hidden layer MLP and a learning rate of 0.001. 500 hidden nodes were used for the portfolio optimization and 10 for the other problems. We mirrored the predictive model exactly for the sampling model $\\mathcal { M } _ { \\xi }$ . For LCGLN, we employed a single hidden layer PICNN with two nodes per layer, a learning rate of 0.001, and a softplus activation function. A figure illustrating the LCGLN can be found in Appendix A.1. For each global surrogate loss model employing model-based sampling, we selected the learning rate that demonstrated the best performance from $\\{ 0 . 0 1 , 0 . 0 5 , 0 . 1 , 0 . 5 , 1 \\}$ . We run 10 experiments for each setting to ensure statistical significance. The experiments were performed on a Ryzen 7 5800X CPU and an RTX 3060 GPU with 64GB of RAM.\n\n![](images/ebe3812fd9bad34a7b40d0f7cc57005846234e6090a481ea3f1f006724636b44.jpg)  \nFigure 4: A histogram presenting normalized test regret $\\mathcal { R } _ { t e s t } / \\mathcal { R } _ { w o r s t }$ with standard error mean (SEM) for global surrogate loss models in budget allocation with varying number of fake targets. We use 16 samples for learning loss. The metric is lower the better and 0 when optimal. We test with $\\{ 0 , 5 , 5 0 , 5 0 0 \\}$ fake targets, noting that the problem becomes more challenging as the number of fake targets increases. Our LCGLN shown in red bars outperforms most settings.\n\n# 5.2 Results\n\nTable 1 shows the normalized test regret $\\mathcal { R } _ { t e s t } / \\mathcal { R } _ { w o r s t }$ with standard error mean (SEM) for the inventory stock, budget allocation with 500 fake targets and portfolio optimization problems. For the surrogate loss models, we used 32 samples to learn the loss. We categorize the methods into four major training paradigms: two-stage, exact differentiation, local surrogate loss, and global surrogate loss.\n\nIn the inventory stock problem, LODL-DQ, EGL-WMSE, and EGL-DQ suffer from high regret, indicating that they do not provide informative gradients. LANCER and LCGLN perform well compared to others due to their expressiveness, as both use neural networks to learn the loss. For the budget allocation problem, we conduct four experiments with $\\{ 0 , 5 , 5 0 , 5 0 0 \\}$ fake targets. Detailed results with different fake targets are available in Appendix C.1. For the hardest problem with 500 fake targets, the surrogate models tend to show better results than PFL or DFL methods. In the portfolio optimization problem, good prediction in parameters showed better decisions. This is evidenced by PFL and DFL showing better results compared to surrogate models. EGLWMSE and LCGLN also demonstrated strong performance in our settings.\n\nTo reduce the computational cost, it is crucial to train the surrogate loss with small sample sizes. We conducted experiments with varying sample sizes, as shown in the line plot in Figure 3. Note that the normalized test regret is better when lower. Since PFL, DFL, and LANCER do not vary with changes in a number of sample predictions, they show consistent results across all sample sizes. The surrogate models showed decreased regret as the sample size increased. At a sample size of 32, LCGLN outperformed the provided baselines. For detailed experimental results for each sample size and problem, please refer to Appendix C.2.\n\nWe also tested different numbers of fake targets, varying in $\\{ 0 , 5 , 5 0 , 5 0 0 \\}$ , to show how models perform on harder problems. We used 16 samples to train the loss model. Figure 4 presents the normalized test regret with SEM for global models across each experimental setting. LCGLN consistently outperformed in most settings.\n\n# 6 Conclusion\n\nIn this paper, we propose Locally Convex Global Loss Network (LCGLN), a global and general surrogate loss for DFL. LCGLN utilizes PICNN as a parametric surrogate to approximate task loss. We use PICNN to guarantee the surrogate to be convex near instances while maintaining a general nonconvex structure globally. With LCGLN, users do not need to manually select the appropriate parametric function form for the task loss. Consequently, LCGLN can address general DFL problems with a single surrogate loss, regardless of the amount of observed data. We evaluated our method on three stochastic optimization problems, achieving better decision quality with fewer training samples compared to the stateof-the-art baselines. However, despite the expressive power of LCGLN, a limitation remains: achieving high decision quality requires careful selection of the samples. Thus, our future research will focus on identifying sampling strategies to improve the decision quality for surrogate loss models.",
    "institutions": [
        "KAIST"
    ],
    "summary": "{\n    \"core_summary\": \"### 核心概要\\n\\n**问题定义**\\n在不确定条件下的决策问题中，预测未知参数通常被认为与优化部分相互独立。决策导向学习（DFL）旨在将预测和优化相结合，但在计算最优决策相对于参数的梯度时面临挑战。现有研究通过平滑改革替代优化或构建模仿任务损失的替代损失函数来应对这一问题，但这些方法仅适用于受限的优化领域。此问题的重要性在于提高决策质量，解决现实世界中如生产优化、能源规划和资产负债管理等应用的决策难题。\\n\\n**方法概述**\\n本文提出了局部凸全局损失网络（Locally Convex Global Loss Network，LCGLN），这是一种全局替代损失模型，可在一般的DFL范式中实现。LCGLN通过部分输入凸神经网络（PICNN）学习任务损失，确保在选定输入上是凸的，同时保持其他输入的非凸全局结构。\\n\\n**主要贡献与效果**\\n- 提出了一种通用的DFL替代损失模型LCGLN，无需手动选择合适的参数函数形式。\\n- 在三个随机决策问题（库存问题、预算分配问题和投资组合优化问题）上进行评估，在库存问题中，LCGLN的归一化测试遗憾值为0.174 ± 0.002，优于LODL - DQ（0.378 ± 0.007）、EGL - WMSE（0.371 ± 0.002）、EGL - DQ（0.369 ± 0.007）和PFL（0.242 ± 0.005）、DFL（0.228 ± 0.002），与LANCER（0.182 ± 0.004）表现相当；在预算分配问题（500个假目标）中，LCGLN的归一化测试遗憾值为0.468 ± 0.009，优于PFL（0.513 ± 0.016）、DFL（0.532 ± 0.020）、LODL - DQ（0.503 ± 0.020）、LANCER（0.490 ± 0.010）、EGL - WMSE（0.510 ± 0.013）和EGL - DQ（0.492 ± 0.005）；在投资组合优化问题中，LCGLN的归一化测试遗憾值为0.185 ± 0.000，优于LANCER（0.246 ± 0.008）、EGL - DQ（0.256 ± 0.002），与PFL（0.189 ± 0.002）、DFL（0.187 ± 0.002）、EGL - WMSE（0.187 ± 0.001）表现相当。在不同样本大小的实验中，当样本大小为32时，LCGLN的归一化测试遗憾值最低，优于所有基线模型。在测试不同数量假目标的实验中，使用16个样本训练损失模型，LCGLN在大多数设置中始终优于其他全局模型。\",\n    \"algorithm_details\": \"### 算法/方案详解\\n\\n**核心思想**\\nLCGLN的核心思想是使用部分输入凸神经网络（PICNN）来近似任务损失。PICNN能保证在选定输入上是凸的，而在其他输入上保持非凸的全局结构，从而为训练预测模型提供有信息的梯度，驱动预测值接近真实值，同时允许用户专注于整体网络架构和简单的超参数搜索，而无需为特定问题选择合适的参数函数形式。\\n\\n**创新点**\\n先前的DFL方法在优化问题不光滑时难以通过优化求解器进行微分，且现有替代损失方法存在应用领域受限、计算成本高、需要手动选择参数函数形式等问题。LCGLN的创新之处在于采用PICNN作为替代损失模型，具有良好的可微性，能轻松进行反向传播；同时，它能在局部凸的情况下捕捉真实任务损失映射的高度非凸结构，提供有信息的梯度，且具有通用性，一个替代损失即可处理一般的DFL问题。\\n\\n**具体实现步骤**\\n1. **生成样本**：采用基于模型的采样（MBS）方法，为每个实例生成K个样本。对于每个实例$y_i$，采样$\\tilde{y}_i^{(1)},\\tilde{y}_i^{(2)},...,\\tilde{y}_i^{(K)}$。避免了高斯采样方法中真实标签未知和难以确定采样标准差的问题。具体做法是，对于数据集$\\mathcal{D} = \\{ ( x _ { i } , y _ { i } ) \\} _ { i = 1 } ^ { N }$，初始化采样模型$M_{\\epsilon}$，通过循环生成样本并添加到样本集$S$中。\\n2. **学习全局替代损失**：使用PICNN作为局部凸全局损失网络（LCGLN），学习遗憾映射$(\\hat{y},y)\\to\\mathcal{R}(\\hat{y},y)$。PICNN具有表达性、易微性、局部凸但全局非凸和通用性等特点。通过最小化$\\underset{\\psi}{\\arg\\min}\\ \\underset{\\hat{y},y}{\\mathbb{E}}[\\vert\\mathcal{L}_{\\psi}(\\hat{y},y)-\\mathcal{R}(\\hat{y},y)\\vert]$来训练全局替代损失模型。同时，为每个实例添加$\\{ ( y _ { i } , y _ { i } , 0 ) \\} _ { i = 1 } ^ { N }$到数据集以诱导局部最小值。\\n3. **训练预测模型**：预测模型$M_{\\theta}$学习映射$x\\to y$。利用MBS方法生成的样本，为每个生成的样本导出真实任务损失的遗憾形式，并将样本、实例和遗憾对添加到数据集中。使用该数据集训练基于PICNN结构的全局替代损失模型，并通过梯度下降利用全局替代损失$\\mathcal{L}_{\\psi}$提供的梯度来训练预测模型$M_{\\theta}$。\\n\\n**案例解析**\\n论文以简单的背包问题为例，假设有两个物品，物品1价值40美元，物品2价值30美元，只能选择一个物品。目标是通过观察物品特征预测物品价值并选择价值更高的物品。从预测导向学习（PFL）的角度来看，所有预测的预测损失相同，无法区分正确决策和错误决策；而从决策导向学习（DFL）的角度来看，正确决策（选择物品1）的任务损失为0，错误决策（选择物品2）的任务损失为10美元。这个例子说明了最小化预测损失不一定能导致较低的任务损失，从而体现了DFL的必要性。\",\n    \"comparative_analysis\": \"### 对比实验分析\\n\\n**基线模型**\\n- **PFL**：一种标准方法，在输入特征上训练预测模型以产生与观察到的参数紧密匹配的预测。在库存问题中使用负对数似然（NLL）损失，在其他问题中使用均方误差（MSE）损失。\\n- **DFL**：一种直接方法，通过求解器进行微分以获得训练预测模型的梯度。在库存和投资组合优化问题中使用可微QP求解器，在预算分配问题中使用多线性松弛。\\n- **LODL - DQ**：局部替代模型，为每个实例局部学习替代损失，创建N个替代损失模型。使用定向二次替代损失。\\n- **LANCER**：全局替代模型，使用交替优化来学习预测模型和全局替代损失模型。\\n- **EGL - WMSE和EGL - DQ**：全局替代模型，通过基于特征的参数化和基于模型的采样学习全局替代损失。分别在预算分配和投资组合优化问题中表现最佳。\\n\\n**性能对比**\\n*   **在 [归一化测试遗憾/Normalized Test Regret] 指标上：** 在库存问题中，LCGLN的归一化测试遗憾值为 **0.174 ± 0.002**，优于PFL（0.242 ± 0.005）、DFL（0.228 ± 0.002）、LODL - DQ（0.378 ± 0.007）、EGL - WMSE（0.371 ± 0.002）和EGL - DQ（0.369 ± 0.007），与LANCER（0.182 ± 0.004）表现相当。在预算分配问题（500个假目标）中，LCGLN的归一化测试遗憾值为 **0.468 ± 0.009**，优于PFL（0.513 ± 0.016）、DFL（0.532 ± 0.020）、LODL - DQ（0.503 ± 0.020）、LANCER（0.490 ± 0.010）、EGL - WMSE（0.510 ± 0.013）和EGL - DQ（0.492 ± 0.005）。在投资组合优化问题中，LCGLN的归一化测试遗憾值为 **0.185 ± 0.000**，优于LANCER（0.246 ± 0.008）、EGL - DQ（0.256 ± 0.002），与PFL（0.189 ± 0.002）、DFL（0.187 ± 0.002）、EGL - WMSE（0.187 ± 0.001）表现相当。在不同样本大小的实验中，当样本大小为32时，LCGLN的归一化测试遗憾值最低，优于所有基线模型。在测试不同数量假目标的实验中，使用16个样本训练损失模型，LCGLN在大多数设置中始终优于其他全局模型。\",\n    \"keywords\": \"### 关键词\\n\\n- 决策导向学习 (Decision - Focused Learning, DFL)\\n- 局部凸全局损失网络 (Locally Convex Global Loss Network, LCGLN)\\n- 部分输入凸神经网络 (Partial Input Convex Neural Network, PICNN)\\n- 随机决策问题 (Stochastic Decision - Making Problems, N/A)\"\n}"
}