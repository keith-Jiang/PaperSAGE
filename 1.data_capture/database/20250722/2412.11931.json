{
    "link": "https://arxiv.org/abs/2412.11931",
    "pdf_link": "https://arxiv.org/pdf/2412.11931",
    "title": "Speeding Up the NSGA-II With a Simple Tie-Breaking Rule",
    "authors": [
        "Benjamin Doerr",
        "Tudor Ivan",
        "Martin S. Krejca"
    ],
    "publication_date": "2024-12-16",
    "venue": "AAAI Conference on Artificial Intelligence",
    "fields_of_study": [
        "Computer Science"
    ],
    "citation_count": 4,
    "influential_citation_count": 0,
    "paper_content": "# Speeding Up the NSGA-II with a Simple Tie-Breaking Rule\n\nBenjamin Doerr1, Tudor Ivan2, Martin S. Krejca1\n\n1Laboratoire d’Informatique (LIX), CNRS, E´ cole Polytechnique, Institut Polytechnique de Paris 2 ´Ecole Polytechnique, Institut Polytechnique de Paris first-name.last-name @polytechnique.edu\n\n# Abstract\n\nThe non-dominated sorting genetic algorithm II (NSGA-II) is the most popular multi-objective optimization heuristic. Recent mathematical runtime analyses have detected two shortcomings in discrete search spaces, namely, that the NSGAII has difficulties with more than two objectives and that it is very sensitive to the choice of the population size. To overcome these difficulties, we analyze a simple tiebreaking rule in the selection of the next population. Similar rules have been proposed before, but have found only little acceptance. We prove the effectiveness of our tiebreaking rule via mathematical runtime analyses on the classic ONEMINMAX, LEADINGONESTRAILINGZEROS, and ONEJUMPZEROJUMP benchmarks. We prove that this modified NSGA-II can optimize the three benchmarks efficiently also for many objectives, in contrast to the exponential lower runtime bound previously shown for ONEMINMAX with three or more objectives. For the bi-objective problems, we show runtime guarantees that do not increase when moderately increasing the population size over the minimum admissible size. For example, for the ONEJUMPZEROJUMP problem with representation length $n$ and gap parameter $k$ , we show a runtime guarantee of $O ( \\operatorname* { m a x } \\{ n ^ { k + 1 } , N n \\} )$ function evaluations when the population size is at least four times the size of the Pareto front. For population sizes larger than the minimal choice $N = \\Theta ( n )$ , this result improves considerably over the $\\Theta ( N n ^ { k } )$ runtime of the classic NSGA-II.\n\n# Introduction\n\nMany real-world optimization tasks face several, usually conflicting objectives. One of the most successful approaches to such multi-objective optimization problems are evolutionary algorithms (EAs) (Coello, Lamont, and van Veldhuizen 2007; Zhou et al. 2011), with the NSGA-II (Deb et al. 2002) standing out as the by far dominant algorithm in practice (over $5 0 0 0 0$ citations on Google Scholar).\n\nRecent mathematical works have shown many positive results for the NSGA-II (see Previous Works) but have also exhibited two difficulties. (1) For more than two objectives, the crowding distance as selection criterion seems to have some shortcomings. This was formally proven for the optimization of the simple ONEMINMAX benchmark, where an exponential lower bound on the runtime was shown for three and more objectives when the population size is linear in the size of the Pareto front (Zheng and Doerr 2024b). The proof of this result suggests that similar problems exist for many optimization problems with three or more objectives. (2) All runtime guarantees proven for the NSGA-II increase linearly with the population size. For some settings, even matching lower bounds proving this effect were proven (Doerr and Qu 2023b). This behavior is very different from many singleobjective EAs, where a moderate increase of the population size increases the cost of an iteration but at the same time reduces the number of iterations in a way that the total runtime (number of function evaluations) is at most little affected.\n\nThe reason for this undesired behavior of the NSGA-II, as the proofs by Doerr and Qu (2023b) reveal, is that the population of the NSGA-II is typically not evenly distributed on the known part of the Pareto front. Instead, the distribution is heavily skewed toward the inner region of the Pareto front.\n\nInspired by this observation, we propose to add a simple tie-breaking criterion to the selection of the next population. In the classic NSGA-II, selection is done according to nondominated sorting, ties are broken according to the crowding distance, and remaining ties are broken randomly. We add the number of individuals having a certain objective value as the third criterion, and break only the remaining ties randomly. We note that a similar idea was suggested already by Fortin and Parizeau (2013) and supported by empirical results, but has not made it into the typical use of the NSGA-II.\n\nOur tie-breaker solves both problems. We rigorously study the runtime for the three most established benchmarks in the theory of multi-objective EAs (MOEAs): ONEMINMAX, LEADINGONESTRAILINGZEROS, and ONEJUMPZEROJUMP. For all defined versions with at least three objectives and for constant gap parameter $k$ , we show that our NSGA-II with a population size exceeding the Pareto front size only by a lower-order term efficiently solves the problem when the Pareto front size is polynomial (Theorem 3).\n\nFor the bi-objective versions of these problems, we prove runtime guarantees showing that for a certain range of the population size, the runtime is (asymptotically) not affected by this parameter. The size of this range depends on the difficulty of the problem. For the difficult ONEJUMPZEROJUMP benchmark with problem size $n$ and gap parameter $k$ , our runtime guarantee is $O ( n ^ { k + 1 } )$ for all population sizes $N$ between $4 ( n - 2 k + 3 )$ and ${ \\dot { O } } ( n ^ { k } )$ , and it is $O ( N n )$ for\n\n$N = \\Omega ( n ^ { k } )$ . Compared to the runtime of $\\Theta ( N n ^ { k } )$ proven by Doerr and Qu (2023a), this is a noteworthy speed-up for larger population sizes. From a practical perspective, this result indicates that our tie-breaking rule significantly reduces the need for a careful optimization of the algorithm parameter $N$ . We support this claim empirically, showing that this speed-up is already noticeable when the chosen and optimal population size deviate only by a constant factor.\n\nOverall, this work shows that adding the simple tiebreaker of preferring individuals with rarer objective values can lead to considerable performance gains and greatly reduce the need of determining an optimal population size.\n\nAll proofs and some additional details are in the full version (Doerr, Ivan, and Krejca 2024a).\n\n# Previous Works\n\nThis being a theoretical work, for space reasons, we refer to the surveys by Coello et al. (2007) and by Zhou et al. (2011) for the success of MOEAs in practical applications.\n\nThe mathematical analysis of randomized search heuristics has supported for a long time the development of these algorithms (Neumann and Witt 2010; Auger and Doerr 2011; Jansen 2013; Zhou, Yu, and Qian 2019; Doerr and Neumann 2020), including MOEAs. The runtime analysis for MOEAs was started in (Laumanns et al. 2002; Giel 2003; Thierens 2003) with very simplistic algorithms like the simple evolutionary multi-objective optimizer (SEMO) or the global SEMO. Due to the complex population dynamics, it took many years until more prominent MOEAs could be analyzed, such as the $( \\mu + 1 )$ SIBEA (Brockhoff, Friedrich, and Neumann 2008), MOEA/D (Li et al. 2016), NSGA-II (Zheng, Liu, and Doerr 2022), NSGA-III (Wietheger and Doerr 2023), or SMS-EMOA (Bian et al. 2023).\n\nThe analysis of the NSGA-II, the by far dominant algorithm in practice, had a significant impact on the field and was quickly followed up by other runtime analyses for this algorithm. The vast majority of these prove runtime guarantees for bi-objective problems. Some are comparable to those previously shown for the (G)SEMO (Bian and Qian 2022; Doerr and $ { \\mathrm { Q u } } 2 0 2 3 \\mathrm { a }$ ; Dang et al. 2023b; Cerf et al. 2023; Deng et al. 2024), others explore new phenomena like approximation properties (Zheng and Doerr 2024a), better robustness to noise (Dang et al. 2023a), or new ways how crossover (Doerr and $\\mathrm { Q u } \\ 2 0 2 3 \\mathrm { c } )$ or archives (Bian et al. 2024) can be advantageous. All these works, except for (Bian et al. 2024), require that the population size is at least a constant factor larger than the size of the Pareto front. Increasing the population size further leads to a proportional increase of the runtime guarantee. Lower bounds for the ONEMINMAX and ONEJUMPZEROJUMP benchmarks show that this increase is real, i.e., the runtime is roughly proportional to the population size. This runtime behavior is very different from what is known from single-objective optimization, where results like (Jansen, Jong, and Wegener 2005; Witt 2006; Doerr and Ku¨nnemann 2015) show that often there is a regime where an increase of the population size does not lead to an increase of the runtime. Hence, for the NSGA-II, the choice of the population size is much more critical than for many single-objective algorithms (or the (G)SEMO with its flexible population size). The results most relevant for our work are the upper and lower bounds for the bi-objective ONEMINMAX, LEADINGONESTRAILINGZEROS, and ONEJUMPZEROJUMP problems. We describe these in the sections where they are relevant.\n\nSo far, there is only one runtime analysis of the NSGA-II on a problem with more than two objectives (Zheng and Doerr 2024b). It shows that the NSGA-II takes at least exponential time to optimize ONEMINMAX in at least three objectives, for any population size at most a constant factor larger than the Pareto front (see also further below). This result was recently extended to LEADINGONESTRAILINGZEROS (Doerr, Korkotashvili, and Krejca 2024).\n\n# Preliminaries\n\nThe natural numbers $\\mathbb { N }$ include 0. For $m , n \\in \\mathbb { N }$ , we define $[ m . . n ] : = [ m , n ] \\cap \\mathbb { N }$ as well as $[ n ] : = [ 1 . . n ]$ .\n\nGiven $m , n \\in \\mathbb { N }$ , an $m$ -objective function $f$ is a tuple $( f _ { j } ) _ { j \\in [ m ] }$ where, for all $j \\in [ m ]$ , it holds that $f _ { j } \\colon \\{ 0 , 1 \\} ^ { n } \\to$ $\\mathbb { R }$ . Given an $m$ -objective function, we implicitly assume that we are also given $n$ . We call each $x \\in \\{ 0 , 1 \\} ^ { n }$ an individual and $f ( x ) : = ( f _ { j } ( x ) ) _ { j \\in [ m ] }$ the objective value of $x$ . For each $i \\in [ n ]$ , we denote the $i$ -th component of $x$ by $x _ { i }$ . We denote the number of 1s of $x$ by $| x | _ { 1 }$ , and its number of 0s by $| x | _ { 0 }$ .\n\nWe consider the maximization of $m$ -objective functions. The objective values of an $m$ -objective function $f$ induce a weak partial order on the individuals, denoted by $\\succeq$ . For $x , y \\in { \\mathsf { \\Gamma } } [ 0 , 1 ] ^ { n }$ , we say that $x$ weakly dominates $y$ (written $x ~ \\succeq ~ y )$ if and only if for all $j \\in [ m ]$ holds that $f _ { j } ( x ) \\geq f _ { j } ( y )$ . If one of these inequalities is strict, we say that $x$ strictly dominates $y$ (written $x \\succ y$ ). We say that $x$ is Pareto-optimal if and only if $x$ is not strictly dominated by any individual. We call the set of objective values of all Pareto-optimal individuals the Pareto front of $f$ , and we call the set of all Pareto-optimal individuals the Pareto set of $f$ .\n\n# The NSGA-II\n\nThe non-dominated sorting genetic algorithm II (NSGA-II, Algorithm 1) is the most popular heuristic for multiobjective optimization. It optimizes a given $m$ -objective function iteratively, maintaining a multi-set (a population) of individuals of a given size $N \\in \\mathbb { N } _ { \\geq 1 }$ . This population is initialized with individuals chosen uniformly at random.\n\nIn each iteration, the NSGA-II generates an additional, new offspring population of $N$ individuals as we detail below. Out of the $2 N$ individuals from the combined population of current and offspring population, the algorithm selects $N$ individuals as the new population for the next iteration. To this end, the NSGA-II utilizes two characteristics defined over individuals, which we also both detail below: non-dominated ranks and crowding distance. The $2 N$ individuals are sorted lexicographically by first minimizing the rank and then by maximizing the crowding distance. Ties are broken uniformly at random (u.a.r.). The first $N$ individuals from the sorted population are kept for the next iteration.\n\nAlgorithm 1 showcases the NSGA-II in a way suited toward our modification described in the following section.\n\nRuntime. The runtime of an algorithm optimizing a function $f$ is the (random) number of evaluations of $f$ until the objective values of the population cover the Pareto front of $f$ . We assume that the objective value of each individual is evaluated exactly once when it is created. Thus, the NSGA-II uses $N$ function evaluations when initializing the population, and $N$ function evaluations per iteration for the offspring population. As the number of function evaluations is essentially $N$ times the number of iterations, we use the term runtime interchangeably for both quantities and always specify which one we mean. We state our runtime results in big-O notation with asymptotics in the problem size $n$ .\n\nOffspring generation. Given a parent population $P$ , the NSGA-II creates $N$ offspring by repeating the following standard bit mutation $N$ times: Choose an individual $x \\in$ $P \\subseteq \\{ 0 , 1 \\} ^ { n }$ uniformly at random, and create a copy $y$ of $x$ where one flips each component of $x$ independently with probability $1 / n$ . That is, for all $i \\in [ n ]$ , we have $y _ { i } = 1 - x _ { i }$ with independent probability $1 / n$ , and $y _ { i } = x _ { i }$ otherwise.\n\nNon-dominated ranks. Given a population $R$ , the rank of each $x \\in R$ is defined inductively and roughly represents how many layers in $R$ dominate $x$ . Individuals in $R$ that are not strictly dominated by any individual in $R$ receive rank 1. The population of all such individuals is denoted as $F _ { 1 } : =$ $\\{ x \\in { \\bar { R ^ { \\cdot } } } | \\forall y \\in R \\colon x \\not \\prec y \\}$ . The population of all individuals of rank $j \\in \\mathbb { N } _ { \\geq 2 }$ is the population of all individuals in $R$ , after removing all individuals of ranks 1 to $j - 1$ , that are not strictly dominated. That is, $F _ { j } : = \\{ x \\in R \\backslash \\bigcup _ { k \\in [ j - 1 ] } F _ { k } \\mid$ $\\begin{array} { r } { \\forall y \\in R \\setminus \\bigcup _ { k \\in [ j - 1 ] } \\colon x \\not \\prec y \\} } \\end{array}$ . If there are in total $r \\in  { \\mathbb { N } } _ { \\geq 1 }$ different ranks of $R$ , then $( F _ { j } ) _ { j \\in [ r ] }$ is a partition of $R$ .\n\nGiven such a partition of $R$ , we say that a rank $j ^ { * } \\in [ r ]$ is critical if and only if $j ^ { \\ast }$ is the minimal index such that the population of all individuals up to rank $j ^ { * }$ is at least $N$ . That is, $\\begin{array} { r } { | \\bigcup _ { j \\in [ j ^ { * } - 1 ] } F _ { j } | < N } \\end{array}$ and $| \\cup _ { j \\in [ j ^ { * } ] } F _ { j } | \\geq N$ . Individuals with a rank strictly smaller than $j ^ { * }$ are definitely selected for the next iteration, and individuals with a strictly larger rank than $j ^ { * }$ are definitely not selected. Among individuals with a rank of exactly $j ^ { * }$ , some individuals may be selected and some not, thus requiring further means to make a choice.\n\nCrowding distance. Given a population $F$ , the crowding distance (CD) of each $x \\in F$ , denoted by $\\operatorname { c D i s } ( x )$ , is the sum of the CD of $x$ per objective. The CD of $x$ for objective $j \\in [ m ]$ is as follows: Let $a = | { \\cal F } |$ , and let $( S _ { j . i } ) _ { i \\in [ a ] }$ denote $F$ sorted by increasing value in objective $j$ , breaking ties arbitrarily. The CD of $S _ { j . 1 }$ and of $S _ { j . a }$ for objective $j$ is infinity. For all $i \\in [ 2 . . a - 1 ]$ , the CD of $S _ { j . i }$ for objective $j$ is $\\left( f ( S _ { j . i + 1 } ) - f ( S _ { j . i - 1 } ) \\right) / \\left( f ( S _ { j . N } ) - f ( S _ { j . 1 } ) \\right)$ .\n\nLet $d \\in [ | F | ]$ , and let $( C _ { c } ) _ { c \\in [ k ] }$ be a partition of $F$ such that for all $c \\in [ k ]$ , all individuals in $C _ { c }$ have the same CD and that for all $\\bar { c _ { 1 } } , c _ { 2 } \\in [ k ]$ with $c _ { 1 } < c _ { 2 }$ , the CD of $C _ { c _ { 1 } }$ is strictly larger than that of $C _ { c _ { 2 } }$ . We say $c ^ { * } \\in [ k ]$ is the critical $C D$ index of $( C _ { c } ) _ { c \\in [ k ] }$ with respect to $d$ if and only if $\\textstyle | \\bigcup _ { c \\in [ c ^ { * } - 1 ] } C _ { c } | < d$ and $| \\textstyle \\bigcup _ { c \\in [ c ^ { * } ] } C _ { c } | \\geq d$ . When selecting $d$ individuals from $F$ , individuals with a CD in a population of index less than $c ^ { * }$ are definitely selected, and those with\n\nAlgorithm 1: The (classic) non-dominated sorting   \n\n<html><body><table><tr><td>geneticalgorithmII(NSGA-Il)withpopulation size N ∈ N≥1, optimizing an m-objective function.</td></tr><tr><td>1 Po ←population of Nindividuals,each u.a.r.;</td></tr><tr><td>2 t←0; 3 while termination criterion not met do</td></tr><tr><td>4 Qt←offspring population of Pt;</td></tr><tr><td>5 Rt←PtUQt;</td></tr><tr><td>6 (Fj) j∈[r] ← partition of Rt W.r.t. non-dom. ranks;</td></tr><tr><td>7 j*←critical rank of (Fj)j∈[r];</td></tr><tr><td>8 (Cc)c∈[k] ← partition of Fj* w.r.t. crowd. dist.;</td></tr><tr><td>9 c* ← critical crowding distance index of</td></tr><tr><td>(Cc)c∈[k] W.r.t. N-1Uj∈[j*-1] Fjl; 10 s ← N-1Uj∈[j*-1]FjUUc∈[c*-1]Cel;</td></tr><tr><td>11 W ← sub-pop. of Cc* of cardinality s, u.a.r.;</td></tr><tr><td>12 Pt+1 ←Uj∈[j*-1]FjUUce[e*-1]CcUW; t←t+1;</td></tr></table></body></html>\n\na CD of a population with a strictly larger index are not.   \nFrom $C _ { c ^ { * } }$ , some individuals may be selected and some not.\n\n# Benchmarks\n\nWe consider the three most common functions for the theoretical analysis of multi-objective search heuristics (see Previous Works). We define here their bi-objective versions, which are the most common ones, and build on these definitions later when defining the many-objective analogs.\n\nThe ONEMINMAX (OMM) benchmark (Giel and Lehre 2010) returns the number of 0s and 1s of each individual, formally, OMM : $x \\mapsto ( | x | _ { 0 } , | x | _ { 1 } )$ . Each individual is Pareto-optimal. The Pareto front is $\\{ ( i , n - i ) \\mid i \\in [ 0 . . n ] \\}$ .\n\nThe ONEJUMPZEROJUMP (OJZJ) benchmark (Doerr and Zheng 2021) extends the classic JUMP benchmark (Droste, Jansen, and Wegener 2002) to several objectives. It is defined similarly as OMM but has an additional parameter $k \\in [ 2 . . n ]$ . It is effectively identical to OMM for all individuals whose number of 1s is between $k$ and $n - k$ or is 0 or $n$ . The objective values of these individuals constitute the Pareto front of the function. For all other individuals, the objective value is strictly worse. Hence, once an algorithm finds solutions with $k$ or $n - k$ 1s, it needs to change at least $k$ positions at once in a solution in order to expand the Pareto front, which is usually a hard task. Formally, for all $i \\in \\{ 0 , 1 \\}$ and all $x \\in \\{ 0 , 1 \\} ^ { \\dot { n } }$ , let\n\n$$\nJ ^ { ( i ) } ( x ) = { \\left\\{ \\begin{array} { l l } { k + | x | _ { i } \\quad { \\mathrm { i f ~ } } | x | _ { i } \\in [ 0 . . n - k ] \\cup \\{ n \\} , } \\\\ { n - | x | _ { i } \\quad { \\mathrm { e l s e } } . } \\end{array} \\right. }\n$$\n\nThen $\\mathrm { O J Z J } ( x ) = ( J ^ { ( 1 ) } ( x ) , J ^ { ( 0 ) } ( x ) )$ , with the Pareto front $\\{ ( i , n + 2 k - i ) \\mid i \\in [ 2 k . . n ] \\cup \\{ k , n + k \\} \\}$ .\n\nThe LEADINGONESTRAILINGZEROS (LOTZ) benchmark (Laumanns, Thiele, and Zitzler 2004), a multiobjective version of LEADINGONES (Rudolph 1997), returns the length of the longest prefix of 1s and suffix of 0s, formally\n\n$$\n\\begin{array} { r } { x \\mapsto \\big ( \\sum _ { i \\in [ n ] } \\prod _ { j \\in [ i ] } x _ { j } , \\sum _ { i \\in [ n ] } \\prod _ { j \\in [ i . . n ] } ( 1 - x _ { j } ) \\big ) . } \\end{array}\n$$\n\nThe Pareto front is the same as that of OMM, but the Pareto set is $\\{ 1 ^ { i } 0 ^ { n - i } \\mid i \\in [ 0 . . n ] \\}$ .\n\n# Improved Tie-Breaking for the NSGA-II\n\nThe NSGA-II selects individuals elaborately; first via the non-dominated ranks, second via the crowding distance, and last uniformly at random. While the final tie-breaker seems reasonable, it neglects the structure of the population.\n\nIn more detail, since the uniform selection is performed over the subpopulation $C _ { c ^ { * } }$ from line 11 in Algorithm 1, any imbalances with respect to different objective values are carried over in expectation to the selected population $W$ . That is, if most of the individuals from $C _ { c ^ { * } }$ have objective value $\\boldsymbol { v } _ { 1 } \\in \\mathbb { R } ^ { m }$ and only very few have objective value $\\boldsymbol { v } _ { 2 } \\in \\mathbb { R } ^ { m }$ , then it is more likely for individuals with objective value $v _ { 1 }$ to be selected although individuals with objective value $v _ { 2 }$ might also have interesting properties. To circumvent this problem, we propose to select the individuals from $C _ { c ^ { * } }$ as evenly as possible from all the different objective values.\n\nBalanced tie-breaking. We replace line 11 in Algorithm 1 with the following procedure, using the same notation as in the pseudo code: Partition $C _ { c ^ { * } }$ with respect to its objective values into $( C _ { c } ^ { \\prime } ) _ { c \\in [ a ] }$ , assuming $a$ different objective values in $C _ { c ^ { * } }$ . That is, for $U : = \\{ f ( x ) \\mid x \\in C _ { c ^ { * } } \\}$ (being a set without duplicates) and for each $u \\in U$ , there is exactly one $c \\in [ a ]$ with $C _ { c } ^ { \\prime } \\ = \\ \\{ x \\ \\in \\ C _ { c ^ { * } }$ $f ( x ) \\ = \\ u \\}$ (where $C _ { c } ^ { \\prime }$ is a multi-set). For each $c \\in [ a ]$ , select $\\operatorname* { m i n } \\ ( | C _ { c } ^ { \\prime } | , \\lfloor s / a \\rfloor )$ individuals uniformly at random from $C _ { c } ^ { \\prime }$ , calling this selected population $\\widetilde { C } _ { c }$ . That is, $\\widetilde { C } _ { c } \\subseteq C _ { c } ^ { \\prime }$ with $| \\widetilde { C } _ { c } | \\ =$ $\\operatorname* { m i n } ( | \\bar { C ^ { \\prime } } _ { c } | , \\bar { \\lfloor } s / a \\rfloor )$ , ehosen unifo mely at random amoeng all sub-multi-sets of $C _ { c } ^ { \\prime }$ of cardinality $\\operatorname* { m i n } ( | C _ { c } ^ { \\prime } | , \\lfloor s / a \\rfloor )$ . Add all individuals in $\\textstyle \\bigcup _ { c \\in [ a ] } { \\widetilde { C } } _ { c }$ to $W$ . If this does not select sufficiently many individual ,ethat is, if $| \\cup _ { c \\in [ a ] } \\widetilde { C } _ { c } | < s$ , then select the missing number of individu als uni oermly at random from the remaining population, that is, from $C _ { c ^ { * } } \\backslash \\cup _ { c \\in [ a ] } \\widetilde { C } _ { c }$ .\n\nSince this tie-breaking aims at balancing the amoun eof individuals per objective value during the third tie-breaker, we call the modified algorithm the balanced NSGA-II.\n\nAdditional cost. Based on our experiments in the empirical section, we observed that balanced tie-breaking is slower than random tie-breaking in terms of wall clock time by a factor of around 10 on average. However, the total time spent on balanced tie-breaking is still, on average, only $1 5 \\%$ of the total time spent on non-dominated sorting, which is always required during selection. Moreover, as we detail in our empirical evaluation, the overall number of function evaluations (and thus wall clock time) of the balanced NSGA-II is typically far faster than that of the classic NSGA-II.\n\n# Properties of the Balanced NSGA-II\n\nFor the classic NSGA-II, if the population size $N$ is large enough w.r.t. the Pareto front of the objective function, no value on the Pareto front is lost. We prove that this same useful property also holds for the balanced NSGA-II.\n\nThe following lemma proves an upper bound on the number of individuals with positive crowding distance among those with critical rank. The lemma is adapted from an argument in the proof of Lemma 1 by Zheng et al. (2022).\n\nLemma 1. Consider the balanced NSGA-II optimizing an $m$ -objective function $f$ . For each iteration $t \\in \\mathbb { N }$ we have that for each objective value in the critical rank $A \\in f ( F _ { i ^ { * } } )$ there exist at most 2m individuals $x \\ \\in \\ F _ { i ^ { * } } \\ \\subseteq \\ R _ { t }$ with $f ( x ) = A$ such that $\\operatorname { c D i s } ( x ) > 0$ .\n\nLemma 1 yields that in the balanced NSGA-II there is always a fair number of individuals with critical rank.\n\nLemma 2. Consider the balanced NSGA-II optimizing an $m$ -objective function. Assume that at some iteration $\\textit { t } \\in  { \\mathbb { N } }$ we select $\\textbf { \\textit { C } } \\in \\textbf { \\textit { N } }$ individuals from the critical rank $F _ { i ^ { * } } \\subseteq R _ { t }$ with size of the objective values set $| f ( F _ { i ^ { * } } ) | = S$ . Then, for any $A \\in f ( F _ { i ^ { * } } )$ we keep at least $\\operatorname* { m i n } \\bigl ( \\operatorname* { m a x } ( \\lfloor \\frac { C } { S } \\rfloor - 2 m , 0 ) , | \\{ x \\in F _ { i ^ { * } } | f ( x ) = A \\}$ | individuals with $f ( x ) = A$ in $P _ { t + 1 }$ .\n\n# The Balanced NSGA-II Is Efficient For Three or More Objectives\n\nWe analyze the performance of the balanced NSGA-II on OMM, LOTZ, and OJZJ with three or more objectives. We show that the balanced NSGA-II optimizes these benchmarks in polynomial time when the number $m$ of objectives (and the gap parameter of OJZJ) is constant (Theorem 3). This result stands in strong contrast to the performance of the classic NSGA-II. Recently, Zheng and Doerr (2024b) proved that the classic NSGA-II with any population size linear in the Pareto front size cannot optimize OMM with $m \\geq 3$ objectives faster than in time $\\exp ( \\Omega ( n ^ { \\lceil m / 2 \\rceil } ) )$ . Their proofs suggest that the classic NSGA-II has similar difficulties on many other many-objective problems (i.e., three or more objectives), including LOTZ and OJZJ.\n\nWe briefly state the definitions of the $m$ -objective versions of OMM, LOTZ, and OJZJ from (Zheng and Doerr 2024b; Laumanns, Thiele, and Zitzler 2004; Zheng and Doerr 2024c) (precise definitions in the full version). All three lift the definition of the two-objective problem to an even number $m$ of objectives by splitting the bit string into $m / 2$ equal-length segments and then taking as $2 i - 1$ -st and $2 i$ -th objective the original function applied to the $i$ -th block.\n\nWe review the (few) main existing runtime result for these benchmarks. In the first mathematical runtime analysis for a many-objective problem, Laumanns et al. (2004) showed that the SEMO algorithm optimizes the COCZ and LOTZ problems in an expected number of $O ( n ^ { m + 1 } )$ function evaluations. COCZ is similar to OMM, so it is quite clear that the relevant part of their proof also applies to OMM, giving again an $O ( n ^ { m + 1 } )$ bound. Also, it is easy to see that their analysis can be extended to the GSEMO, giving the same runtime guarantees. The bounds for COCZ were improved slightly to $O ( n ^ { m } )$ , and $O ( n ^ { 3 } \\log { n } )$ for $m \\ = \\ 4$ , by Bian et al. (2018). Huang et al. (2021) analyzed how the MOEA/D optimizes COCZ and LOTZ. We skip the details since the MOEA/D is very different from all other algorithms discussed in this work. Wietheger and Doerr (2023) proved a runtime guarantee of $O ( N n \\log n )$ for the NSGA-III optimizing the 3-objective OMM problem when the population size is at least the size of the Pareto front. The only many-objective results for $\\mathrm { O J Z J } _ { k }$ are an $O ( M ^ { 2 } n ^ { k } )$ bound for the GSEMO and an $O ( \\mu M n ^ { k } )$ bound for the SMS-EMOA with population size $\\mu \\geq M$ , where $M$ is the size of the Pareto front, see (Zheng and Doerr 2024c). Note that as the runtimes of many-objective problems are not too well understood, and in the absence of any reasonable lower bound, there is a high risk that the results above are far from tight.\n\nBefore we state our main result of this section, we note that our main goal is to show the drastic difference to the behavior of the classic NSGA-II exhibited by Zheng and Doerr (2024b). We do not optimize our runtime estimates with more elaborate methods but are content with polynomialtime bounds for constant $m$ and $k$ and population sizes linear in the Pareto front size. Near-tight bounds for manyobjective evolutionary optimization of our benchmarks were recently proven in (Wietheger and Doerr 2024). For the same reason, we also do not prove bounds that do not show an increase of the runtime with growing population size in certain ranges (as we do for two objectives), though clearly this would be possible with similar arguments.\n\nTheorem 3. Let $\\textit { m } \\in \\mathrm { ~ N ~ }$ be even and $m ^ { \\prime } = m / 2$ . Assume that $n ^ { \\prime } = n / m ^ { \\prime } \\in \\mathbb { Z } .$ . Let $k \\in [ 2 . . n ^ { \\prime } / 2 ]$ . Consider the OMM, LOTZ, or $\\mathrm { O J Z J } _ { k }$ problem. Denote by $M$ the size of the Pareto front and by $S$ the size of a largest set of pairwise incomparable solutions. Assume that we optimize these problems via the balanced NSGA-II with population size $N \\geq S + 2 m ( n ^ { \\prime } + 1 ) = S + 4 n + 2 m$ . Then we have the following bounds for the expected runtime:\n\n1. For OMM, it is at most 2enM iterations.   \n2. For LOTZ, it is at most $2 e n M + 2 e n ^ { 2 }$ iterations.   \n3. For $\\mathrm { O J Z J } _ { k }$ , it is at most $2 e n ^ { k } M + 2 e k m ^ { \\prime } n$ iterations.\n\nAs many runtime analyses, our bounds depend on the size $S$ of the largest incomparable set of solutions the problem admits. For this, the following bounds are known or can easily be found: For OMM, we have $S = M = ( n ^ { \\prime } + 1 ) ^ { m / 2 }$ , for LOTZ, we have $S \\leq ( n ^ { \\prime } + 1 ) ^ { m - 1 }$ (Opris et al. 2024), and for OJZJ, we have $S \\le ( n ^ { \\prime } + 1 ) ^ { m / 2 }$ .\n\nThe reason for the drastically different behavior of the classic and the balanced NSGA-II is that the former can lose Pareto optimal solution values with any population size that is linear in the size of the Pareto front. In contrast, for the balanced NSGA-II often a population size exceeding the Pareto front size only by a lower-order term suffices to prevent such a loss of objective values. This follows easily from arguments similar to those used to prove Lemma 2. For the convenience of this and possible future works, we formulate and prove this crucial statement as a separate lemma.\n\nLemma 4. Consider the balanced NSGA-II with population size $N$ optimizing some m-objective optimization problem. Assume that $S$ is an upper bound on the size of any set of pair-wise incomparable solutions. Assume that $U$ is an upper bound on the number of individuals with positive crowding distance in a set of solutions such that any two are incomparable or have identical objective values. If $N \\geq S + U$ , then the following survival property holds.\n\nAssume that at some time t the combined parent and offspring population $R _ { t }$ contains a solution x that is contained in the first front $F _ { 1 }$ of the non-dominated sorting of $R _ { t }$ . Then its objective value survives into the next generation, i.e., surely, $P _ { t + 1 }$ contains an individual y such that $f ( y ) = f ( x )$ .\n\nThe results above show that the balanced NSGA-II does not have the efficiency problems of the classic NSGA-II for even numbers $m \\geq 4$ of objectives. Since Zheng and Doerr (2024b) show that already the case $m = 3$ is problematic for the classic NSGA-II, we show that the balanced NSGA-II optimizes OMM for three objectives also efficiently. The first objective counts the number of zeros in the argument $x \\in \\{ 0 , 1 \\} ^ { n }$ ; the second and third objectives count the numbers of ones in the first and second half of $x$ , resp.\n\nTheorem 5. Consider optimizing the 3-objective OMM problem via the balanced NSGA-II with population size $\\begin{array} { r } { \\overline { { N } } \\geq ( \\frac { n } { 2 } + 1 ) ^ { 2 } + 4 n + 6 . } \\end{array}$ . Then after an expected number of at most $2 e n ( \\textstyle { \\frac { n } { 2 } } + 1 ) ^ { 2 }$ iterations, the Pareto front is found.\n\n# Runtime Analysis on Bi-Objective OMM\n\nWe bound the expected runtime of the balanced NSGA-II on OMM by $O ( n + \\frac { \\overline { { n } } ^ { 2 } \\log n } { N } )$ iterations, hence $O ( N n + n ^ { 2 } \\log n )$ function evaluations, when the population size at least four times the Pareto front size (Corollary 9). This bound is $O ( n ^ { 2 } \\log { n } )$ function evaluations when $N = O ( n \\log n )$ .\n\nTo put this result into perspective, we note that the classic NSGA-II, again for $N \\geq 4 ( n + 1 )$ , satisfies the guarantee of $O ( n \\log n )$ iterations, that is, $O ( N n \\log n )$ function evaluations (Zheng and Doerr 2023). This bound is asymptotically tight for all $N ~ \\leq ~ n ^ { 2 - \\varepsilon }$ , $\\varepsilon > 0$ any constant (Doerr and $ { \\mathrm { Q u } } 2  { 0 2 3  { \\mathrm { b } } } )$ ). Hence the classic NSGA-II obtains a $\\Theta ( n ^ { 2 } \\log n )$ runtime (function evaluations) only with the smallest admissible population size of $\\Theta ( n )$ . Recently, a bound of $O ( N n \\log n )$ function evaluations was also proven for the SPEA2 (Ren et al. 2024a). For completeness, we note that the simplistic SEMO algorithm finds the full Pareto front of OMM in $O ( n ^ { 2 } \\log { n } )$ iterations and function evaluations (Giel and Lehre 2010). This result can easily be extended to the GSEMO algorithm. A matching lower bound of $\\Omega ( n ^ { 2 } \\log n )$ was shown for the SEMO in (Covantes Osuna et al. 2020) and for the GSEMO in (Bossek and Sudholt 2024). An upper bound of $O ( \\mu n \\log n )$ function evaluations was shown for the hypervolume-based $( \\mu + 1 )$ SIBEA with $\\mu \\geq n + 1$ (Nguyen, Sutton, and Neumann 2015).\n\nAs all individuals are Pareto-optimal for OMM, the runtime follows from how fast the algorithm spreads its population on the Pareto front. We bound this time by considering the extremities of the currently covered Pareto front, i.e., the individuals with the largest number of 1s or of 0s. Those are turned into individuals with one more 1 or 0, respectively, within about $n$ iterations in expectation, requiring only a single bit flip. The balance property of the algorithm guarat about $\\textstyle { \\frac { N } { n + 1 } }$ (Lemma 6). This number is quickly reached\n\nWe also prove a general result that bounds the expected time to cover certain parts of the Pareto front (Theorem 8).\n\nWe use Lemma 1 from Zheng, Liu, and Doerr (2022), which also applies to the balanced NSGA-II, as it does not impose any restrictions on how to choose from individuals with the same CD. The lemma states that a Pareto-optimal objective value in the population is never lost.\n\nThe following lemma is a direct application of Lemma 2. It shows that the population maintains all individuals per objective value it found so far, up to a bound of $\\textstyle { \\big \\lfloor } { \\frac { N } { n + 1 } } { \\big \\rfloor } - 4$ .\n\nLemma 6. Consider the balanced NSGA-II with population size $N \\geq 4 ( n + 1 )$ on OMM. Then, for each objective value $( k , n - k )$ with $k \\in [ 0 . . n ]$ , from the individuals $x$ in $R _ { t }$ with $f ( x ) = ( k , n - k )$ , the population $P _ { t + 1 }$ contains at least $\\operatorname* { m i n } ( \\lfloor { \\frac { N } { n + 1 } } \\rfloor - 4 , | \\{ x \\in R _ { t } \\mid f ( x ) = ( k , n - k ) \\} | )$ .\n\nLemma 6 shows that the population can maintain subpopulations of a size about nN+1 . Once such a size is reached, there is a decent chance to extend the Pareto front. The following lemma formalizes how quickly this happens.\n\nLemma 7. Consider the balanced NSGA-II with population size $N \\geq 4 ( n + 1 )$ on OMM. For $v \\in [ 1 . . n ]$ and $i \\in \\{ 1 , 2 \\}$ , let $T _ { v } ^ { i }$ denote the number of iterations needed, starting with an individual $x _ { 0 }$ in the parent population with $f _ { i } ( x _ { 0 } ) = v$ , to obtain an individual $x _ { f }$ in the resulting population such that $f _ { i } ( x _ { f } ) = v - 1 .$ . Then, $\\begin{array} { r } { E [ T _ { v } ^ { i } ] = O ( \\log \\left\\lceil \\frac { n } { v } \\right\\rceil + \\frac { n ^ { 2 } } { N v } + 1 ) } \\end{array}$ .\n\nWe prove Lemma 7 via the multiplicative up-drift theorem by Doerr and Ko¨tzing (2021, Theorem 3). This theorem provides a bound on the expected number of steps for a random process to grow to a certain number if it increases in every single step by a multiple of its expected value.\n\nUsing Lemma 7 lets us prove the following more general result of the bound for expanding the Pareto front. It shows how quickly the population expands on a symmetric portion of the Pareto front, centered around $n / 2$ .\n\nTheorem 8. Consider the balanced NSGA-II with population size $N \\geq 4 ( n + 1 )$ optimizing OMM. Let $\\alpha \\in$ $\\left[ 0 . . \\lfloor { \\frac { n } { 2 } } \\rfloor \\right]$ , and assume that there exists an $x \\in \\ P _ { 0 }$ with $| x | _ { 1 } \\in [ \\alpha , n - \\alpha ]$ . Then the expected number of iterations to cover $\\{ x \\in \\{ 0 , 1 \\} ^ { n } \\mid | x | _ { 1 } \\in [ \\alpha , n - \\alpha ] \\}$ is $\\begin{array} { r } { O ( n + \\frac { n ^ { 2 } \\log n } { N } ) } \\end{array}$ .\n\nFor $\\alpha = 0$ , since the Pareto front covers the entire population, we get the following runtime bound for OMM.\n\nCorollary 9. The expected runtime of balanced NSGA-II with population size $N \\geq 4 ( n + 1 )$ optimizing OMM is $\\begin{array} { r } { O ( n + \\frac { n ^ { 2 } \\log n } { N } ) } \\end{array}$ iterations, i.e., $O \\big ( n N + n ^ { 2 } \\log n \\big )$ expected function evaluations.\n\n# Runtime Analysis on Bi-Objective OJZJ\n\nWe analyze the runtime of the balanced NSGA-II on $\\mathrm { O J Z J } _ { k }$ with k = [2.. 2n ]. We show that this time is O(n + nkN ) iterations and thus $O ( N n + n ^ { k + 1 } )$ function evaluations when the population size is at least four times the size of the Pareto front (Theorem 13). This guarantee is $O ( n ^ { k + 1 } )$ function evaluations when $N = O ( n ^ { \\overline { { k } } } )$ , exhibiting a large parameter range with the asymptotically best runtime guarantee.\n\nPrevious results on the runtime of MOEAs on this benchmark include an $O ( n ^ { k + 1 } )$ iterations and function evaluations guarantee for the GSEMO and the result that the\n\nSEMO cannot optimize this benchmark (Doerr and Zheng 2021). An upper bound of $O ( n ^ { k } )$ iterations, hence $O ( N n ^ { k } )$ function evaluations, was shown for the classic NSGA-II with population size at least four times the size of the Pareto front (Doerr and $ { \\mathrm { Q u } } 2  { \\mathrm { 0 2 3 a } } )$ . The latter bound is tight apart from constant factors when $N = { o ( n ^ { 2 } / k ^ { 2 } ) }$ (Doerr and $\\mathrm { Q u }$ 2023b). The same bound $O ( N n ^ { k + 1 } )$ was recently proven for the SPEA2 (Ren et al. 2024a). For the SMS-EMOA with population size $\\mu \\geq n - 2 k + 3$ , the bounds of $O ( n ^ { k } )$ and $\\dot { \\Omega ( n ^ { k } / \\mu ) }$ iterations, hence $O ( \\mu n ^ { k } )$ and $\\Omega ( n ^ { k } )$ function evaluations, were shown by Bian et al. (2023). The authors also show that a stochastic population update reduces the runtime by a factor of order $\\operatorname* { m i n } \\{ 1 , \\mu / 2 ^ { \\bar { k } / 4 } \\}$ . (Ren et al. 2024b) show an expected runtime of $\\dot { O } ( N ^ { 2 } 4 ^ { \\acute { k } } + N n \\log n )$ for a modified version of the NSGA-II that reorders individuals by maximizing the Hamming distance and uses crossover.\n\nIn our analysis of the balanced NSGA-II, we follow the approach of Doerr and Qu (2023a), who analyzed how the classic NSGA-II optimizes this benchmark. This means we split the analysis into three stages. The first stage bounds the time to find a solution on the inner Pareto front. The second stage bounds the time to cover the inner Pareto front. The third stage bounds the time to cover the outer Pareto front, which consists of only two objective values. We show in the full version that once the algorithm enters a later stage, it does not return to an earlier one. Thus, we bound the expected number of iterations by separately analyzing each stage.\n\nFor stage 1, we find that with very high probability at least one of the initial individuals is on the inner Pareto front. This leads, in expectation, to a constant length of this stage.\n\nLemma 10. Regardless of the population size $N$ and of the initial population, for all $k \\in [ 2 . . n / 2 ]$ , stage 1 needs an expected number of at most $\\textstyle { \\frac { e } { N } } k ^ { k } + 1$ iterations.\n\nFor stage 2, as $\\mathrm { O J Z J } _ { k }$ and OMM are similar, we apply Theorem 8 with $\\alpha = k$ , resulting in the following lemma.\n\nLemma 11. Using population size $N \\geq 4 ( n - 2 k + 3 ) $ , stage 2 needs in expectation $\\begin{array} { r } { O ( n + \\frac { n ^ { 2 } \\log n } { N } ) } \\end{array}$ iterations.\n\nFor stage 3, the arguments follow those for Lemma 7, but now with a jump of $k$ bits instead of 1.\n\nLemma 12. Using $N \\geq 4 ( n - 2 k + 3 )$ , stage 3 needs in expectation $\\begin{array} { r } { O ( \\log { \\frac { N } { n } } ) + 2 + \\frac { 8 e n ^ { k } ( n + 1 ) } { N } } \\end{array}$ iterations.\n\nCombining the results for all three stages, we obtain the following runtime guarantee.\n\nTheorem 13. The expected runtime of the balanced NSGA-II with population size $N \\geq 4 ( n - 2 k + 3 )$ on $\\mathrm { O J Z J } _ { k }$ with $k \\in [ 2 . . \\frac { n } { 2 } ]$ is $O ( n + n ^ { k + 1 } / \\dot { N } )$ iterations, i.e., $O ( N n + n ^ { k + 1 } )$ expected function evaluations.\n\n# Runtime Analysis on Bi-Objective LOTZ\n\nWe bound the expected runtime of the balanced NSGA-II on LOTZ by $\\begin{array} { r } { O ( \\frac { \\overline { { n } } ^ { 3 } } { N } + n \\log \\frac { N } { n + 1 } ) } \\end{array}$ iterations, i.e., $O ( n ^ { 3 } +$ $\\begin{array} { r } { N n \\log { \\frac { N } { n + 1 } } ) } \\end{array}$ ) function evaluations, when the population size bound is $O ( n ^ { 3 } )$ function evaluations for $\\begin{array} { r } { N = O ( \\frac { n ^ { 2 } } { \\log n } ) } \\end{array}$ .\n\nThe following runtime results are known for LOTZ. The SEMO takes $\\Theta ( n ^ { 3 } )$ iterations and function evaluations (Laumanns, Thiele, and Zitzler 2004). For the GSEMO, Giel (2003) showed an upper bound of $\\overset { \\cdot } { O } ( n ^ { 3 } )$ iterations and evaluations, a matching lower bound was proven only for unrealistically small mutation rates (Doerr, Kodric, and Voigt 2013). An upper bound of $O ( \\mu n ^ { 2 } )$ iterations and function evaluations was shown for the $( \\mu + 1 )$ SIBEA with population size $\\mu \\geq n + 1$ (Brockhoff, Friedrich, and Neumann 2008). The classic NSGA-II with population size at least $4 ( n + 1 )$ solves the LOTZ problem in ${ \\dot { O } } ( n ^ { 2 } )$ iterations and thus $O ( \\dot { N } n ^ { 2 } )$ function evaluations. The same bound was recently proven for the SPEA2 (Ren et al. 2024a). For the SMS-EMOA with population size $\\mu \\geq n + 1$ , a runtime guarantee of $O ( \\mu n ^ { 2 } )$ iterations and function evaluations was given by Zheng and Doerr (2024c).\n\nOur analysis considers two phases. The first phase bounds the time until the current population contains the all-1s bit string, which is Pareto-optimal. The second phase bounds the remaining time until the entire Pareto front is covered. Both phases take about the same time in expectation.\n\nDuring the first phase, we consider individuals with an increasing prefix of 1s. In the second phase, we consider individuals with an increasing suffix of 0s. Each such improvement denotes a segment. Each segment consists of the following two steps: (1) We bound the time until the population contains about nN+1 individuals that can easily be turned into improving offspring. This step takes $\\begin{array} { r } { O ( \\log { \\frac { N } { n + 1 } } ) } \\end{array}$ in expectation (Lemma 14). (2) We bound the time to create an improving offspring by $\\scriptstyle O ( { \\frac { n ^ { 2 } } { N } } )$ in expectation. Theorem 15 then follows since there are at most $n$ segments per phase.\n\nLemma 14. Consider the balanced NSGA-II with population size $N \\geq 4 ( n + 1 )$ optimizing the $\\operatorname { L O T Z } = : f$ function. Let $t _ { 0 }$ be any iteration. Furthermore, for all $t \\in N$ , let $v = \\operatorname* { m a x } _ { y \\in R _ { t _ { 0 } + t } } f _ { 1 } ( y )$ and $Y _ { t } = \\{ y \\in R _ { t _ { 0 } + t } \\ | \\ f _ { 1 } ( y ) = v \\}$ . Last, let $T$ denote the first iteration $t \\in \\mathbb { N }$ such that $| Y _ { t } | \\geq$ $\\operatorname* { m a x } ( 1 , \\lfloor { \\frac { N } { n + 1 } } \\rfloor - 4 ) = : B$ or such that there is a $z \\in R _ { t + t _ { 0 } }$ with $f _ { 1 } ( z ) > v$ . Then $E [ T \\mid t _ { 0 } ] = O ( \\log B )$ .\n\nThe same statement holds when exchanging $f _ { 1 }$ by $f _ { 2 }$ .\n\nLemma 14 is sufficient to prove our main result.\n\nTheorem 15. The expected runtime of the balanced NSGA$\\boldsymbol { { I I } }$ with $N \\geq 4 ( n + 1 )$ on LOTZ is $\\begin{array} { r } { O \\big ( \\frac { n ^ { 3 } } { N } + n \\log \\frac { N } { n + 1 } \\big ) } \\end{array}$ iterations, i.e., $\\begin{array} { r } { O ( n ^ { 3 } + N n \\log \\frac { N } { n + 1 } ) } \\end{array}$ ) function evaluations.\n\n# Empirical Runtime Analysis\n\nWe complement our theoretical results with experiments, aiming to see how much the population size of the NSGA-II actually influences the number of function evaluations. Our code is publicly available (Doerr, Ivan, and Krejca 2024b).\n\nWe run the classic and the balanced NSGA-II on OMM, for problem sizes $n ~ \\in ~ 1 0 \\cdot [ 3 . . 1 2 ]$ and three population sizes $N$ . For each combination of $n$ and $N$ per algorithm, we start 50 independent runs and log the number of function evaluations until the Pareto front is covered for the first time. Let $M = n + 1$ denote the size of the Pareto front. We consider the choices $N \\in \\{ 2 M , 4 M , 8 M , 1 6 M \\}$ , noting that our theoretical result holds for all $N \\geq 4 M$ (Corollary 9).\n\n![](images/14c0fea7d5193d014f30c30b5c8be771caf3f8d9fe22eebe73c44f0b400587e2.jpg)  \nFigure 1: The average number of function evaluations of the classic (dashed lines) and the balanced (solid lines) NSGA-II optimizing ONEMINMAX, for the shown population sizes $N$ and problem sizes $n$ . The value $M$ denotes the size of the Pareto front, i.e., $M = n + 1$ . Each point is the average of 50 independent runs.\n\nFigure 1 shows that the runtime increases for both algorithms for increasing $N$ . This additional cost is larger for the classic NSGA-II than for the balanced one, statistically significantly for $N \\in \\{ 8 M , 1 6 M \\}$ . Hence, not choosing the optimal population size for the classic NSGA-II is already for constant factors more penalized than for the balanced NSGA-II. For $N \\in \\{ 2 M , \\hat { 4 } M \\}$ , the runtime of the classic and the balanced NSGA-II is roughly the same. This shows that the classic NSGA-II still can perform very well for a careful choice of $N$ . If the optimal choice for $N$ is unknown, the balanced NSGA-II is a more robust choice.\n\nWe note that qualitatively very similar results hold for OJZJ and LOTZ (as shown in the full version). Moreover, we show in the full version that the balanced NSGA-II optimizes the 4-objective OMM problem quickly.\n\n# Conclusion\n\nWe propose and analyze a simple tie-breaking modification to the classic NSGA-II, aiming to distribute individuals more evenly among different objective values with the same non-dominated rank and crowding distance. Our theoretical results prove two major advantages of this modification: (1) It is capable of efficiently optimizing multi-objective functions with at least three objectives for which the classic NSGA-II has at least an exponential expected runtime. (2) Not choosing an optimal population size is far less important and leads for certain ranges to no asymptotic runtime loss. Our experiments show that this effect can be already very clear when choosing slightly sub-optimal population sizes.\n\nFor future work, it would be interesting to prove lower bounds for the bi-objective scenarios and to improve the bounds in the many-objective setting. Furthermore, we are optimistic that similar results could be obtained for other MOEAs that resort to random tie-breaking at some stage, for example, the NSGA-III (Deb and Jain 2014) and the SMSEMOA (Beume, Naujoks, and Emmerich 2007).\n\n# Acknowledgments\n\nThis research benefited from the support of the FMJH Program Gaspard Monge for optimization and operations research and their interactions with data science.",
    "institutions": [
        "Laboratoire d’Informatique (LIX)",
        "CNRS",
        "École Polytechnique",
        "Institut Polytechnique de Paris"
    ],
    "summary": "{\n    \"core_summary\": \"### 核心概要\\n\\n**问题定义**\\n非支配排序遗传算法II（NSGA - II）是最流行的多目标优化启发式算法，但在离散搜索空间中存在两个缺点：一是处理超过两个目标时存在困难，如在优化ONEMINMAX基准测试时，当目标数为三个及以上且种群规模与帕累托前沿大小呈线性关系时，运行时间有指数下界；二是对种群规模的选择非常敏感，所有已证明的运行时间保证都随种群规模线性增加。这些问题限制了NSGA - II在实际应用中的性能和效率，解决这些问题对于多目标优化领域具有重要意义。\\n\\n**方法概述**\\n论文提出在选择下一代种群时添加一个简单的平局决胜规则，即增加个体具有特定目标值的数量作为第三选择标准，优先选择具有更稀有目标值的个体，以解决NSGA - II存在的问题，该改进算法被称为平衡NSGA - II。\\n\\n**主要贡献与效果**\\n- **解决多目标优化难题**：证明修改后的平衡NSGA - II能在多项式时间内优化具有至少三个目标的ONEMINMAX、LEADINGONESTRAILINGZEROS和ONEJUMPZEROJUMP基准问题，而经典NSGA - II对ONEMINMAX三个及以上目标的优化运行时间至少为指数级。如对于OMM问题，平衡NSGA - II的期望运行时间最多为2enM次迭代；对于LOTZ最多需要$2 e n M + 2 e n ^ { 2 }$次迭代；对于$\\mathrm { O J Z J } _ { k }$最多需要$2 e n ^ { k } M + 2 e k m ^ { \\prime } n$次迭代。\\n- **降低种群大小敏感性**：对于双目标问题，在一定种群大小范围内，运行时间不受种群大小影响。如对于ONEJUMPZEROJUMP问题，当种群大小至少是帕累托前沿大小的四倍时，运行时间保证为$O ( \\max \\{ n ^ { k + 1 } , N n \\} )$函数评估，相比经典NSGA - II的$\\Theta ( N n ^ { k } )$运行时间有显著提升；对于ONEMINMAX问题，平衡NSGA - II种群大小至少为帕累托前沿大小四倍时，运行时间为$O ( n + \\frac { n ^ { 2 } \\log n } { N } )$迭代，即$O ( N n + n ^ { 2 } \\log n )$函数评估，当$N = O ( n \\log n )$时，运行时间为$O ( n ^ { 2 } \\log n )$函数评估；对于LOTZ问题，平衡NSGA - II种群大小$N \\geq 4 ( n + 1 )$时，运行时间为$O ( \\frac { n ^ { 3 } } { N } + n \\log \\frac { N } { n + 1 } )$迭代，即$O ( n ^ { 3 } + N n \\log \\frac { N } { n + 1 } )$函数评估。\\n- **减少参数优化需求**：实验表明，即使选择的种群大小与最优值仅相差一个常数因子，修改后的算法也能显著减少对算法参数$N$进行仔细优化的需求。\",\n    \"algorithm_details\": \"### 算法/方案详解\\n\\n**核心思想**\\n经典NSGA - II在选择个体时，最终的随机平局决胜规则忽略了种群结构，可能导致某些目标值的个体选择不均衡，某些目标值的个体被过度选择，而另一些目标值的个体被忽视。新的平局决胜规则旨在在第三轮平局决胜时平衡每个目标值的个体数量，使个体在不同目标值之间更均匀地分布，从而提高算法性能。\\n\\n**创新点**\\n先前的NSGA - II在处理多目标问题和种群大小选择方面存在不足，经典NSGA - II在处理多目标问题时存在对目标数量和种群规模敏感的问题。而平衡NSGA - II在经典NSGA - II的基础上，添加了一个简单的平局决胜规则，通过平衡不同目标值的个体数量，提高了算法在多目标优化中的效率和鲁棒性。类似的思想虽曾被提出，但未被广泛应用于NSGA - II。\\n\\n**具体实现步骤**\\n1. **初始化种群**：随机均匀选择$N$个个体初始化种群$P_0$。\\n2. **生成后代种群**：在每次迭代中，对每个父代个体进行标准位变异，生成$N$个后代个体，形成后代种群$Q_t$。\\n3. **合并种群**：将当前种群$P_t$和后代种群$Q_t$合并为一个大小为$2N$的合并种群$R_t$。\\n4. **非支配排序**：根据非支配排序将$R_t$划分为不同的等级$(F_j)_{j\\in[r]}$，确定临界等级$j^*$。\\n5. **计算拥挤距离**：对于临界等级$F_{j^*}$中的个体，根据拥挤距离进行划分，得到$(C_c)_{c\\in[k]}$，确定临界拥挤距离索引$c^*$。\\n6. **排序选择**：按非支配等级从小到大、拥挤距离从大到小对个体进行字典序排序。\\n7. **平局决胜**：在选择最终种群时，首先根据非支配等级和拥挤距离进行选择，对于仍有平局的情况，将临界等级中具有相同目标值的个体划分为不同的子集$(C_c')_{c\\in[a]}$，从每个子集中随机选择$\\min(|C_c'|, \\lfloor s / a \\rfloor)$个个体，若选择的个体数量不足，则从剩余个体中随机选择。\\n8. **更新种群**：选择前$N$个个体作为下一代种群$P_{t + 1}$。\\n\\n**案例解析**\\n论文通过对ONEMINMAX、LEADINGONESTRAILINGZEROS和ONEJUMPZEROJUMP这三个经典基准测试问题的分析，展示了平衡NSGA - II的性能。例如在多目标优化中，平衡NSGA - II能在多项式时间内优化这些问题，而经典NSGA - II在处理三个及以上目标的ONEMINMAX问题时至少需要指数时间。在双目标问题中，也体现出平衡NSGA - II在运行时间上的优势。\",\n    \"comparative_analysis\": \"### 对比实验分析\\n\\n**基线模型**\\n经典NSGA - II、SEMO、GSEMO、NSGA - III、SMS - EMOA、SPEA2、$( \\mu + 1 )$ SIBEA等。\\n\\n**性能对比**\\n*   **在多目标优化运行时间指标上**：对于三个及以上目标的OMM、LOTZ和$\\mathrm { O J Z J } _ { k }$问题，经典NSGA - II在优化OMM时至少需要指数时间，而平衡NSGA - II在满足一定种群规模条件下，对于OMM最多需要2enM次迭代，对于LOTZ最多需要$2 e n M + 2 e n ^ { 2 }$次迭代，对于$\\mathrm { O J Z J } _ { k }$最多需要$2 e n ^ { k } M + 2 e k m ^ { \\prime } n$次迭代，远优于经典NSGA - II。\\n*   **在双目标ONEMINMAX问题运行时间指标上**：平衡NSGA - II种群大小至少为帕累托前沿大小四倍时，运行时间为$O ( n + \\frac { n ^ { 2 } \\log n } { N } )$迭代，即$O ( N n + n ^ { 2 } \\log n )$函数评估；经典NSGA - II在相同条件下运行时间为$O ( n \\log n )$迭代，即$O ( N n \\log n )$函数评估。当$N = O ( n \\log n )$时，平衡NSGA - II的运行时间为$O ( n ^ { 2 } \\log n )$函数评估，与经典NSGA - II在最小允许种群大小时的运行时间相当。\\n*   **在双目标ONEJUMPZEROJUMP问题运行时间指标上**：当种群规模$N \\geq 4 ( n - 2 k + 3 )$时，平衡NSGA - II的期望运行时间为$O ( n + n ^ { k + 1 } / N )$次迭代，即$O ( N n + n ^ { k + 1 } )$次函数评估；经典NSGA - II的运行时间为$O ( n ^ { k } )$次迭代，即$O ( N n ^ { k } )$次函数评估。当$N = O ( n ^ { k } )$时，平衡NSGA - II的运行时间为$O ( n ^ { k + 1 } )$次函数评估，优于经典NSGA - II。\\n*   **在双目标LOTZ问题运行时间指标上**：平衡NSGA - II种群大小$N \\geq 4 ( n + 1 )$时，运行时间为$O ( \\frac { n ^ { 3 } } { N } + n \\log \\frac { N } { n + 1 } )$迭代，即$O ( n ^ { 3 } + N n \\log \\frac { N } { n + 1 } )$函数评估；经典NSGA - II种群大小至少为$4 ( n + 1 )$时，运行时间为$\\dot { O } ( n ^ { 2 } )$迭代，即$O ( \\dot { N } n ^ { 2 } )$函数评估。\",\n    \"keywords\": \"### 关键词\\n\\n- 多目标优化 (Multi - Objective Optimization, MOO)\\n- 非支配排序遗传算法II (Non - Dominated Sorting Genetic Algorithm II, NSGA - II)\\n- 平局决胜规则 (Tie - Breaking Rule, N/A)\\n- 平衡NSGA - II (Balanced NSGA - II, N/A)\\n- ONEMINMAX (ONEMINMAX, OMM)\\n- LEADINGONESTRAILINGZEROS (LEADINGONESTRAILINGZEROS, LOTZ)\\n- ONEJUMPZEROJUMP (ONEJUMPZEROJUMP, OJZJ)\"\n}"
}