{
    "link": "https://arxiv.org/abs/2405.18836",
    "pdf_link": "https://arxiv.org/pdf/2405.18836",
    "title": "Do Finetti: On Causal Effects for Exchangeable Data",
    "authors": [
        "Siyuan Guo",
        "Chi Zhang",
        "Karthika Mohan",
        "Ferenc Husz'ar",
        "Bernhard Schölkopf"
    ],
    "institutions": [
        "Max Planck Institute for Intelligent Systems",
        "Toyota Research Institute",
        "Oregon State University",
        "University of Cambridge Equal supervision"
    ],
    "publication_date": "2024-05-29",
    "venue": "Neural Information Processing Systems",
    "fields_of_study": [
        "Mathematics",
        "Computer Science"
    ],
    "citation_count": 5,
    "influential_citation_count": 0,
    "paper_content": "# Do Finetti: on Causal Effects for Exchangeable Data\n\nSiyuan Guo14 ∗ Chi Zhang2 Karthika Mohan3 Ferenc Huszár4† Bernhard Schölkopf1† 1Max Planck Institute for Intelligent Systems 2Toyota Research Institute 3 Oregon State University 4 University of Cambridge Equal supervision\n\n# Abstract\n\nWe study causal effect estimation in a setting where the data are not i.i.d. (independent and identically distributed). We focus on exchangeable data satisfying an assumption of independent causal mechanisms. Traditional causal effect estimation frameworks, e.g., relying on structural causal models and do-calculus, are typically limited to i.i.d. data and do not extend to more general exchangeable generative processes, which naturally arise in multi-environment data. To address this gap, we develop a generalized framework for exchangeable data and introduce a truncated factorization formula that facilitates both the identification and estimation of causal effects in our setting. To illustrate potential applications, we introduce a causal Pólya urn model and demonstrate how intervention propagates effects in exchangeable data settings. Finally, we develop an algorithm that performs simultaneous causal discovery and effect estimation given multi-environment data.\n\n# 1 Introduction\n\nInferring causal effects from observational data is a central task for scientific applications from health and epidemiology to the social and behavioral sciences. Scientists aim to understand Nature’s mechanisms to discover feasible intervention targets and estimate intervention effects. The existing causal effect estimation theory is often formulated for structural causal models [Pearl, 2009], focusing on the study of independent and identically distributed (i.i.d.) data. Indeed, the do-calculus [Pearl, 2012] and its extensions and applications (e.g., mediation analysis [Pearl, 2022], stochastic interventions [Correa and Bareinboim, 2020]) developed in the i.i.d. framework has been widely used in practice.\n\nA more recent line of work relaxes the i.i.d. assumption and considers causal inference under the assumption of independent causal mechanisms (ICM) [Schölkopf et al., 2012, Pearl, 2009, Guo et al., 2023a], which postulates that distinct causal mechanisms of the true underlying generating process do not inform or influence one another. The Causal de Finetti theorems of Guo et al. [2023a] provide a mathematical justification of the ICM assumption in exchangeable data-generation processes, thus establishing a foundation for studying causality in exchangeable data. Exchangeable data generation processes that adhere to the ICM principle are referred to as ICM generative processes, or ICM-exchangeable data.\n\nGuo et al. [2023a] showed that data from ICM generative processes, or more succinctly ICMexchangeable data, are more informative than i.i.d. data in that they often permit unique causal structure identification in cases where i.i.d. data does not. In contrast, the present work focuses on causal effect identification and estimation. Standard formalisms in the i.i.d. framework, e.g., using structural causal models and do-operators, do not apply in the exchangeable non-i.i.d. setting. We study the meaning of interventions, feasible intervention targets, and finally causal effect identification and estimation for ICM generative processes. In doing so, we make three contributions:\n\n![](images/20401498d68138049ca99f55afa275614fd6756c07217ef55713beb656677d07.jpg)  \nFigure 1: A bivariate illustration demonstrates differences in causal effect between i.i.d. processes and ICM-generative processes. Suppose ${ \\mathcal { G } } = X \\to Y$ . The hammer represents an intervention on the closest node. (a): Data generated according to $\\mathcal { G }$ under an i.i.d. process; (b): Data generated under an ICM-generative process (using plate notation). Block A shows how $P ( { Y } | d o ( { X } ) )$ differs between the i.i.d. (a) and the exchangeable (b) case. Note that the causal effect under i.i.d. is a special case of that under exchangeable processes with $p ( \\psi ) = \\delta ( \\psi = \\psi _ { 0 } )$ , for some value $\\psi _ { 0 }$ . Corollary 1 below justifies that we omit position indices from Block A in ICM-generative processes. Block $\\mathbf { B }$ shows the difference in intervention effect when conditioned on other observations, for i.i.d. (a) and ICM-generative (b) processes. In the i.i.d. case (a), due to $\\left( Y _ { 1 } , X _ { 1 } \\right) \\perp \\left( Y _ { 2 } , X _ { 2 } \\right)$ , conditioning on $( X _ { 2 } , Y _ { 2 } )$ conveys no information on the prediction of the interventional effect on $Y _ { 1 }$ . In contrast, for an ICM-generative process (b), observing $( X _ { 2 } , Y _ { 2 } )$ does provide additional information about the effect on $Y _ { 1 }$ when intervening on $X _ { 1 }$ . Graph (c) illustrates the graph surgery performed on $\\operatorname { I C M } ( { \\mathcal { G } } )$ (cf. Def. 7 in Appendix A). We observe that conditioning on a collider $Y _ { 2 }$ provides additional information about the effect on $Y _ { 1 }$ when intervening on $X _ { 1 }$ .\n\n• Causal effect in ICM generative processes (Section 3): We establish the operational meaning of interventions and the feasible intervention targets in ICM generative processes that differ from the traditional framework in i.i.d. data. • Our main causal effect identification and estimation theorem (Section 3.1) provides an explicit truncated factorization formula for ICM generative processes that solves the problems of identification and estimation of causal effects. In particular, we introduce a causal Pólya urn model (Section 3.2) and show that the post-interventional distribution changes when conditioning on other observations – a property that does not exist in i.i.d. data. • Causal effect estimation in multi-environment data (Section 4): we connect ICM processes with multi-environment data, showing that extending the causal framework to exchangeable data does not necessarily mean a decrease of its ability in graphical identification and effect estimation. Theorem 2, informally stated, shows that with no prior graphical assumptions, data adhering to the ICM principle and generated by an exchangeable process alone is sufficient for both graphical and effect identification. We developed a $D o$ -Finetti algorithm for multi-environment data, and empirically validate our results in Section 5.\n\nFig. 1 illustrates the main differences in causal effects between i.i.d. and ICM generative processes.\n\n# 2 Preliminaries\n\nNotation Denote $X$ as a random variable with realization $x$ with boldsymboled $\\mathbf { X }$ as a set of random variables with realizations $\\mathbf { x }$ . Data generated by either i.i.d. or ICM generative processes is a sequence of random variables $\\mathbf { X } _ { : ; 1 } , \\mathbf { X } _ { : ; 2 } , \\mathbf { X } _ { : ; 3 } , \\ldots .$ , where $\\mathbf { X } _ { : : n } : = ( X _ { 1 : n } , \\ldots \\bar { , } X _ { d : n } )$ and $d$ denotes the number of variable indices and $n$ denotes the position index within a sequence. For example, $X _ { i ; n }$ denotes the $i$ -th random variable observed at the $n$ -th position in a sequence. Often in this work, $N$ denotes the number of positions observed in a sequence and $[ N ] : = \\{ 1 , \\cdot \\cdot \\cdot , N \\}$ as the set of positive integers less than or equal to $N$ and $[ \\neg \\mathbf { S } ]$ denotes the set of positive integers less than equal to $N$ excluding values contained in S. To abbreviate notation, write $\\mathbf { X } _ { i ; [ N ] } : = ( X _ { i ; 1 } , \\ldots , X _ { i ; N } )$ . For simplicity of illustration, we use bivariate examples with $X _ { n } , Y _ { n }$ as a pair of random variables observed at the $n$ -th position. Putting the bivariate notation in the above multivariate context, $X _ { 1 ; n }$ corresponds to $X _ { n }$ and $X _ { 2 ; n }$ corresponds to $Y _ { n }$ where the first index indicates different variables in the same position. Denote uppercase $P$ for probability distribution and lowercase $p$ for probability density functions.\n\n# 2.1 The Causal Framework in i.i.d. Data\n\nStructural Causal Model [Peters et al., 2017, Pearl, 2009, Haavelmo et al., 1995, Wright, 1921] A structural causal model (SCM) ${ \\mathcal { M } } : = ( \\mathbf { F } , P _ { \\mathbf { U } } )$ consists of a set of structural assignments ${ \\bf { F } } : =$ $\\{ f _ { 1 } , \\ldots , f _ { d } \\}$ such that $X _ { j } : = f _ { j } ( \\mathbf { P A } _ { j } , U _ { j } ) , j = 1 , \\ldots , d ,$ where $\\mathbf { P A } _ { j } \\subseteq \\{ X _ { 1 } , \\ldots , X _ { d } \\} \\backslash \\{ X _ { j } \\}$ and are often called as parents of $X _ { j }$ . The joint distribution $P _ { \\mathbf { U } }$ over the noise or exogenous variables $\\mathbf { U }$ is assumed to be jointly independent. When such a condition is satisfied, the SCM is a Markovian model that assumes the absence of unmeasured confounders. A graph $\\mathcal { G }$ of an SCM is obtained by creating one vertex $X _ { j }$ and drawing directed edges from each parent in $\\mathbf { P A } _ { j }$ to $X _ { j }$ . We assume $\\mathcal { G }$ is acyclic. Our lack of knowledge in noise variables $P _ { \\mathbf { U } }$ and together with the structural assignments $\\mathbf { F }$ induces a joint distribution over the observable variables $P ( X _ { 1 } , \\ldots , X _ { d } )$ . Such joint distribution satisfies the Markov factorization property with respect to $\\mathcal { G }$ :\n\n$$\nP ( X _ { 1 } , \\ldots , X _ { d } ) = \\prod _ { i = 1 } ^ { d } P ( X _ { i } \\mid \\mathbf { P A } _ { i } ) ,\n$$\n\nGiven two disjoint sets of variables $\\mathbf { X }$ and $\\mathbf { Y }$ , the causal effect of $\\mathbf { X }$ on $\\mathbf { Y }$ , denoted as $P ( \\mathbf { Y } | d o ( \\mathbf { X } ) )$ , is defined with respect to modifications of an existing SCM (also known as graph surgery): for each realization $\\mathbf { x }$ of $\\mathbf { X }$ , $P ( \\mathbf { y } | d o ( \\mathbf { x } ) )$ gives the probability of $\\mathbf { Y } = \\mathbf { y }$ induced by deleting from the SCM all structural assignments corresponding to variables in $\\mathbf { X }$ and substituting $\\mathbf { X } = \\mathbf { x }$ in the remaining equations. In Markovian models, given a graph, causal effect is identifiable via Eq. (2):\n\n$$\nP ( X _ { 1 } , \\dots , X _ { d } | d o ( \\mathbf { X } = \\mathbf { x } ) ) = \\prod _ { i : X _ { i } \\notin \\mathbf { X } } P ( X _ { i } | \\mathbf { P A } _ { i } ) { \\big | } _ { \\mathbf { X } = \\mathbf { x } } ,\n$$\n\nwhere $\\lvert \\mathbf { x } { = } \\mathbf { x }$ enforces $X _ { 1 } , \\ldots , X _ { d }$ to be consistent with realizations of $\\mathbf { X }$ else Eq. (2) takes value 0. This principled approach is known as $g$ -computation formula [Robins, 1986], truncated factorization [Pearl, 2009] or manipulation theorem [Spirtes et al., 1993]. Appendix A details the standard graphical terminology.\n\nIndependent Causal Mechanism (ICM) postulates how Markov factors (hereon referred to as causal mechanisms) in Eq. (1) should relate to each other. Schölkopf et al. [2012] and Peters et al. [2017] express the insights as follows:\n\nCausal mechanisms are independent of each other in the sense that a change in one mechanism $P ( X _ { i } \\mid \\mathbf { P } \\mathbf { A } _ { i } )$ does not inform or influence any of the other mechanisms $P ( X _ { j } \\mid \\mathbf { P A } _ { j } )$ , for $i \\neq j$ .\n\nThis notion of invariant, independent, and autonomous mechanisms has appeared in many forms throughout the history of causality research: from early work led by Haavelmo [1944] and Aldrich [1989] to Pearl [2009]. Studying properties of independent causal mechanisms rigorously demands a statistical understanding of what such independence means between distributions. Guo et al. [2023a] provides a statistical formalization of ICM in exchangeable data, thus providing necessary tools to study causal framework in exchangeable data. The next section introduces relevant background.\n\n# 2.2 The Causal Framework in Exchangeable Data\n\nDefinition 1 (Exchangeable Sequence) An exchangeable sequence of random variables is a finite or infinite sequence $X _ { 1 } , X _ { 2 } , X _ { 3 } , . . .$ such that for any finite permutation $\\sigma$ of the position indices $\\{ 1 , \\ldots , N \\}$ , the joint distribution of the permuted sequences remains unchanged to that of original:\n\n$$\nP ( X _ { \\sigma ( 1 ) } , \\dots , X _ { \\sigma ( N ) } ) = P ( X _ { 1 } , \\dots , X _ { N } )\n$$\n\nNote an independent and identically distributed (i.i.d.) sequence of random variables is an exchangeable sequence, i.e., $\\begin{array} { r } { P ( X _ { 1 } , \\ldots , X _ { N } ) = \\prod _ { i = 1 } ^ { N } P ( X _ { i } ) } \\end{array}$ , but not all exchangeable sequences are i.i.d. Examples of exchangeable non-i.i.d. sequeQnces include but are not limited to Pólya urn model [Hoppe, 1984], Chinese restaurant processes [Aldous et al., 1985] and Dirichlet processes [Ferguson, 1973].\n\nAn important result of exchangeable data are de Finetti’s theorems [de Finetti, 1931] which show any exchangeable sequence can be represented as a mixture of conditionally i.i.d. data. Building upon the work of de Finetti [1931], Guo et al. [2023a] observes that exchangeable but not i.i.d. data possess extra conditional independence relationships compared to i.i.d. data. This enables:\n\n![](images/fed17bd9117c0af7aa76c99a45d2cd153b8791cb2f655af3b7205c6b50289880.jpg)  \nFigure 3: An illustration of differences in what the do-operator does between a structural causal model (a) and an ICM generative process (b). In the observational phase, SCMs (a), where the dotted plate indicates i.i.d. sampled, illustrates that fixed assignment of $U _ { X }$ and $U _ { Y }$ leads to fixed observable values $X$ and $Y$ ; on the other hand, for ICM-generative processes where exch. is an abbreviation for an exchangeable process, fixing $\\theta , \\psi$ does not fix $X$ and $Y$ , instead, it means sampling from a fixed distribution. Because SCM fails to characterize ICM-generative processes, we define the operational meaning of do-interventions on ICM-generative processes as assigning $\\delta$ -distribution to the intervened variables and substituting the corresponding values in the remaining distributions.\n\n• unique causal structure identification (Theorem 5 in [Guo et al., 2023a]), and • statistical formalization of ICM principle (causal de Finetti theorems in [Guo et al., 2023a])\n\nIn contrast to previous work’s focus on structure identification, this work studies causal effect identification and estimation in exchangeable data. Markovian models here mean there are no unmeasured confounders for each tuple of random variables observed in an exchangeable sequence.\n\nTo start with, we introduce the necessary terminologies inherited from Guo et al. [2023a].\n\nDefinition 2 (ICM generative process) We say data is generated from an ICM generative process with respect to a DAG $\\mathcal { G }$ if the sequence of random variable arrays $\\{ \\mathbf { X } _ { : ; n } \\}$ is infinitely exchangeable and satisfies $X _ { i ; [ n ] } \\perp \\overline { { N } } \\overline { { D } } _ { i ; [ n ] } , N D _ { i ; n + 1 } | P A _ { i ; [ n ] }$ for all $i \\in [ d ]$ and $n \\in \\mathbb { N }$ , where $\\pmb { P A } _ { i }$ denotes parents of node $X _ { i }$ , ${ \\bf N D } _ { i }$ denotes the corresponding non-descendants and $\\overline { { N D } } _ { i }$ denotes the set of non-descendants excluding its own parents. By causal de Finetti theorems, it is equivalent to say the joint distribution of the sequence can be represented as:\n\n$$\nP ( { \\bf X } _ { : : [ N ] } = { \\bf x } _ { : , [ N ] } ) = \\int \\int \\prod _ { n = 1 } ^ { N } \\prod _ { i = 1 } ^ { d } p ( x _ { i ; n } \\mid p a _ { i ; n } ^ { \\mathcal { G } } , \\pmb { \\theta } _ { i } ) d \\nu _ { 1 } ( \\pmb { \\theta _ { 1 } } ) \\dots d \\nu _ { d } ( \\pmb { \\theta _ { d } } ) ,\n$$\n\nwhere $\\nu _ { i }$ are probability measures.\n\nIn this work, we assume that any probability measure has a corresponding density function. Following Definition 2, an immediate result is any distribution $P$ generated by an ICM generative process is Markov to $\\operatorname { I C M } ( { \\mathcal { G } } )$ . Definition 7 in Appendix A defines formally what we mean by an ICM operator on a DAG $\\mathcal { G }$ . Here we illustrate an example of $\\operatorname { I C M } ( { \\mathcal { G } } )$ and the use of our notation. Consider a DAG $\\mathcal { G } : = X _ { 1 } \\left. X _ { 2 } \\right. X _ { 3 }$ with 3 variable indices. Two data tuples are generated under an ICM generative process with respect to $\\mathcal { G }$ . Fig. 2 shows the Markov structure compatible with the above ICM generative process.\n\n$$\n\\begin{array} { r l } & { X _ { 1 ; 1 } \\bullet \\bullet X _ { 2 ; 1 } \\prec \\bullet X _ { 3 ; 1 } } \\\\ & { \\quad \\bullet \\quad \\bullet \\quad \\bullet } \\\\ & { \\quad \\theta _ { 1 } \\quad \\quad \\quad \\theta _ { 2 } \\quad \\quad \\theta _ { 3 } } \\\\ & { \\quad \\quad \\quad \\quad \\quad \\mathbf { \\check { V } } } \\\\ & { X _ { 1 ; 2 } \\bullet \\bullet X _ { 2 ; 2 }  \\bullet X _ { 3 ; 2 } } \\end{array}\n$$\n\nFigure 2: An example of $\\operatorname { I C M } ( { \\mathcal { G } } )$ : Two data tuples are generated by an ICM generative process with respect to $\\mathcal { G } : =$ $X _ { 1 } \\left. X _ { 2 } \\right. X _ { 3 }$ , where $X _ { i ; n }$ is the $i$ - th variable in the $n$ -th position and gray means latent variables.\n\n# 3 Causal Effect in Exchangeable Data\n\nWe first motivate our study of causal effects in exchangeable data by noting exogenous variables are different from causal de Finetti parameters. Traditional causal effect in i.i.d. processes is defined as graph surgery with respect to SCMs (cf. Section 2.1). Such a definition does not transfer its operational meaning to that in exchangeable processes because SCMs fail to characterize ICM generative processes. In this section, we first define what causal effect means and show their differences in properties compared to that of i.i.d. processes. We proceed to illustrate in the simplest possible case - a pair of random variables, and then provide a general statement for the multivariate case.\n\nFigure 3 illustrates how SCMs fail to characterize ICM generative processes in the bivariate example. In SCMs, a fixed assignment of values to exogenous variables $U _ { X }$ and $U _ { Y }$ uniquely determines the values of all the observable variables $X$ and $Y$ . This is not the case for ICM generative processes. A fixed assignment to causal de Finetti parameters $\\theta$ and $\\psi$ only restricts the observable variables $X$ and $Y$ to sample from fixed distributions but does not uniquely determine their values. Therefore, do-operator commonly defined as graph surgery in SCMs demands a new operational meaning in ICM generative processes. Definition 3 defines that $d o ( X = x )$ in ICM generative processes means assigning the sampling density $p ( x | \\theta )$ to $\\delta ( X = x )$ .2. Doing so, we have:\n\ni.i.d. generative process : $\\begin{array} { r } { P ( Y = y | d o ( X = x ) ) = p ( y | x , \\psi _ { 0 } ) = P ( Y = y | x ) , \\psi _ { 0 } \\in \\mathbb { R } } \\end{array}$\n\n$$\n. P ( Y = y | d o ( X = x ) ) = \\int p ( y | x , \\psi ) p ( \\psi ) d \\psi = P ( Y = y | x )\n$$\n\nDespite being identical in expression, causal effect has different implications in i.i.d. and ICM generative processes. Under i.i.d., the randomness captured in $P$ is driven only by the randomness in exogenous variables $U _ { Y }$ . Under the ICM generative process, the randomness in $P$ is driven both by $p ( \\boldsymbol { y } | \\boldsymbol { x } , \\boldsymbol { \\psi } )$ and the randomness in the causal de Finetti parameter $p ( \\psi )$ . It is well-known that i.i.d is a subcase of exchangeability. Here we observe that the causal effect expression follows the same pattern, i.e., the causal effect expression in i.i.d. is also a subcase of that under exchangeability whenever $p ( \\psi ) = \\delta ( \\psi = \\psi _ { 0 } )$ .\n\nEquipped with this operational meaning of intervention, we next consider the set of feasible intervention targets. Here we first clarify what we mean by the data-generating process. Data generated from i.i.d. or ICM processes refers to a sequence of random variables. For example, in the bivariate case, the sequence is $( X _ { 1 } , Y _ { 1 } ) , ( X _ { 2 } , Y _ { 2 } ) , \\dotsc . . . .$ Often one omits position indices in i.i.d. because:\n\n$$\n. { \\mathrm { g e n e r a t i v e ~ p r o c e s s : ~ } } P ( X _ { 1 } , Y _ { 1 } , \\ldots , X _ { N } , Y _ { N } ) { \\overset { i n d } { \\mathop { = } } } \\prod _ { n = 1 } ^ { N } P ( X _ { n } , Y _ { n } ) { \\overset { i d e } { \\mathop { = } } } [ P ( X , Y ) ] ^ { N }\n$$\n\nThe first equality is due to independence and the second equality is due to identical distributions. One thus does not differentiate the position indices in i.i.d. as $P ( X , Y )$ characterizes the joint distribution fully by Eq. (7). Intervention is thus defined only on $X$ and $Y$ rather than $X _ { n }$ and $Y _ { n }$ . However, in the ICM generative process, $P ( X , Y )$ cannot fully characterize the joint distribution. An example application of Definition 2 in the bivariate case gives:\n\n$$\n\\mathrm { I C M ~ g e n . ~ p r o c e s s : ~ } P ( x _ { 1 } , y _ { 1 } , \\ldots , x _ { N } , y _ { N } ) = \\int \\int \\prod _ { n = 1 } ^ { N } p ( y _ { n } | x _ { n } , \\psi ) p ( x _ { n } | \\theta ) d \\mu ( \\theta ) d \\nu ( \\psi )\n$$\n\nEq. (8) shows that one can no longer omit the position indices in ICM generative processes, as $P ( X , Y )$ cannot fully characterize the joint distribution. Intervention in ICM generative processes thus should be considered at the level of $X _ { n }$ and $Y _ { n }$ . Definition 3, presented below, formalizes the concept of causal effect in ICM generative processes. In particular, both intervention sets and target variables of interest can be any random variables observed in the sequence.\n\nDefinition 3 (Causal Effect in ICM generative processes) Let $\\mathbf { X }$ and $\\mathbf { Y }$ be two disjoint sets of variables generated by an ICM-generative process. For each realization $\\mathbf { x }$ of $\\mathbf { X }$ , $P ( \\mathbf { y } | \\dot { d } o ( \\mathbf { x } ) )$ in the ICM-generative process denotes the probability of $\\mathbf { Y } = \\mathbf { y }$ induced by assigning $p ( x _ { i ; n } | p \\pmb { a } _ { i ; n } ^ { \\mathcal { G } } , \\theta _ { i } ) =$ $\\delta ( X _ { i ; n } = x _ { i ; n } )$ in Eq. (4), $\\forall X _ { i ; n } \\in \\mathbf { X }$ , and substituting ${ \\bf X } = { \\bf x }$ in the remaining conditional distributions.\n\nAlthough marginal distribution $P ( X , Y )$ cannot characterize the joint distribution in Eq. (8) due to mutual dependence of $X _ { n } , Y _ { n }$ with causal de Finetti parameters $\\theta$ and $\\psi$ , we note variables in different positions share identical marginal distributions. Mathematically, data generated under an exchangeable process shares identical marginal distributions: $P ( X _ { n } , Y _ { n } ) = P ( { \\bar { X } } _ { m } , Y _ { m } ) , \\forall n \\neq m$ . This also means that identical interventions performed on variables in different positions result in the same post-interventional distributions: $\\bar { P } ( Y _ { n } | d o ( X _ { n } = x ) ) = P ( Y _ { m } | d o ( X _ { m } = x ) ) , \\forall n \\neq m$ . Similar to i.i.d., quantities such as $P ( Y | d o ( X = x ) )$ are thus well-defined in ICM generative processes. Corollary 1 proves the multivariate equivalent of identical marginal intervention effects in ICM generative processes.\n\nCorollary 1 (Identical marginal post-interventional distributions) Let $P$ be the distribution for some ICM generative process. Let $\\mathbf { I }$ and $\\mathbf { J }$ be two disjoint subsets in $[ d ] : = \\{ 1 , \\ldots , d \\}$ . Denote $\\mathbf { X } _ { \\mathbf { I } ; n } : = \\{ X _ { i ; n } : i \\in \\mathbf { I } \\}$ and similarly for $\\mathbf { X } _ { \\mathbf { J } ; n }$ . Then,\n\n$$\nP ( \\mathbf { X } _ { J ; n } \\mid d o ( \\mathbf { X } _ { I ; n } = \\mathbf { x } ) ) = P ( \\mathbf { X } _ { J ; m } \\mid d o ( \\mathbf { X } _ { I ; m } = \\mathbf { x } ) ) , \\forall n \\neq m\n$$\n\ni.e., identical interventions on variables in different positions share the same marginal postinterventional distributions. See Appendix $B$ for the proof.\n\nOne can thus omit the notation of position indices when appropriate as supported by Corollary 1 and as illustrated in Figure 1 Block A. In the next section, we address a focal problem in causal effect estimation: causal effect identifiability in ICM generative processes.\n\n# 3.1 Causal Effect Identifiability in ICM generative processes\n\nContinuing with the bivariate example in Fig. 3 (b), consider $X _ { 1 } , Y _ { 1 } , X _ { 2 } , Y _ { 2 }$ is generated under an ICM generative process with respect to $\\mathcal { G } : = X  Y$ . Suppose one performs hard intervention on $X _ { 1 }$ , i.e., $\\mathrm { l o } ( X _ { 1 } = \\hat { x } )$ ). Applying traditional truncated factorization developed for i.i.d. data (Eq. (2)) yields:\n\n$$\nP ( x _ { 1 } , y _ { 1 } , x _ { 2 } , y _ { 2 } | d o ( X _ { 1 } = \\hat { x } ) ) = P ( y _ { 1 } | \\hat { x } ) P ( y _ { 2 } | x _ { 2 } ) P ( x _ { 2 } ) \\mathbb { 1 } _ { x _ { 1 } = \\hat { x } }\n$$\n\nHowever, the independence between $( X _ { 1 } , Y _ { 1 } )$ and $( X _ { 2 } , Y _ { 2 } )$ in i.i.d. generative processes does not hold in ICM generative processes. In fact, in ICM generative processes, applying Definition 3 gives:\n\n$$\nP ( x _ { 1 } , y _ { 1 } , x _ { 2 } , y _ { 2 } | d o ( X _ { 1 } = \\hat { x } ) ) = \\int p ( y _ { 1 } | \\hat { x } , \\psi ) p ( y _ { 2 } | x _ { 2 } , \\psi ) p ( \\psi ) d \\psi p ( x _ { 2 } ) \\mathbb { 1 } _ { x _ { 1 } = \\hat { x } }\n$$\n\nEq. (11) does not equal to Eq. (10) whenever $p ( \\psi ) \\neq \\delta ( \\psi = \\psi _ { 0 } )$ for some $\\psi _ { 0 }$ . Thus, for data generated under ICM generative processes, a new theorem for truncated factorization is required. See Theorem 1 for the statement for general multivariate distributions and Appendix C for a detailed derivation.\n\nTheorem 1 (Truncated Factorization in ICM generative processes) For a given graph $\\mathcal { G }$ , let $P$ be the probability distribution for data generated under an ICM generative process with respect to $\\mathcal { G }$ and let $p$ be the corresponding density. The post-interventional distribution after intervening on $\\mathbf { X } = { \\hat { \\mathbf { x } } }$ has density given by:\n\n$$\np ( \\mathbf { x } _ { : : 1 } , \\dots , \\mathbf { x } _ { : : N } | d o ( \\mathbf { X } = \\hat { \\mathbf { x } } ) ) = \\prod _ { i \\in I _ { \\mathbf { X } } } p ( \\mathbf { x } _ { i ; [ - \\mathbf { N } _ { i } ] } | p a _ { i ; [ - \\mathbf { N } _ { i } ] } ^ { \\mathcal { G } } ) \\prod _ { i \\not \\in I _ { \\mathbf { X } } } p ( \\mathbf { x } _ { i ; [ N ] } | p a _ { i ; [ N ] } ^ { \\mathcal { G } } ) \\big | _ { \\mathbf { X } = \\hat { \\mathbf { x } } } ,\n$$\n\nwhere ${ \\bf I } _ { { \\bf X } } : = \\{ i : X _ { i ; n } \\in { \\bf X } \\}$ denotes the set of variable indices being intervened on and $\\mathbf { N } _ { i } : = \\{ n :$ $X _ { i ; n } \\in \\mathbf { X } \\}$ denotes the set of position indices corresponding to variable index $i$ in the intervention set $\\mathbf { X }$ and $[ \\neg \\mathbf { N } _ { i } ]$ denotes the set of positive integers less than or equal to $N$ excluding values in $\\mathbf { N } _ { i }$ .\n\nTheorem 1 presents a procedure for computing the joint post-interventional distribution using pre-interventional conditional distributions when intervening on any set of variables in the Markovian model. This demonstrates that causal effects are identifiable in Markovian models under ICM generative processes. Note that the traditional truncated factorization in i.i.d. processes is again a special case of Eq. (12) just as i.i.d. processes are a special case of exchangeable processes.\n\n# 3.2 Conditional Interventional distributions\n\nThe fundamental difference between i.i.d. and ICM generative processes lies in the violation of the independence condition inherent to i.i.d.. Consequently, interventional distributions computed by conditioning on observations differ between the two. Specifically, causal effect of $d o ( X _ { 1 } = \\bar { x } )$ on $Y _ { 1 }$\n\ngiven $X _ { 2 } , Y _ { 2 }$ differs when computed under i.i.d. (Eq. (13)) and ICM generative processes (Eq. (14)).   \nThis difference arises because $( \\mathbf { \\bar { X } } _ { 1 } , Y _ { 1 } ) \\perp ( X _ { 2 } , Y _ { 2 } )$ holds in i.i.d but not in ICM generative processes.\n\nFig. 1 (c) depicts this example of intervention via graph surgery on $\\operatorname { I C M } ( { \\mathcal { G } } )$ where the operational meaning of edge deletion is explained in Figure 3. We observe that conditioning on the collider node $Y _ { 2 }$ in the ICM generative process renders $Y _ { 1 } \\not \\approx X _ { 2 } | Y _ { 2 }$ . Lemma 1 provides the corresponding general statement for the multivariate case when conditioning on other observations. See Appendix $\\mathrm { \\Delta D }$ for the proof.\n\nLemma 1 (Intervention effect conditioned on other observations) For a given graph $\\mathcal { G }$ , let $P$ be the distribution for the ICM generative process with respect to $\\mathcal { G }$ . Let $\\mathbf { X }$ be the intervention set. Assume $\\mathbf { X } = \\mathbf { X } _ { \\Gamma / n } : = \\{ X _ { i ; n } : \\forall i \\in \\mathbf { I } \\}$ . Let ${ \\bf S } \\subseteq [ N ]$ such that $n \\not \\in { \\bf S }$ and $[ \\neg \\mathbf { I } ]$ denotes $[ d ] \\backslash \\mathbf { I } .$ . Then,\n\n$$\nP ( \\mathbf { X } _ { - \\mathbf { I } ; n } | d o ( \\mathbf { X } _ { \\mathbf { I } ; n } = \\hat { \\mathbf { x } } ) , \\mathbf { X } _ { : ; \\mathbf { S } } ) = \\prod _ { i \\notin \\mathbf { I } } P ( \\mathbf { X } _ { i ; n } | \\mathbf { X } _ { i ; \\mathbf { S } } , P A _ { i ; \\mathbf { S } \\cup \\{ n \\} } ) | _ { \\mathbf { X } _ { \\mathbf { I } ; n } = \\hat { \\mathbf { x } } }\n$$\n\nA similar argument also applies to the intervention effect conditioned on observations of experimental results performed on other tuples of random variables in the sequence. Appendix E discusses in detail. Here we show the implications of conditional interventional distributions via a causal Pólya urn model.\n\nCausal Pólya Urn Model Imagine an urn with left and right compartments. The experimenter puts $\\alpha$ white balls and $\\beta$ black balls in each compartment. At each step $n$ , one ball is uniformly drawn from the left and one ball is uniformly drawn from the right. The chosen two balls in the order of left and right are then placed in a dark chamber unobserved by the experimenter. A hidden mechanism reads the color of the two balls and outputs $X _ { n } , Y _ { n }$ to the experimenter. The mechanism outputs $X _ { n } = 1$ whenever the $n$ -th left ball is black else $X _ { n } = 0$ and $Y _ { n } = 1$ whenever the left and right balls disagree in color. After observing $X _ { n }$ and $Y _ { n }$ , the experimenter puts the original balls back in the corresponding compartment and add a ball of the same color as $X _ { n }$ in the left and add a ball of the same color as $Z _ { n } : \\bar { = } \\left( 1 - X _ { n } \\right) * Y _ { n } + \\left( 1 - Y _ { n } \\right) * X _ { n }$ in the right.\n\nCausal de Finetti application The causal Pólya urn model is a real-world illustration of causal de Finetti thereom in its bivariate form. The joint distribution of observed sequence $P ( x _ { 1 } , y _ { 1 } , . . . , x _ { n } , y _ { n } )$ for all $n \\in \\mathbb { N }$ can be perfectly modelled as the RHS of Eq. (4) with two variables and $X  Y$ :\n\n$$\n\\int \\int \\prod _ { n } p ( y _ { n } \\mid x _ { n } , \\psi ) p ( x _ { n } \\mid \\theta ) p ( \\theta ) p ( \\psi ) d \\theta d \\psi ,\n$$\n\nwhere $p ( \\theta ) , p ( \\psi )$ are Beta distributions and $p ( y _ { n } \\mid x _ { n } , \\psi ) , p ( x _ { n } \\mid \\theta )$ are Bernoulli distributions. Appendix F provides a detailed analysis of how causal Pólya Urn Model satisfies both exchangeability and certain conditional independences conditions. Therefore causal de Finetti theorems apply to the causal Pólya urn model in the sense the joint observational distribution can be equivalently modelled as ICM generative processes in bivariate form. Next, we study how intervention propagates in this model.\n\nDiscussion For a given $n$ , if $X _ { m } = 1 , Y _ { m } = 0$ for many $m < n$ , then it is more likely $X _ { n } = 1 , Y _ { n } =$ 0 as there are more black balls are added to both left and right urn compartments. Consider an intervention: imagine an agent replaces the left ball in the dark chamber to be a white ball for the $n$ -th draw, $d o ( X _ { n } = 0 )$ , then if $X _ { m } = 1 , Y _ { m } = 0$ for many $m < n$ , it is more likely that $Y _ { n } = 1$ as more black balls are placed in the right compartment and $X _ { n }$ is fixed to be a white ball by intervention. This illustrates a practical example of the aforementioned conditional post-interventional distributions. After the intervention, the observer, ignorant of what happens in the dark chamber, proceeds as normal with the replacement process. The intervention thus changes the dynamics of causal Pólya urn model. We consider causal Pólya model interesting as it illustrates through simple game-like settings that observables $( X _ { n } , Y _ { n } )$ satisfying $Y _ { [ n ] } \\perp \\perp X _ { n + 1 } | X _ { [ n ] }$ are indeed driven by the independent mechanisms hidden from the observers. This is akin to how Nature hides causal mechanisms from observers and scientists can only reason through observables.\n\n# 3.3 Rules of compact representation of causal effect\n\nFrom Theorem 1, any interventional effect $P ( \\mathbf { Y } | d o ( \\mathbf { X } ) )$ can be obtained from marginalization. However, in practice, marginalization on many variables is computationally expensive. Further, Theorem\n\n1 requires observations and measurements of all joint variables which is resource-intensive in practice. Such problem on the observability of variables is more explicitly posed as out-of-variable problem in Guo et al. [2023b]. In this section, we present rules that allow simplification of causal expressions.\n\nLemma 2 (Intervention effect on differing positions) Given a graph $\\mathcal { G }$ and let $P$ be the distribution for the ICM generative process with respect to $\\mathcal { G }$ . Let $\\mathbf { X }$ and $\\mathbf { Y }$ be two disjoint sets such that $\\mathbf { X }$ is the intervention set and $\\mathbf { Y }$ is the target set. Let $\\mathbf { N } _ { \\mathbf { X } } : = \\{ n : X _ { i ; n } \\in \\mathbf { X } \\}$ be the set of position indices being intervened, and similarly $\\mathbf { N } _ { \\mathbf { Y } }$ be the set of position indices being targeted to observe. Assume $\\mathbf { N _ { X } } \\cap \\mathbf { N _ { Y } } = \\emptyset$ . Then,\n\n$$\nP ( \\mathbf { Y } \\mid d o ( \\mathbf { X } = \\mathbf { x } ) ) = P ( \\mathbf { Y } ) ,\n$$\n\nLemma 3 (Intervention effect within the same position) Given a graph $\\mathcal { G }$ and let $P$ be the distribution for the ICM generative process with respect to $\\mathcal { G }$ . Let $\\mathbf { X }$ be the intervention set such that it consists only ${ \\bf X } _ { \\mathbf { I } ; n }$ where $n \\in \\mathbf { S } \\subseteq [ N ]$ and $\\mathbf { I } \\subseteq [ d ]$ is a set of variable indices. Let $\\mathbf { Y }$ be the target set such that it consists only $\\mathbf { X } _ { \\mathbf { J } ; n }$ where $n \\in \\mathbf { S } \\dot { \\subseteq } \\bar { [ { N } ] }$ and $\\mathbf { J } \\subseteq [ d ]$ . Note $\\mathbf { I } \\cap \\mathbf { J } = \\varnothing$ . Then,\n\n$$\nP ( \\mathbf { Y } \\mid d o ( \\mathbf { X } = { \\hat { \\mathbf { x } } } ) ) = \\sum _ { p a _ { \\mathbf { X } } } P ( \\mathbf { Y } \\mid { \\hat { \\mathbf { x } } } , p a _ { \\mathbf { X } } ) P ( p a _ { \\mathbf { X } } ) ,\n$$\n\nwhere $P A _ { \\mathbf { X } }$ denotes the parent set of intervened variables $\\mathbf { X }$ .\n\nLemma 2 shows that the interventional distributions on target variables of interest are unchanged when only intervening on variables in differing positions other than the target variables. Lemma 3 shows for arbitrary causal queries when acting on a consistent set of variables across positions (i.e., the intervention set $\\mathbf { X }$ consists of ${ \\bf X } _ { \\mathbf { I } ; n }$ , where each position $n$ shares the same set of variable indices I being intervened on), the post-interventional distribution can be estimated by only observing and measuring $\\mathbf { Y } , \\mathbf { X } , \\mathbf { P A } _ { \\mathbf { X } }$ , where $\\mathbf { P A } _ { \\mathbf { X } }$ denotes the parent set of $\\mathbf { X }$ . This is consistent with the parent adjustment formula under i.i.d. generative processes, with the additional dependence structure across variables in differing positions. See Appendix $\\mathbf { G }$ and $\\mathrm { ~ H ~ }$ for detailed statements and proofs.\n\n# 4 Causal Effect in Multi-environment data\n\nIn Section 3, we establish the identifiability of causal effects given the graph $\\mathcal { G }$ and the distribution $P$ generated by an ICM generative process. Note under i.i.d. generative processes, causal effect identification hinges on the knowledge of causal diagram $\\mathcal { G }$ . Here, we show that generalizing causality to an exchangeable framework does not necessarily mean we have less ability to perform graphical identification and effect estimation. In fact, with an unknown graph, ICM generative processes allow one to identify graph and causal effects simultaneously. In other words, data adhering to the ICM principle and generated under an exchangeable process alone is sufficient for both graphical and effect identification.\n\nTheorem 2 (Causal effect identification in ICM generative processes) Denote $\\mathbf { Y }$ , X be two disjoint subsets of observable variables in $\\{ \\mathbf { X } _ { : ; n } \\} _ { n \\in \\mathbb { N } }$ . Then $P ( \\mathbf { Y } | d o ( \\mathbf { X } = \\mathbf { x } ) )$ is identifiable given the distribution $P$ from the class of distributions generated from ICM generative processes. Here identifiability means the causal query can be computed uniquely from $P$ .\n\nInformally, Theorem 2 says that for ICM generative processes, both causal graphs and causal effects can be identified simultaneously. This is derived from a concatenation of Theorem 5 in Guo et al. [2023a] and Theorem 1 in the current work. Theorem 5 in Guo et al. [2023a] shows for ICM generative processes, causal graph is identifiable and Theorem 1 shows the computation, and thus identifiability, of causal effects in ICM generative processes given graph.\n\nTo see how to apply Theorem 2 in practice, we build connection between exchangeable and grouped or multi-environment data and propose the $D o$ -Finetti algorithm. In the causal literature, grouped data refers to data available from multiple environments, each producing (conditionally) i. i. d observations from a different distribution, which are related through some invariant causal structure shared by all environments. We can interpret multi-environment data through the lens of exchangeability as follow: In each environment $e$ , we observe exchangeable random variables $\\mathbf { X } _ { : ; [ N _ { e } ] } ^ { e }$ , where $X _ { d ; n } ^ { e }$ denotes the $d$ th random variable observed at $n$ -th position in environment $e$ . $N _ { e }$ denotes the number of observations from environment $e$ . Data across environments are independent and identically distributed in the sense that the distribution of $\\mathbf { X } _ { : ; [ N ] } ^ { e }$ and X:e;′[N] is identical for all N < min(Ne, Ne′ ). Each environment thus provides a finite marginal of an i. i.d˙ copy of the same exchangeable process.\n\n![](images/2a8a36ef21d2ee69ffb1efcb762f2a4319f0da779b5150358479971062ee202d.jpg)  \nFigure 4: Our method’s (do-Finetti) performance in simultaneously identifying DAG (right) and causal effect estimation (left), compared to the i.i.d. algorithm (i.i.d.) and corresponding methods with known true DAG (do Finetti with true $D A G$ and i.i.d. with true $D A G$ ) in bivariate setting. Left shown are the mean and standard deviation of MSE compared to analytic solutions for each method aggregated over 100 experiments. Right shows the accuracy of identifying the correct underlying DAG for each method. $D o$ -Finetti identifies unique causal structures and achieves near-perfect causal effect estimation.\n\nThe $D o$ -Finetti algorithm combines Causal-de-Finetti algorithm developed in Guo et al. [2023a] and the truncated factorization for ICM generative processes developed in Section 3 of this paper. It provides a proof-of-concept algorithm to verify that multi-environment data generated under the independent causal mechanism principle alone via an exchangeable process can simultaneously estimate the causal effect and causal graph. See Algorithm 1 in Appendix I for details of the procedure.\n\n# 5 Experiments\n\nWe construct synthetic datasets according to causal Pólya urn model (cf. Section 3.2) and demonstrate that $D o$ -Finetti algorithm can estimate causal effects and graphs simultaneously. We compare with the standard method in i.i.d. processes (i.e., PC algorithm and truncated factorization Eq. (2)) and show empirically that the traditional truncated factorization cannot estimate causal effects in our setting. We then perform ablation studies to attribute errors to either graphical misclassification or effect estimation.\n\nLet superscript e denote variables generated in environment $e$ . The data-generating process for $X  Y$ , for example, as follows:\n\n$$\n\\begin{array} { c } { { \\theta ^ { e } \\sim \\operatorname { B e t a } ( \\alpha , \\beta ) , \\psi ^ { e } \\sim \\operatorname { B e t a } ( \\alpha , \\beta ) } } \\\\ { { X  Y : X _ { i } ^ { e } : = \\operatorname { B e r } ( \\theta ^ { e } ) , Y _ { i } ^ { e } : = \\operatorname { B e r } ( \\psi ^ { e } ) \\oplus X _ { i } ^ { e } } } \\end{array}\n$$\n\nwhere $\\oplus$ denotes xor operation and $X _ { i } ^ { e } , Y _ { i } ^ { e }$ denote variables generated at the $i$ -th position in environment $e$ . We collect two pairs of random variables across all environments and run do-Finetti algorithm to compute the post-interventional distributions with randomly initialized intervened variable and its corresponding values as in Eq. (12). We repeat the experiment for 100 times and report the mean squared error loss between predicted and analytic solutions across varying number of environments. Fig. 4 shows i.i.d. fails to estimate causal effects, giving high estimation error in ICM generative processes. Even with knowledge of the true DAG and infinite data, i.i.d. with true $D A G$ never achieves analytic solutions (Fig. 4a). On the other hand, do-Finetti achieves near-zero causal effect estimation error, meaning correct DAG identification and correct effect estimation. Appendix K details exact experiment setups.\n\n# 6 Discussion\n\nCausality and exchangeability. Causal effect estimation in randomized controlled trials [Rubin, 2005] relies on the exchangeability assumption between the controlled and treatment group. More recent work [Dawid, 2021] introduces a decision-theoretic framework for causality and uses pre-treatment and post-treatment exchangeability as foundational assumptions on external data used to solve a decision problem. Jensen et al. [2020] studies exchangeability in the context of object conditioning. It shows object conditioning, due to exchangeability, mitigates latent confounding and measurement errors for causal inference. Guo et al. [2023a] characterize independent causal mechanisms in exchangeable data via causal de Finetti theorems. Reizinger et al. [2024] proposes relaxed conditions for causal discovery in ICM generative processes and shows exchangeable non-i.i.d. data is the key to both structure and representation identifiability. This work extends on causal de Finetti and studies causal effect identification and estimation in ICM generative processes.\n\nCausal effect estimation in multi-environment data. Bareinboim and Pearl [2016] study the transportability of causal effects for populations under different experimental conditions. Peters and Meinshausen [2016] quantify causal effect estimation and its uncertainties through exploiting invariance of causal mechanisms. Jaber et al. [2019] develop a complete algorithm for causal effect identification in the Markov equivalence class of causal graphs which was previously deemed impossible to identify further without additional assumptions in the i.i.d. framework. In the present work, we show ICM generative processes, naturally arising in multi-environment data, allow simultaneous causal structure recovery and effect identification. Further, we illustrate via a causal Pólya urn model that an exchangeable process, though related, is not limited to only multi-environment data.\n\nCausality in non-i.i.d. data. A classical problem in causality is the study of interference, motivated by real-world complex interdependencies within subjects. For example, in social networks and infectious disease, treatments on one subject affects outcomes of other subjects. Sherman [2022] provides a general identification formula of causal estimands under dependent data when graphs contain unobserved confounders. Ogburn and VanderWeele [2014] provides a comprehensive review on causal inference under interference and studies how to determine what variables must be measured for computation of causal estimands. Zhang et al. [2023] provides an elegant study on modeling uncertain interaction using linear graphical causal models. Maier [2014] studies causal discovery in relational data. This work focuses on a particular type of non-i.i.d. data, namely exchangeable data. In contrast with classical setting where we assume aprior known causal graph and develop causal estimands from thereon, the series of causal de Finetti work focus on empirical inference of causality from exchangeable non-i.i.d. data. This we hope paves the way to uncover governing laws of Nature from empirical observations.\n\nReal-world Applications. Exchangeable data offers an expressive and realistic representation of complex structured relational data, which often appears in clinical studies [Bowman and George, 1995], microarray gene expression data [Qin, 2006], or in high-dimensional inference tasks for images [Korshunova et al., 2018, 2020], 3D point cloud modeling [Yang et al., 2020] to topic modeling [McAuliffe and Blei, 2007]. While it is beyond the scope of the present work, we hope that our work, through building a theoretical framework of interventions in exchangeable data, may ultimately help study and understand naturally occurring mechanisms in scientific domains.\n\n# 7 Conclusion\n\nWe study causal effects and prove a generalized truncated factorization for an important class of exchangeable generative processes. We show for conditional interventional distributions that other observations are relevant to the causal query for exchangeable but not for i.i.d. data. We introduce causal Pólya urn models and demonstrate in-practice interventions in exchangeable data. We develop a $D o$ - Finetti algorithm that performs simultaneous DAG and effect estimation from multi-environment data.\n\nIt is exciting to start to understand the complexities of non-i.i.d. data, and much is left to do: from developing algorithms that perform at scale to understanding counterfactual queries in exchangeable contexts. Appendix L details limitations and broader impact. Going beyond i.i.d. has been a major bottleneck when applying machine learning to real-world applications, and exchangeable data offers a doable and realistic next step.",
    "summary": "{\n    \"core_summary\": \"### 核心概要\\n\\n**问题定义**\\n传统的因果效应估计框架通常局限于独立同分布（i.i.d.）数据，无法扩展到更一般的可交换生成过程，而可交换数据在多环境数据中自然出现。解决非i.i.d.的可交换数据下的因果效应估计问题，对于从健康、流行病学到社会和行为科学等多个科学领域从观测数据中推断因果效应至关重要。\\n\\n**方法概述**\\n论文开发了一个适用于可交换数据的广义框架，引入截断分解公式以促进因果效应的识别和估计。提出因果Pólya urn模型，并开发Do - Finetti算法用于多环境数据的因果发现和效应估计。\\n\\n**主要贡献与效果**\\n- 建立了ICM生成过程中干预的操作意义和可行干预目标，提出截断分解公式，解决了因果效应的识别和估计问题。\\n- 引入因果Pólya urn模型，展示了干预在可交换数据设置中的传播效果，该模型是因果de Finetti定理双变量形式的实际例证，其联合分布可用特定公式建模。\\n- 开发的Do - Finetti算法在多环境数据上实现了近乎零的因果效应估计误差，在双变量设置中接近完美地估计因果效应，且能够准确识别潜在的DAG，在100次实验中与解析解相比，均方误差表现良好，识别正确潜在DAG的准确率高，优于i.i.d.算法和i.i.d. with true DAG方法。\",\n    \"algorithm_details\": \"### 算法/方案详解\\n\\n**核心思想**\\n算法基于独立因果机制（ICM）假设，认为不同的因果机制相互独立。可交换数据生成过程遵循ICM原则，其比i.i.d.数据更具信息性，能够在无图先验假设的情况下实现图形和效应的识别。通过引入截断分解公式，利用可交换数据中的额外条件独立性关系，将因果效应的识别和估计问题转化为可计算的形式。\\n\\n**创新点**\\n先前的因果效应估计理论主要针对i.i.d.数据，传统方法如基于结构因果模型和do - 演算的框架无法扩展到可交换数据。本方法开发了适用于可交换数据的广义框架，引入截断分解公式和新的操作定义，以适应可交换数据的特点。此外，开发了适用于多环境数据的Do - Finetti算法，实现了同时进行因果发现和效应估计。\\n\\n**具体实现步骤**\\n1. 定义ICM生成过程：数据生成满足特定的条件独立性，通过因果de Finetti定理等价表示联合分布，其联合分布可表示为$P ( { \\bf X } _ { : : [ N ] } = { \\bf x } _ { : , [ N ] } ) = \\int \\int \\prod _ { n = 1 } ^ { N } \\prod _ { i = 1 } ^ { d } p ( x _ { i ; n } \\mid p a _ { i ; n } ^ { \\mathcal { G } } , \\pmb { \\theta } _ { i } ) d \\nu _ { 1 } ( \\pmb { \\theta _ { 1 } } ) \\dots d \\nu _ { d } ( \\pmb { \\theta _ { d } } )$的积分形式。\\n2. 定义因果效应：在ICM生成过程中，对于干预集$\\mathbf { X }$的每个实现$\\mathbf { x }$，通过分配$p ( x _ { i ; n } | p \\pmb { a } _ { i ; n } ^ { \\mathcal { G } } , \\theta _ { i } ) = \\delta ( X _ { i ; n } = x _ { i ; n } )$，并将${ \\bf X } = { \\bf x }$代入剩余的条件分布，得到因果效应$P ( \\mathbf { y } | \\dot { d } o ( \\mathbf { x } ) )$。\\n3. 提出截断分解公式：对于给定图$\\mathcal { G }$和ICM生成过程的分布$P$，通过公式$p ( \\mathbf { x } _ { : : 1 }, \\dots, \\mathbf { x } _ { : : N } | d o ( \\mathbf { X } = \\hat { \\mathbf { x } } ) ) = \\prod _ { i \\in I _ { \\mathbf { X } } } p ( \\mathbf { x } _ { i ; [ - \\mathbf { N } _ { i } ] } | p a _ { i ; [ - \\mathbf { N } _ { i } ] } ^ { \\mathcal { G } } ) \\prod _ { i \\not \\in I _ { \\mathbf { X } } } p ( \\mathbf { x } _ { i ; [ N ] } | p a _ { i ; [ N ] } ^ { \\mathcal { G } } ) \\big | _ { \\mathbf { X } = \\hat { \\mathbf { x } } }$计算干预后的联合分布密度，其中${ \\bf I } _ { { \\bf X } } : = \\{ i : X _ { i ; n } \\in { \\bf X } \\}$表示被干预的变量索引集，$\\mathbf { N } _ { i } : = \\{ n : X _ { i ; n } \\in \\mathbf { X } \\}$表示干预集中对应变量索引$i$的位置索引集，$[ \\neg \\mathbf { N } _ { i } ]$表示小于等于$N$且排除$\\mathbf { N } _ { i }$中值的正整数集。\\n4. 开发Do - Finetti算法：结合Causal - de - Finetti算法和截断分解公式，用于多环境数据的因果发现和效应估计，具体算法步骤见论文附录I。\\n\\n**案例解析**\\n因果Pólya urn模型：想象一个有左右隔层的urn，每个隔层放入$\\alpha$个白球和$\\beta$个黑球。每一步从左右隔层各均匀抽取一个球，放入暗室，隐藏机制根据球的颜色输出$X_n$和$Y_n$。$X_n = 1$表示第$n$个左球为黑色，$Y_n = 1$表示左右球颜色不同。观察后将球放回并添加相同颜色的球。若在第$n$次抽取时进行干预，将左球换为白球（$do(X_n = 0)$），且之前多次$X_m = 1$，$Y_m = 0$，则更有可能$Y_n = 1$，说明干预改变了模型的动态。该模型是因果de Finetti定理的双变量形式的实际例证，其联合分布可以用公式$\\int \\int \\prod _ { n } p ( y _ { n } \\mid x _ { n }, \\psi ) p ( x _ { n } \\mid \\theta ) p ( \\theta ) p ( \\psi ) d \\theta d \\psi$建模，其中$p ( \\theta )$、$p ( \\psi )$是Beta分布，$p ( y _ { n } \\mid x _ { n }, \\psi )$、$p ( x _ { n } \\mid \\theta )$是Bernoulli分布。\",\n    \"comparative_analysis\": \"### 对比实验分析\\n\\n**基线模型**\\n- i.i.d.算法：传统的基于i.i.d.数据的因果效应估计方法，如PC算法和截断因式分解公式。\\n- i.i.d. with true DAG：已知真实有向无环图（DAG）的i.i.d.算法。\\n- do Finetti with true DAG：已知真实DAG的Do - Finetti算法。\\n\\n**性能对比**\\n*   **在 [均方误差/MSE] 指标上：** 本文的Do - Finetti算法在多环境数据上与解析解相比的均方误差近乎零，显著优于i.i.d.算法和i.i.d. with true DAG方法。i.i.d.算法在ICM生成过程中给出了高估计误差，即使i.i.d. with true DAG方法在有真实DAG和无限数据的情况下，也无法达到解析解。Do - Finetti算法在100次实验中与解析解相比的均方误差均值和标准差表现良好。\\n*   **在 [DAG识别准确率] 指标上：** Do - Finetti算法能够准确识别潜在的DAG，其准确率高于i.i.d.算法和i.i.d. with true DAG方法，能够识别唯一的因果结构。\",\n    \"keywords\": \"### 关键词\\n\\n- 因果效应估计 (Causal Effect Estimation, N/A)\\n- 可交换数据 (Exchangeable Data, N/A)\\n- 独立因果机制 (Independent Causal Mechanisms, ICM)\\n- Do - Finetti算法 (Do - Finetti Algorithm, N/A)\\n- 因果Pólya urn模型 (Causal Pólya Urn Model, N/A)\"\n}"
}