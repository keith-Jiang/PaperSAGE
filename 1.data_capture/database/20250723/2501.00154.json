{
    "source": "Semantic Scholar",
    "arxiv_id": "2501.00154",
    "link": "https://arxiv.org/abs/2501.00154",
    "pdf_link": "https://arxiv.org/pdf/2501.00154.pdf",
    "title": "Probabilistic Explanations for Linear Models",
    "authors": [
        "Bernardo Subercaseaux",
        "Marcelo Arenas",
        "Kuldeep S. Meel"
    ],
    "categories": [
        "cs.AI",
        "cs.CC"
    ],
    "publication_date": "2024-12-30",
    "venue": "未找到发表会议",
    "fields_of_study": [
        "Computer Science"
    ],
    "citation_count": 0,
    "influential_citation_count": 0,
    "institutions": [
        "Carnegie Mellon University",
        "Pontificia Universidad Cat´olica de Chile",
        "IMFD Chile",
        "RelationalAI",
        "Georgia Institute of Technology",
        "University of Toronto"
    ],
    "paper_content": "# Probabilistic Explanations for Linear Models\\*\n\nBernardo Subercaseaux1, Marcelo Arenas2, 3, 4, Kuldeep S. Meel5, 6\n\n1Carnegie Mellon University   \n2Pontificia Universidad Cat´olica de Chile   \n3IMFD Chile   \n4RelationalAI   \n5Georgia Institute of Technology   \n6University of Toronto\n\n# Abstract\n\nFormal XAI is an emerging field that focuses on providing explanations with mathematical guarantees for the decisions made by machine learning models. A significant amount of work in this area is centered on the computation of “sufficient reasons”. Given a model $\\mathcal { M }$ and an input instance $\\pmb { x }$ , a sufficient reason for the decision $\\mathcal { M } ( \\pmb { x } )$ is a subset $S$ of the features of $\\pmb { x }$ such that for any instance $z$ that has the same values as $\\pmb { x }$ for every feature in $S$ , it holds that $\\mathcal { M } ( \\pmb { x } ) = \\mathcal { M } ( z )$ . Intuitively, this means that the features in $S$ are sufficient to fully justify the classification of ${ \\pmb x }$ by $\\mathcal { M }$ . For sufficient reasons to be useful in practice, they should be as small as possible, and a natural way to reduce the size of sufficient reasons is to consider a probabilistic relaxation; the probability of $\\mathcal { M } ( \\pmb { x } ) = \\mathcal { M } ( z )$ must be at least some value $\\hat { \\delta } \\in ( 0 , 1 \\bar { ] }$ , for a random instance $z$ that coincides with $\\pmb { x }$ on the features in $S$ . Computing small $\\delta \\cdot$ -sufficient reasons $\\mathbf { \\boldsymbol { \\delta } }$ -SRs) is known to be a theoretically hard problem; even over decision trees — traditionally deemed simple and interpretable models — strong inapproximability results make the efficient computation of small $\\delta$ -SRs unlikely. We propose the notion of $( \\delta , \\epsilon )$ - SR, a simple relaxation of $\\delta$ -SRs, and show that this kind of explanations can be computed efficiently over linear models.\n\nExtended version — https://arxiv.org/abs/2501.00154\n\n# 1 Introduction\n\nExplaining the decisions of Machine Learning classifiers is a fundamental problem in XAI (Explainable AI), and doing so with formal mathematical guarantees on the quality, size, and semantics of the explanations is in turn the core of Formal XAI (Marques-Silva and Ignatiev 2022). Within formal XAI, one of the most studied kinds of explanations is that of sufficient reasons (Darwiche and Hirth 2020), which aim to explain a decision $\\mathcal { M } ( \\pmb { x } ) = 1$ by presenting a subset $S$ of the features of the input $\\scriptstyle { \\pmb x }$ that implies $\\mathcal { M } ( z ) = 1$ for any $z$ that agrees with $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ on $S$ . In the language of theoretical computer science, these correspond to certificates for $\\mathcal { M } ( \\pmb { x } )$ .\n\nExample 1. Consider a binary classifier $\\mathcal { M }$ defined as\n\n$$\n\\mathcal { M } ( \\pmb { x } ) = \\left( x _ { 1 } \\vee \\overline { { x _ { 3 } } } \\right) \\wedge \\left( x _ { 2 } \\vee \\overline { { x _ { 1 } } } \\right) \\wedge \\left( x _ { 4 } \\vee x _ { 3 } \\right) ,\n$$\n\nand the input instance $\\pmb { x } = ( 1 , 1 , 0 , 1 )$ . We can say that $\\mathcal { M } ( \\pmb { x } ) = 1$ “because” $x _ { 1 } = 1 , x _ { 2 } = 1$ , and $x _ { 4 } = 1$ , as they are sufficient to determine the value of $\\mathcal { M } ( \\pmb { x } )$ regardless of $x _ { 3 }$ .\n\nLet us start formalizing the framework for our work. First, we consider binary boolean models $\\mathcal { M } \\colon \\{ 0 , 1 \\} ^ { d } \\to \\{ 0 , 1 \\}$ . Despite our domain being binary, we will need a third value, $\\perp$ , to denote “unknown” values. For example, we may represent a person who does have a car, does not have a house, and for whom we do not know if they have a pet or not, as $( 1 , 0 , \\bot )$ . We say elements of $\\{ 0 , 1 , \\bot \\} ^ { d }$ are partial instances, while elements of $\\{ 0 , 1 \\} ^ { d }$ are simply instances. To illustrate, in Example 1 we used the partial instance $y =$ $( 1 , 1 , \\bot , 1 )$ to explain $\\begin{array} { l } { \\displaystyle \\mathcal { M } ( \\pmb { x } ) ~ = ~ 1 } \\end{array}$ . We use the notation $y \\subseteq x$ to denote that the (partial) instance $\\textbf { \\em x }$ “fills in” values of the partial instance $_ y$ ; more formally, we use $y \\subseteq x$ to mean that $y _ { i } = \\perp \\lor y _ { i } = x _ { i }$ for every $i \\in [ d ]$ . Finally, for any partial instance $_ y$ we denote by $\\mathrm { C o m p } ( \\pmb { y } )$ the set of instances $\\scriptstyle { \\mathbf { { \\boldsymbol { x } } } }$ such that $y \\subseteq x$ , thinking of $\\operatorname { C o m p } ( y )$ as the set of completions of $_ y$ . One can define sufficient reasons as follows with this notation.\n\nDefinition 1 (Sufficient Reason (Darwiche and Hirth 2020)). We say $_ y$ is a sufficient reason for $\\scriptstyle { \\mathbf { { \\boldsymbol { x } } } }$ if for any completion $z \\in \\operatorname { C o m p } ( y )$ it holds that $\\mathcal { M } ( \\pmb { x } ) = \\mathcal { M } ( z )$ .\n\nA crucial factor for the helpfulness of sufficient reasons as explanations is their size; even though $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ is always a sufficient reason for its own classification, we long for explanations that are much smaller than $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ itself. Miller (1956), for instance, goes on to say that explanations consisting of more than 9 features are probably too large for human stakeholders. In general, empirical research suggests that explanations ought to be small (Narayanan et al. 2018; Lage et al. 2019). There are several ways of formalizing the succinctness we desire for sufficient reasons:\n\n• (Minimum Size) For a sufficient reason $\\pmb { y }$ , we define its explanation size $| \\boldsymbol { y } | _ { e }$ as the number of defined features in $_ y$ , or equivalently, $| \\pmb { y } | _ { e } : = d - | \\pmb { y } | _ { \\bot }$ , where $| \\pmb { y } | _ { \\bot }$ is the number of features of $\\textbf {  { y } }$ taking $\\perp$ . See e.g., (Barcel´o et al. 2020).1\n\n• (Subset minimality) We say a sufficient reason $\\boldsymbol { y }$ for a pair $( \\mathcal { M } , \\pmb { x } )$ is minimal if there is no other sufficient reason $\\boldsymbol { y } ^ { \\prime }$ for $( \\mathcal { M } , \\pmb { x } )$ such that $y ^ { \\prime } \\subsetneq y$ . In fact, the original definition of sufficient reasons of Darwiche and Hirth (2020) includes minimality as a requirement, and so is the case under the “abductive explanation” naming (Ignatiev et al. 2021).\n\n• (Relative to average explanation) Blanc, Lange, and Tan (2021) compute explanations that are small relative to the “certificate complexity” of the classifier $\\mathcal { M }$ , meaning the average size of the minimum sufficient reason where the average is taken over all possible instances $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ .\n\nNevertheless, there is a path toward even smaller explanations: probabilistic sufficient reasons (Wa¨ldchen et al. 2021; Izza et al. 2023a). As will be shown in Example 2, and is noted as a remark by Blanc, Lange, and Tan (2021), these can be significantly smaller than minimum size sufficient reasons.\n\n# 2 Probabilistic Sufficient Reasons\n\nThe main idea of probabilistic sufficient reasons is to relax the condition “all completions of the explanation y have the same class as ${ \\boldsymbol { x } } ^ { \\prime \\prime }$ to “a random completion of y has the same class as $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ with high probability”.\n\nLet us use notation $z \\sim \\mathbf { U } ( y )$ to denote that $z$ is a completion of $\\textbf {  { y } }$ drawn uniformly at random. With this notation we can define $\\delta$ -sufficient reasons:2\n\nDefinition 2 ((Wa¨ldchen et al. 2021)). For any $\\delta \\in [ 0 , 1 ]$ , a $\\delta$ -sufficient reason $\\mathit { \\Omega } _ { \\delta }$ -SR) for an instance $\\scriptstyle { \\pmb x }$ , is a partial instance $y \\subseteq x$ such that\n\n$$\n\\operatorname* { P r } _ { \\boldsymbol { z } \\sim \\mathbf { U } ( \\boldsymbol { y } ) } \\big [ \\mathcal { M } ( \\boldsymbol { z } ) = \\mathcal { M } ( \\boldsymbol { x } ) \\big ] \\gtrsim \\delta .\n$$\n\nNaturally, a minimum $\\delta$ -SR is a $\\delta \\mathrm { - } \\mathrm { S R }$ of minimum size. Note immediately that Definition 2 and Definition 1 coincide when $\\delta = 1$ .\n\n# 2.1 The size of $\\delta$ -SRs\n\nInterestingly, even a 0.999999-SR can be arbitrarily smaller, in terms of defined features, than the smallest sufficient reason (i.e., 1-SR) for a pair $( \\mathcal { M } , \\pmb { x } )$ , even when $\\mathcal { M }$ is a linear model, as we will illustrate in Example 2. Before providing the example, let us define linear models.\n\nDefinition 3. A (binary) linear model $\\mathcal { L }$ of dimension $d$ is a pair $( { \\pmb w } , t )$ , where $\\pmb { w } \\in \\mathbb { Q } ^ { d }$ and $t \\in \\mathbb { Q }$ . Its classification over an instance $\\scriptstyle { \\pmb x }$ is defined simply as\n\n$$\n\\mathcal { L } ( \\pmb { x } ) = \\left\\{ \\begin{array} { l l } { 1 } & { i f \\pmb { x } \\cdot \\pmb { w } \\geqslant t } \\\\ { 0 } & { o t h e r w i s e . } \\end{array} \\right.\n$$\n\nExample 2. Consider a linear model $\\mathcal { L }$ of dimension $d =$ 1000 with parameters $t = 1 2 5 0$ and\n\n$$\n\\pmb { w } = ( 1 0 0 0 , 1 , 1 , 1 , 1 , . . . , 1 ) .\n$$\n\nLet the instance x be $( 1 , 1 , 1 , 1 , 1 , . . . , 1 )$ , so that clearly $\\begin{array} { l l l } { { { \\mathcal L } ( { \\pmb x } ) } } & { { = } } & { { 1 } } \\end{array}$ . One can easily see that any 1-SR for x under $\\mathcal { L }$ has size 251, as it must include the first feature and any 250 other features. However, if we consider $\\pmb { y } = ( 1 , \\perp , \\overset { . } { \\bot } , \\perp , \\perp , . . . , \\overset { . } { \\bot } )$ , then a simple application of the Chernoff-Hoeffding concentration bound (in the appendix for the completeness) gives that\n\n$$\n\\operatorname* { P r } _ { z \\sim \\mathbf { U } ( y ) } \\Big [ \\mathcal { L } ( z ) = 1 \\Big ] \\geqslant 0 . 9 9 9 9 9 9 .\n$$\n\nThis suggests that we might say $\\begin{array} { r } { \\mathcal { L } ( \\pmb { x } ) = 1 } \\end{array}$ “because” $x _ { 1 } =$ 1; formally, $_ y$ is a 0.999999-SR, and 251 times smaller than any 1-SR for $\\mathcal { L } ( \\pmb { x } )$ .\n\nWe generalize this example as follows. Let $\\mathbf { M } \\mathbf { I N } ( \\mathcal { M } , \\pmb { x } , \\delta )$ denote the size of the smallest $\\delta$ -SR for $( { \\mathcal { M } } , { \\pmb x } )$ . Then, we have\n\nProposition 1. For any $\\delta \\in ( 0 , 1 )$ , $\\gamma > 0$ , and any $\\varepsilon > 0$ such that $\\delta + \\varepsilon \\leqslant 1$ , there are pairs $( { \\mathcal { L } } , { \\pmb x } )$ where $\\mathcal { L }$ is $a$ linear model of dimension $d ,$ , and $\\scriptstyle { \\pmb x }$ an instance of dimension $d ,$ , such that\n\n$$\n\\frac { \\mathrm { M I N } ( \\mathcal { L } , \\pmb { x } , \\delta + \\varepsilon ) } { \\mathrm { M I N } ( \\mathcal { L } , \\pmb { x } , \\delta ) } = \\Omega \\left( d ^ { \\frac { 1 } { 2 } - \\gamma } \\right) .\n$$\n\nProposition 1 showcases a key subtlety of $\\delta$ -SRs: a slight change in $\\delta$ might lead to large changes on the smallest explanation size.\n\n# 3 Approximating $\\delta$ -Sufficient Reasons\n\nUnfortunately, computing small $\\delta$ -SRs is computationally challenging, even when attempting to find approximate solutions. Let us contextualize our main result by summarizing first what is known about the complexity of computing $\\delta$ -SRs and their deterministic predecessors, 1-SRs.\n\nBarcelo´ et al. (2020) showed that computing a minimum 1-SR is $\\Sigma _ { 2 } ^ { p }$ -hard for neural networks, NP-hard for decision trees, and polynomial-time solvable for linear models. Then, Wa¨ldchen et al. (2021, Theorem 2.4) showed that computing minimum δ-SRs for neural networks is hard for NPPP, and Arenas et al. (2022) proved that even for the restricted class of decision trees, which are usually considered interpretable, minimum $\\delta$ -SRs cannot be computed in polynomial time unless ${ \\mathrm { P } } = { \\mathrm { N P } }$ (and neither can subset-minimal $\\delta$ -SRs for $\\delta < 1$ , in contrast to the $\\delta = 1$ setting which is in $\\mathrm { \\Delta P }$ (Izza, Ignatiev, and Marques-Silva 2020; Subercaseaux 2020)). For linear models, even computing the value\n\n$$\n\\operatorname* { P r } _ { z \\sim \\mathbf { U } y } \\left[ \\mathscr { L } ( z ) = \\mathscr { L } ( \\pmb { x } ) \\right]\n$$\n\nexactly is $\\# \\mathrm { P }$ -hard (Barcelo´ et al. 2020), from where the following is easy to show.3\n\nProposition 2. Given a linear model $\\mathcal { L }$ , an instance $\\scriptstyle { \\pmb x }$ , and $\\delta \\in [ 0 , 1 ]$ , the value $\\mathbf { M I N } ( \\mathcal { L } , \\pmb { x } , \\delta )$ cannot be computed in polynomial time unless $\\mathrm { F P } = \\# \\mathrm { P }$ .\n\nFurthermore, the situation does not improve if we aim to efficiently approximate the value $\\mathbf { M } \\mathbf { I N } ( \\bar { \\mathcal { M } } , \\pmb { x } , \\delta )$ . W¨aldchen et al. (2021, Theorem 2.5) studied general classifiers (e.g., neural networks) and showed that no algorithm can achieve an approximation factor of $d ^ { 1 - \\alpha }$ for this problem, where $d$ is the dimension of the classifier and $\\alpha > 0$ , unless $\\mathrm { P } = \\mathrm { N P }$ . Kozachinskiy (2023) proved that this approximation task is also hard for decision trees.\n\nHowever, these hardness results do not preclude the existence of efficient algorithms for computing or approximating $\\delta$ -SR for linear models. Hence, the goal of this section is to explore these questions for such models, given their practical importance.\n\n# 3.1 A Simple Relaxation: $( \\delta , \\varepsilon )$ -min-SR\n\nIn light of the hardness results for $\\delta$ -SRs, it is natural to consider a further relaxation that would allow for tractability. Consider for instance a customer of a bank who wants a 0.95-SR for why their application for a loan was rejected. Such an explanation would consist of a small number of features of their application profile that are relevant to the decision since $9 5 \\%$ of applicants with such a profile would also get rejected. We expect that, in such a scenario, the user would not particularly care if the explanation she obtains holds for $9 \\hat { 5 } \\%$ of potential applicants or for $9 4 . 9 9 9 7 \\%$ of them. In other words, the value of $\\delta$ is chosen in a trade-off between the size of the explanation and the desired level of confidence or “explanation power”. We posit that in such a trade-off, the user is more sensitive to increases in the explanation size than they are to a minor perturbation in $\\delta$ , the probability guarantee. As we showed in Proposition 1, by changing $\\delta$ very slightly, the size of the best explanation can change significantly. This motivates the following definition:\n\nDefinition 4 ( $( \\delta , \\varepsilon )$ -min-SR). Given a model $\\mathcal { M }$ , an instance $\\scriptstyle { \\pmb x }$ , and values $\\delta , \\varepsilon \\in ( 0 , 1 )$ , we say a partial instance $_ y$ of size is $a$ $( \\delta , \\varepsilon )$ -min-SR if there exists a value $\\delta ^ { \\star } \\in [ \\delta - \\varepsilon , \\delta + \\varepsilon ]$ such that $_ y$ is a minimum $\\delta ^ { \\star } \\lrcorner S R$ for $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ under $\\mathcal { M }$ .\n\nNote that, even though the guarantee of a $( \\delta , \\varepsilon )$ -min-SR is symmetric around $\\delta$ , our definition is such that the ability of efficiently computing $( \\delta , \\varepsilon )$ -min-SRs is enough for the following two tasks:\n\n1. A user wants an explanation as small as possible and of probability “close” to $\\delta$ . Then, by computing a $( \\delta -$ $\\varepsilon / 2 , \\varepsilon / 2 )$ -min-SR, they obtain an explanation whose probability guarantee is at most $\\varepsilon$ away from $\\delta$ , and is no larger in size than the minimum $\\delta$ -SR.   \n2. The owner of the model wants to offer a $\\delta$ -SR that is as small as possible to a customer, and they want to be strict on the $\\delta$ part, since offering a $( \\delta - \\varepsilon )$ -SR would be misleading and could lead to legal issues. Then, by computing a $( \\bar { \\delta } + \\varepsilon / 2 , \\varepsilon / 2 )$ -min-SR, they can guarantee that the explanation is at least $\\delta \\mathrm { - } S \\mathbf { R }$ , while still being likely much smaller than a minimum 1-SR.\n\nThe inapproximability result of Kozachinskiy (2023) can be translated to the $( \\delta , \\bar { \\varepsilon ) }$ -min-SR problem as follows:\n\nTheorem 1 (Kozachinskiy (2023), Theorem 1). Unless SAT can be solved in quasi-polynomial times, one cannot compute a $( \\delta , \\varepsilon )$ -min-SR for decision trees in polynomial time, and furthermore, any polynomial-time algorithm that guarantees to provide a $\\delta ^ { \\prime }$ -SR for some $\\delta ^ { \\prime } \\in \\bar { [ \\delta - \\varepsilon , \\delta + \\varepsilon ] }$ will produce explanations that are up to $\\Omega ( \\bar { d } ^ { 1 - \\alpha } )$ times larger than any $( \\delta , \\varepsilon )$ -min-SR, for any $\\alpha > 0$ .\n\nNote that this hardness result for decision trees implies in turn hardness for neural networks by using standard compilation techniques (Barcelo´ et al. 2020). Our main result is that, for linear models, we can efficiently compute $( \\delta , \\varepsilon )$ -min-SRs, making them the first class of models for which we have such a positive result. To state our runtime more cleanly, we use the standard notation ${ \\tilde { O } } ( f )$ to mean $O ( f \\cdot \\log ( f ) ^ { c } )$ for some positive constant $c \\in \\mathbb { R }$ .\n\nTheorem 2. Given a linear model $\\mathcal { L }$ and an input $\\scriptstyle { \\pmb x }$ , we can compute a $( \\delta , \\varepsilon )$ -min-SR successfully with probability $1 - \\gamma$ in time $\\begin{array} { r } { \\widetilde { O } \\left( \\frac { d } { \\varepsilon ^ { 2 } \\gamma ^ { 2 } } \\right) } \\end{array}$ ; that is, polynomial in $d , 1 / \\varepsilon$ , and $1 / \\gamma$ .\n\nWe remark that previous approaches for computing approximate probabilistic explanations lacked theoretical guarantees on the size of the explanations produced (Izza et al. 2023b, 2021; Izza, Meel, and Marques-Silva 2024).\n\nIn order to prove Theorem 2 we will need two main ideas: first, the fact that we can estimate the probabilities of models accepting a partial instance through sampling (which is already present in the work of Izza, Meel, and Marques-Silva (2024)), and second, that under the uniform distribution it is easy to decide which features ought to be part of small explanations over linear models.\n\n# 3.2 Estimating the Probability of Acceptance\n\nThe hardness of computing $\\mathrm { P r } _ { z \\sim \\mathbf { U } ( \\pmb { y } ) } [ \\mathcal { M } ( z ) = 1 ]$ is about computing it to arbitrarily high precision, i.e., with an additive error within $O ( 2 ^ { - d } )$ . However, computing a less precise estimation of $\\mathrm { P r } _ { z \\sim \\mathbf { U } ( \\pmb { y } ) } [ \\mathcal { M } ( z ) = 1 ]$ is simple, as the next fact (which is a direct consequence of Hoeffding’s inequality) states.\n\nFact 1. Let $f$ be an arbitrary boolean function on n variables. Let $M$ be any positive integer, and let $\\pmb { x } _ { 1 } , \\ldots , \\pmb { x } _ { M }$ be $M$ uniformly random samples from $\\{ 0 , 1 \\} ^ { n }$ . Then\n\n$$\n{ \\widehat { \\mu } } ( M ) : = { \\frac { \\sum _ { i = 1 } ^ { M } [ f ( \\pmb { x } _ { i } ) = 1 ] } { M } }\n$$\n\nis an unbiased estimator for\n\n$$\n\\mu : = \\operatorname* { P r } _ { \\pmb { x } \\in \\{ 0 , 1 \\} ^ { n } } [ f ( \\pmb { x } ) = 1 ] ,\n$$\n\nand $\\operatorname* { P r } [ | \\widehat { \\mu } ( M ) - \\mu | \\leqslant t ] \\geqslant 1 - 2 \\exp ( - 2 t ^ { 2 } M )$ , which is at least $1 - \\gamma$ for $\\begin{array} { r } { M = \\frac { 1 } { 2 t ^ { 2 } } \\log ( 2 / \\gamma ) } \\end{array}$ .\n\nAs a consequence of the previous idea, although a minimum $\\delta$ -SR might be hard to compute, this crucially depends on the value of $\\delta$ . In order to deal with this, our algorithm will sample a value $\\delta ^ { \\star }$ uniformly at random from $\\bar { [ \\delta \\mathrm { ~ - ~ } } \\varepsilon , \\delta \\mathrm { ~ + ~ } \\varepsilon ]$ , and then compute a minimum $\\delta ^ { \\star } \\ – S \\mathbf { R }$ . Intuitively, the idea is that as $\\delta ^ { \\star }$ is chosen at random, it will be unlikely that a value that makes the computation hard is chosen.\n\nBefore proving Theorem 2, we need to prove a lemma concerning the easiness of selecting the features of the desired explanation.\n\n# 3.3 Feature Selection\n\nEven if we were granted an oracle computing the probabilities $\\operatorname* { P r } _ { z \\in \\mathbf { D } ( \\pmb { y } ) } [ \\mathcal { \\bar { M } } ( z ) = 1 ]$ , that would not be necessarily enough to efficiently compute a minimum $\\delta$ -SR. Indeed, for decision trees, the counting problem can be easily solved in polynomial time (Barcelo´ et al. 2020), and yet the computation of $\\delta$ -SRs of minimum size is hard, even to approximate (Arenas et al. 2022; Kozachinskiy 2023). Intuitively, the problem for decision trees is that, even if we were told that the minimum $\\delta \\cdot$ -SR has exactly $k$ features, it is not obvious how to search for it better than enumerating all $\\textstyle { \\binom { d } { k } }$ subsets. The case of linear models, however, is different, at least under the uniform distribution. In this case, every feature $i$ that is not part of the explanation will take value 0 or 1 independently with probability $^ 1 / 2$ , and contribute to the classification according to its weight $w _ { i }$ . In other words, we can sort the features according to their weights (with some care about signs), and select them greedily to build a small $\\delta$ -SR. A proof for the deterministic case $\\langle \\delta \\ = \\ 1 \\rangle$ ) was already given in (Barcelo´ et al. 2020) and sketched earlier on by (Marques-Silva et al. 2020a).\n\nDefinition 5. Given a linear model $\\mathcal { L } = ( \\boldsymbol { w } , t )$ , and an instance $\\textbf { \\em x }$ , both having dimension $d$ , we define the score of feature $i \\in [ d ]$ as\n\n$$\ns _ { i } : = w _ { i } \\cdot ( 2 x _ { i } - 1 ) \\cdot ( 2 { \\mathcal { L } } ( { \\boldsymbol { \\mathbf { \\mathit { x } } } } ) - 1 ) .\n$$\n\nIn other words, the sign of $s _ { i }$ is $+ 1$ if the feature is “helping” the classification, and $- 1$ if it is “hurting” it. The magnitude of $s _ { i }$ is proportional to the weight of the feature $i$ . Changing the value of feature $i$ in an instance $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ would decrease ${ \\pmb w } \\cdot { \\pmb x }$ by $s _ { i }$ if $\\begin{array} { r } { \\mathcal { L } ( \\pmb { x } ) ~ = ~ 1 } \\end{array}$ , and increase it by $s _ { i }$ if $\\begin{array} { l } { \\displaystyle \\mathcal { L } ( \\boldsymbol { x } ) ~ = ~ 0 } \\end{array}$ . For the uniform distribution (or more generally, any distribution in which all features are Bernoulli variables with the same parameter), we can prove the following lemma that basically states that, for linear models it is good to choose features greedily according to their score.\n\nLemma 1. Given a linear model $\\mathcal { L }$ , and an instance $\\textbf { \\em x }$ , if $\\pmb { y } ^ { ( 0 ) } , \\ldots , \\pmb { y } ^ { ( d ) }$ are the partial instances of $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ such that ${ \\pmb y } ^ { ( k ) } \\subseteq$ $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ is defined only in the top $k$ features of maximum score, then\n\n$$\n\\operatorname* { P r } _ { z \\sim \\mathbf { U } ( y ^ { ( k + 1 ) } ) } \\big [ \\mathcal { L } ( z ) = \\mathcal { L } ( \\pmb { x } ) \\big ] \\geqslant \\operatorname* { P r } _ { z \\sim \\mathbf { U } ( y ^ { ( k ) } ) } \\big [ \\mathcal { L } ( z ) = \\mathcal { L } ( \\pmb { x } ) \\big ]\n$$\n\nfor all $0 \\in \\{ 1 , \\ldots , d - 1 \\}$ , and naturally,\n\n$$\n\\operatorname* { P r } _ { z \\sim \\mathbf { U } ( y ^ { ( d ) } ) } [ \\mathscr { L } ( z ) = \\mathscr { L } ( { \\pmb { x } } ) ] = 1 .\n$$\n\nMoreover, $\\mathbf { M } \\mathrm { I N } ( \\mathcal { L } , \\pmb { x } , \\delta ) = k$ if and only if $\\mathbf { \\boldsymbol { y } } ^ { ( k ) }$ is a $\\delta$ -SR for $\\scriptstyle { \\pmb x }$ , and either $k = 0$ or $\\pmb { y } ^ { ( k - 1 ) }$ is not a $\\delta$ -SR for $\\scriptstyle { \\mathbf { { \\boldsymbol { x } } } }$ .\n\nEven though a proof of Lemma 1 is presented in the supplementary material, let us provide a self-contained example to help convince a reader of the veracity of the lemma.\n\n<html><body><table><tr><td>Partialinstance</td><td>Features included</td><td>Probability</td></tr><tr><td></td><td>{1,3}</td><td>7/8</td></tr><tr><td></td><td>{1,4}</td><td>8</td></tr><tr><td></td><td>{3,4}</td><td></td></tr><tr><td></td><td>{3,5}</td><td>3/8</td></tr><tr><td></td><td>{2,3}</td><td>3/8</td></tr><tr><td></td><td>{1,5}</td><td>3/8</td></tr><tr><td></td><td>{1,2}</td><td>3/8</td></tr><tr><td></td><td>{4,5}</td><td>1/4</td></tr><tr><td></td><td>{2,4}</td><td></td></tr><tr><td></td><td>{2,5}</td><td>1/4 1/8</td></tr></table></body></html>\n\nTable 1: Table of probabilities associated to Example 3.\n\nExample 3. Consider an instance $\\pmb { x } = ( 1 , 0 , 0 , 1 , 1 )$ and the linear model $\\mathcal { L }$ be defined by\n\n$$\n{ \\pmb w } = ( 5 , 1 , - 3 , 2 , - 1 ) \\quad ; \\quad t = 5 .\n$$\n\nIt is easy to check that ${ \\pmb w } \\cdot { \\pmb x } = 6$ , and thus $\\begin{array} { r } { \\mathcal { L } ( \\pmb { x } ) = 1 } \\end{array}$ . The feature scores, according to Definition 5, are:\n\n$$\ns _ { 1 } = 5 , \\ s _ { 2 } = - 1 , \\ s _ { 3 } = 3 , \\ s _ { 4 } = 2 , \\ s _ { 5 } = - 1 .\n$$\n\nFor the first part, the main idea is that a positive score $s _ { i }$ means that the feature is helping the classification (i.e., adding it to a partial instance does not decrease its probability guarantee), while a negative score means that the feature is hurting the classification (i.e., adding it to a partial instance does not increase its probability guarantee). Because the partial instances\n\n$$\n\\pmb { y } ^ { ( 0 ) } \\subseteq \\pmb { y } ^ { ( 1 ) } \\subseteq \\cdot \\cdot \\cdot \\pmb { y } ^ { ( d ) }\n$$\n\nare obtained by adding a single feature at a time, and thus features are added in decreasing order of their scores, then this procedure will have two phases: (i) First, it will add features with a positive score, which raise or maintain the probability of the classification being the same as x, as the lemma says, and then (ii) it will start adding features with a negative score, which would seem to contradict the lemma, but it turns out that at that point the partial instance $\\mathbf { \\boldsymbol { y } } ^ { ( k ) }$ would have probability guarantee 1; this is because $\\pmb { y } ^ { ( d ) } = \\pmb { x }$ , which trivially has probability guarantee 1. Table 2 presents the probabilities associated to the partial instances $\\pmb { y } ^ { ( 0 ) } , \\ldots , \\bar { \\pmb { y } } ^ { ( d ) }$ .\n\nFor the second part, consider the partial instances $\\boldsymbol { y } ^ { \\star } =$ $( \\bot , 0 , 0 , 1 , 1 )$ and ${ \\pmb y } ^ { \\dagger } = ( 1 , \\bot , 0 , \\dot { 1 } , 1 )$ . The instance $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ is a completion of both $y ^ { \\star }$ and $y ^ { \\dagger }$ , but $y ^ { \\star }$ also has completion $\\pmb { x } ^ { \\star } = ( 0 , 0 , 0 , 1 , 1 )$ , whereas $y ^ { \\dagger }$ has also completion ${ \\pmb x } ^ { \\dagger } =$ $( 1 , 1 , 0 , 1 , 1 )$ . Note that ${ \\pmb w } \\cdot { \\pmb x } ^ { \\star } = 1 = { \\pmb w } \\cdot { \\pmb x } - s _ { 1 }$ , whereas ${ \\pmb w } \\cdot { \\pmb x } ^ { \\dagger } = 6 = { \\pmb w } \\cdot { \\pmb x } - s _ { 2 }$ . Intuitively, this means that it is better to keep feature 1 as part of the explanation, but not feature 2. If we want an explanation with only two features, we should choose feature 1 and feature 3, as they have the highest scores. Indeed, Table 1 presents the probabilities to all possible explanations of size 2.\n\nWith Lemma 1 in hand, we can proceed to prove Theorem 2.\n\nTable 2: Table of probabilities associated to Example 3. The last column denotes the score of the feature added to the partial instance in that row with respect to the previous row.   \nAlgorithm 1: LinearMonteCarloExplainer   \n\n<html><body><table><tr><td>Partial instance Features</td><td>Probability</td><td>Score</td></tr><tr><td>y(0） (⊥，⊥，⊥，⊥,⊥)</td><td>1/4</td><td>-</td></tr><tr><td>(1,⊥，⊥,⊥，⊥) 3(1)</td><td>1/2</td><td>5</td></tr><tr><td>(1,⊥,0,⊥,⊥) y(2)</td><td>7/8</td><td>3</td></tr><tr><td>(1,⊥,0,1,⊥) y(3)</td><td>1/1</td><td>2</td></tr><tr><td>(1,0,0,1,⊥) 3(4)</td><td>1/1</td><td>-1</td></tr><tr><td>(1, 0, 0, 1, 1) (5)</td><td>1/1</td><td>-1</td></tr></table></body></html>\n\nProof of Theorem 2. We use Algorithm 1. Let us define the partial instances ${ \\pmb y } ^ { ( 0 ) } , { \\pmb y } ^ { ( 1 ) } \\ldots , { \\bar { \\pmb y } } ^ { ( d ) }$ so that ${ \\pmb y } ^ { ( k ) } \\subseteq { \\pmb x }$ is the partial instance defined only in the $k$ features with maximum score (line 6). We then define a sequence of values $v _ { k }$ as\n\n$$\nv _ { k } : = \\operatorname* { P r } _ { z \\sim \\mathbf { U } ( \\pmb { y } ^ { ( k ) } ) } [ \\mathscr { L } ( z ) = \\mathscr { L } ( \\pmb { x } ) ] ,\n$$\n\nand note that due to Lemma 1, the sequence $v _ { 0 } , \\ldots , v _ { d }$ is non-decreasing. Let $\\begin{array} { r } { M = \\frac { \\log ^ { 2 } d } { 2 \\varepsilon ^ { 2 } \\gamma ^ { 2 } } \\log ( 2 \\log d / \\gamma ) } \\end{array}$ , as in line 8, and let us define random variables $\\widetilde { v _ { k } }$ as follows: if Algorithm 1 enters line 13 with $m \\ = \\ k$ ,rthen $\\widetilde { v _ { k } }$ is the output of Algorithm 2 (i.e., $\\widehat { v } _ { k } ( M ) )$ , and otherw er $\\tilde { v _ { k } } \\ = \\ v _ { k }$ . We use binary search (lines 10-19), to find $k ^ { \\star }$ , the smallest $k$ such that $\\tilde { v _ { k } } \\geqslant \\delta ^ { \\star }$ , and our goal is to show that with good probability $k ^ { \\star }$ is also the smallest $k$ such that $v _ { k } \\geqslant \\delta ^ { \\star }$ , which would imply the correctness of the algorithm by Lemma 1. Note, however, that even though the sequence $v _ { 0 } , \\ldots , v _ { d }$ is non-decreasing (Lemma 1), the estimated values $\\widehat { v _ { k } }$ are not necessarily so. Let $S$ be a random variable corresponding to the set of values $k$ such that Algorithm 1 enters line 13 with $m = k$ , and note that if for every $k$ in $S$ it happens that the events\n\n$$\nA _ { k } : = \\left( v _ { k } \\geqslant \\delta ^ { \\star } \\right) \\mathrm { ~ a n d ~ } B _ { k } : = \\left( \\tilde { v _ { k } } \\geqslant \\delta ^ { \\star } \\right)\n$$\n\nare equivalent (i.e., either both occur or neither occurs), then the algorithm will succeed, as that would indeed imply that $k ^ { \\star }$ is the smallest $k$ such that $v _ { k } \\geqslant \\delta ^ { \\star }$ .\n\nThen, for $k \\in [ d ]$ , define events $E _ { k }$ and $F _ { k }$ as follows:\n\n$$\n\\begin{array} { r } { E _ { k } : = | \\delta ^ { \\star } - v _ { k } | \\geqslant \\displaystyle \\frac { \\varepsilon \\gamma } { \\log d } , } \\\\ { F _ { k } : = | \\widetilde { v _ { k } } - v _ { k } | \\leqslant \\displaystyle \\frac { \\varepsilon \\gamma } { \\log d } . } \\end{array}\n$$\n\nWe claim that if both $E _ { k }$ and $F _ { k }$ hold for some $k$ , then $A _ { k }$ and $B _ { k }$ are equivalent events for that $k$ . Indeed,\n\n$$\n\\begin{array} { r l } & { A _ { k } \\iff v _ { k } \\geqslant \\delta ^ { \\star } } \\\\ & { \\iff v _ { k } \\geqslant \\delta ^ { \\star } + \\frac { \\varepsilon \\gamma } { \\log d } } \\\\ & { \\iff v _ { k } - \\frac { \\varepsilon \\gamma } { \\log d } \\geqslant \\delta ^ { \\star } } \\\\ & { \\iff \\tilde { v _ { k } } \\geqslant \\delta ^ { \\star } } \\\\ & { \\iff B _ { k } . } \\end{array}\n$$\n\nInput: Linear model $\\mathcal { L }$ , instance $\\scriptstyle { \\pmb x }$ , parameters $\\delta \\in ( 0 , 1 )$ Parameter: $ { \\varepsilon } \\in ( 0 , 1 )$ , $\\gamma \\in ( 0 , 1 )$   \nOutput: A value $\\delta ^ { \\star } \\in [ \\delta - \\varepsilon , \\delta + \\varepsilon ]$ together with a minimum $\\delta ^ { \\star }$ -SR explanation for $\\scriptstyle { \\pmb x }$ .\n\n1: $\\delta ^ { \\star } \\gets$ uniformly random sample from $[ \\delta - \\varepsilon , \\delta + \\varepsilon ]$   \n2: for $i \\in \\{ 1 , \\ldots , d \\}$ do   \n3: $s _ { i } \\gets w _ { i } \\cdot ( 2 x _ { i } - 1 ) \\cdot ( 2 \\mathcal { L } ( \\pmb { x } ) - 1 )$   \n4: end for   \n5: for $k \\in \\{ 0 , 1 \\ldots , d \\}$ do   \n6: Let ${ \\pmb y } ^ { ( k ) } \\subseteq { \\pmb x }$ be the partial instance defined only in   \nthe top $k$ features with maximum score $s _ { i }$ .   \n7: end for   \n8: $M \\gets ( \\log ^ { 2 } d ) / ( 2 \\varepsilon ^ { 2 } \\gamma ^ { 2 } ) \\log ( 2 \\log d / \\gamma )$   \n9: $\\mathrm { L B } \\gets 0$ , $\\mathrm { U B } \\gets d$ , and $\\mathrm { \\Delta S T E P S  0 }$   \n10: while $\\mathbf { L B } \\neq \\mathbf { U B }$ and STEPS $\\leqslant \\log d$ do   \n11: $\\mathrm { S T E P S  \\mathrm { S T E P S + 1 } }$   \n12: $\\begin{array} { r } { \\begin{array} { r } { m \\gets \\left( \\mathbf { L B } + \\mathbf { U B } \\right) / 2 } \\\\ { \\widehat { v } _ { m } \\gets \\mathbf { M o N T E C A R L O E S T I M A T I O N } \\left( \\mathcal { L } , \\pmb { y } ^ { ( m ) } , \\pmb { x } , M \\right) } \\end{array} } \\end{array}$   \n13:   \n14: if $\\hat { v } _ { m } \\geqslant \\delta ^ { \\star }$ then   \n15: $\\mathrm { U B } \\gets m$   \n16: else   \n17: $\\mathbf { L B } \\gets ( m + 1 )$   \n18: end if   \n19: end while   \n20: $k ^ { \\star } \\gets \\mathrm { L B }$ (or equivalently, UB)   \n21: return $( \\delta ^ { \\star } , \\pmb { y } ^ { ( \\bar { k } ^ { \\star } ) } )$\n\nThus, if we show that $E _ { k }$ and $F _ { k }$ hold with good probability for every $k \\in S$ , we can conclude the theorem. Notice first that, because of the condition on the variable STEPS (lines 10, 11) we have $| S | \\leqslant \\log d$ , allowing us to do a binary search in case the desired events $E _ { k }$ and $F _ { k }$ hold, and preventing the algorithm from looping otherwise; this way the runtime is controlled not only on expectation but deterministically. 4 Then, note that for any $k$ we have5\n\n$$\n\\begin{array} { r } { \\operatorname* { P r } \\left[ \\overline { { F _ { k } } } \\right] \\leqslant \\operatorname* { P r } \\left[ \\overline { { F _ { k } } } \\mid k \\in { \\cal S } \\right] = \\operatorname* { P r } \\left[ \\left| \\hat { v _ { k } } ( M ) - v _ { k } \\right| > \\frac { \\varepsilon \\gamma } { \\log d } \\right] } \\\\ { \\leqslant \\frac { \\gamma } { \\log d } . \\qquad \\mathrm { ( b y ~ F a c t ~ 1 ) } } \\end{array}\n$$\n\nBecause $S$ itself is a random variable, whose size is also a random variable, we need to be careful before applying a union bound or any related tricks. Let us refer to the elements of $S$ as $\\{ s _ { 1 } , \\ldots , s _ { \\ell } \\}$ , and let us denote $F ( i )$ for $i \\in [ \\log d ]$ to the event $F _ { s _ { i } }$ if $i \\leqslant \\ell$ , and to the sample space $\\Omega$ (i.e., the event that always happens) otherwise.6 Then, we\n\nAlgorithm 2: MonteCarloEstimation\n\nInput: Linear model $\\mathcal { L }$ , a partial instance $_ y$ , an instance $\\scriptstyle { \\pmb x }$ , and a number of samples $M$ Output: An estimate $\\widehat { v }$ of $\\mathrm { P r } _ { z \\sim \\mathbf { U } ( \\pmb { y } ) } [ \\mathcal { L } ( z ) = \\mathcal { L } ( \\pmb { x } ) ]$ .\n\n1: $\\widehat { \\boldsymbol { v } } \\gets 0$   \n2: for $i = 1$ to $M$ do   \n3: Sample $z \\sim \\mathbf { U } ( y )$   \n4: if $\\begin{array} { r } { \\pmb { \\mathcal { L } } ( \\pmb { z } ) = \\pmb { \\mathcal { L } } ( \\pmb { x } ) } \\end{array}$ then   \n5: $\\widehat { v } \\gets \\widehat { v } + 1$   \n6: end if   \n7: end for   \n8: return $\\widehat { v } / M$\n\nclaim that for any $1 \\leqslant i \\neq j \\leqslant \\lceil \\log d \\rceil$ , we have\n\n$$\n\\operatorname* { P r } [ F ( i ) \\cap F ( j ) ] = \\operatorname* { P r } [ F ( i ) ] \\cdot \\operatorname* { P r } [ F ( j ) ] ,\n$$\n\nas either $\\operatorname* { m a x } \\{ i , j \\} \\leqslant \\ell$ , in which case the claim holds by independence (since both events depend only on disjoint sets of independent random samples), or the claim holds trivially since $\\bar { \\mathrm { P r } } [ F ( i ) ] = 1$ for $i > \\ell$ . Therefore, we have\n\n$$\n\\begin{array} { l } { { \\displaystyle \\operatorname* { P r } \\left[ \\displaystyle \\bigcap _ { k \\in S } F _ { k } \\right] = \\operatorname* { P r } \\left[ F ( 1 ) \\cap F ( 2 ) \\cap \\cdots \\cap F ( \\lceil \\log d \\rceil ) \\right] } \\ ~ } \\\\ { { \\displaystyle \\qquad = \\prod _ { i \\in [ \\log d ] } \\operatorname* { P r } [ F ( i ) ] \\qquad ( \\mathrm { b y ~ E q u a t i o n ~ ( } \\log b \\in \\lceil \\log d \\rceil ) ) } \\ ~ } \\\\ { { \\displaystyle \\qquad \\geqslant \\left( 1 - \\frac { \\gamma } { \\log d } \\right) ^ { \\log d } \\geqslant 1 - \\gamma } . } \\end{array}\n$$\n\nWe now argue that the event $\\cap _ { k \\in S } E _ { k }$ happens with good probability. To see that, note first that for every $k \\in [ d ]$ , line 1 implies\n\n$$\n\\operatorname* { P r } [ \\overline { { E _ { k } } } ] = \\operatorname* { P r } \\bigg [ \\delta ^ { \\star } \\in \\bigg [ v _ { k } \\pm \\frac { \\varepsilon \\gamma } { \\log d } \\bigg ] \\bigg ] \\leqslant \\frac { \\frac { 2 \\varepsilon \\gamma } { \\log d } } { 2 \\varepsilon } = \\frac { \\gamma } { \\log d } .\n$$\n\nOnce again, we need to be careful as the events $E _ { k }$ are not independent of $S$ , nor between them this time. Using the law of total probabilities, we have\n\n$$\n\\begin{array} { r l r } & { } & { \\mathrm { P r } \\left[ \\displaystyle \\bigcap _ { k \\in S } E _ { k } \\right] = \\displaystyle \\sum _ { S ^ { \\prime } \\subseteq [ d ] } \\mathrm { P r } \\left[ S = S ^ { \\prime } \\mid \\displaystyle \\bigcap _ { k \\in S ^ { \\prime } } E _ { k } \\right] \\mathrm { P r } \\left[ \\displaystyle \\bigcap _ { k \\in S ^ { \\prime } } E _ { k } \\right] } \\\\ & { } & { = \\displaystyle \\sum _ { S ^ { \\prime } \\subseteq [ d ] } \\mathrm { P r } \\left[ S = S ^ { \\prime } \\mid \\displaystyle \\bigcap _ { k \\in S ^ { \\prime } } E _ { k } \\right] \\mathrm { P r } \\left[ \\displaystyle \\bigcap _ { k \\in S ^ { \\prime } } E _ { k } \\right] , } \\\\ & { } & { | S ^ { \\prime } | \\leqslant \\log d } \\end{array}\n$$\n\nwhere we can now effectively use the union bound to say that for any fixed $S ^ { \\prime }$ with $| S ^ { \\prime } | \\leqslant \\log d$ we have\n\n$$\n\\operatorname* { P r } \\left[ \\bigcap _ { k \\in S ^ { \\prime } } E _ { k } \\right] \\geqslant 1 - \\gamma .\n$$\n\nTherefore, we conclude that\n\n$$\n\\begin{array} { l } { { \\displaystyle \\operatorname* { P r } \\left[ \\bigcap _ { k \\in S } E _ { k } \\right] = \\sum _ { \\stackrel { S ^ { \\prime } \\subseteq [ d ] } { | S ^ { \\prime } | \\leqslant \\log d } } \\operatorname* { P r } \\left[ S = S ^ { \\prime } \\bigm | \\bigcap _ { k \\in S ^ { \\prime } } E _ { k } \\right] \\operatorname* { P r } \\left[ \\bigcap _ { k \\in S ^ { \\prime } } E _ { k } \\right] } } \\\\ { { \\displaystyle \\operatorname* { P r } \\left( 1 - \\gamma \\right) \\sum _ { \\stackrel { S ^ { \\prime } \\subseteq [ d ] } { | S ^ { \\prime } | \\leqslant \\log d } } \\operatorname* { P r } \\left[ S = S ^ { \\prime } \\bigm | \\bigcap _ { k \\in S ^ { \\prime } } E _ { k } \\right] } . } \\end{array}\n$$\n\nRecall that $\\operatorname* { P r } [ F _ { k } | k \\notin S ] \\geqslant \\operatorname* { P r } [ F _ { k } | k \\in S ]$ for any $k$ , from where it follows that for every set $S ^ { \\prime }$ of size at most $\\log d$ we have $\\begin{array} { r } { \\operatorname* { P r } \\left[ \\bigcap _ { k \\in S ^ { \\prime } } F _ { k } \\right] \\geqslant \\operatorname* { P r } \\left[ \\bigcap _ { k \\in S } F _ { k } \\right] } \\end{array}$ . Then, note that for any index $k \\in [ d ]$ , the event $F _ { k }$ is conditionally independent of all events $E _ { j }$ , with $j \\in [ d ]$ given the event $k \\in S$ . That is, $\\operatorname* { P r } \\left[ F _ { k } | k \\in S \\right] = \\operatorname* { P r } \\left[ F _ { k } | E _ { j } , k \\in S \\right]$ for any $j \\in [ d ]$ . We thus deduce that for any fixed $\\bar { S ^ { \\prime } }$ with $| S ^ { \\prime } | \\leqslant \\log d$ we have\n\n$$\n\\begin{array} { r l } & { \\operatorname* { P r } \\left[ \\displaystyle \\bigcap _ { k \\in S ^ { \\prime } } F _ { k } \\mid \\displaystyle \\bigcap _ { k \\in S ^ { \\prime } } E _ { k } \\right] \\geqslant \\operatorname* { P r } \\left[ \\displaystyle \\bigcap _ { k \\in S ^ { \\prime } } F _ { k } \\mid \\displaystyle \\bigcap _ { k \\in S ^ { \\prime } } E _ { k } \\cap \\{ k \\in S \\} \\right] } \\\\ & { \\qquad = \\operatorname* { P r } \\left[ \\displaystyle \\bigcap _ { k \\in S ^ { \\prime } } F _ { k } \\mid \\displaystyle \\bigcap _ { k \\in S ^ { \\prime } } k \\in S \\right] } \\\\ & { \\qquad \\geqslant \\operatorname* { P r } \\left[ \\displaystyle \\bigcap _ { k \\in S } F _ { k } \\right] \\geqslant ( 1 - \\gamma ) . } \\end{array}\n$$\n\nThen our key observation is that there is a single value $S ^ { \\star } \\subseteq$ $[ d ]$ , with $| S ^ { \\star } | \\leqslant \\log d$ , that the binary search can take if we condition on all the events $E _ { k }$ and $F _ { k }$ happening, since in that case events $\\boldsymbol { A } _ { k }$ and $B _ { k }$ coincide. In other words, there exists $S ^ { \\star }$ , with $S ^ { \\star } \\subseteq [ d ]$ and $| S ^ { \\star } | \\leqslant \\log d$ , such that\n\n$$\n\\operatorname* { P r } \\Bigg [ S = S ^ { \\star } \\mid \\bigcap _ { k \\in S ^ { \\star } } E _ { k } \\cap \\bigcap _ { k \\in S ^ { \\star } } F _ { k } \\Bigg ] = 1 .\n$$\n\nWe can then argue as follows:\n\n$$\n\\mathrm { P r } \\left[ \\bigcap _ { k \\in S } E _ { k } \\right] \\geqslant ( 1 - \\gamma ) \\sum _ { { S ^ { \\prime } } \\subseteq [ d ] } \\mathrm { P r } \\left[ S = S ^ { \\prime } \\bigm | \\bigcap _ { k \\in S ^ { \\prime } } E _ { k } \\right]\n$$\n\n$$\n\\begin{array} { r l } & { \\ g \\left( 1 - \\gamma \\right) \\operatorname* { P r } \\Bigg [ S = S ^ { * } \\ \\underset { k \\in S ^ { * } } { \\bigcap } \\ E _ { k } \\Bigg ] } \\\\ & { \\ g \\left( 1 - \\gamma \\right) \\operatorname* { P r } \\Bigg [ S = S ^ { * } \\underset { k \\in S ^ { * } } { \\bigcap } \\ F _ { k } \\ \\underset { k \\in S ^ { * } } { \\prod } \\ E _ { k } \\Bigg ] } \\\\ & { = \\left( 1 - \\gamma \\right) \\operatorname* { P r } \\Bigg [ S = S ^ { * } \\ \\underset { k \\in S ^ { * } } { \\bigcap } \\ \\underset { k \\in S ^ { * } } { \\prod } \\ F _ { k } \\ \\underset { k \\in S ^ { * } } { \\prod } \\ F _ { k } \\Bigg ] } \\\\ & { \\qquad \\cdot \\ \\operatorname* { P r } \\Bigg [ \\underset { k \\in S ^ { * } } { \\prod } \\ F _ { k } \\ \\underset { k \\in S ^ { * } } { \\prod } \\ E _ { k } \\Bigg ] } \\\\ & { \\ g \\left( 1 - \\gamma \\right) ^ { 2 } . } \\end{array}\n$$\n\nTherefore, the algorithm will succeed with probability at least\n\n$$\n\\operatorname* { P r } \\left[ \\bigcap _ { k \\in S } E _ { k } \\right] \\cdot \\operatorname* { P r } \\left[ \\bigcap _ { k \\in S } F _ { k } \\right] \\geqslant ( 1 - \\gamma ) ^ { 3 } \\geqslant 1 - 3 \\gamma .\n$$\n\nThe runtime is simply $O ( \\log d \\cdot M \\cdot d )$ ; as (i) the binary search performs $O ( \\log d )$ steps; (ii) each of the binary search steps requires $M$ samples, and (iii) each sample requires evaluating the model $\\mathcal { L }$ and thus takes time $O ( d )$ . Naturally, running the algorithm with $\\gamma ^ { \\prime } = 1 / 3 \\cdot \\gamma$ will yield a success probability of $1 - \\gamma$ without changing the asymptotic runtime, and thus we conclude the proof.\n\n# 4 Locally Minimal Probabilistic Explanations\n\nDue to the complexity of finding even subset-minimal $\\delta \\cdot$ - SR, Izza, Meel, and Marques-Silva (2024) have proposed to study “locally minimal” $\\delta$ -SR, which are $\\delta$ -SRs such that the removal of any feature from the explanation would decrease its probabilistic guarantee below $\\delta$ . Interestingly, we can generalize a proof from (Arenas et al. 2022) to show that, over lineal models even in the more general case of product distributions (distributions over $\\{ 0 , \\bar  1 \\} ^ { d }$ that are products of independent Bernoulli variables of potentially different parameters), every locally minimal $\\delta \\mathrm { - } S \\mathbf { R }$ is a subset-minimal $\\delta$ -SR. This allows leveraging the previous results of Izza, Meel, and Marques-Silva (2024) to subset-minimal $\\delta \\cdot$ -SRs in the case of linear models.\n\n# Theorem 3. For linear models, under any product distribution, every locally minimal $\\delta$ -SR is a subset-minimal $\\delta { - } S R$ .\n\nProof sketch. Define the “locality” gap $\\operatorname { L G A P } ( y )$ of a locally minimal $\\delta$ -SR $\\textbf {  { y } }$ as the smallest value $g$ such that $| { \\pmb y } ^ { \\star } | _ { \\bot } - | { \\pmb y } | _ { \\bot } = g$ for some $y ^ { \\star } \\subseteq y$ that is a $\\delta \\cdot$ -SR. If $g \\ : = \\ : 0$ , then $_ y$ is globally minimal, and we are done. If $g$ were to be 1, then $_ y$ would not be locally minimal, a contradiction. Therefore, we can safely assume $g \\ \\geqslant \\ 2$ from now on. Let $\\mathcal { L } , \\boldsymbol { y }$ be such that $_ y$ is locally minimal $\\delta$ -SR and $\\operatorname { L G A P } ( y ) \\geqslant 2$ . We will find a contradiction by the following method:\n\n• Let $y ^ { \\star }$ be the $\\delta$ -SR such that $| \\pmb { y } \\backslash \\pmb { y } ^ { \\star } | = \\mathrm { L G A P } ( \\pmb { y } )$ . • Every feature in $\\boldsymbol { y } \\boldsymbol { \\cdot } \\boldsymbol { y } ^ { \\star }$ is either “good”, if its score is positive, or “bad” if its score is negative. • Fix any feature $i$ in $\\boldsymbol { y } \\boldsymbol { \\cdot } \\boldsymbol { y } ^ { \\star }$ . If $i$ is good, then $\\mathbf { \\boldsymbol { y } } ^ { \\star } \\textcircled { + } i$ , meaning the partial instance obtained by taking $_ y$ and setting its $i$ -th feature to $x _ { i }$ , has a probability guarantee greater or equal than that of $y ^ { \\star }$ (the proof of this fact is very similar to the proof of Lemma 1), and the gap has reduced. On the other hand, if $i$ is bad, then $\\pmb { y } \\Theta \\boldsymbol { i }$ , meaning the partial instance obtained from $_ y$ by setting $y _ { i } = \\perp$ , has greaterequal probability than $_ y$ , contradicting the fact that $_ y$ is locally minimal.\n\n# 5 Conclusion and Future Work\n\nWe have proved a positive result for the case of linear models, showing that a $( \\delta , \\varepsilon )$ -min-SRs can be computed efficiently, and also a more abstract reason suggesting that linear models might be easier to explain than, e.g., decision trees. However, a variety of natural questions and directions of research remain open. First, even though the runtime of Theorem 2 is polynomial and only has a quasi-linear dependency on $d$ , our future work includes lowering the dependency in $1 / \\varepsilon$ and $1 / \\gamma$ ; on a dataset with $d = 5 0 0$ , setting $\\varepsilon \\ = \\ 0 . 1$ and $\\gamma = 0 . 0 1$ is already computationally expensive. We acknowledge, in terms of practical implementations and heuristics, the work of Bounia and Koriche (2023); Izza, Meel, and Marques-Silva (2024); Izza et al. (2023b).\n\nSecond, our theoretical result has some natural directions for generalization. We considered only binary features, whereas in order to offer a practically useful tool to the community, we will need to understand how to compute (approximate) probabilistic explanations for mixtures realvalued features and categorical features, for example under the “extended linear classifier” definition of Marques-Silva et al. (2020b). Another fascinating theoretical question is handling the generalization of our setting to that of product distributions (i.e., feature $i$ takes value 1 with probability $p _ { i }$ and 0 otherwise) can also be solved efficiently. A straightforward extension of our techniques does not seem to work on such a generalized setting, since the feature selection argument of Section 3.3 no longer holds. Therefore, we believe that new techniques will be needed.\n\nThird, it would be interesting to allow for a more declarative way of specifying the probabilistic guarantees or constraints on the explanations. While a recent line of research has studied the design of languages for defining explainability queries with a uniform algorithmic treatment (Arenas et al. 2021; Barcelo´, Pe´rez, and Subercaseaux 2020; Arenas et al. 2024), we are not aware of any work on that line that allows for probabilistic terms.",
    "summary": "```json\n{\n  \"core_summary\": \"### 🎯 核心概要\\n\\n> **问题定义 (Problem Definition)**\\n> *   论文解决的核心问题是：如何为线性模型提供具有数学保证的概率性解释（probabilistic explanations），特别是在计算“充分理由”（sufficient reasons）时面临的效率和理论难题。\\n> *   该问题的重要性在于：现有的充分理由计算方法在理论上难以高效实现，尤其是在决策树等传统“简单”模型上，存在强烈的不可近似性结果。\\n\\n> **方法概述 (Method Overview)**\\n> *   论文提出了一种称为$(\\\\delta, \\\\epsilon)$-min-SR的简单松弛方法，能够高效地为线性模型计算概率性解释。\\n\\n> **主要贡献与效果 (Contributions & Results)**\\n> *   提出$(\\\\delta, \\\\epsilon)$-min-SR概念，证明其可以在多项式时间内为线性模型计算。\\n> *   证明了对于线性模型，在任意乘积分布下，每个局部最小的$\\\\delta$-SR都是子集最小的$\\\\delta$-SR。\\n> *   通过理论分析展示了该方法在解释大小和概率保证之间的有效权衡，例如在维度$d$的线性模型上，解释大小可以比最小的1-SR小$\\\\Omega(d^{1/2-\\\\gamma})$倍。\",\n  \"algorithm_details\": \"### ⚙️ 算法/方案详解\\n\\n> **核心思想 (Core Idea)**\\n> *   核心思想是通过松弛概率条件（从“所有补全必须满足”到“随机补全以高概率满足”），从而允许更小的解释大小。\\n> *   设计哲学是：在实际应用中，用户对解释大小的敏感性高于对概率保证的微小扰动。\\n\\n> **创新点 (Innovations)**\\n> *   **与先前工作的对比：** 先前工作表明计算最小的$\\\\delta$-SR在理论上非常困难，甚至对于决策树也是NP难的。\\n> *   **本文的改进：** 通过引入$(\\\\delta, \\\\epsilon)$-min-SR的松弛概念，论文首次为线性模型提供了高效计算概率性解释的方法。\\n\\n> **具体实现步骤 (Implementation Steps)**\\n> 1.  随机采样一个$\\\\delta^\\\\star$值，范围在$[\\\\delta-\\\\epsilon, \\\\delta+\\\\epsilon]$内。\\n> 2.  根据特征权重对特征进行排序，构建部分实例$y^{(k)}$，仅包含前$k$个最高得分的特征。\\n> 3.  使用蒙特卡洛估计方法计算每个$y^{(k)}$的概率保证。\\n> 4.  通过二分搜索找到最小的$k$，使得$y^{(k)}$是一个$\\\\delta^\\\\star$-SR。\\n\\n> **案例解析 (Case Study)**\\n> *   论文提供了一个具体的线性模型示例（Example 2），展示了如何通过松弛概率条件显著减小解释大小。例如，一个0.999999-SR可以比最小的1-SR小251倍。\",\n  \"comparative_analysis\": \"### 📊 对比实验分析\\n\\n> **基线模型 (Baselines)**\\n> *   论文未明确提供基线模型，但引用了先前工作在决策树和神经网络上的理论结果作为对比。\\n\\n> **性能对比 (Performance Comparison)**\\n> *   **在解释大小上：** 论文通过理论分析表明，$(\\\\delta, \\\\epsilon)$-min-SR可以显著减小解释大小，例如在维度$d$的线性模型上，解释大小可以比最小的1-SR小$\\\\Omega(d^{1/2-\\\\gamma})$倍。\\n> *   **在计算效率上：** 论文提出的算法运行时间为$\\\\widetilde{O}\\\\left(\\\\frac{d}{\\\\varepsilon^2 \\\\gamma^2}\\\\right)$，表明其对于高维数据具有多项式时间复杂度。\",\n  \"keywords\": \"### 🔑 关键词\\n\\n*   可解释人工智能 (Explainable AI, XAI)\\n*   概率性解释 (Probabilistic Explanations, N/A)\\n*   充分理由 (Sufficient Reasons, SR)\\n*   线性模型 (Linear Models, N/A)\\n*   算法效率 (Algorithmic Efficiency, N/A)\\n*   蒙特卡洛估计 (Monte Carlo Estimation, N/A)\\n*   乘积分布 (Product Distributions, N/A)\"\n}\n```"
}