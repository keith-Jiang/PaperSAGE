{
    "source": "Semantic Scholar",
    "arxiv_id": "2412.18557",
    "link": "https://arxiv.org/abs/2412.18557",
    "pdf_link": "https://arxiv.org/pdf/2412.18557.pdf",
    "title": "FedVCK: Non-IID Robust and Communication-Efficient Federated Learning via Valuable Condensed Knowledge for Medical Image Analysis",
    "authors": [
        "Guochen Yan",
        "Luyuan Xie",
        "Xin Gao",
        "Wentao Zhang",
        "Qingni Shen",
        "Yuejian Fang",
        "Zhonghai Wu"
    ],
    "categories": [
        "cs.LG"
    ],
    "publication_date": "2024-12-24",
    "venue": "arXiv.org",
    "fields_of_study": [
        "Computer Science"
    ],
    "citation_count": 1,
    "influential_citation_count": 0,
    "institutions": [
        "Peking University",
        "PKU-OCTA Laboratory for Blockchain and Privacy Computing",
        "National Engineering Research Center for Software Engineering",
        "The University of Queensland",
        "Center for Machine Learning Research"
    ],
    "paper_content": "# FedVCK: Non-IID Robust and Communication-Efficient Federated Learning via Valuable Condensed Knowledge for Medical Image Analysis\n\nGuochen $\\mathbf { Y a n } ^ { 1 , 3 , 4 }$ , Luyuan $\\mathbf { X _ { i e } } ^ { 2 , 3 , 4 }$ , Xinyi $\\mathbf { G a o } ^ { 5 }$ , Wentao Zhang6, Qingni $\\mathbf { S h e n } ^ { 2 , 3 , 4 * }$ , Yuejian Fang2,3,4, Zhonghai $\\mathbf { W _ { u } } ^ { 2 , 3 , 4 \\dagger }$\n\n1School of Computer Science, Peking University, Beijing, China 2School of Software and Microelectronics, Peking University, Beijing, China 3PKU-OCTA Laboratory for Blockchain and Privacy Computing, Peking University, Beijing, China 4National Engineering Research Center for Software Engineering, Peking University, Beijing, China 5The University of Queensland, Brisbane, Australia 6Center for Machine Learning Research, Peking University, Beijing, China Guochen Yan@outlook.com, 2201110745@stu.pku.edu.cn, xinyi.gao $@$ uq.edu.au, wentao.zhang@pku.edu.cn, qingnishen $@$ ss.pku.edu.cn, fangyj $@$ ss.pku.edu.cn, wuzh $@$ pku.edu.cn\n\n# Abstract\n\nFederated learning has become a promising solution for collaboration among medical institutions. However, data owned by each institution would be highly heterogeneous and the distribution is always non-independent and identical distribution (non-IID), resulting in client drift and unsatisfactory performance. Despite existing federated learning methods attempting to solve the non-IID problems, they still show marginal advantages but rely on frequent communication which would incur high costs and privacy concerns. In this paper, we propose a novel federated learning method: Federated learning via Valuable Condensed Knowledge (FedVCK). We enhance the quality of condensed knowledge and select the most necessary knowledge guided by models, to tackle the non-IID problem within limited communication budgets effectively. Specifically, on the client side, we condense the knowledge of each client into a small dataset and further enhance the condensation procedure with latent distribution constraints, facilitating the effective capture of highquality knowledge. During each round, we specifically target and condense knowledge that has not been assimilated by the current model, thereby preventing unnecessary repetition of homogeneous knowledge and minimizing the frequency of communications required. On the server side, we propose relational supervised contrastive learning to provide more supervision signals to aid the global model updating. Comprehensive experiments across various medical tasks show that FedVCK can outperform state-of-the-art methods, demonstrating that it‚Äôs non-IID robust and communication-efficient.\n\n# Introduction\n\nFederated learning has become increasingly attractive since it allows collaborative training among sensitive institutions without direct data sharing. However, in reality, each medical institution would have its specialization, and the private data are highly related to the regional demographic characteristics. The data owned by each client are non-independent and identical distribution (non-IID), exhibiting significant data heterogeneity and imbalance. Under this scenario, federated learning methods suffer a global model with unsatisfactory performance due to the model divergence and client drift phenomenon (Li et al. 2019, 2022a). Meanwhile, frequent communication between heterogeneous and dispersed institutions would incur high communication costs, delays, and complex administrative procedures, with increasing privacy and safety risks (Zhu, Liu, and Han 2019; Mothukuri et al. 2021). A non-IID robust and communication-efficient federated learning method is desired.\n\nTable 1: Representative data-centric methods‚Äô problems of 1) synthesis data quality and 2) knowledge selection in the synthesis. ‚Äòheuristic‚Äô indicates they adopt heuristic diversity loss with no relation to the need of models. ‚Äòrepeated‚Äô indicates they do nothing and thus select data with repeated knowledge in synthesis. In contrast, we adopt latent distribution constraints and model-guided selection respectively.   \n\n<html><body><table><tr><td>Method</td><td>Syn.Data Quality</td><td>Knowledge Selection</td></tr><tr><td>FedGen FedMix FedGAN DFRD FedDM DESA</td><td>calibrate classifiers distorted sample match single sample infidelity only match final feature only match final feature</td><td>heuristic repeated repeated heuristic repeated repeated</td></tr><tr><td>FedVCK</td><td>latent dist.constraints</td><td>model-guided selection</td></tr></table></body></html>\n\nMany federated learning methods are proposed to cope with non-IID problems by modifying local training process (Li et al. 2020; Li, He, and Song 2021; Zhou, Zhang, and Tsang 2023) or global aggregation process (Chen and Chao 2020; Lin et al. 2020; Zheng et al. 2023). However, they are mainly model-centric. They focus on mitigating model parameter-level divergence indirectly under a typical paradigm of local training and global aggregation, leading to marginal advantages in performance and communication (a) We use the distribution matching-based method to condense knowledge on the OrganC dataset. Without our latent distribution constraints (Vanilla, dashed line), $L _ { c o n d }$ would be easily reduced in each round but the model‚Äôs performance struggles to improve with the condensed knowledge, demonstrating the low-quality problem of vanilla methods.\n\n![](images/67035bf606ec571f88b48501daa7c88a6a976bd9ca0b600dda730c1b7a702783.jpg)  \n(b) We measure the average MMD of condensed knowledge classwisely between adjacent rounds on the Path dataset. Greater MMD indicates a larger distribution difference. The vanilla selection causes more knowledge repetition between rounds. Our model-guided selection $( P _ { w } )$ ensures that the condensed knowledge between adjacent rounds exhibits greater differences.\n\n![](images/8801069d67fb369ac43aa85ddda69c7a2bb98e70fed5633d70443c370fc60bed.jpg)\n\nFigure 1: Illustration of the low synthesized data quality problem in Figure (a) and repeated knowledge problem in Figure (b)\n\ncosts under severe non-IID scenarios (Li et al. 2022a).\n\nThe model divergence originates from the data divergence (Zhao et al. 2018), thus mitigating the data-level divergence would be more essential to tackle the non-IID problems. Recently, various data-centric federated learning methods attempted to share virtual or synthesized data to mitigate data divergence. They synthesize diverse objectives including latent features (Zhu, Hong, and Zhou 2021), approximated real data (Li et al. 2022b; Zhu and Luo 2022; Yoon et al. 2021), inverted data (Zhang et al. 2022; Wang et al. 2024a), condensed data (Xiong et al. 2023; Huang et al. 2024; Wang et al. 2024b) and so on. However, under severe non-IID scenarios, these methods still face problems because of: 1) low synthesized data quality. For instance, mix-up would distort data (Verma et al. 2019). The inverted data is of infidelity with biased models. And the advanced dataset condensation cannot effectively extract subtle and meaningful knowledge which we demonstrate in Figure 1a. These low-quality data would fail to guide the model training; 2) repeated knowledge. The data are randomly selected to synthesize virtual data, and their value and importance to the current model are not considered. Thus, the knowledge contained tends to be homogeneous and unnecessarily repeated (see Figure 1b), thus cannot effectively update the model after several rounds. We summarize problems in the above two aspects of representative data-centric federated learning methods in Table 1. Additionally, some synthesis methods would incur privacy concerns, and most methods are not communication-efficient. They still face challenges to achieve a satisfactory performance under limited communication rounds in non-IID scenarios.\n\nMotivated by the above limitations, we propose a novel data-centric Federated learning method via Valuable Condensed Knowledge (FedVCK). Our method includes two parts, valuable knowledge condensation on the client side and relational supervised learning-aided updating on the server side. Specifically, we condense each client‚Äôs knowledge into a small dataset. To ensure condensing high-quality knowledge, we propose latent distribution constraints to better capture subtle and meaningful knowledge in latent spaces. To minimize redundancy in each round of knowledge condensation, we explicitly measure the missing knowledge of the current model and select the most necessary knowledge in condensation on each client. On the server side, we identify the hard negative classes for each class and propose a relational supervised contrastive learning to enhance the supervision signals during model updating. Due to the balanced, high-quality, unrepeated, and necessary condensed knowledge, the training of the global model is insulated from the effects of non-IID problems and can achieve enhanced performance within limited communication rounds (e.g. 10). Moreover, our method only condenses task-related high-level knowledge with random noise initialization, thereby facilitating privacy protection. Our main contributions are summarized as follows:\n\n‚Ä¢ We propose a novel data-centric federated learning method: FedVCK, for collaborative medical image analysis. FedVCK is robust to severe non-IID scenarios and communication efficient with valuable knowledge. ‚Ä¢ On the client side, we propose model-guided selection to sample the most needed knowledge each round to avoid unnecessary repetition. We also propose latent distribution constraints to enhance the quality of knowledge. ‚Ä¢ On the server side, we identify the hard negative classes and propose relational supervised contrastive learning to enhance supervised learning in model updating. ‚Ä¢ We conduct comprehensive experiments and results show that our method achieves better predictive performance, especially under limited communication budgets. We also conduct experiments to verify the privacypreserving ability and generality of our method.\n\n# Related Works\n\nThe data owned by each client is typically highly heterogeneous and does not follow an independent and identical distribution. Under severe non-IID scenarios, models trained on clients tend to be highly biased and divergent, a phenomenon known as client drift. Aggregating these biased and divergent client models at the server often results in suboptimal performance. Many model-centric methods focus on modifying local training process, such as introducing regularization or contrastive terms to reduce divergence (Li et al. 2020; Acar et al. 2021; Li, He, and Song 2021; Xie et al. 2024c,b,a) or improving aggregation process (Lin et al. 2020; Chen and Chao 2020; Zheng et al. 2023). They try to alleviate the client drift from the model parameter level.\n\nThe model divergence originates from the data divergence (Zhao et al. 2018). Directly reducing the difference in data distribution would reduce the model divergence fundamentally. Recently, data-centric federated learning methods have drawn attention since they can synthesize and then share virtual synthesized data to mitigate the non-IID problem in a data-centric manner. Besides that FedGen (Zhu, Hong, and Zhou 2021) which generates virtual representation, various format data are synthesized on the server or clients. FedMix (Yoon et al. 2021) broadcasts the mixup data to approximate the real data. FedGAN (Nguyen et al. 2021) and SDA-FL (Li et al. 2022b) train and share GANs to imitate real data to support COVID-19 detection. FedFTG (Zhang et al. 2022) and advanced version DFRD (Wang et al. 2024a) use model inversion (Yin et al. 2020) to generate data for knowledge distillation. FedDM (Xiong et al. 2023) condenses the knowledge to update the global model. DESA (Huang et al. 2024) distills anchor data and broadcasts them to enable mutual regularization and distillation among clients.\n\n# Proposed Method\n\n# Overview\n\nThe overview of FedVCK is shown in Figure 2. In short, it consists of two parts: valuable knowledge condensation on the client side and relational supervised learning-aided updating on the server side. On the client side, we borrow distribution matching techniques in dataset condensation and optimize the learnable dataset to condense knowledge from local data. To ensure quality, we record dynamic distribution statistics of the local data batch in each encoder layer and replace the statistics during embedding learnable knowledge as fixed constraints, which could force the latent distribution of the condensed knowledge to capture subtle and meaningful knowledge of different levels. To minimize redundancy in each round of condensation, we explicitly measure the prediction error on each sample and select the data on which the model performs poorly. We consider such data critical as it contains knowledge not yet captured by the current model. By focusing more on these important samples, the condensation process ensures that the condensed knowledge complements the global model‚Äôs missing capabilities. On the server side, we collect the condensed knowledge dataset and train the global model with supervised learning and relational contrastive learning. We first identify hard negative classes for each class where the global model tends to mispredict by uploaded logit prototypes. Then we use supervised contrastive learning in a bootstrap manner to draw the features of the same class closer to their prototypes and push the features away from their hard negative classes‚Äô prototypes. We will introduce our designs in detail in the following sections.\n\n# Preliminary: Dataset Condensation\n\nThe objective of dataset condensation (Wang et al. 2018; Yu, Liu, and Wang 2023; Gao et al. 2024a,b) is to condense knowledge from a large dataset into a small learnable dataset, which could be used to train models to achieve comparable performance. Distribution matching is an advanced method widely used in dataset condensation.\n\nDistribution matching. The intuition behind is to optimize a small dataset $s$ to match the latent feature distribution of local data $\\tau$ by minimizing the distance to the latent features of local data with maximum mean discrepancy (MMD) (Gretton et al. 2012; Zhao and Bilen 2023):\n\n$$\n\\underset { \\mathcal { S } } { \\arg \\operatorname* { m i n } } \\ \\underset { \\| \\psi _ { \\theta } \\| _ { \\mathcal { H } } \\leq 1 } { \\operatorname* { s u p } } ( \\mathbb { E } [ \\psi _ { \\theta } ( \\mathcal { T } ) ] - \\mathbb { E } [ \\psi _ { \\theta } ( \\mathcal { S } ) ] ) ,\n$$\n\nwhere $\\mathcal { H }$ is reproducing kernel Hilbert space (RKHS), $\\psi _ { \\boldsymbol { \\theta } }$ is the shared embedding function to map the input to its latent feature, parameterized by a multi-layer encoder. In practice, We minimize the estimated empirical MMD loss by classwisely align the latent feature distributions to optimize $s$ :\n\n$$\nL _ { c o n d } = \\sum _ { c = 0 } ^ { C - 1 } \\lVert \\frac { 1 } { | B _ { c } | } \\sum _ { x _ { i } \\in B _ { c } } \\psi _ { \\theta } ( x _ { i } ) - \\frac { 1 } { | S _ { c } | } \\sum _ { s _ { i } \\in S _ { c } } \\psi _ { \\theta } ( s _ { i } ) \\rVert ^ { 2 } ,\n$$\n\nwhere $C$ is the number of classes, $\\mathcal { T } _ { c }$ is the local data with class $c$ , $B _ { c }$ is a batch randomly sampled from $\\mathcal { T } _ { c }$ with a uniform distribution, and $ { \\boldsymbol { S } } _ { c }$ is the knowledge dataset corresponding to class $c$ . To enable the high-order estimation, we choose to align the latent feature distributions in an RKHS with kernel $\\kappa$ (Zhang et al. 2024), and minimize the following empirical MMD as condensation loss:\n\n$$\nL _ { c o n d } = \\sum _ { c = 0 } ^ { C - 1 } \\sum _ { \\stackrel { { \\cal B } _ { c } } { \\sim } \\mathcal { T } _ { c } } \\hat { K } _ { B _ { c } , B _ { c } } + \\hat { K } _ { S _ { c } , S _ { c } } - 2 \\hat { K } _ { B _ { c } , S _ { c } } ,\n$$\n\nwhere ÀÜX,Y $\\begin{array} { r l r } { \\hat { K } _ { X , Y } } & { = } & { \\frac { 1 } { | { \\boldsymbol X } | \\cdot | { \\boldsymbol Y } | } \\sum _ { i = 1 } ^ { | { \\boldsymbol X } | } \\sum _ { j = 1 } ^ { | { \\boldsymbol Y } | } { K } ( \\psi _ { \\boldsymbol \\theta } ( x _ { i } ) , \\psi _ { \\boldsymbol \\theta } ( y _ { j } ) ) , } \\end{array}$ $\\{ x _ { i } \\} _ { i = 1 } ^ { | X | } \\sim X , \\quad \\{ y _ { j } \\} _ { j = 1 } ^ { | Y | } \\sim Y$ . The kernel function $\\kappa$ can be a linear kernel, inner-product kernel, or Gaussian kernel.\n\nKnowledge initialization. There are several manners to initialize learnable knowledge dataset $s$ whose format is the same as real data. To best prevent the privacy leak of the local data, we choose random Gaussian noise $\\mathcal { N } ( 0 , 1 )$ to initialize the knowledge dataset, making the knowledge can only be condensed by matching the latent distributions. The condensed knowledge dataset $s$ would contain no individual and privacy information in pixel space and the adversary can hardly infer the membership from the condensed knowledge datasets (Dong, Zhao, and Lyu 2022).\n\nClient i Upload: Condensed knowledge ùêøùëü_ùëêùëúùëõùëë logit prototypes 7 Server Latent feat. Latent feat. ‰∏™ i   \n{ùúáùêø, ùúéùêø} {ùúáùêø, ùúéùêø} Latent Distribution Constraints logit prototypes Update Global Model   \n{ùúá1, ùúé1} Ôºö {ùúá1, ùúé1} Local Data kCnollwelceteddg ecoùë∫n:ùíïdensed ùë¥ ‰∏™ ‰∏™ 0 Download: Global model ùêåùê≠ ùëÉùë§ ‚àº ùë§ùëÄùë°   \ncondensed ùë¥ùíï: model at t-th round real data $\\pmb { B } _ { c }$   \nknowledge ùë∫ùíÑ ùë∫ùíï:  condensed knowledge at t-th round Model-guided Knowledge Selectio ùë∫ùíÑ:  condensed knowledge corresponding to class $c$ $\\pmb { B } _ { c }$ :  real data batch by importance sampling $P _ { w }$\n\nFigure 2: Overview of FedVCK. On the client side, we sample local data by importance sampling guided by the current model and then impose latent distribution constraints in optimization. We upload the condensed knowledge dataset and logit prototypes to the server. On the server side, we use cross entropy loss and relational contrastive loss to update the global model.\n\n# Latent Distribution Constraints\n\nBy optimizing $s$ with $L _ { c o n d }$ in Eq. 2 or Eq. 3, the condensed knowledge dataset $s$ can replace the real data to effectively train models. However, it‚Äôs challenging to ensure the condensation quality when condensing the knowledge from local data into a small random noise-initialized dataset, because random noises have no prior about the local data. Moreover, the condensation loss $( L _ { c o n d } )$ is not sufficient to guide the learning of subtle meaningful knowledge since the latent features of $s$ can take shortcuts to over-fit the latent features of local data. To assess the deficiency of the vanilla optimization process, we show in Figure 1a that while $L _ { c o n d }$ is easily reduced at each round, it can not effectively condense meaningful knowledge to improve performance effectively. Additionally, matching the distribution of the final representation of the encoder neglects the previous intermediate latent feature distributions.\n\nTo enhance the effectiveness and ensure consistent distribution of all latent features, we transfer dynamic distribution statistics (mean and variation) from the local real data to the condensed knowledge data during the condensation procedure. Compared to (Yin et al. 2020), our approach does not require the addition of an extra loss term, enabling a more flexible and efficient condensation procedure. Specifically, we first record the distribution statistics of each layer $\\{ \\{ \\mu _ { 1 } , \\sigma _ { 1 } \\} , . . . , \\{ \\mu _ { L } , \\sigma _ { L } \\} \\}$ with a $L$ layer encoder when embedding a batch of local data. Then the statistics during embedding condensed data are replaced and fixed with recorded statistics:\n\n$$\n\\begin{array} { c } { { s _ { i } ^ { ( 1 ) } = N o r m ( \\psi _ { 1 } ( s _ { i } ) , \\{ \\mu _ { 1 } , \\sigma _ { 1 } \\} ) , } } \\\\ { { s _ { i } ^ { ( 2 ) } = N o r m ( \\psi _ { 2 } ( s _ { i } ^ { ( 1 ) } ) , \\{ \\mu _ { 2 } , \\sigma _ { 2 } \\} ) , } } \\\\ { { \\ldots } } \\\\ { { \\psi _ { \\theta } ( s _ { i } ) = s _ { i } ^ { ( L ) } = N o r m ( \\psi _ { L } ( s _ { i } ^ { ( L - 1 ) } , \\{ \\mu _ { L } , \\sigma _ { L } \\} ) } } \\end{array}\n$$\n\nwhere $\\psi _ { l }$ is $l$ -th layer of encoder $\\psi _ { \\theta }$ and Norm denotes batch normalization (Ioffe and Szegedy 2015). The distribution statistics constraint could force the optimization process to consider intermediate latent distributions and prevent it from taking shortcuts. Thus the quality of condensed knowledge can be largely improved.\n\n# Model-guided Knowledge Selection\n\nIf we uniformly sample real data from local data to conduct condensation, the condensed knowledge in each round will be repeated and homogeneous, dominated by simple and easy-to-learn knowledge. It would be less beneficial to further improve the performance of the global model. However, from the model perspective, we find that the importance of the knowledge contained in each sample varies. The current global model may perform well on some local data but lacks the ability to make correct predictions on others, exposing that the current model lacks some knowledge. The data containing the missing knowledge would be more important at this round and it‚Äôs better to focus on condensing knowledge from these data to complement the model knowledge. Specifically, we first measure the importance of each data sample explicitly by model prediction error as $t$ -th round:\n\n$$\nw _ { \\mathbf { M } _ { t } } ( x _ { i } ) = \\frac { 1 } { 1 + e ^ { - e r r _ { t } ( x _ { i } ) + b } } ,\n$$\n\nwhere the $e r r _ { t } ( x _ { i } )$ refers to the prediction error on $x _ { i }$ of current model $\\mathbf { M } _ { t }$ at $t$ -th round and $b$ is a constant to control the scale range. The higher the prediction error, the more important $x _ { i }$ would be. Here we adopt the cross-entropy loss as the prediction error with the current model $\\mathbf { M } _ { t }$ :\n\n$$\ne r r _ { t } ( x _ { i } ) = L _ { c e } ( y _ { i } , \\mathbf { M } _ { t } ( x _ { i } ) ) .\n$$\n\nThe current model is usually not well-trained and may over-fit on limited uploaded condensed knowledge, the distribution of loss would be skewed and less calibrated to reflect the proper importance relation. We propose the selfensemble of the current model $\\mathbf { M } _ { t }$ and previous model $\\mathbf { M } _ { t - 1 }$ to smooth and regularize the distribution of loss. Thus the desired knowledge can be condensed progressively. we refine the prediction error of Eq. 6 as:\n\n$$\n\\begin{array} { r } { e \\tilde { r } r _ { t } ( x _ { i } ) = L _ { c e } ( y _ { i } , \\alpha \\mathbf { M } _ { t } ( x _ { i } ) + ( 1 - \\alpha ) \\mathbf { M } _ { t - 1 } ( x _ { i } ) ) , } \\end{array}\n$$\n\nwhere $\\alpha$ is a hyper-parameter. With refined prediction error, we can calculate the refined importance in Eq. 5 and replace the uniform sampling $P _ { u }$ in Eq. 3 with importance sampling $P _ { w }$ conditioned on model $\\mathbf { M } _ { t }$ and $\\mathbf { M } _ { t - 1 }$ :\n\n$$\nP _ { w } ( x _ { i } | \\mathbf { M } _ { t } , \\mathbf { M } _ { t - 1 } ) = \\frac { w _ { \\mathbf { M } _ { t } } ( x _ { i } ) } { \\sum _ { x _ { j } } w _ { \\mathbf { M } _ { t } } ( x _ { j } ) } .\n$$\n\nWe then refine the condensation loss of Eq. 3 as :\n\n$$\nL _ { r . c o n d } = \\sum _ { c = 0 } ^ { C - 1 } \\hat { K } _ { B _ { c } ^ { P w } , B _ { c } ^ { P w } } + \\hat { K } _ { S _ { c } , S _ { c } } - 2 \\hat { K } _ { B _ { c } ^ { P w } , S _ { c } } ,\n$$\n\nwhere data in each batch $B _ { c } ^ { P _ { w } }$ is sampled based on $P _ { w }$ . Thus the condensation process in the $t$ -th round can be regarded as a biased variant of Eq. 1 where the where the expectation over $\\tau$ is replaced by a weighted expectation under $P _ { w }$ :\n\n$$\n\\mathop { \\mathrm { a r g m i n } } _ { \\pmb { S } } \\operatorname* { s u p } _ { \\| \\psi _ { \\theta } \\| _ { \\mathcal { H } } \\leq 1 } ( \\mathbb { E } _ { P _ { w } } [ \\psi _ { \\theta } ( \\pmb { \\mathscr { T } } ) ] - \\mathbb { E } [ \\psi _ { \\theta } ( \\pmb { S } ) ] ) ,\n$$\n\nNote that the current model $\\mathbf { M } _ { t }$ is dynamically updating. We measure the importance and derive the importance sampling $P _ { w }$ at each round. Thus, the condensed knowledge in each round can continue to transition from known knowledge to missing knowledge. The global model could complement its ability at each round, making its performance improve consistently.\n\n# Relational Prototype-wise Contrastive Learning\n\nOn the server side, we calculate the global logit prototype for each class and identify their hard negative classes. Afterward, prototype-wise contrastive learning is deployed to facilitate the discrimination between classes.\n\nAt the $t$ -th round, besides the condensed knowledge dataset, each client $k$ uploads the logit prototypes $\\{ \\mathbf { p _ { 0 } } ^ { k , t } , . . . , \\mathbf { p } _ { \\mathbf { C } - 1 } { } ^ { k , t } \\}$ calculated by the global model as:\n\n$$\n\\mathbf { p _ { c } } ^ { k , t } = \\frac { 1 } { N _ { c , k } } \\sum _ { i } ^ { N _ { c , k } } f _ { M _ { t - 1 } } ( x _ { i , c , k } ) ,\n$$\n\nwhere the $x _ { i , c , k }$ denotes the local data with class $c$ in client $k$ , and $f _ { M _ { t - 1 } }$ denotes the current model without the last softmax layer at the beginning of the $t$ -th round. Then we aggregate these prototypes uploaded from each client into global logit prototypes $\\left\\{ \\mathbf { \\bar { p } _ { 0 } } ^ { t } , . . . , \\mathbf { p } \\mathbf { c } . . \\mathbf { 1 } ^ { t } \\right\\}$ :\n\n$$\n{ \\bf p _ { c } } ^ { t } = \\frac { 1 } { | T _ { c } | } \\sum _ { k } ^ { N } | \\mathcal { T } _ { c , k } | { \\bf p _ { c } } ^ { k , t } ,\n$$\n\nwhere $N$ denotes the number of clients, $| \\mathcal { T } _ { c } |$ denotes the total number of data of class $c$ , and $| \\mathcal { T } _ { c , k } |$ denotes the number of data of class $c$ in client $k$ . With global logit prototypes, we can derive the Top-K hard negative classes for class $c$ as :\n\n$$\nH N ( c ) = \\{ j _ { 1 } , j _ { 2 } , . . . j _ { K } \\} = \\underset { j \\neq c } { \\arg t o p } K \\ : \\mathbf { p _ { c } } [ j ] ,\n$$\n\nwhere $H N ( c )$ contains the class indices with Top-K values in prototype vector $\\mathbf { p _ { c } }$ except $c$ . We recognize $\\mathsf { \\bar { H } N } ( c )$ as hard negative classes‚Äô indices set for class $c$ since the global always predicts a higher probability on these classes and tends to mis-classify. To amplify discrimination ability of the global model, it would be more effective to push features of class $c$ away from that of $H N ( c )$ . Note that the global logit prototypes may change across rounds with the updated global model, $H N ( c )$ would also change adaptively.\n\nWe also calculate feature prototypes $\\{ \\mathbf { f _ { 0 } } ^ { \\ t } , . . . , \\mathbf { f _ { C - 1 } } ^ { \\ t } \\}$ with condensed knowledge datasets on the server at $t$ -th round:\n\n$$\n\\mathbf { f _ { c } } ^ { t } = \\frac { 1 } { | S _ { c } ^ { : t - 1 } | } \\sum _ { s _ { i } \\in S _ { c } ^ { 0 , \\dots , t - 1 } } \\psi _ { \\boldsymbol \\theta } ^ { t - 1 } ( s _ { i } ) ,\n$$\n\nwhere $S _ { c } ^ { : t - 1 }$ is the accumulated knowledge dataset of class $c$ uploaded before $t$ -th round, and $\\psi _ { \\theta } ^ { t - 1 }$ is the encoder of the global model $\\mathbf { M } _ { t - 1 }$ at the very beginning of $t$ -th round.\n\nWith hard negative classes set $H N ( c )$ and feature prototypes, inspired by SimSiam (Chen and He 2021), we propose relational supervised contrastive learning with prototypes in a bootstrap manner:\n\n$$\nL _ { r c } = \\sum _ { ( s _ { i } , c _ { i } ) \\in S ^ { : t } } - \\log \\frac { \\exp { ( h ( \\psi _ { \\theta } ^ { t } ( s _ { i } ) ) \\cdot \\mathbf { f _ { c _ { i } } } ^ { t } } / \\tau ) } { \\sum _ { c _ { j } \\in H N ( c _ { i } ) } \\exp { ( h ( \\psi _ { \\theta } ^ { t } ( s _ { i } ) ) \\cdot \\mathbf { f _ { c _ { j } } } ^ { t } } / \\tau ) } ,\n$$\n\nwhere $h$ is a learnable projector similar with (Chen and He 2021; Grill et al. 2020) and $\\tau$ is the temperature hyperparameter. Then we update the global model along with cross-entropy loss at $t$ -th round with:\n\n$$\nL _ { u p d a t e } = L _ { c e } ( S ^ { : t } ) + L _ { r c } ,\n$$\n\nwhere $L _ { c e }$ denotes the cross-entropy loss with condensed knowledge datasets and the relational supervised contrastive learning offers more supervision signals in model updating.\n\n# Experiments\n\nDatasets. We evaluate the performance of our proposed FedVCK on 4 medical tasks, which contain 5 datasets with different modalities from (Yang, Shi, and Ni 2021; Yang et al. 2023): 1) Colon Pathology, we adopt the Path dataset, 2) Retinal OCT scans, we adopt the OCT dataset, 3) Abdominal CT scans, we adopt the OrganS and OrganC dataset, 4) Chest X-Ray, we adopt the Pneumonia dataset. To validate the generality, we also select CIFAR10 (Krizhevsky 2009), STL10 (Coates, $\\mathbf { N } \\mathbf { g }$ , and Lee 2011), and ImageNette (Howard and Team 2019) datasets. Our selected datasets enjoy a wide range of modalities and resolutions from $2 8 \\times 2 8$ to $2 2 4 \\times 2 2 4$ and detailed introductions about datasets are shown in the Appendix.\n\nBaselines. We compare FedVCK with nine federated learning methods including both model-centric methods (FedAvg, FedProx, and MOON) and data-centric methods (FedGen, FedMix, FedGAN, DFRD, FedDM, and DESA). We summarize rationale of the baseline selection and their synthesis objectives and methods in Table 1 in Appendix.\n\nTable 2: Overall predictive accuracy comparison on medical datasets. We test our method and baselines under two non-IID scenarios: $D i r ( 0 . 0 5 )$ and $D i r ( 0 . 0 2 )$ . For datasets with $2 2 4 \\times 2 2 4$ image sizes, we adopt the ResNet18 model. Bold numbers indicate the best accuracy results. ‚ÄòOOM‚Äô indicates out-of-memory.   \n\n<html><body><table><tr><td>Œ≤</td><td colspan=\"5\">0.05</td><td colspan=\"5\">0.02</td></tr><tr><td>Mode1</td><td></td><td colspan=\"2\">ConvNet</td><td colspan=\"2\">ResNet18</td><td colspan=\"3\">ConvNet</td><td colspan=\"2\">ResNet18</td></tr><tr><td>Acc(%)</td><td>Path</td><td>OCT</td><td>OrganS</td><td>OrganC</td><td>Pneumonia</td><td>Path</td><td>OCT</td><td>OrganS</td><td>OrganC</td><td>Pneumonia</td></tr><tr><td>FedAvg</td><td>46.34</td><td>62.00</td><td>66.27</td><td>70.38</td><td>69.87</td><td>43.72</td><td>26.54</td><td>60.70</td><td>65.87</td><td>63.14</td></tr><tr><td>FedProx</td><td>61.34</td><td>62.50</td><td>69.14</td><td>71.80</td><td>69.07</td><td>40.15</td><td>32.20</td><td>67.76</td><td>60.94</td><td>62.50</td></tr><tr><td>MOON</td><td>51.91</td><td>56.10</td><td>52.33</td><td>71.82</td><td>62.50</td><td>50.88</td><td>29.90</td><td>62.84</td><td>61.81</td><td>62.50</td></tr><tr><td>FedGen</td><td>42.03</td><td>53.25</td><td>59.90</td><td>49.65</td><td>60.37</td><td>39.87</td><td>34.74</td><td>47.06</td><td>37.63</td><td>58.43</td></tr><tr><td>FedGAN</td><td>54.40</td><td>56.80</td><td>71.76</td><td>00M</td><td>75.32</td><td>54.37</td><td>25.20</td><td>70.34</td><td>00M</td><td>62.50</td></tr><tr><td>FedMix</td><td>35.78</td><td>48.90</td><td>62.10</td><td>60.63</td><td>62.50</td><td>31.50</td><td>29.30</td><td>54.65</td><td>29.22</td><td>62.50</td></tr><tr><td>DFRD</td><td>37.44</td><td>31.50</td><td>39.80</td><td>0OM</td><td>OOM</td><td>14.01</td><td>34.20</td><td>37.93</td><td>0OM</td><td>0OM</td></tr><tr><td>FedDM</td><td>73.97</td><td>61.70</td><td>71.37</td><td>35.60</td><td>75.80</td><td>73.64</td><td>62.20</td><td>69.46</td><td>18.20</td><td>68.75</td></tr><tr><td>DESA</td><td>33.37</td><td>47.00</td><td>69.98</td><td>54.16</td><td>61.38</td><td>66.41</td><td>35.20</td><td>67.32</td><td>39.46</td><td>62.50</td></tr><tr><td>FedVCK</td><td>80.36</td><td>68.30</td><td>73.23</td><td>79.52</td><td>86.70</td><td>81.10</td><td>68.20</td><td>72.90</td><td>79.04</td><td>84.62</td></tr></table></body></html>\n\n<html><body><table><tr><td>Œ≤</td><td colspan=\"5\">0.05</td><td colspan=\"5\">0.02</td></tr><tr><td>Model</td><td colspan=\"3\">ConvNet</td><td colspan=\"2\">ResNet18</td><td colspan=\"3\">ConvNet</td><td colspan=\"2\">ResNet18</td></tr><tr><td>Acc(%)</td><td>Path</td><td>OCT</td><td>OrganS</td><td>OrganC</td><td>Pneumonia</td><td>Path</td><td>OCT</td><td>OrganS</td><td>OrganC</td><td>Pneumonia</td></tr><tr><td>FedAvg</td><td>18.55</td><td>53.70</td><td>36.92</td><td>29.31</td><td>62.50</td><td>12.84</td><td>25.00</td><td>39.32</td><td>25.13</td><td>35.74</td></tr><tr><td>FedProx</td><td>56.94</td><td>49.70</td><td>48.76</td><td>50.60</td><td>63.78</td><td>40.15</td><td>28.70</td><td>49.60</td><td>46.13</td><td>62.50</td></tr><tr><td>MOON</td><td>49.40</td><td>32.00</td><td>45.69</td><td>33.43</td><td>62.50</td><td>26.96</td><td>25.00</td><td>42.60</td><td>25.83</td><td>62.50</td></tr><tr><td>FedGen</td><td>34.47</td><td>27.60</td><td>45.75</td><td>24.89</td><td>58.00</td><td>37.20</td><td>25.00</td><td>37.79</td><td>18.77</td><td>57.50</td></tr><tr><td>FedGAN</td><td>19.89</td><td>48.00</td><td>55.65</td><td>00M</td><td>64.74</td><td>32.32</td><td>25.00</td><td>44.67</td><td>00M</td><td>62.50</td></tr><tr><td>FedMix</td><td>28.97</td><td>31.60</td><td>57.35</td><td>32.46</td><td>62.50</td><td>28.48</td><td>25.00</td><td>42.37</td><td>17.73</td><td>62.50</td></tr><tr><td>DFRD</td><td>22.40</td><td>25.00</td><td>39.05</td><td>00M</td><td>00M</td><td>10.45</td><td>25.00</td><td>29.93</td><td>00M</td><td>00M</td></tr><tr><td>FedDM</td><td>72.76</td><td>61.70</td><td>71.32</td><td>31.66</td><td>73.27</td><td>70.39</td><td>62.20</td><td>69.33</td><td>15.12</td><td>62.50</td></tr><tr><td>DESA</td><td>29.48</td><td>36.90</td><td>66.00</td><td>50.72</td><td>38.78</td><td>43.62</td><td>27.80</td><td>66.42</td><td>39.46</td><td>37.50</td></tr><tr><td>FedVCK</td><td>78.52</td><td>66.41</td><td>72.65</td><td>71.39</td><td>83.01</td><td>78.61</td><td>65.90</td><td>71.68</td><td>71.89</td><td>82.48</td></tr></table></body></html>\n\nTable 3: Predictive accuracy comparison on medical datasets under limited communication budgets.\n\nConfiguration. Following the commonly used setting, we simulate non-IID scenarios with Dirichlet distribution $D i r ( \\beta )$ among 10 clients where $\\beta$ is 0.05 and 0.02 to simulate severe non-IID scenarios. We adopt the ConvNet (Gidaris and Komodakis 2018) and ResNet18 (He et al. 2016). We set the size of the condensed knowledge dataset $s$ to $p \\%$ of the original dataset size, where $p$ is selected from $\\{ 1 , 2 , 5 \\}$ according to different datasets. We initialize $S$ from $\\mathcal { N } ( 0 , 1 )$ . Hyper-parameters in each method are tuned as suggested in the original papers. We run all experiments with NVIDIA Geforce RTX 3090 GPU and report the mean results among three runs. More details are introduced in the Appendix.\n\n# Performance Under Non-IID Scenarios\n\nOverall performance. We evaluate all methods‚Äô overall performance under non-IID scenarios in Table 2, assuming the communication budgets are adequate (100 communication rounds). We can observe that model-centric federated learning methods struggle with mediocre performance. Some data-centric methods (e.g. FedGen and DFRD) perform worse. We find this is because the poor synthesis quality and poor global model hinder each other and cause a vicious circle. On OrganC and Pneumonia datasets, FedGAN and DRFD face the out-of-memory problem. Clients in FedGAN must train and upload huge generators and discriminators and the server in DFRD must maintain ensemble models and huge generators. Most data-centric baselines degrade hardly on the two datasets since capturing subtle and meaningful knowledge in larger sizes is harder. Our method successfully condenses knowledge with high quality and high necessity for the global model, thus showing advantages over all datasets‚Äô baselines.\n\nUnder limited communication budgets. Since communication budgets are usually limited in reality, a method that can achieve high performance within a few communication rounds is more desired. We compare the performance of our method and baselines within 10 communication rounds under non-IID scenarios. The experimental results are shown in Table 3. We can observe that all baselines cannot achieve satisfactory performance within limited rounds, while our method consistently outperforms others on all datasets. The performance is relatively close to the overall performance in Table 2 and would not be significantly affected by more severe non-IID ( $\\beta = 0 . 0 2 ,$ ), demonstrating that our method is not only communication-efficient but also robust to non-IID.\n\n# Performance Analysis\n\nAblation study. We conduct ablation study to evaluate the effectiveness of our designs. The experimental results are shown in Table 4. Besides, we measure the empirical MMD of the condensed knowledge between two adjacent rounds\n\n<html><body><table><tr><td>Acc(%)</td><td>Path</td><td>OrganS</td><td>Path</td><td>OrganS</td></tr><tr><td>w.o. all</td><td>72.76</td><td>71.32</td><td>73.97</td><td>71.37</td></tr><tr><td>W.o. Lrc + Pu</td><td>73.04</td><td>71.74</td><td>76.48</td><td>72.13</td></tr><tr><td>w.0. Lrc</td><td>74.52</td><td>71.93</td><td>78.56</td><td>72.40</td></tr><tr><td>FedVCK</td><td>78.52</td><td>72.65</td><td>80.36</td><td>73.23</td></tr></table></body></html>\n\nTable 4: Ablation study on medical datasets. The left part of the table is the performance under limited communication rounds and the right part is the overall performance.\n\nTable 5: Per-round upload communication costs. $p \\%$ indicates the size of the condensed knowledge dataset as a proportion of the size of the original dataset.   \n\n<html><body><table><tr><td>Method</td><td>Path</td><td>OrganS</td><td>Pneumonia</td></tr><tr><td>FedMix,DRFD FedAvg,FedProx MOON,FedGen DESA</td><td>12.13 MB</td><td>12.20 MB 426.15MB</td><td></td></tr><tr><td>FedGAN</td><td></td><td></td><td>178.85MB178.69MB2349.40MB</td></tr><tr><td>FedVCK, FedDM</td><td>2.04 MB</td><td>0.52 MB</td><td>11.77 MB</td></tr><tr><td>p%</td><td>1%</td><td>5%</td><td>5%</td></tr></table></body></html>\n\nwith or without model-guided selection in Figure 1b. We can note that with model-guided selection, the condensed knowledge between adjacent rounds exhibits greater MMD values, reflecting that it can avoid repeated knowledge and force the optimization process to condense more heterogeneous and model-specific knowledge. We also study the impact of the size of learnable knowledge dataset in the Appendix. Larger size would have more capacity but increase optimization difficulty and communication overhead.\n\nCommunication analysis. Our method is communication efficient from two aspects. From the perspective of communication rounds, we have demonstrated our method can quickly achieve satisfactory performance under limited budgets in Table 3. From the perspective of upload communication costs, we quantify the actual per-round upload communication costs of all clients in Table 5. Our method‚Äôs perround uploading costs are less than that of model-centric federated learning. More analysis about the communication and full experimental results are shown in the Appendix.\n\n# Privacy Analysis\n\nTo practically test whether the condensed knowledge would leak individual privacy, we conduct the membership inference attack following an advanced method: LiRA (Carlini et al. 2022) and compare FedVCK with the model-centric federated learning method (e.g. FedAvg). We attack uploaded models or condensed knowledge from clients and record the AUC of ROC on each client with a balanced test set. Since the MIA task is a binary classification, we set the minimum AUC to 0.5 and mark it as a total defense if the AUC of a client is less than or equal to 0.5. We calculate the max and mean AUC of all clients and defense rate (the proportion of clients achieving total defense) in Table 6. The results show that our method better preserves privacy than FedAvg, and enables more total defense cases. In addition, since our method needs fewer communication rounds, privacy can be further protected from potential temporal-based MIA (Zhu et al. 2024).\n\nTable 6: The AUC results of MIA experiment on OrganS dataset. $\\downarrow$ means the lower, the better. $\\uparrow$ means the opposite.   \n\n<html><body><table><tr><td>Method</td><td></td><td></td><td>Max AUC‚ÜìMean AUC‚ÜìDefenseRate‚Üë</td></tr><tr><td>FedAvg</td><td>0.556</td><td>0.529</td><td>10%</td></tr><tr><td>FedVCK</td><td>0.544</td><td>0.514</td><td>50%</td></tr></table></body></html>\n\nTable 7: Overall predictive accuracy comparison on natural datasets. We adopt the ConvNet model by default.   \n\n<html><body><table><tr><td>Acc(%)</td><td>CIFAR10</td><td>STL10</td><td>ImageNette</td></tr><tr><td>B FedAvg</td><td>0.05 0.02 52.13 52.01</td><td>0.05 0.02 46.03 39.60</td><td>0.05 0.02 47.21 38.17</td></tr><tr><td>FedProx MOON FedGen</td><td>57.60 53.39 46.63 42.03 39.36 32.71</td><td>42.93 42.88 38.08 38.42 38.11 37.44</td><td>52.66 32.84 35.26 21.32 51.92 41.89</td></tr><tr><td>FedGAN FedMix DFRD FedDM DESA</td><td>55.79 53.86 42.28 43.97 52.07 37.53 54.75 50.47 53.90 48.19</td><td>51.84 50.03 46.56 42.88 31.60 21.03 54.90 51.62 46.74</td><td>50.80 40.31 50.80 39.41 33.20 16.20 52.25 43.82</td></tr><tr><td>FedVCK</td><td>62.96 60.56</td><td>37.33 57.04 56.89</td><td>42.29 28.90 62.76 61.73</td></tr></table></body></html>\n\n# Extend to Natural Datasets\n\nTo validate the generality of our method, we also extend our evaluation on natural datasets. The natural datasets contain various colored objects with more significant inter-class differences. The overall experimental results are shown in Table 7. Our method still outperforms others consistently, which demonstrate a boarder generality of our method. Full experiments about the predictive performance, communication cost, and privacy-preserving are listed in the Appendix.\n\n# Conclusion and Discussion\n\nIn this paper, we propose a novel data-centric federated learning method, FedVCK, for collaborative medical image analysis. FedVCK can tackle the non-IID problem in a communication-efficient manner. Specifically, FedVCK adaptively selects the most necessary knowledge with the guidance of current models, and condenses it into a small knowledge dataset with latent distribution constraints to enhance the quality. The condensed knowledge can effectively update the global model with the help of relational supervised contrastive learning. Our method generally outperforms state-of-the-art methods in non-IID scenarios, especially under limited communication budgets. Further work is to extend to more data modalities such as 3D CT and to adopt advanced techniques to improve the effectiveness and efficiency of condensation.",
    "summary": "```json\n{\n  \"core_summary\": \"### üéØ Ê†∏ÂøÉÊ¶ÇË¶Å\\n\\n> **ÈóÆÈ¢òÂÆö‰πâ (Problem Definition)**\\n> *   ËÆ∫ÊñáËß£ÂÜ≥ÁöÑÊ†∏ÂøÉÈóÆÈ¢òÊòØËÅîÈÇ¶Â≠¶‰π†Âú®ÂåªÁñóÂõæÂÉèÂàÜÊûê‰∏≠Èù¢‰∏¥ÁöÑÈùûÁã¨Á´ãÂêåÂàÜÂ∏ÉÔºànon-IIDÔºâÊï∞ÊçÆÈóÆÈ¢òÔºå‰ª•ÂèäÁî±Ê≠§ÂØºËá¥ÁöÑÊ®°ÂûãÊÄßËÉΩ‰∏ãÈôçÂíåÈÄö‰ø°ÊàêÊú¨È´òÊòÇÁöÑÈóÆÈ¢ò„ÄÇ\\n> *   ËØ•ÈóÆÈ¢òÁöÑÈáçË¶ÅÊÄßÂú®‰∫éÔºåÂåªÁñóÊï∞ÊçÆÈÄöÂ∏∏ÂÖ∑ÊúâÈ´òÂ∫¶ÁöÑÂºÇË¥®ÊÄßÂíåÂàÜÂ∏É‰∏çÂπ≥Ë°°ÊÄßÔºåÁé∞ÊúâÁöÑËÅîÈÇ¶Â≠¶‰π†ÊñπÊ≥ïÂú®ÈùûIIDÂú∫ÊôØ‰∏ãË°®Áé∞‰∏ç‰Ω≥Ôºå‰∏îÈ¢ëÁπÅÈÄö‰ø°‰ºöÂ¢ûÂä†ÈöêÁßÅÊ≥ÑÈú≤È£éÈô©„ÄÇ\\n\\n> **ÊñπÊ≥ïÊ¶ÇËø∞ (Method Overview)**\\n> *   ËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫FedVCKÁöÑÊñ∞ÂûãËÅîÈÇ¶Â≠¶‰π†ÊñπÊ≥ïÔºåÈÄöËøáÊúâ‰ª∑ÂÄºÁöÑÁü•ËØÜÊµìÁº©ÔºàValuable Condensed KnowledgeÔºâÊù•Ëß£ÂÜ≥ÈùûIIDÈóÆÈ¢òÔºåÂêåÊó∂ÂáèÂ∞ëÈÄö‰ø°ÊàêÊú¨„ÄÇ\\n\\n> **‰∏ªË¶ÅË¥°ÁåÆ‰∏éÊïàÊûú (Contributions & Results)**\\n> *   **ÂàõÊñ∞Ë¥°ÁåÆÁÇπ1Ôºö** ÊèêÂá∫Ê®°ÂûãÂºïÂØºÁöÑÁü•ËØÜÈÄâÊã©Êú∫Âà∂ÔºåÈÅøÂÖçÈáçÂ§çÁü•ËØÜÁöÑ‰º†ËæìÔºåÊèêÂçáÈÄö‰ø°ÊïàÁéá„ÄÇ\\n> *   **ÂàõÊñ∞Ë¥°ÁåÆÁÇπ2Ôºö** ÂºïÂÖ•ÊΩúÂú®ÂàÜÂ∏ÉÁ∫¶ÊùüÔºàlatent distribution constraintsÔºâÔºåÊèêÂçáÊµìÁº©Áü•ËØÜÁöÑË¥®Èáè„ÄÇ\\n> *   **ÂàõÊñ∞Ë¥°ÁåÆÁÇπ3Ôºö** Âú®ÊúçÂä°Âô®Á´ØÊèêÂá∫ÂÖ≥Á≥ªÁõëÁù£ÂØπÊØîÂ≠¶‰π†Ôºàrelational supervised contrastive learningÔºâÔºåÂ¢ûÂº∫Ê®°ÂûãÊõ¥Êñ∞ÁöÑÁõëÁù£‰ø°Âè∑„ÄÇ\\n> *   **ÂÖ≥ÈîÆÊï∞ÊçÆÔºö** Âú®Â§ö‰∏™ÂåªÁñóÊï∞ÊçÆÈõÜ‰∏äÔºåFedVCKÂú®ÈùûIIDÂú∫ÊôØ‰∏ãÁöÑÂáÜÁ°ÆÁéáÊØîÂü∫Á∫øÊ®°ÂûãÂπ≥ÂùáÊèêÂçá10-15%Ôºå‰∏îÂú®10ËΩÆÈÄö‰ø°ÂÜÖÂç≥ÂèØËææÂà∞Êé•ËøëÊúÄ‰ºòÊÄßËÉΩ„ÄÇ\",\n  \"algorithm_details\": \"### ‚öôÔ∏è ÁÆóÊ≥ï/ÊñπÊ°àËØ¶Ëß£\\n\\n> **Ê†∏ÂøÉÊÄùÊÉ≥ (Core Idea)**\\n> *   FedVCKÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÈÄöËøáÊµìÁº©ÂÆ¢Êà∑Á´ØÁöÑÈ´òË¥®ÈáèÁü•ËØÜÔºåÂπ∂Âú®ÊúçÂä°Âô®Á´ØÂà©Áî®Ëøô‰∫õÁü•ËØÜËøõË°åÈ´òÊïàÁöÑÊ®°ÂûãÊõ¥Êñ∞Ôºå‰ªéËÄåËß£ÂÜ≥ÈùûIIDÊï∞ÊçÆÂ∏¶Êù•ÁöÑÊåëÊàò„ÄÇ\\n> *   ËØ•ÊñπÊ≥ïÈÄöËøáÊΩúÂú®ÂàÜÂ∏ÉÁ∫¶ÊùüÂíåÊ®°ÂûãÂºïÂØºÁöÑÈÄâÊã©Êú∫Âà∂ÔºåÁ°Æ‰øùÊµìÁº©ÁöÑÁü•ËØÜÊó¢È´òË¥®ÈáèÂèàÂÖ∑ÊúâÈíàÂØπÊÄß„ÄÇ\\n\\n> **ÂàõÊñ∞ÁÇπ (Innovations)**\\n> *   **‰∏éÂÖàÂâçÂ∑•‰ΩúÁöÑÂØπÊØîÔºö** Áé∞ÊúâÊï∞ÊçÆ‰∏≠ÂøÉÁöÑËÅîÈÇ¶Â≠¶‰π†ÊñπÊ≥ïÂ≠òÂú®ÂêàÊàêÊï∞ÊçÆË¥®Èáè‰ΩéÂíåÁü•ËØÜÈáçÂ§çÁöÑÈóÆÈ¢ò„ÄÇ\\n> *   **Êú¨ÊñáÁöÑÊîπËøõÔºö** FedVCKÈÄöËøáÊΩúÂú®ÂàÜÂ∏ÉÁ∫¶ÊùüÊèêÂçáÁü•ËØÜË¥®ÈáèÔºåÂπ∂ÈÄöËøáÊ®°ÂûãÂºïÂØºÁöÑÈÄâÊã©Êú∫Âà∂ÈÅøÂÖçÈáçÂ§çÁü•ËØÜÁöÑ‰º†Ëæì„ÄÇ\\n\\n> **ÂÖ∑‰ΩìÂÆûÁé∞Ê≠•È™§ (Implementation Steps)**\\n> *   1. **ÂÆ¢Êà∑Á´ØÁü•ËØÜÊµìÁº©Ôºö** ‰ΩøÁî®ÊΩúÂú®ÂàÜÂ∏ÉÁ∫¶Êùü‰ºòÂåñÊµìÁº©Áü•ËØÜÊï∞ÊçÆÈõÜÔºåÁ°Æ‰øùÂÖ∂Ë¥®Èáè„ÄÇ\\n> *   2. **Ê®°ÂûãÂºïÂØºÁöÑÁü•ËØÜÈÄâÊã©Ôºö** Ê†πÊçÆÂΩìÂâçÊ®°ÂûãÁöÑÈ¢ÑÊµãËØØÂ∑ÆÔºåÈÄâÊã©ÊúÄÈáçË¶ÅÁöÑÁü•ËØÜËøõË°åÊµìÁº©„ÄÇ\\n> *   3. **ÊúçÂä°Âô®Á´ØÊ®°ÂûãÊõ¥Êñ∞Ôºö** Âà©Áî®ÂÖ≥Á≥ªÁõëÁù£ÂØπÊØîÂ≠¶‰π†Â¢ûÂº∫Ê®°ÂûãÊõ¥Êñ∞ÁöÑÁõëÁù£‰ø°Âè∑„ÄÇ\\n> *   **ÂÖ≥ÈîÆÂÖ¨ÂºèÔºö** ÊµìÁº©ÊçüÂ§±ÂáΩÊï∞Ôºà$L_{cond}$ÔºâÂíåÂÖ≥Á≥ªÁõëÁù£ÂØπÊØîÊçüÂ§±ÂáΩÊï∞Ôºà$L_{rc}$ÔºâÊòØÁÆóÊ≥ïÁöÑÊ†∏ÂøÉÊï∞Â≠¶Ë°®Ëææ„ÄÇ\\n\\n> **Ê°à‰æãËß£Êûê (Case Study)**\\n> *   ËÆ∫ÊñáÊú™ÊòéÁ°ÆÊèê‰æõÊ≠§ÈÉ®ÂàÜ‰ø°ÊÅØ„ÄÇ\",\n  \"comparative_analysis\": \"### üìä ÂØπÊØîÂÆûÈ™åÂàÜÊûê\\n\\n> **Âü∫Á∫øÊ®°Âûã (Baselines)**\\n> *   FedAvg, FedProx, MOON, FedGen, FedMix, FedGAN, DFRD, FedDM, DESA„ÄÇ\\n\\n> **ÊÄßËÉΩÂØπÊØî (Performance Comparison)**\\n> *   **Âú®ÂáÜÁ°ÆÁéá‰∏äÔºö** Êú¨ÊñáÊñπÊ≥ïÂú®PathÊï∞ÊçÆÈõÜ‰∏äËææÂà∞‰∫Ü80.36%ÔºåÊòæËëó‰ºò‰∫éÂü∫Á∫øÊ®°ÂûãFedAvgÔºà46.34%ÔºâÂíåFedDMÔºà73.97%Ôºâ„ÄÇ‰∏éË°®Áé∞ÊúÄ‰Ω≥ÁöÑÂü∫Á∫øÁõ∏ÊØîÔºåÊèêÂçá‰∫Ü6.39‰∏™ÁôæÂàÜÁÇπ„ÄÇ\\n> *   **Âú®ÈÄö‰ø°ÊïàÁéá‰∏äÔºö** Êú¨ÊñáÊñπÊ≥ïÂú®10ËΩÆÈÄö‰ø°ÂÜÖÂç≥ÂèØËææÂà∞Êé•ËøëÊúÄ‰ºòÊÄßËÉΩÔºåËÄåÂü∫Á∫øÊ®°ÂûãÈúÄË¶Å100ËΩÆÈÄö‰ø°ÊâçËÉΩËææÂà∞Á±ª‰ººÊïàÊûú„ÄÇ\\n> *   **Âú®ÈöêÁßÅ‰øùÊä§‰∏äÔºö** Êú¨ÊñáÊñπÊ≥ïÁöÑÊàêÂëòÊé®ÁêÜÊîªÂáªÔºàMIAÔºâÈò≤Âæ°Áéá‰∏∫50%ÔºåÊòæËëóÈ´ò‰∫éFedAvgÁöÑ10%„ÄÇ\",\n  \"keywords\": \"### üîë ÂÖ≥ÈîÆËØç\\n\\n> **ÊèêÂèñ‰∏éÊ†ºÂºèÂåñË¶ÅÊ±Ç**\\n> *   ËÅîÈÇ¶Â≠¶‰π† (Federated Learning, FL)\\n> *   ÈùûÁã¨Á´ãÂêåÂàÜÂ∏É (Non-Independent and Identical Distribution, non-IID)\\n> *   Áü•ËØÜÊµìÁº© (Knowledge Condensation, N/A)\\n> *   ÂåªÁñóÂõæÂÉèÂàÜÊûê (Medical Image Analysis, MIA)\\n> *   ÊΩúÂú®ÂàÜÂ∏ÉÁ∫¶Êùü (Latent Distribution Constraints, N/A)\\n> *   ÂÖ≥Á≥ªÁõëÁù£ÂØπÊØîÂ≠¶‰π† (Relational Supervised Contrastive Learning, N/A)\\n> *   ÈÄö‰ø°ÊïàÁéá (Communication Efficiency, N/A)\"\n}\n```"
}