{
    "source": "Semantic Scholar",
    "arxiv_id": "2405.16304",
    "link": "https://arxiv.org/abs/2405.16304",
    "pdf_link": "https://arxiv.org/pdf/2405.16304.pdf",
    "title": "Federated Unsupervised Domain Generalization using Global and Local Alignment of Gradients",
    "authors": [
        "Farhad Pourpanah",
        "Mahdiyar Molahasani",
        "Milad Soltany",
        "Michael A. Greenspan",
        "A. Etemad"
    ],
    "categories": [
        "cs.LG",
        "cs.AI"
    ],
    "publication_date": "2024-05-25",
    "venue": "AAAI Conference on Artificial Intelligence",
    "fields_of_study": [
        "Computer Science"
    ],
    "citation_count": 2,
    "influential_citation_count": 0,
    "institutions": [
        "Queen’s University"
    ],
    "paper_content": "# Federated Unsupervised Domain Generalization Using Global and Local Alignment of Gradients\n\nFarhad Pourpanah\\*, Mahdiyar Molahasani\\*, Milad Soltany\\*, Michael Greenspan, Ali Etemad\n\nQueen’s University, Canada {f.pourpanahnavan, m.molahasani, milad.soltany, michael.greenspan, ali.etemad}@queensu.ca\n\n# Abstract\n\nWe address the problem of federated domain generalization in an unsupervised setting for the first time. We first theoretically establish a connection between domain shift and alignment of gradients in unsupervised federated learning and show that aligning the gradients at both client and server levels can facilitate the generalization of the model to new (target) domains. Building on this insight, we propose a novel method named FedGaLA, which performs gradient alignment at the client level to encourage clients to learn domain-invariant features, as well as global gradient alignment at the server to obtain a more generalized aggregated model. To empirically evaluate our method, we perform various experiments on four commonly used multi-domain datasets, PACS, OfficeHome, DomainNet, and TerraInc. The results demonstrate the effectiveness of our method which outperforms comparable baselines. Ablation and sensitivity studies demonstrate the impact of different components and parameters in our approach.\n\nCode — https://github.com/MahdiyarMM/FedGaLA\n\n# 1 Introduction\n\nFederated learning (McMahan et al. 2017; Zhang et al. 2021a) has emerged as a promising framework for training machine learning models across multiple decentralized clients while preserving data privacy. It allows clients to collaboratively train a global model without the need to exchange their sensitive and local data. Each client trains a local model using its data and a server aggregates these models at a certain frequency (Ghosh et al. 2020; Charles et al. 2021). However, given that each client collects a different set of local training data, two issues arise. First, the data collected by each client is often recorded under unique conditions that may result in mutual domain shifts (Liu et al. 2021). Second, labeling training data is inherently challenging and resource-intensive; this issue is even more pronounced in the context of federated settings. A typical example of this scenario is a network of wearable activity monitors where variations in user conditions such as demographics or ambient factors can lead to significant domain shifts across devices, meanwhile, the users are generally not asked to provide ground-truth labels for their performed activities.\n\n![](images/588053c5bf0ac029119f64839280d47080b2c2f43c73f77fbfc1efd7d60a303c.jpg)  \nFigure 1: Overview of FedGaLA.\n\nIn prior works, each of these issues has been addressed as a separate problem statement: (i) federated domain generalization (Zhang et al. 2021b; Nguyen, Torr, and Lim 2022; Bai, Bagchi, and Inouye 2024), and (ii) federated unsupervised learning (Zhuang et al. 2021; Han et al. 2022). Despite the effectiveness of both problem definitions, each ignores the fundamental assumptions of the other regarding the data in terms of distributions and availability of labels. To further approach federated learning in a more practical scenario, we propose to merge these two under a new umbrella called federated unsupervised domain generalization, which we define as Definition 1. To our knowledge, prior works have not studied federated learning under such constraints.\n\nDefinition 1. Federated unsupervised domain generalization is the problem of learning general representations from various decentralized unlabeled datasets, each belonging to a different domain, in a federated setup where data sharing is restricted due to privacy concerns.\n\nTo address this new problem, we propose a novel method called Federated Unsupervised Domain Generalization using Global and Local Alignment of Gradients (FedGaLA). To learn more generalized representations from multiple domains, FedGaLA relies on gradient alignment at both client (local) and server (global) levels. At the client level, local models are trained with unlabeled local data available to each client using self-supervised learning (SSL). To learn domaininvariant representations, gradients that are not aligned with the reference gradient, i.e., the global learning direction, are discarded. At the server level, to achieve better generalization, the local models are aggregated based on their alignment with each other (see Figure 1). Specifically, the local gradients that are more closely aligned with the average gradient are given greater weight in the aggregation stage. Moreover, we provide a detailed theoretical framework establishing a connection between the alignment of gradients from different clients and the similarity between their data distributions. Since FedGaLA does not require the sharing of data between clients to perform alignment at either the server or client sides, it effectively preserves data privacy. We verify the performance of our approach using four public datasets, PACS (Yu et al. 2022), OfficeHome (Venkateswara et al. 2017), DomainNet (Peng et al. 2019), and TerraInc (Beery, Van Horn, and Perona 2018) and demonstrate strong performance in federated unsupervised domain generalization in comparison to various baselines. We also conduct different ablation and sensitivity studies to understand the impact of different parameters and the choice of SSL frameworks.\n\nIn summary, the main contributions of this study are as follows. (1) To our knowledge, this is the first work to address federated unsupervised domain generalization, introducing a new problem class in this area. (2) We propose a novel technique that aligns gradients at both the local and global levels. In doing so, our solution effectively extracts domain-invariant information in local training and aligns each client’s contributions during the aggregation process, boosting the model’s generalization across various target domains. (3) We conduct extensive experiments and ablations to demonstrate the effectiveness of our proposed method on various benchmarks. To enable fast reproducibility and contribute to the area, we make our code public at: https://github.com/MahdiyarMM/FedGaLA.\n\n# 2 Related Works\n\nFederated Learning. Federating learning is a technique of distributed training that enables learning from decentralized clients without the need to transfer raw data to a central server (McMahan et al. 2017; Zhang et al. 2021a). In the first work in the area of federated learning, FedAVG (McMahan et al. 2017) aggregates the weights of clients via averaging to form the global model. Various federated learning techniques have been since developed for different purposes. FedProx (Li et al. 2020) adds a proximal term to the objective to tackle the data heterogeneity problem. FedBuf (Nguyen et al. 2022) proposes to use buffered asynchronous aggregation to address scalability and privacy issues. FedALA (Zhang et al. 2023b) dynamically aggregates the downloaded global model with the local model on each client, ensuring alignment with the local objective. Moon (Li, He, and Song 2021) leverages the similarity between model representations to improve the local training of individual parties through contrastive learning. FLTrust (Cao et al. 2020) and SignGuard (Xu et al. 2022) leverage gradient filtering to detect and eliminate malicious gradients with the aim of enhancing the robustness of federated learning systems against model poisoning attacks. Federated Domain Generalization. This category of problems aims to learn a general model in a privacy-preserving manner that generalizes well to new target domains with distribution shifts (Liu et al. 2021; Li et al. 2023). There have been several studies to explore this direction, mainly focusing on learning domain-invariant features (Nguyen, Torr, and Lim 2022; Wu and Gong 2021) or identifying common features across multiple domains (Zhang et al. 2021b). FedDG (Liu et al. 2021) allows clients to share their data in the frequency space for medical image segmentation. FedSR (Nguyen, Torr, and Lim 2022) proposes to learn a simple representation of data to better generalize to target domains through two regularizers, i.e., L2-norm and conditional Mutual Information. FedADG (Zhang et al. 2021b) leverages adversarial training to align source domain distributions by matching each distribution with a reference distribution. FedKA (Sun, Chong, and Ochiai 2023) learns domain-invariant features by employing feature distribution matching in a universal workspace. CCST (Chen et al. 2023) aligns various client distributions and mitigates model biases by adapting local models to diverse sample styles via cross-client style transfer. FedDG-GA (Zhang et al. 2023c) uses domain divergence and a moment mechanism to enhance generalization through dynamic domain weight adjustment.\n\nFedSB (Soltany et al. 2024) enhances domain generalization by introducing controlled uncertainty to local clients and ensuring balanced contributions from each client. StableFDG (Park et al. 2024) uses style and attention-based strategies to address the federated domain generalization problem. hFedF (Bartholet et al. 2024) utilizes hypernetworks for non-linear aggregation to facilitate generalization to unseen domains. PerAda (Xie et al. 2024) uses knowledge distillation to align each client’s adapter with a global adapter, blending their knowledge. This approach helps the model handle shifting distributions across diverse domains while keeping computational costs low. gPerXAN (Le et al. 2024) combines a personalized normalization scheme with a guiding regularizer to address domain shifts in federated learning, reducing privacy risks and communication costs. MCGDM (Wei and Han 2024) uses intra- and inter-domain gradient matching to minimize domain-specific overfitting, promoting robust generalization on unseen domains. Finally, FGGP (Wan, Huang, and Ye 2024) captures domain information using clustered prototypes and contrastive learning.\n\nFederated Unsupervised Learning. This category attempts to learn representations from unlabeled data distributed across clients while preserving data privacy (Jin et al. 2020). The study by (van Berlo, Saeed, and Ozcelebi 2020) is the first to propose federated unsupervised learning using an encoder-decoder structure. FedU (Zhuang et al. 2021) employs a contrastive learning approach with online and target networks to enable each client to learn representations from unlabeled data independently. It also introduces a dynamic aggregation mechanism to update the predictor, either locally or globally. Similarly, FedEMA (Zhuang, Wen, and Zhang 2022) uses the exponential moving average of the global model to update local ones. FedX (Han et al. 2022) proposes to use knowledge distillation to learn representation from local data and refine the central server’s knowledge. FedCA (Zhang et al. 2023a) consists of two components: (i) a dictionary module to gather the representations of samples from each client to maintain consistency in the representation space across all clients, and $( i i )$ an alignment module to adjust each client’s representation to match a base model trained on public data.\n\n# 3 Approach\n\n# 3.1 Problem Formulation\n\nTo formalize Definition 1, assume $K$ clients, $C _ { i }$ , in a federaEtaecdhsedtautpa,seta chonwsiitsht sitsofo udnaltabpeoliendtsdasta $\\mathcal { D } _ { i } = \\{ \\mathbf { x } _ { i } ^ { ( n ) } \\} _ { n = 1 } ^ { N _ { i } }$ $N _ { i }$ tinct data distribution $p ( \\mathbf { x } _ { i } )$ , where $\\mathbf { x } _ { i }$ is a vector of $F$ features, i.e., $\\mathbf x _ { i } = [ x _ { i } ^ { 1 } , x _ { i } ^ { 2 } , . . . x _ { i } ^ { F } ] ^ { T }$ . The data distributions are assumed to be different among the clients with each distribution $p ( \\mathbf { x } _ { i } )$ sampled from a family of distributions $\\mathcal { P }$ . Privacy constraints prevent the transfer of data between clients or to the server $S$ . The objective is to learn generalized representations from $\\mathbf { x } _ { i }$ that perform well across unseen distributions $p ( \\mathbf { x } _ { t } ) \\sim \\mathcal { P }$ , where $\\bar { p } ( \\mathbf { x } _ { i } ) \\neq p ( \\mathbf { x } _ { t } )$ . This is formulated as minimizing the expected loss over the unseen distributions:\n\n$$\n\\operatorname* { m i n } _ { \\theta } \\mathbb { E } _ { p ( \\mathbf { x } _ { t } ) \\sim \\mathcal { P } } \\left[ \\mathbb { E } _ { p ( \\mathbf { x } _ { t } ) } \\left[ \\mathcal { L } ( \\theta ; \\mathbf { x } ) \\right] \\right] ,\n$$\n\nwhere $\\mathcal { L }$ is the unsupervised loss function, and $\\theta$ is the set of global model parameters. Each client contributes to this goal by computing a local objective function approximating the expected loss with respect to its own data distribution:\n\n$$\n\\operatorname* { m i n } _ { \\theta _ { i } } \\mathbb { E } _ { p ( \\mathbf { x } _ { i } ) } \\left[ l _ { i } ( \\boldsymbol { \\theta } _ { i } ; \\mathbf { x } ) \\right] \\approx \\frac { 1 } { N _ { i } } \\sum _ { n = 1 } ^ { N _ { i } } \\mathcal { L } ( \\boldsymbol { \\theta } _ { i } ; \\mathbf { x } _ { i } ^ { ( n ) } ) ,\n$$\n\nwhere $\\theta _ { i }$ indicates the local parameters of client $C _ { i }$ , and $\\theta$ is the global aggregation of all local $\\theta _ { i }$ .\n\n# 3.2 Gradient Alignment and Domain Shift\n\nUnder a federated learning framework, privacy constraints prevent clients and servers from accessing each other’s data, including distribution information such as data means and variances. They can, however, observe individual client gradients at the server level and the average aggregated gradient across clients at the client level. We motivate our work on the fact that alignment of gradients may infer characteristics of the client domain distributions, thus facilitating improved model generalization. While empirically the utility of gradients has been demonstrated in the area of domain generalization (Mansilla et al. 2021), no theoretical basis has been proposed for this approach under federated constraints. Accordingly, we aim to establish a link between gradient alignment and domain shifts within the proposed problem formulation (Definition 1). Our theoretical findings provide the basis for effective local parameter updates and global model aggregation to address federated unsupervised domain generalization.\n\nAssumption 1. Let each $\\mathbf { x } _ { i } ^ { f }$ be a random variable drawn from a Normal distribution $p ( \\mathbf { x } _ { i } ^ { f } ) \\sim \\mathcal { P }$ (Bar-Hillel et al. 2003). Within a single domain, following (Sˇtrumbelj and\n\nKononenko 2014, 2011), features are assumed to be independent $( C o v ( x _ { i } ^ { f _ { 1 } } , x _ { i } ^ { f _ { 2 } } ) = 0 ,$ ). Across different domains, corresponding features of $\\mathbf { x } _ { i } ^ { f }$ and $\\mathbf { x } _ { j } ^ { f }$ are bivariate with a covariance of $\\sigma _ { x _ { i } ^ { f } , x _ { j } ^ { f } }$ . In line with contemporary practices in deep learning, the features are normalized with $\\mu = 0$ and $\\sigma ^ { 2 } = 1$ (Yu and Spiliopoulos 2022; Qi, Zhou, and Wang 2022; Huang et al. 2023). We also assume that each client is a one-layer encoder with the sigmoid activation function. Following (Chen et al. 2020), local training is performed using contrastive loss where a random augmentation of a data sample is used as the positive pair and all other samples are utilized as the negative pairs. The random augmentation is performed with the same random Affine transformation $( A x _ { i } + B )$ (Wang et al. 2023) broadcast to all clients. After each epoch, the local models are aggregated in the server and sent back to all clients. The gradient $\\mathbf { g } _ { i }$ of the model is assumed to be differentiable.\n\nTheorem 1 (Gradient Misalignment in Federated Self-supervised Learning Dependent upon Domain Shift). Given Assumption $\\boldsymbol { { \\mathit { 1 } } }$ , under the problem proposed in Definition $\\boldsymbol { { \\mathit { 1 } } }$ , for two distinct domains characterized by random variables $\\mathbf { x } _ { i }$ and $\\mathbf { x } _ { j }$ belonging to two different clients $C _ { i }$ and $C _ { j }$ , an increase in domain shift across the clients results in a decrease in covariance $C o \\nu ( \\mathbf { g } _ { i } , \\mathbf { g } _ { j } )$ of the corresponding gradients $\\mathbf { g } _ { i }$ , $\\mathbf { g } _ { j }$ across $C _ { i }$ and $C _ { j }$ ’s respective local models.\n\nProof of Theorem 1. Motivated by previous works where the similarity between the representations of different domains under domain shift is measured by Mutual Information (Gao et al. 2020; Menapace, Lathuili\\`ere, and Ricci 2020; Wang et al. 2021), we use this concept for modeling the similarity between different domains drawn from a family of distributions. To calculate the mutual information we introduce the following Lemma.\n\nLemma 1. Given Assumption $\\jmath$ , the mutual information between two random variables $\\mathbf { x } _ { i }$ and $\\mathbf { x } _ { j }$ can be calculated as:\n\n$$\nI ( \\mathbf { x } _ { i } ; \\mathbf { x } _ { j } ) = - \\frac { 1 } { 2 } \\sum _ { f = 1 } ^ { F } \\log ( 1 - \\sigma _ { x _ { i } ^ { f } , x _ { j } ^ { f } } ^ { 2 } ) .\n$$\n\nThe full proof of this lemma is presented in Appendix A.1.\n\nSince $\\sigma _ { x _ { i } ^ { f } , x _ { i } ^ { f } } = \\sigma _ { x _ { i } ^ { f } } ^ { 2 }$ , given identical and standardized domains we have $\\sigma _ { x _ { i } ^ { f } , x _ { j } ^ { f } } = 1$ . Therefore, we observe from Eq. (3) that as the shift between the domain approaches zero, the Mutual Information approaches infinity. On the other hand, as the two domains shift apart, $\\sigma _ { x _ { i } ^ { f } , x _ { j } ^ { f } }$ approaches zero, and consequently the Mutual information monotonically decreases toward zero. Accordingly, $I ( \\mathbf { x } _ { i } ; \\mathbf { x } _ { j } )$ and $\\sigma _ { x _ { i } ^ { f } , x _ { i } ^ { f } }$ are positively and monotonically correlated. To establish the link between the covariance of the features and the variance of the gradient and demonstrate their relationship, the following lemma and claim are introduced.\n\nLemma 2. Given Assumption $^ { 1 }$ , the covariance between the differentiable function g with inputs $\\mathbf { x } _ { i }$ and $\\mathbf { x } _ { j }$ can be\n\n$$\n\\mathrm { C o v } ( \\mathbf { g } _ { i } , \\mathbf { g } _ { j } ) _ { m n } \\approx \\sum _ { f = 1 } ^ { F } \\sigma _ { x _ { i } ^ { f } , x _ { j } ^ { f } } \\left( \\frac { \\partial g _ { i ( m ) } } { \\partial x _ { i } ^ { f } } \\bigg | _ { \\mu _ { i } ^ { f } } \\right) \\left( \\frac { \\partial g _ { j ( n ) } } { \\partial x _ { j } ^ { f } } \\bigg | _ { \\mu _ { j } ^ { f } } \\right) ,\n$$\n\nwhere $\\sigma _ { x _ { i } ^ { f } , x _ { j } ^ { f } }$ is the covariance between the $f ^ { t h }$ feature of $x _ { i }$ and $x _ { j }$ and $g _ { i ( m ) }$ is the $m ^ { t h }$ dimension of $g _ { i }$ . The proof for this Lemma is provided through the Taylor expansion derived in Appendix A.2.\n\nClaim 1. For all clients trained under the federated unsupervised domain generalization setup using self-supervised learning described in Assumption $\\jmath$ , for two clients $C _ { i }$ and $C _ { j }$ , for both positive and negative contrastive data pairs, the sign of ( ∂gif $\\begin{array} { r } { \\big ( \\frac { \\partial \\mathbf { g } _ { i } } { \\partial x _ { i } ^ { f } } \\bigg | _ { x _ { i } ^ { f } = \\mu _ { i } ^ { f } } \\big ) \\big ( \\frac { \\partial \\mathbf { g } _ { j } } { \\partial x _ { j } ^ { f } } \\bigg | _ { x _ { j } ^ { f } = \\mu _ { j } ^ { f } } \\big ) } \\end{array}$ is always positive in all dimensions. S\fee proof in A\fppendix A.3.\n\nAccording to Eq. (4) introduced in Lemma 2 and Claim 1, we conclude that $\\mathrm { C o v } ( \\mathbf { g } _ { i } , \\mathbf { g } _ { j } )$ and $\\sigma _ { x _ { i } ^ { f } , x _ { j } ^ { f } }$ are positively and monotonically correlated. Therefore, $\\mathrm { C o v } ( \\mathbf { g } _ { i } , \\mathbf { g } _ { j } )$ and $I ( \\mathbf { x } _ { i } ; \\mathbf { x } _ { j } )$ are also positively and monotonically correlated, which completes the proof. □\n\nOur theoretical findings may also be applicable to Federated Supervised Domain Generalization, which could form the subject of future research as expressed in Appendix A.4 and (Molahasani et al. 2024). We further investigate the relationship between the distribution of the domains and their corresponding gradients through the following Corollary.\n\nCorollary 1. Given the assumptions stated, for two distinct domains characterized by random variables $\\mathbf { x } _ { i }$ and $\\mathbf { x } _ { j }$ from the distribution family $\\mathcal { P }$ , as $I ( \\mathbf { x } _ { i } , \\mathbf { x } _ { j } )$ decreases, then the variance of the difference of the corresponding gradients, $\\mathrm { V a r } ( \\mathbf { g } _ { i } - \\mathbf { g } _ { j } )$ , increases. The full proof is presented in Appendix A.6.\n\n# 3.3 FedGaLA\n\nThe analysis above establishes a link between gradient alignment and domain shift, forming the basis for our proposed FedGaLA framework. Figure 1 illustrates an overview of our framework for addressing the newly proposed problem setup (Definition 1). FedGaLA is remotely inspired by prior works that demonstrate improved generalization in centralized (nonfederated) learning through gradient alignment (Mansilla et al. 2021; Shi et al. 2022; Rame, Dancette, and Cord 2022). However, our framework extends this notion by integrating gradient alignment into the field of unsupervised and federated learning, and assumes, unlike (Mansilla et al. 2021; Shi et al. 2022; Rame, Dancette, and Cord 2022), that the distribution of data from different clients is not known. Our core idea includes $( i )$ enabling clients to learn domain-invariant representations at the client level through local gradient alignment, and $( i i )$ adjusting the aggregation weights at the server level using global gradient alignment.\n\n1: Input: data $\\mathcal { D } _ { i }$ , initialization $\\Theta ^ { 0 }$   \n2: Output: $\\boldsymbol { \\Theta } ^ { T }$   \n3: for $t$ from 1 to $T$ do   \n4: Server:   \n5: Calculate client updates: $\\mathbf { g } _ { i } ^ { ( t ) } \\gets \\boldsymbol { \\Theta } _ { i } ^ { ( t ) } - \\boldsymbol { \\Theta } ^ { ( t - 1 ) }$   \n6: Initialize global update: $\\mathbf { g } ^ { ( t + 1 ) }  \\mathrm { F e d A V G } ( \\mathbf { g } _ { i } ^ { ( t ) } )$   \n7: for $j$ from 1 to iter do   \n8: Calculate weights: $\\begin{array} { r } { w _ { i } \\gets \\frac { \\mathrm { C o s i n e } ( \\mathbf { g } _ { i } ^ { ( t ) } , \\mathbf { g } ^ { ( t + 1 ) } ) + 1 } { \\gamma } } \\end{array}$   \n9: Normalize weights: $\\begin{array} { r } { w _ { i } \\gets \\frac { w _ { i } } { \\sum w _ { i } } } \\end{array}$   \n10: Aggregate updates: $\\begin{array} { r } { \\hat { \\mathbf { g } } ^ { ( t + 1 ) }  \\sum _ { i = 1 } ^ { K } w _ { i } \\mathbf { g } _ { i } ^ { ( t ) } } \\end{array}$   \n11: end for   \n12: Update global model: $\\Theta ^ { ( t + 1 ) } \\gets \\Theta ^ { ( t ) } + \\hat { \\mathbf { g } } ^ { ( t + 1 ) }$   \n13: Communicate: $\\Theta _ { i } \\gets \\Theta ^ { ( t + 1 ) }$   \n14: Client:   \n15: for $j$ from 1 to $N _ { \\mathrm { b a t c h } }$ do   \n16: Compute batch gradient: $\\mathbf { g } _ { i , j } ^ { ( t ) }  \\nabla l _ { i } ( x _ { i , j } , \\theta _ { i } ^ { ( t ) } )$   \n187: for $\\mathbf { \\xi } _ { l }$ ftiroma 1r teo $L$ ed:o $\\hat { \\mathbf { g } } _ { e s t } ^ { ( l , t ) } = \\theta ^ { ( l , t ) } - \\theta ^ { ( l , t - 1 ) }$   \n19: if $\\mathrm { C o s i n e } ( \\mathbf { g } _ { i , j } ^ { ( l , t ) } , \\hat { \\mathbf { g } } _ { \\mathrm { e s t } } ^ { ( l , t ) } ) > \\tau$ then   \n20: Update weights:   \n$\\overset { \\bullet } { \\theta } _ { i } ^ { ( l , t ) } \\gets \\theta _ { i } ^ { ( l , t - 1 ) } - \\eta \\cdot \\nabla l _ { i } ^ { ( l , t ) } ( x _ { i , j } , \\theta _ { i } ^ { ( l , t ) } )$   \n21: end if   \n22: end for   \n23: end for   \n24: Communicate: $S \\gets \\Theta _ { i }$   \n25: end for\n\nAt each communication round, clients are initialized with the global model. Subsequently, each client updates its parameters using SSL for $E$ epochs based on the local data through local gradient alignment and sends these updates back to the server. Finally, the server employs the global gradient alignment technique to perform aggregation. This procedure is repeated for $T$ communications rounds to determine the global model. The remaining part of this section provides details on local and global gradient alignment, and the complete framework is outlined in Algorithm 1.\n\nLocal Gradient Alignment. Our method performs layerwise local gradient alignment using a reference gradient. This reference is derived from the $\\bar { l } ^ { \\mathrm { t h } }$ layer of the global model’s parameter updates between the current and the previous communication round. Suppose $\\Theta = \\{ \\theta ^ { ( l ) } \\} _ { l = 1 } ^ { L }$ indicates the parameters of the global model, where $\\theta ^ { ( l ) }$ represents the parameters of the ${ { \\mathit { l } } ^ { \\mathrm { { t h } } } }$ layer. The reference gradient for the ${ { l } ^ { t h } }$ layer is computed as ˆg(els,t) = θ(l,t) − θ(l,t−1), where θ(l,t) and are the parameters of the $l ^ { \\mathrm { t h } }$ layer of the global cmaloldyelusaetdrotuondest $t$ ramnidn $t - 1$ e,trhesrptehcet vgrealyd.ieTnhteonf, $\\hat { \\mathbf { g } } _ { e s t } ^ { ( l , t ) }$ liasyleorobtained during training (e.g., via SGD) is aligned with the reference. The cosine similarity between the batch gradient and the reference for each layer $l$ at round $t$ is computed $\\begin{array} { r } { c o s ( \\phi ) ^ { ( l , t ) } = \\frac { \\langle { \\bf g } _ { i , k } ^ { ( l , t ) } , { \\bf g } _ { \\mathrm { e s t } } ^ { ( l , t ) } \\rangle } { \\| { \\bf g } _ { i , k } ^ { ( l , t ) } \\| \\cdot \\| { \\bf g } _ { \\mathrm { e s t } } ^ { ( l , t ) } \\| } } \\end{array}$ g⟨(gli(,,lt,k) ,ge(gslte(,slt,)t⟩) , where gi(,l,kt) is the gradient of $k ^ { \\mathrm { { t h } } }$ batch of the $i ^ { \\mathrm { t h } }$ client at layer $l$ and round $t$ . Finally, batch gradients whose similarity with $\\hat { \\mathbf { g } } _ { e s t } ^ { ( l , t ) }$ are less than a user-defined threshold $\\tau$ are discarded during the update process. This prevents clients from learning domain-specific features by disregarding local gradients that are not aligned with the global model. The rationale for discarding unaligned gradients instead of applying soft weighting is that when a gradient vector is unaligned with $\\hat { \\bf g } _ { e s t }$ , scaling does not change this alignment, as the cosine of the angle between them is independent of scale. To establish a theoretical basis for the proposed local alignment, we introduce the following.\n\nProposition 1. Given two sets of gradient vectors $\\mathbf { g } _ { i }$ and $\\mathbf { g } _ { j }$ , by removing the $K ^ { t h }$ vector in $\\mathbf { g } _ { j }$ where $c o s ( \\mathbf { g } _ { j , K } , \\mathbf { g } _ { e s t } ) < 0 ,$ the covariance of two sets increases. For more details on this Proposition and its proof, see Appendix A.8.\n\nTheorem 1 highlighted how an increase in domain shift between clients $C _ { i }$ and $C _ { j }$ correlates with a decrease in the covariance of their gradient vectors, $\\mathbf { g } _ { i }$ and $\\mathbf { g } _ { j }$ . Therefore, gradient covariance can be used as an indicator of domain shift. Proposition 1 complements this by showing that by selectively removing gradients from $\\mathbf { g } _ { j }$ that have a negative cosine similarity with an estimated target direction, $\\mathbf { g } _ { e s t }$ , we can effectively increase the covariance of the gradient sets, thus potentially counteracting the effects of domain shift.\n\nGlobal Gradient Alignment. To aggregate the local (client) models at the server, the locally measured gradients that closely match the average gradient across all clients are assigned greater weights. This soft weighting process operates as follows. Once the server receives the local models, it first obtains the local update ˆgi(t) = Θi(t) − Θ(t−1). Then, the initial global update $\\hat { \\mathbf { g } } ^ { ( t + 1 ) }$ is calculated by averaging all $\\hat { \\mathbf { g } } _ { i } ^ { ( t ) }$ . Subsequently, the weight of each client is computed $i ^ { \\mathrm { { t h } } }$ nclgiewnit and = cos(ˆgi(t),ˆg2(t+1))+1 , where wi is the weight for the $\\hat { \\mathbf { g } } _ { i } ^ { ( t ) }$ is the gradient o e $i ^ { \\mathrm { { t h } } }$ client at round $t$ . This weight reflects the degree of alignment between each client’s update and the global model’s update direction. To ensure these weights are properly normalized using $w _ { i } = w _ { i } / { \\sum _ { k = 1 } ^ { K } w _ { k } }$ . The normalization of weights allows for the proportional contribution of each client’s update.\n\nFinally, the normalized weights are used to perform aggregation. Each client’s model update is scaled by its respective weight, and these weighted updates are then aggregated to compute the weighted average update. The global model at round t + 1 is updated based on ˆg(t+1) = PiK=1 ˆg( . This aggregation step is repeated three times, refining the weights with each iteration. This ensures the global model update is significantly influenced by clients whose updates align closely with the global learning objective. After completing the aggregation process, the global model is further updated based on $\\Theta ^ { ( t + 1 ) } \\gets \\Theta ^ { ( t ) } + \\hat { \\mathbf { g } } ^ { ( t + 1 ) }$ . The rationale for using different alignment strategies at the client and server levels stems from the inherent differences between local training and global aggregation. At the client level, we manage batch gradients, allowing us to specifically discard the unaligned ones without significant information loss. However, discarding gradients at the server-level corresponds to the deletion of entire clients, which can adversely affect the outcome.\n\n# 4 Experiment Setup\n\nDatasets. To evaluate the effectiveness of our proposed method, we conduct experiments across four commonly used benchmarks for domain generalization. They include: PACS (Li et al. 2017), which consists of 9,991 images from four domains: ‘Photo’, ‘Art-painting’, ‘Cartoon’, and ‘Sketch’, across seven classes; Office-Home (Venkateswara et al. 2017), which consists of 15,588 images from four domains: ‘Art’, ‘Clipart’, ‘Product’, and ‘Real-world’, across 65 classes; TerraInc (Beery, Van Horn, and Perona 2018), which includes 24,788 images from four domains ‘Location $3 8 ^ { \\circ }$ , ‘Location 43’, ‘Location $4 6 ^ { \\circ }$ , and ‘Location $1 0 0 ^ { \\circ }$ , across nine classes; DomainNet (Peng et al. 2019), which consists of 569,010 images in six domains: ‘Clipart’, ‘Infograph’, ‘Painting’, ‘Quickdraw’, ‘Real’, and ‘Sketch’, covering 345 classes. Following (Zhang et al. 2022), for the DomainNet dataset, we select the following classes: zigzag, tiger, tornado, flower, giraffe, toaster, hexagon, watermelon, grass, hamburger, blueberry, violin, fish, sun, broccoli, Eiffel tower, horse, train, bird, and bee (Zhang et al. 2022), resulting in a total of 38556 samples. In all experiments using this dataset, three domains are used for training (‘Painting’, ‘Real’, and ‘Sketch’) and the other three domains (‘Clipart’, ‘Infographics’, and ‘Quickdraw’) are used for testing.\n\nEvaluation. We use the leave-one-domain-out setting used in prior works (Zhang et al. 2023a, 2022; Gulrajani and Lopez$\\mathrm { P a z } 2 0 2 1 \\AA$ ). This involves selecting one domain as the target, training the model on the rest of the domains, and then testing the model’s performance on the selected target domain. Linear evaluation, a common feature evaluation approach, is utilized to evaluate the quality of learned representations (Feng, Xu, and Tao 2019; Zhang, Isola, and Efros 2017; Kolesnikov, Zhai, and Beyer 2019). For linear evaluation, following (van Berlo, Saeed, and Ozcelebi 2020; Zhuang, Wen, and Zhang 2022), we utilize $10 \\%$ and $30 \\%$ of the target data to train the linear classifier and evaluate the remaining $90 \\%$ and $70 \\%$ of the data, respectively.\n\nBaselines. To evaluate our method, we take a two-pronged approach: (1) We adapt several popular SSL approaches to the federated domain generalization task, denoting them as FedSimCLR, FedMoCo, FedBYOL, and FedSimSiam. To this end, we employed SimCLR (Chen et al. 2020), MoCo (He et al. 2020), BYOL (Grill et al. 2020), and SimSiam (Chen and He 2021) in a federated setup. Each of these models consists of two encoders. BYOL and MoCo utilize exponential moving averages to update one of the encoders (target network) using the other encoder (online network). In contrast, SimCLR and SimSiam share weights between their two encoders. Additionally, SimCLR and MoCo, being contrastive-based SSL models, leverage negative samples in the learning process. Conversely, BYOL and SimSiam, which do not rely on negative samples, include a predictor on top of the online encoder to enhance learning from unlabeled samples. We then train each client locally using the respective SSL method. Next, we aggregate the trained encoders at the server using FedAVG (McMahan et al. 2017). For BYOL and SimSiam, we follow the procedure in (Zhuang et al. 2021) and apply FedAVG on the online encoder and projector. We also adapt FedEMA (Zhuang, Wen, and Zhang 2022), which is a commonly used method originally developed for federated unsupervised learning. FedEMA integrates BYOL as an SSL technique into its structure.\n\n<html><body><table><tr><td rowspan=\"2\">Model</td><td rowspan=\"2\">Labeled ratio</td><td colspan=\"5\">PACS</td><td colspan=\"4\">DomainNet</td></tr><tr><td>P</td><td>A</td><td>C</td><td>S</td><td>Ave.</td><td>C</td><td>I</td><td>Q</td><td>Ave.</td></tr><tr><td>FedEMA</td><td rowspan=\"7\">10%</td><td>50.0(0.7)</td><td>29.5(1.9)</td><td>42.4(2.3)</td><td>45.6(0.16)</td><td>41.9</td><td>38.6(1.1)</td><td>13.7(0.5)</td><td>45.5(1.6)</td><td>32.4</td></tr><tr><td>FedBYOL</td><td>52.1(1.1)</td><td>31.8(1.1)</td><td>45.4(2.2)</td><td>47.4(1.9)</td><td>44.2</td><td>38.1(0.5)</td><td>14.1(0.4)</td><td>53.6(2.9)</td><td>31.8</td></tr><tr><td>FedMoCo</td><td>58.5(2.2)</td><td>35.7(9.6)</td><td>37.7(12.9)</td><td>36.6(8.2)</td><td>42.1</td><td>30.5(0.6)</td><td>10.9(2.1)</td><td>46.4(0.8)</td><td>27.2</td></tr><tr><td>FedSimSiam</td><td>46.2(1.1)</td><td>28.6(1.0)</td><td>46.7(0.6)</td><td>37.6(1.3)</td><td>39.8</td><td>44.8(1.5)</td><td>12.2(0.3)</td><td>40.3(2.4)</td><td>36.9</td></tr><tr><td>FedSimCLR</td><td>64.2(1.2)</td><td>41.9(1.5)</td><td>58.4(1.3)</td><td>70.1(1.2)</td><td>58.6</td><td>45.2(0.4)</td><td>13.7(0.3)</td><td>59.7(0.7)</td><td>39.5</td></tr><tr><td>FedGaLA (ours)</td><td>64.7(1.9)</td><td>44.2(1.2)</td><td>60.5(2.2)</td><td>70.5(1.3)</td><td>60.0</td><td>47.6(0.9)</td><td>14.2(0.5)</td><td>61.4(0.3)</td><td>41.1</td></tr><tr><td>FedEMA</td><td>53.5(0.3)</td><td>33.9(2.8)</td><td>48.3(2.4)</td><td>45.3(2.3)</td><td></td><td>43.5(0.8)</td><td>20.0(1.5)</td><td>49.0(2.8)</td><td>37.5</td></tr><tr><td>FedBYOL</td><td rowspan=\"6\">30%</td><td>55.1(1.2)</td><td>35.3(1.5)</td><td>48.3(1.5)</td><td>48.9(0.5)</td><td>45.2 46.9</td><td>44.6(1.2)</td><td>20.5(1.1)</td><td>50.4(0.9)</td><td>38.5</td></tr><tr><td></td><td>58.5(2.2)</td><td>35.7(9.6)</td><td>37.7(12.9)</td><td>36.6(8.2)</td><td>42.1</td><td>35.7(1.1)</td><td>14.9(3.9)</td><td>44.6(3.5)</td><td>31.8</td></tr><tr><td>FedSimSiam</td><td>47.3(1.6)</td><td></td><td></td><td>34.4(1.7)</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>FedMoCo</td><td>69.8(1.1)</td><td>30.2(3.4) 46.4(2.1)</td><td>47.4(0.7)</td><td></td><td>39.9</td><td>51.5(1.8)</td><td>18.2(0.1)</td><td>59.9(3.6)</td><td>43.2</td></tr><tr><td>FedSimCLR</td><td>71.1(2.0)</td><td></td><td>63.9(1.6)</td><td>73.4(3.0) 74.5(1.1)</td><td>63.3</td><td>51.7(1.0) 52.4(0.7)</td><td>16.3(0.2) 16.2(0.6)</td><td>66.5(0.9) 68.8(0.6)</td><td>44.8 45.8</td></tr><tr><td>FedGaLA (ours)</td><td>46.8(2.1)</td><td colspan=\"3\">65.7(1.6)</td><td colspan=\"5\">64.6</td></tr><tr><td>Model</td><td>Labeled</td><td colspan=\"4\">C Office-Home</td><td colspan=\"4\">L43 TerraLInc</td><td>Ave.</td></tr><tr><td>FedEMA</td><td rowspan=\"5\">10%</td><td>A 6.7(0.5)</td><td></td><td>20.8(0.9)</td><td>R 14.1(0.8)</td><td>Ave.</td><td>L38 43.5(3.0)</td><td>43.4(0.4)</td><td>L100</td><td>53.2</td></tr><tr><td>FedBYOL</td><td>7.4(0.3)</td><td>12.5(0.4) 12.9(0.5)</td><td>20.9(1.1)</td><td>13.8(0.1)</td><td>13.5</td><td>62.1(0.4) 43.3(0.5)</td><td>44.3(0.3)</td><td>63.9(0.7) 66.3(2.4)</td><td>54.3</td></tr><tr><td></td><td>8.5(0.5)</td><td>19.8(0.8)</td><td>28.2(0.8)</td><td>16.2(0.6)</td><td>13.8 18.9</td><td>63.4(0.2)</td><td></td><td></td><td>47.9</td></tr><tr><td>FedSimSiam FedMoCo</td><td>10.8(0.4)</td><td>9.4(0.3)</td><td>12.4(0.9)</td><td>10.1(0.7)</td><td>10.7</td><td>54.0(6.8) 36.0(1.5) 50.0(2.4) 33.8(0.3)</td><td>40.9(3.7) 29.7(2.3)</td><td>60.8(1.6) 60.2(0.1)</td><td>45.7</td></tr><tr><td>FedSimCLR</td><td>8.9(0.4)</td><td></td><td>35.2(1.2)</td><td>20.0(0.2)</td><td></td><td></td><td>42.9(1.8)</td><td>68.8(0.3)</td><td>55.1</td></tr><tr><td>FedGaLA (ours)</td><td>8.9(0.4)</td><td>24.3(0.3) 25.3(0.6)</td><td>36.6(0.3)</td><td>21.2(0.5)</td><td>22.0 23.0</td><td>62.8(0.2) 63.6(0.1)</td><td>45.8(1.1) 47.6(1.4)</td><td>43.9(2.9)</td><td>71.7(0.9)</td><td>56.7</td></tr><tr><td></td><td rowspan=\"5\"></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>67.6(2.0)</td><td></td></tr><tr><td>FedEMA</td><td>10.0(0.3) 10.4(0.3)</td><td>17.3(0.7) 17.4(1.2)</td><td>28.2(1.1) 29.4(1.3)</td><td>17.8(0.3) 17.6(0.6)</td><td>18.2</td><td>62.7(0.6)</td><td>47.1(0.3) 46.7(1.3)</td><td>46.1(0.4) 46.1(0.2)</td><td>55.9</td></tr><tr><td>FedBYOL</td><td>12.7(1.1)</td><td>24.1(1.9)</td><td>36.5(0.7)</td><td></td><td>18.7</td><td>63.6(0.9)</td><td>35.7(2.3)</td><td>68.8(2.5)</td><td>56.3</td></tr><tr><td>FedSimSiam</td><td></td><td></td><td></td><td>21.6(1.1)</td><td>23.4</td><td>56.8(0.1)</td><td></td><td>38.9(2.0) 61.4(1.)</td><td>48.2</td></tr><tr><td></td><td>13.6(1.3)</td><td>35.3(0.7)</td><td>47.6(0.9)</td><td>26.6(1.0)</td><td>30.7</td><td>65.8(0.3)</td><td></td><td></td><td></td></tr><tr><td>FedSimCLR FedGaLA (ours)</td><td>13.6(0.6)</td><td>35.1(0.2)</td><td>48.0(1.3)</td><td>27.0(0.7)</td><td>30.9</td><td>66.2(0.5)</td><td>54.5(1.2) 52.4(1.7)</td><td>49.0(0.4) 51.7(0.8)</td><td>71.0(1.6) 74.6(1.3)</td><td>60.1 61.3</td></tr></table></body></html>\n\nTable 1: Results of linear eval. on PACS, DomainNet, Office-Home, and TerraInc datasets.\n\nIt is important to note that we avoid direct comparisons with FedDG (Liu et al. 2021), FedSR (Nguyen, Torr, and Lim 2022), FedADG (Zhang et al. 2021b), FedIIR (Guo et al. 2023), and FedDG-GA (Zhang et al. 2023c) since unlike our method, they employ the label information in their solutions. (2) Given the absence of prior research specifically addressing the problem of federated unsupervised domain generalization, we also compare FedGaLA to established centralized unsupervised domain generalization methods on the PACS and DomainNet datasets. We could not identify unsupervised domain generalization methods for Office-Home and TerraInc datasets. This comparison includes the following solutions: SimCLR (Chen et al. 2020), MoCo (He et al. 2020), BYOL (Grill et al. 2020), AdCo (Hu et al. 2021), and DARLING (Zhang et al. 2022). It is important to note that these methods are implemented in a non-federated environment and do not incorporate any data privacy constraints. All the results for these models are reported from (Zhang et al. 2022).\n\nImplementation Details. We use SimCLR as the SSL module in FedGaLA due to its performance on domain generalization problems as previously shown (Zhang et al. 2022). Following(Zhang et al. 2022), ResNet-18 (He et al. 2016) is employed as the encoder network architecture for all experiments, which we train from scratch. We present details regarding data augmentations, projector architecture, and encoder hyperparameters in Appendix B. Following (Feng, Xu, and Tao 2019; Zhang, Isola, and Efros 2017), we first learn a representation by FedGaLA and the baseline models for 100 communication rounds with 7 local epochs. Next, we freeze the backbone model and train a liner classier for 100 epochs to perform prediction on the target domain. Appendix B presents all the hyperparameters used for FedGaLA. For FedEMA, we use the hyperparameters reported in (Zhuang, Wen, and Zhang 2022). All experiments were implemented using PyTorch and trained on 8 NVIDIA GeForce RTX 3090 GPUs. For each experiment, we train the models three times with random initialization seeds and report the average.\n\nCross-Silo vs. Cross-Device Federated Learning. Two frameworks can generally be considered in federated learning: cross-silo and cross-device. In cross-silo, the number of clients $K$ is small, and each client is capable of retaining its local model and state across training rounds. In contrast, cross-device federated learning works under the assumption of having millions of stateless clients, where only a limited number of clients participate in training during each communication round. However, due to limitations in experimental settings, the majority of studies typically conduct experiments involving at most hundreds of clients (Wang et al. 2020; Zhuang, Wen, and Zhang 2022). In this study, given the limited number of domains FedGaLA works within the cross-silo framework. Moreover, each client is equipped with the necessary resources to participate in the collaborative learning process. Additionally, we ensure that every client updates its local model with a sufficient number of epochs.\n\n×10 3 Domain Shift 68 66 46 AS CA 70 63456 566802 SC 9 epochs SP AP PC 40 61 52 + 5 epochs 7 epochs 0 30 60 50 1.50 1.25 1.00 0.75 0.50 0 20 40 60 80 100 32 64 128 256 0.1 0.0 0.1 Mutual Information Communication rounds Batch size $\\tau$ (Local alignment threshold) (a) (b) (c) (d)\n\nTable 2: Comparison of linear eval. $( 1 0 \\% )$ results with nonfederated (centralized) domain generalization methods on PACS and DomainNet datasets.   \n\n<html><body><table><tr><td>Model</td><td colspan=\"4\">PACS</td><td colspan=\"4\">DomainNet</td></tr><tr><td></td><td>P</td><td>A</td><td>C</td><td>S</td><td>Ave.</td><td>C</td><td>I</td><td>Q Ave.</td></tr><tr><td>BYOL</td><td>27.0 25.9 21.0 19.7</td><td></td><td></td><td></td><td>23</td><td>14.6</td><td>8.7 5.9</td><td>9.7</td></tr><tr><td>MoCo</td><td>44.225.933.525.0</td><td></td><td></td><td></td><td></td><td>32.5 18.5</td><td>8.1</td><td>19.7</td></tr><tr><td>SimCLR</td><td>54.7 37.7 46.0 28.3</td><td></td><td></td><td></td><td></td><td>/</td><td>19.9</td><td>12.3 23.1</td></tr><tr><td>AdCo</td><td>46.530.231.5 22.9</td><td></td><td></td><td></td><td></td><td>.3</td><td></td><td>17.9 11.6 20.6</td></tr><tr><td>DARLING</td><td>53.4 39.9 46.4 30.2</td><td></td><td></td><td></td><td>42</td><td>35.2</td><td>20.9</td><td>15.7 23.9</td></tr><tr><td>FedGaLA (ours)</td><td>64.7 44.260.5 70.5 60.0</td><td></td><td></td><td></td><td></td><td></td><td>47.614.2 61.4 41.1</td><td></td></tr></table></body></html>\n\n# 5 Results\n\nIn this section, we first present the performance evaluation of FedGaLA across various datasets, comparing it against baseline methods to demonstrate its effectiveness. This is followed by ablation studies and sensitivity analyses, which provide detailed insights into the contributions of individual components and the robustness of our proposed framework.\n\n# 5.1 Performance\n\nFederated Unsupervised Domain Generalization. We report the accuracy rates of FedGaLA and baseline models on the four datasets. As shown in Table 1, FedGaLA consistently outperforms all baselines across all four datasets, with the exception of the ‘Art-painting’ domain in Office-Home, for the $10 \\%$ data regime. When $30 \\%$ of the data are used, our method still generally outperforms the baseline models, although, for some of the domains, the baseline solutions produce slightly better results. This observation is expected given that with the introduction of more domain-specific training data, the need for domain generalization declines, and thus, methods that are not explicitly designed for domain generalization can produce competitive results. Across the four datasets, we observe that among the baseline models, FedSimCLR achieves better results compared to FedSimSiam, FedBYOL, and FedMoCo. This finding is consistent with (Zhang et al. 2022) where it was demonstrated that SimCLR provides a better foundation for domain generalization versus other SSL methods, albeit in a non-federated setup.\n\nTable 3: The performance of FedGaLA when employing different SSL methods.   \n\n<html><body><table><tr><td>Model</td><td>P</td><td>A</td><td>C</td><td>S</td><td>Ave.</td></tr><tr><td>FedMoCo</td><td>46.2(1.1)</td><td>28.6(1.0)</td><td>46.7(0.6)</td><td>37.6(1.3)</td><td>39.8</td></tr><tr><td>FedGaLAw/MoCo</td><td>46.5(0.3)</td><td>28.9(0.4)</td><td>47.9(0.3)</td><td>39.6(2.4)</td><td>40.7</td></tr><tr><td>FedBYOL</td><td>52.1(1.1)</td><td>31.8(1.1)</td><td>45.4(2.2)</td><td>47.4(1.9)</td><td>44.2</td></tr><tr><td>FedGaLAw/BYOL</td><td>52.8(0.6)</td><td>31.7(0.5)</td><td>46.3(3.1)</td><td>47.6(1.2)</td><td>44.6</td></tr><tr><td>FedSimCLR</td><td>64.2(1.2)</td><td>41.9(1.5)</td><td>58.4(1.3)</td><td>70.1(1.2)</td><td>58.6</td></tr><tr><td>FedGaLAw/SimCLR</td><td>64.7(1.9)</td><td>44.2(1.2)</td><td>60.5(2.2)</td><td>70.5(1.3)</td><td>60.0</td></tr></table></body></html>\n\nTable 4: Ablation study on PACS (GA: global alignment; LA: local alignment).   \n\n<html><body><table><tr><td>Model</td><td>P</td><td>A</td><td>C</td><td>S</td><td>Ave.</td></tr><tr><td>FedGaLA</td><td>64.7(1.9)</td><td>44.2(1.2)</td><td>60.5(2.2)</td><td>70.5(1.3)</td><td>60.0</td></tr><tr><td>w/o GA</td><td>64.7(0.4)</td><td>42.6(1.2)</td><td>58.1(0.6)</td><td>69.9(1.1)</td><td>58.8</td></tr><tr><td>w/o LA</td><td>63.7(1.5)</td><td>41.6(1.4)</td><td>59.8(1.5)</td><td>68.9(1.1)</td><td>58.5</td></tr><tr><td>w/o GA&LA</td><td>64.2(1.2)</td><td>41.9(1.5)</td><td>58.4(1.3)</td><td>70.1(1.2)</td><td>58.6</td></tr></table></body></html>\n\nCentralized Unsupervised Domain Generalization. We compare the performance of FedGaLA with centralized (nonfederated) methods for PACS and DomainNet datasets, where the baselines are trained on the entire dataset consisting of all the domains. The results presented in Table 2 show that FedGaLA outperforms centralized methods by large margins. This is an expected observation as prior works have shown that federation can boost domain generalization (Nguyen, Torr, and Lim 2022; Arasteh et al. 2023).\n\nFedGaLA With Other SSL Techniques. Recall that we used SimCLR in our federated framework. To further explore whether FedGaLA can improve the performance of other federated SSL methods, we perform additional experiments in which we employ MoCo and BYOL in FedGaLA instead of SimCLR. We evaluate the performance on the PACS dataset, as presented in Table 3. The results show that FedGaLA consistently improves the performance of all federated SSL frameworks, demonstrating its ability to adapt to different SSL methodologies while boosting domain generalization.\n\n![](images/c71697170d7ef6778e0914a9b6e8d036367822d1b56070870a71bb906a82c883.jpg)  \nFigure 3: (a) Impact of the number of iterations for global alignment. (b) Stability of the training. (c) Effect of different labeled data ratios on linear evaluation performance. (d) Performance of the model in different communication rounds. Results are reported for domain $P$ of PACS dataset with $1 0 \\%$ label ratio, except for (c) where the label ratio is changing.\n\nTable 5: Impact of communication frequency $( E )$ on model accuracy over 900 total local epochs.   \n\n<html><body><table><tr><td>Model</td><td colspan=\"3\">Communication Frequency(E) E=1 E=5 E=7</td></tr><tr><td>FedGaLA</td><td>67.8</td><td>65.2</td><td>64.8</td><td>64.7</td></tr></table></body></html>\n\n# 5.2 Empirical Verification of Theorem 1\n\nGradient Misalignment Due to Domain Shift. In Figure 2a we illustrate the amount of measured covariance for different domains in PACS versus the amount of domain shift between each pair measured through Mutual Information. We observe that, except for a single outlier, the trend follows our prediction based on Theorem 1.\n\n# 5.3 Ablation Studies and Component Analysis\n\nAblation Studies. Here we examine the effectiveness of the local and global gradient alignment components individually on the final performance of FedGaLA. To this end, we systematically remove each of these components. As shown in Table 4, each component plays an important role in the overall performance. It is noteworthy to mention that FedGaLA essentially becomes the FedSimCLR baseline by removing both global and local alignments.\n\nRatio of Discarded Local Gradients. Figure 2b demonstrates the ratio of local gradients discarded due to local gradient alignment during training versus communication rounds. For this experiment, the local models are trained for 1 epoch at each communication round. As observed, the ratio of discarded local gradients decreases from approximately $6 8 \\%$ in the early communication rounds to $37 \\%$ by round 100. This trend indicates that as the number of communication rounds increases, the local gradient directions become more aligned with the global model, suggesting that with increasing the number of communications, local models learn more domain-invariant features.\n\n<html><body><table><tr><td>Models</td><td>P</td><td>A</td><td>C</td><td>S</td><td>Ave.</td></tr><tr><td>RF: 0.001</td><td>64.3(1.9)</td><td>41.8(1.2)</td><td>58.1(2.3)</td><td>68.3(1.1)</td><td>58.1</td></tr><tr><td>RF: 0.01</td><td>63.8(1.4)</td><td>42.0(1.7)</td><td>58.1(0.4)</td><td>68.3(1.6)</td><td>58.6</td></tr><tr><td>RF: 0.1</td><td>64.1(1.7)</td><td>40.9(2.1)</td><td>58.5(1.4)</td><td>70.4(0.4)</td><td>58.5</td></tr><tr><td>FedGaLA (ours)</td><td>64.7(1.9)</td><td>44.2(1.2)</td><td>60.5(2.2)</td><td>70.5(1.3)</td><td>60.0</td></tr></table></body></html>\n\nTable 6: Results on PACS dataset for different reweightfactors and our FedGaLA method. ‘RF’ indicates the reweight factor.\n\n# 5.4 Hyperparameter Sensitivity and Stability\n\nBatch Size. To identify the optimal training hyperparameters, we conduct a grid search on various batch sizes, testing values of 32, 64, 128, and 256, as illustrated in Figure 2c. The results indicate that FedGaLA achieves its best performance with a batch size of 128, which balances efficient gradient updates and stability during training.\n\nLocal Threshold vs. the Number of Local Epochs. In Figure 2d we study the impact of the threshold for the similarity between gradients and the reference $( \\tau )$ and the number of local epochs $E$ on performance. In this experiment, we use three different values for $\\tau { : - 0 . 1 , 0 }$ , and 0.1, and three different values for $E$ : 5, 7 or 9 (local epochs per communication round). We observe that our method produces the best results when $\\tau = 0$ , i.e., when we keep all gradients with positive cosine similarity with the reference. Expectedly, even discarding gradients with small amounts of alignment $\\stackrel { \\cdot } { \\tau } = 0 . 1 \\dot { } \\stackrel { \\cdot } { }$ ) degrades the results, while keeping gradients that are not aligned with the reference $( \\tau = - 0 . 1 )$ also hurts performance. Moreover, we see that setting $E = 7$ yields the best performance as increasing the number of epochs beyond 7 does not have a positive impact, and only increases computational time.\n\nGlobal Gradient Alignment Iterations. Figure 3a shows the impact of different gradient alignment iterations (line 7 in Algorithm 1) on performance. FedGaLA produces the best results when the iteration number is 3. When the number of iterations increases, the model places too much emphasis on clients aligned with the global average and decreases the impact of unaligned clients harshly, leading to a decline in the overall performance of the model. On the other hand, with small iteration values, global gradient alignment is not performed effectively, and thus performance declines.\n\n<html><body><table><tr><td rowspan=\"2\">Model</td><td colspan=\"5\">PACS</td><td colspan=\"5\">DomainNet</td></tr><tr><td>P</td><td>A</td><td>C</td><td></td><td></td><td>Ave.</td><td>C</td><td>I</td><td>Q</td><td>Ave.</td></tr><tr><td>FedGaLA+L2 (入= 0.001)</td><td>64.8(0.5)</td><td>42.8(1.1)</td><td>58.7(1.6)</td><td>67.3(0.6)</td><td>58.4</td><td></td><td>46.3(0.8)</td><td>16.4(0.9)</td><td>62.8(0.2)</td><td>41.6</td></tr><tr><td>FedGaLa+L2(入= 0.01)</td><td>66.5(0.9)</td><td>43.4(0.9)</td><td>56.9(2.7)</td><td>65.2(0.6)</td><td></td><td>57.9</td><td>38.9(1.2)</td><td>14.6(0.7)</td><td>52.5(0.8)</td><td>35.3</td></tr><tr><td>FedGaLA+FedProx (μ= 0.001)</td><td>62.1(0.2)</td><td>41.4(0.7)</td><td>58.9(3.1)</td><td>68.8(0.1)</td><td></td><td>57.8</td><td>44.6(0.2)</td><td>13.4(1.0)</td><td>60.9(1.1)</td><td>39.6</td></tr><tr><td>FedGaLA+FedProx (μ = 0.01)</td><td>63.1(0.2)</td><td>41.6(1.2)</td><td>58.5(2.0)</td><td>68.9(1.9)</td><td></td><td>58.0</td><td>44.7(1.2)</td><td>13.2(0.4)</td><td>61.7(0.4)</td><td>39.9</td></tr><tr><td>FedGaLA (ours)</td><td>64.7(1.9)</td><td>44.2(1.2)</td><td>60.5(2.2)</td><td>70.5(1.3)</td><td>60.0</td><td>47.6(0.9)</td><td></td><td>14.2(0.5)</td><td>61.4(0.3)</td><td>41.1</td></tr><tr><td rowspan=\"2\">Model</td><td colspan=\"5\"></td><td colspan=\"5\"></td></tr><tr><td>A C</td><td></td><td>Office-fome</td><td>R</td><td>Ave.</td><td>L38</td><td>L43</td><td>Terralnc</td><td>L100</td><td>Ave.</td></tr><tr><td>FedGaLA+L2(入= 0.001)</td><td>11.8(0.4)</td><td>23.9(0.5)</td><td>37.1(0.4)</td><td>21.9(0.7)</td><td>23.6</td><td>61.6(0.9)</td><td>45.8(0.6)</td><td>46.6(0.7)</td><td>70.8(0.7)</td><td>56.2</td></tr><tr><td>FedGaLa+L2(入=0.01)</td><td>11.8(0.2)</td><td>21.2(0.1)</td><td>34.5(0.3)</td><td>22.1(0.2)</td><td>22.4</td><td>61.5(0.7)</td><td>38.1(2.9)</td><td>44.9(0.1)</td><td>57.8(3.3)</td><td>50.6</td></tr><tr><td>FedGaLA+FedProx(μ= 0.001)</td><td>10.2(0.4)</td><td>24.2(0.4)</td><td>36.4(1.1)</td><td>19.7(0.32)</td><td>22.6</td><td>63.8(0.7)</td><td>49.3(1.5)</td><td>47.2(0.1)</td><td>71.5(0.9)</td><td>57.9</td></tr><tr><td>FedGaLA+FedProx(μ= 0.01)</td><td>9.2(0.3)</td><td>23.6(0.7)</td><td>37.1(0.6)</td><td>20.4(0.4)</td><td>22.6</td><td>63.2(1.1)</td><td>47.8(2.1)</td><td>44.8(0.4)</td><td>71.4(0.8)</td><td>56.0</td></tr><tr><td>FedGaLA (ours)</td><td>8.9(0.4)</td><td>25.3(0.6)</td><td>36.6(0.3)</td><td>21.2(0.5)</td><td>23.0</td><td>63.6(0.1)</td><td>47.6(1.4)</td><td>43.9(2.9)</td><td>71.7(0.9)</td><td>56.7</td></tr></table></body></html>\n\nTable 7: The effect of regularizers on the performance of FedGaLA across PACS, DomainNet, Office-Home, and TerraInc.\n\nTraining Stability. Figure 3b demonstrates that FedGaLA maintains robust training stability, rapidly improving accuracy in the initial iterations and stabilizing after approximately 40 iterations. Despite discarding dissimilar gradients, the method avoids divergence and ensures consistent optimization, effectively learning domain-invariant features while maintaining steady performance throughout training.\n\n# 5.5 Data and Communication Efficiency\n\nRatio of Labeled Data. Figure 3c presents the results when evaluated with different ratios of labeled data, ranging from $10 \\%$ to $60 \\%$ . As can be seen, the accuracy increases significantly from $64 \\%$ to $72 \\%$ when the label ratio rises from $10 \\%$ to $30 \\%$ , followed by a steady climb to $74 \\%$ as the label ratios increase to $60 \\%$ . Overall, when more labeled data are used to train the linear classifier, the final performance expectedly improves.\n\nCommunication Rounds. We investigate the effect of the communication rounds $T$ on the model’s performance. Following (Zhuang et al. 2021; Zhuang, Wen, and Zhang 2022) we set $E = 1$ and vary the number of communication rounds $T$ from 100 to 900. We observe from Figure 3d that performance improves significantly from 1 to 200 communication rounds, with this trend slowing down from 200 to 900.\n\nFedGaLA and Communication Cost. We conduct an experiment to analyze the trade-off between communication frequency and model performance. In this setup, local models are trained for a total of 900 epochs, with aggregation occurring after every $E$ local epochs. As $E$ increases, communication frequency decreases, thereby reducing the overhead. The performance of the model is then assessed for different values of $E$ , as demonstrated in Table 5. The results indicate that increasing the communication frequency (lower $E$ ) improves accuracy and the model maintains consistent performance even with reduced communication, particularly for $E > 1$ . This indicates the ability of the model to adapt to less frequent aggregation intervals.\n\n# 5.6 Model Variations\n\nGradient Discarding vs. Gradient Re-Weighting. Gradient re-weighting is an alternative approach to discarding unaligned gradients. To further highlight the effectiveness of gradient discarding in the local alignment module of FedGaLA, we conducted an additional experiment replacing gradient discarding with gradient re-weighting in FedGaLA. Here, rather than discarding the unaligned gradients, they are multiplied by a re-weight factor reducing their impact. The results are presented in Table 6, demonstrating that while re-weighting is effective, our original method of discarding unaligned gradients yields the best overall performance.\n\nEffects of Regularizers on FedGaLA. Prior works have demonstrated that adding regularizers can indeed improve generalization across domains or non-IID data (Li et al. 2020; Nguyen, Torr, and Lim 2022). To this end, we test the impact of regularizers on FedGaLA by applying two types of regularizers based on L2 norm (Li et al. 2020) and FedProx (Nguyen, Torr, and Lim 2022). Please refer to Appendix B.4 for more details regarding these two techniques. The results in Table 7 demonstrate that FedGaLA is highly compatible with regularizers and that the addition of such approaches can further boost the performance of our method.\n\n# 6 Conclusion\n\nIn this work, we first introduced a new problem category, federated unsupervised domain generalization, and subsequently proposed FedGaLA to tackle it. Building the relationship between gradient alignment and domain shift, FedGaLA comprises two alignment strategies at the global and local levels designed to address the problem of domain generalization in an unsupervised and federated setup. We assessed the performance of FedGaLA through extensive experiments where our approach outperformed various baseline models. Detailed ablation studies and sensitivity analyses were also conducted to provide more insights into different aspects of our solution.",
    "summary": "```json\n{\n  \"core_summary\": \"### 🎯 核心概要\\n\\n> **问题定义 (Problem Definition)**\\n> *   论文首次提出并解决了**联邦无监督域泛化（Federated Unsupervised Domain Generalization, FUDG）**问题，即在无标签数据且隐私受限的联邦学习框架下，学习能够泛化到新目标域的模型。\\n> *   该问题的重要性在于：1) 现实场景中数据标注成本高且隐私敏感（如可穿戴设备数据）；2) 现有方法要么仅关注联邦域泛化（需标签），要么仅解决联邦无监督学习（忽略域偏移），而本文统一了这两个方向。\\n\\n> **方法概述 (Method Overview)**\\n> *   提出 **FedGaLA** 框架，通过理论证明梯度对齐与域偏移的关联性（Theorem 1），并在客户端（局部梯度对齐）和服务器（全局梯度对齐）两个层级实现梯度对齐，从而学习域不变特征并提升模型泛化能力。\\n\\n> **主要贡献与效果 (Contributions & Results)**\\n> *   **1. 新问题定义**：首次形式化FUDG问题（Definition 1），填补了研究空白。\\n> *   **2. 理论创新**：建立梯度对齐与域偏移的数学关联（Theorem 1），证明梯度协方差与域偏移负相关（Corollary 1）。\\n> *   **3. 性能优势**：在PACS等4个数据集上平均准确率达`60.0%`（10%标签比例），显著优于FedSimCLR基线（`58.6%`），且超越集中式无监督域泛化方法DARLING（`23.9%`）。\\n> *   **4. 数据效率**：在Office-Home数据集上，使用30%标记数据时平均准确率达`23.0%`，比FedSimCLR提升1个百分点。\",\n  \"algorithm_details\": \"### ⚙️ 算法/方案详解\\n\\n> **核心思想 (Core Idea)**\\n> *   核心直觉：**梯度方向隐含域分布信息**。通过对齐客户端和服务器间的梯度方向，可减少域特异性特征的学习（Proposition 1）。\\n> *   理论支撑：Theorem 1证明域偏移与梯度协方差负相关，故梯度对齐可缓解域偏移（Lemma 2）。\\n\\n> **创新点 (Innovations)**\\n> *   **先前局限**：现有联邦学习方法未考虑无监督+域泛化的双重约束，且缺乏梯度对齐的理论分析。\\n> *   **本文改进**：\\n>     1. **局部对齐**：客户端丢弃与全局参考梯度方向不一致的批次梯度（阈值τ=0），抑制域特异性特征（Claim 1）。\\n>     2. **全局对齐**：服务器根据梯度相似性加权聚合模型（余弦相似度权重），增强泛化性（Algorithm 1）。\\n>     3. **理论创新**：首次在联邦无监督场景下建立梯度对齐与域偏移的数学关联（Theorem 1）。\\n\\n> **具体实现步骤 (Implementation Steps)**\\n> 1. **客户端训练**：\\n>    - 使用SimCLR进行自监督学习，计算批次梯度`g_i`。\\n>    - 若`cos(g_i, g_est)`<τ（`g_est`为参考梯度），则丢弃该梯度（Proposition 1）。\\n> 2. **服务器聚合**：\\n>    - 计算初始平均梯度`g_avg`。\\n>    - 迭代3次调整权重：`w_i = [cos(g_i, g_avg)+1]/γ`，归一化后加权聚合。\\n> 3. **关键公式**：梯度协方差近似为（Lemma 2）：\\n>    ```math\\n>    Cov(g_i, g_j)_{mn} ≈ ∑_f σ_{x_i^f,x_j^f} (∂g_i/∂x_i^f)(∂g_j/∂x_j^f)\\n>    ```\\n\\n> **案例解析 (Case Study)**\\n> *   论文未明确提供此部分信息。\",\n  \"comparative_analysis\": \"### 📊 对比实验分析\\n\\n> **基线模型 (Baselines)**\\n> *   联邦基线：FedSimCLR、FedBYOL、FedMoCo、FedEMA\\n> *   集中式基线：SimCLR、BYOL、DARLING等\\n\\n> **性能对比 (Performance Comparison)**\\n> *   **在PACS数据集（10%标签）上：** FedGaLA平均准确率达`60.0%`，显著优于FedSimCLR（`58.6%`）和FedEMA（`41.9%`）。在\\\"Sketch\\\"域上达到`70.5%`，比最佳基线FedSimCLR（`70.1%`）提升0.4个百分点。\\n> *   **在DomainNet数据集（10%标签）上：** FedGaLA平均`41.1%`，远超集中式方法DARLING（`23.9%`），证明联邦框架的域泛化优势。\\n> *   **在通信效率上：** 当本地训练轮次E=7时性能最优（`64.7%`），而E=1或E=9分别导致性能下降至`67.8%`和`64.8%`，显示适度通信频率的重要性（Table 5）。\\n> *   **在数据效率上：** 使用30%标记数据时，FedGaLA在Office-Home数据集上平均准确率达`23.0%`，比FedSimCLR（`22.0%`）提升1个百分点（Table 1）。\\n> *   **在梯度对齐效果上：** 实验显示梯度丢弃比例从初始`68%`降至`37%`（Figure 2b），验证了局部对齐的有效性。\",\n  \"keywords\": \"### 🔑 关键词\\n\\n*   联邦学习 (Federated Learning, FL)\\n*   无监督域泛化 (Unsupervised Domain Generalization, N/A)\\n*   梯度对齐 (Gradient Alignment, N/A)\\n*   自监督学习 (Self-Supervised Learning, SSL)\\n*   域偏移 (Domain Shift, N/A)\\n*   隐私保护 (Privacy Preservation, N/A)\\n*   模型聚合 (Model Aggregation, N/A)\\n*   分布式训练 (Distributed Training, N/A)\"\n}\n```"
}