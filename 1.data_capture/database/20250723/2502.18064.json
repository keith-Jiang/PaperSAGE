{
    "source": "Semantic Scholar",
    "arxiv_id": "2502.18064",
    "link": "https://arxiv.org/abs/2502.18064",
    "pdf_link": "https://arxiv.org/pdf/2502.18064.pdf",
    "title": "HEROS-GAN: Honed-Energy Regularized and Optimal Supervised GAN for Enhancing Accuracy and Range of Low-Cost Accelerometers",
    "authors": [
        "Yifeng Wang",
        "Yi Zhao"
    ],
    "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
    ],
    "publication_date": "2025-02-25",
    "venue": "AAAI Conference on Artificial Intelligence",
    "fields_of_study": [
        "Computer Science",
        "Engineering",
        "Mathematics"
    ],
    "citation_count": 2,
    "influential_citation_count": 0,
    "institutions": [
        "Harbin Institute of Technology"
    ],
    "paper_content": "# HEROS-GAN: Honed-Energy Regularized and Optimal Supervised GAN for Enhancing Accuracy and Range of Low-Cost Accelerometers\n\nYifeng Wang, Yi Zhao\\*\n\nSchool of Science, Harbin Institute of Technology, Shenzhen wangyifeng $@$ stu.hit.edu.cn, zhao.yi@hit.edu.cn\n\n# Abstract\n\nLow-cost accelerometers play a crucial role in modern society due to their advantages of small size, ease of integration, wearability, and mass production, making them widely applicable in automotive systems, aerospace, and wearable technology. However, this widely used sensor suffers from severe accuracy and range limitations. To this end, we propose a honed-energy regularized and optimal supervised GAN (HEROS-GAN), which transforms low-cost sensor signals into high-cost equivalents, thereby overcoming the precision and range limitations of low-cost accelerometers. Due to the lack of frame-level paired low-cost and high-cost signals for training, we propose an Optimal Transport Supervision (OTS), which leverages optimal transport theory to explore potential consistency between unpaired data, thereby maximizing supervisory information. Moreover, we propose a Modulated Laplace Energy (MLE), which injects appropriate energy into the generator to encourage it to break range limitations, enhance local changes, and enrich signal details. Given the absence of a dedicated dataset, we specifically establish a Low-cost Accelerometer Signal Enhancement Dataset (LASED) containing tens of thousands of samples, which is the first dataset serving to improve the accuracy and range of accelerometers and is released in Github. Experimental results demonstrate that a GAN combined with either OTS or MLE alone can surpass the previous signal enhancement SOTA methods by an order of magnitude. Integrating both OTS and MLE, the HEROS-GAN achieves remarkable results, which doubles the accelerometer range while reducing signal noise by two orders of magnitude, establishing a benchmark in the accelerometer signal processing.\n\n# Introduction\n\nLow-cost accelerometers are indispensable in modern technology due to their small size, ease of integration, and widespread availability [Li et al. 2022b; Ehatisham-ul Haq et al. 2021]. In industry, they are used for posture control, navigation, and path planning of machinery. By measuring motion, accelerometers enable the monitoring and control of equipment in complex environments, aiding in structural health monitoring and vehicle dynamic performance testing [Caesar et al. 2020]. On production lines, accelerometers detect abnormal vibrations in real time to predict equipment failures. In smart manufacturing, they assist in positioning and motion control, enhancing product quality and stability [Wang and Zhao 2024d]. In robotics, accelerometers monitor robotic arm movements for precise operations [Gromov et al. 2019; Liu et al. 2020a]. In IoT applications, they ensure optimal operation by monitoring equipment status [Yang et al. 2023]. In communication, accelerometers are used in mobile devices for posture detection and user interaction [Liu et al. 2020b; Li et al. 2023]. They enable automatic screen rotation, step counting, game control, and AR applications, enhancing user convenience and interactivity. In smartphones, accelerometers support gesture recognition, fall detection, and gait analysis, offering intelligent and personalized services [Wang and Zhao 2024b]. In medical and health monitoring, accelerometers have promising applications. Embedded in wearable devices, they allow real-time monitoring of patientsâ€™ activity and physiological parameters, aiding diagnosis and health management. For example, accelerometers detect falls in the elderly by monitoring sudden changes in body acceleration and providing emergency alerts. They also monitor movements in rehabilitation training, assess recovery progress, and guide exercises.\n\nHowever, the widely used low-cost accelerometers face significant accuracy and range issues [Malayappan et al. 2022]. Limited accuracy with severe noise hinders low-cost accelerometers in high-precision motion capture and subtle vibration monitoring [Wang, Xu, and Zhao 2024]. In industrial automation, precise machine motion control relies on high-quality acceleration signals, but severe noise can significantly affect the stable operation and control of machines. In medical monitoring, noise interferes with accurately measuring movements and physiological parameters, hindering remote diagnosis and health management [Gupta et al. 2020]. Moreover, low-cost accelerometers typically operate within a range of $\\pm 2 \\mathrm { g }$ or $\\pm 8 \\mathrm { g }$ , which easily leads to sensor saturation, data loss, and signal distortion in high-dynamic environments. For example, in industrial automation, accurately capturing complex motions requires accelerometers with a range of up to $\\pm 1 6 \\mathrm { g }$ [Niu et al. 2022]. However, industrial-grade accelerometers meeting these requirements are priced between $\\$ 10$ and $\\$ 20$ per unit, which is too expensive for consumer-end deployment. Top-tier accelerometers, like Xsens, can exceed $\\$ 1500$ per unit due to their superior accuracy and range. In comparison, these widely used low-cost accelerometers are available for as little as $\\$ 0.20$ to $\\$ 0.50$ per unit. While affordable, these sensors are inadequate for many demanding applications. In healthcare, low-range accelerometers struggle to detect rapid movements or sudden events, such as falls, where accelerations often surpass $1 0 \\mathrm { g }$ , causing missed alerts and defective health monitoring. Therefore, extending the range of low-cost accelerometers is crucial for enabling broader and more robust applications in various realms. In summary, by using advanced algorithms to enhance low-cost sensors, we can achieve high-end performance at a fraction of the cost, offering transformative potential across industries and making cutting-edge experiences accessible to all.\n\nThe rapid development of artificial intelligence [Xu et al. 2024; Wang et al. 2020; Liu et al. 2024], particularly in generative deep learning models [Li et al. 2024a; Wang and Zhao 2024a], offers promising avenues for enhancing the range and accuracy of low-cost accelerometers. A potential solution lies in training a generative model to map low-cost sensor signals to high-cost ones, thereby improving the quality of low-cost signals. However, it is impractical to obtain frame-by-frame paired data between low-cost and high-cost sensors [Pei et al. 2023]. Unpaired data pose significant challenges in training generative models due to the lack of supervision and guidance [Li et al. 2024b], often resulting in unreliable generated signals that fail to meet the stringent requirements of accelerometer applications. To address the severe problem in training with unpaired data, we propose a HEROS-GAN, which leverages optimal transport theory to maximize the use of supervisory information from unpaired data and injects Laplacian energy into the generator to encourage local changes. The core contributions of this paper are encapsulated in the following four aspects.\n\nâ€¢ We propose to utilize deep learning algorithms for extending accelerometers range for the first time and introduce generative deep learning methods into accelerometer signal processing.   \nâ€¢ Considering the lack of supervision from unpaired data, we design an Optimal Transport Supervision (OTS) to explore potential correlations within unpaired data, providing the model with as much supervisory information as possible.   \nâ€¢ We design a Modulated Laplace Energy for GANs, guiding the model to generate more reasonable local changes, thereby enriching the generated signal details and breaking range limitation.   \nâ€¢ We release the first accelerometer signal enhancement dataset in Github. Based on this dataset, our HEROSGAN can extend the range of low-cost accelerometer signals from $8 \\mathrm { g }$ to $1 6 \\mathrm { g }$ , while reducing signal noise by an order of magnitude.\n\n# Related Work\n\n# Over-Range Signal Recovery for Accelerometers\n\nRestoring over-range signals for accelerometers is an unexplored area within the current research landscape. Overrange signals are lost when the acceleration of the measured object exceeds the sensorâ€™s range, presenting a critical challenge in high dynamic applications such as automotive crash testing, industrial machinery monitoring, and sports science. However, few attempts are dedicated to the accelerometer over-range signal restoration problem. Several factors contribute to the scarcity of research in this area. The nonlinearity and complexity of signal distortion when an accelerometer exceeds its measurement range make the restoration task highly challenging. Also, the recovery of over-range signals is highly context-dependent and relies on experience observing massive data, which is difficult for traditional non-datadriven models [Yang et al. 2024]. Finally, obtaining paired high-range and low-range data for training data-driven models is inherently tricky. The rarity of such paired datasets impedes the development of supervised learning approaches, further complicating the task of over-range signal restoration. Consequently, most existing efforts have focused on improving the dynamic range of sensors through hardware advancements rather than algorithm design [Wu et al. 2024].\n\n# Signal Quality Enhancement for Accelerometers\n\nCompared to the rarely explored area of over-range signal restoration, considerable research has focused on reducing noise in accelerometer signals. Traditional signal denoising approaches rely on various filtering techniques, including Kalman filters, Savitzky-Golay filters [Karaim, Noureldin, and Karamat 2019], and empirical mode decomposition [Liu et al. 2020c]. While these methods have proven effective in separating the noise from the signal and improving signal quality, they usually rely on prior knowledge of the signal or noise characteristics [Skog and Handel 2009], causing poor generalization ability. In contrast, data-driven methods learn the denoising function from data without relying on the information about signal characteristics, which can adapt to different sensors and noise patterns. In data-driven approaches, generative deep learning models directly map low-cost signals to high-cost signals, providing a more effective way to enhance signal quality. However, their superior performance typically relies on strictly paired training data, which is impractical to obtain for low-cost and high-cost accelerometers [Wu et al. 2019]. Therefore, few studies have attempted to apply GANs to improve accelerometer signals.\n\n# Methodology\n\nThe primary challenge in enhancing low-cost accelerometer signals lies in the inability to obtain strictly paired highcost and low-cost sensor signals. Consequently, end-to-end methods with fully supervised training are impractical for converting low-quality signals into high-quality ones. To address this, we utilize CycleGAN as the baseline to construct a mapping between unpaired signals of varying qualities. Given the lack of paired data for guidance and supervision, we propose a honed-energy regularized and optimal supervised GAN (HEROS-GAN), as illustrated in Fig. 1. In this architecture, Optimal Transport Supervision (OTS) is designed to mine supervisory information from unpaired data, while Modulated Laplace Energy (MLE) guides the model to generate realistic local changes, thereby enriching signal details.\n\nLow-cost Signal GANLâ†’H High-cost Signal GANHâ†’L Low-cost Signal   \n>swI WW WA >>w Features Features   \nMW M WW +â†’tA Impose OTS Inject MLE WAW Unpaired Explore potential MWANw Unpaired 1 Inject Modulated Laplace Energy (MLE) to Features supervision & enrich signal details Supervision (OTS) to Features Impose Optimal Transport   \niw M TBww ä» sww   \nWW\\> WI>\\> WWAA Features Features   \n5 T>B>I W   \nHigh-cost Signal GANHâ†’L Low-cost Signal GANLâ†’H High-cost Signal\n\n# Optimal Transport Supervision\n\nAlthough both high-cost and low-cost signals are fed into the network simultaneously, the absence of paired data precludes the use of simple element-wise constraints (such as L1 or L2 loss), to enforce low-cost signal features approaching high-cost ones. Nonetheless, unpaired data still exhibit similar characteristics within their feature layers [Yang, Wang, and Yang 2021]. To exploit these similarities, we propose the Optimal Transport Supervision (OTS) mechanism to align the features of low-cost signals with those of highcost signals, thereby maximizing the supervision information obtained from unpaired data.\n\nHigh-cost Signal â–¡>æ±‡+O   \nFeatures   \nLoSiwg-ncaolst Features â–³å·±â–¡â–³ (a) Elementwise Supervision: Simple and Crude Supervision   \nHigh-cost $\\bigcirc \\bigcirc$ Signal â–¡L+   \nFeatures   \nLoSiwg-ncaolst Features â–³â–¡â–³ (b) Optimal Transport Supervision: Exploring Similar Features for Supervision\n\nAs shown in Fig. 2, the core idea of OTS is to explore similar features hidden in unpaired high-cost and low-cost signals for supervision, which is achieved by employing the optimal transport theory. Let $F _ { L } ( x _ { L } ) \\ =$ $\\{ f _ { L 1 } , \\bar { f } _ { L 2 } , \\ldots , \\bar { f _ { L N } } \\} \\ \\in \\ \\mathbb { R } ^ { \\bar { N } \\times d }$ represent the features of low-cost signals, and $F _ { H } ( x _ { H } ) = \\bar { \\{ f _ { H 1 } , f _ { H 2 } , \\ldots , f _ { H N } \\} } \\in$ $\\mathbb { R } ^ { N \\times d }$ represent the features of high-cost signals. The goal of the optimal transport problem is to find an optimal mapping between these two feature distributions that minimizes the transportation cost. This problem can be formulated as:\n\n$$\n\\operatorname* { m i n } _ { \\gamma \\in \\Gamma ( F _ { L } , F _ { H } ) } \\int _ { \\mathcal { X } \\times \\mathcal { Y } } c ( f _ { L i } , f _ { H j } ) d \\gamma ( f _ { L i } , f _ { H j } )\n$$\n\nwhere $\\Gamma ( F _ { L } , F _ { H } )$ represents the set of all joint distributions that couple $F _ { L }$ and $F _ { H }$ , and $c ( f _ { L i } , f _ { H j } )$ is the cost function, which is defined as $c ( f _ { L i } , f _ { H j } ) = e ^ { 1 - f _ { L i } \\cdot f _ { H j } }$ . The Sinkhorn algorithm can be applied to Eq. 1 for approximating the optimal transport solution, which provides a transport mapping $T : \\mathcal { X }  \\mathcal { Y }$ by mining the feature consistency between lowcost and high-cost signals. This mapping allows us to identify and align the most similar features between the two distributions. Subsequently, we can define the OTS loss $\\mathcal { L } _ { O T S }$ to impose appropriate supervision that encourages low-cost signal features to align with certain high-cost signal features.\n\n$$\n\\begin{array} { r l } & { \\mathcal { L } _ { O T S } = \\mathbb { E } _ { x _ { L } \\sim P _ { L } , x _ { H } \\sim P _ { H } } \\left[ \\| F _ { G _ { L } } ( x _ { L } ) - T ( F _ { H } ( x _ { H } ) ) \\| ^ { 2 } \\right. } \\\\ & { \\qquad + \\left. \\| F _ { G _ { H } } ( x _ { H } ) - T ^ { - 1 } ( F _ { L } ( x _ { L } ) ) \\| ^ { 2 } \\right] } \\end{array}\n$$\n\nwhere $P _ { L }$ and $P _ { H }$ denote the data distributions for domains of low-cost and high-cost signals. By minimizing $\\mathcal { L } _ { O T S }$ , the generative model is encouraged to produce low-cost signal features that are aligned with the high-cost signal features.\n\n# Modulated Laplace Energy\n\nEnhancing the detail of generated signals is crucial for accurately capturing the subtle variations inherent in accelerometer data. Low-cost signals tend to be less sensitive, resulting in less detailed and more simplified signals [Yuan et al. 2024]. In contrast, high-cost accelerometers can capture richer details and finer variations due to their higher sensitivity. This disparity directly affects performance and reliability in applications such as health monitoring, mobile device interactions, and precision engineering. Traditional GANs often struggle to generate these fine-grained\n\nFeatures in Laplace Energy Inject Modulated Laplace Energy Deep Learning âˆ‡2ğ‘“ğ‘“ = ğ‘“âˆ‡ğ‘“ğ‘“(È‰ğ‘¥(ğ‘¥âˆ‡+ğ‘“ğ‘“)âˆ†ğ‘¥ğ‘¥) of Feature ğ’‰ğ’‰(ğ‘›ğ‘›) NUN to Network through Regularization âˆ‘ğ‘–ğ‘‘ğ‘– ğ‘‘(â„(ğ‘›ğ‘›)âˆ’ğ’‰à´¥ğ’‰ ğ‘›ğ‘› )4 ğ‘“ğ‘“ğ‘“(ğ‘¥ğ‘¥) ğ¸ğ¸ğ¿(ğ¿ğ¿ğ‘›ğ¿ğ‘›)ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ ğ’‰ğ’‰(ğ‘›ğ‘›) âˆ’ logğ¸à·¨ğ¸ğ¿(ğ¿ğ¿ğ‘›ğ¸à·¨ğ¿ğ‘› ğ¸)ğ¿(ğ¿ğ¿ğ¿ğ‘›ğ¿ ğ¿ğ‘›ğ¿)ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ ğ¿ğ¿ğ¿ ğ¿ğ¿ğ¿=ğ¿ğ¿ ğ‘ ğ‘ ğ‘ âˆ’ğ‘ ğ‘ ğ‘ ğœ…ğ‘ ğœ… ğ‘ È‰ğ‘ lğ‘ ğ‘ ğ‘ oğ‘ gğ‘ (ğ¸1ğ¸ğ¿(ğ¿ğ¿ğ‘›âˆ’ğ¿ğ‘›)ğ¿ğ¿ğ¿ğ¿ğ¸à·¨ğ¿ğ¸ğ¿ğ¿(ğ¿ğ¿ğ¿ğ¿ğ‘›ğ¿ğ¿ğ¿ğ‘›)ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ğ¿ $\\succ$ SLamraglel âˆ‘ğ‘–ğ‘‘ğ‘– ğ‘‘(â„(ğ‘›ğ‘›)âˆ’ğ’‰à´¥ğ’‰ ğ‘›ğ‘› )2 $\\kappa$ : need lmesosre neenregrygy [ğ’‰ğ’‰(1), â‹¯ , ğ’‰ğ’‰(ğ‘ğ‘)] âˆ‡2â„(ğ‘›ğ‘›) = $\\succ$ ğ’‰ğ’‰(ğ‘›ğ‘›) = [â„ ğ‘›ğ‘› , â‹¯ , â„(ğ‘›ğ‘›)] âˆ†ğ‘¥ğ‘¥ â†’ 0 â„ğ‘–(ğ‘–+ğ‘›ğ‘›)1 âˆ’ 2â„ğ‘–(ğ‘–ğ‘›ğ‘›) + â„ğ‘–(ğ‘–âˆ’ğ‘›ğ‘›)1 ğœ…ğœ… < 1 ğœ…ğœ… = 1 ğœ…ğœ… > 1 UseFeature Kurtosis to Adaptively Adjust Injected Laplace Energy\n\ndetails, leading to oversimplified and less realistic signals [Wang and Zhao 2024c]. To address this issue, we leverage the Laplacian operator, denoted as $\\nabla ^ { 2 }$ , which measures the second-order derivatives of a function and is effective in highlighting fine details and variations within the signal. Based on Laplacian operator, we propose the concept of Laplace Energy for features in a deep learning architecture, as shown in Equation 3 and 4:\n\n$$\nE _ { L a p l a c e } ^ { ( n ) } ( { h ^ { ( n ) } } ) = \\sum _ { i = 2 } ^ { d - 1 } ( { \\nabla ^ { 2 } h _ { i } ^ { ( n ) } } ) ^ { 2 }\n$$\n\n$$\n\\nabla ^ { 2 } h _ { i } ^ { ( n ) } = h _ { i + 1 } ^ { ( n ) } - 2 h _ { i } ^ { ( n ) } + h _ { i - 1 } ^ { ( n ) }\n$$\n\nwhere $h ^ { ( n ) } \\in \\mathbb { R } ^ { d }$ denotes the $n$ -th feature within the network, d is the dimension of the feature, and hi(n) is the i-th element in the feature $h ^ { ( n ) }$ . The Laplace Energy evaluates the volatility of the features, with higher Laplace Energy indicating stronger volatility and more significant local variations, while lower energy suggests smoother and less detailed features in the generated signal. An intuitive approach is to design a regularization term based on Laplace Energy to guide the model in enhancing the feature volatility. However, unrestricted enhancement of Laplace Energy is clearly unreasonable, as it could introduce noise and instability in the generated signals. Therefore, we devise a Modulated Laplace Energy (MLE) as shown in Fig. 3, which adaptively injects an appropriate amount of energy into the feature via regulation term $R _ { M L E }$ .\n\n$$\nR _ { M L E } = - \\log \\left( E _ { L a p l a c e } \\right) - \\kappa \\cdot \\log \\left( 1 - E _ { L a p l a c e } \\right)\n$$\n\n$$\n\\tilde { E } _ { L a p l a c e } = \\sigma ( E _ { L a p l a c e } )\n$$\n\nwhere $\\sigma$ denotes the sigmoid function, normalizing the Laplace energy to the range $( 0 , 1 )$ . $\\kappa$ is a modulation parameter, set to feature kurtosis that is shifted to range $( 0 , + \\infty )$ .\n\nThis regularization term exhibits important properties. Firstly, when $\\tilde { E } _ { L a p l a c e }$ approaches 0 or 1, $R _ { M L E }$ tends towards infinity, imposing a strong penalty on both very low and very high Laplace energy values. So the Laplace energy should remain within a moderate range. For instance, when $\\kappa = 1$ , the regularization term is symmetric, and its minimum occurs at $\\tilde { E } _ { L a p l a c e } = 0 . 5$ , thereby avoiding the injection of excessive or insufficient energy.\n\nSecondly, the modulation parameter $\\kappa$ controls the amount of injected energy by controlling the minimum point of the regularization term. Specifically, high kurtosis (large $\\kappa$ ) indicates strong volatility in the feature, necessitating less energy. Under this scenario, a large $\\kappa$ exactly ensures that the minimum of $R _ { M L E }$ occurs at a lower value of $\\tilde { E } _ { L a p l a c e }$ , leading to lower Laplace energy. Conversely, low kurtosis (small $\\kappa$ ) indicates weak volatility, necessitating more energy. Under this scenario, a small $\\kappa$ exactly shifts the minimum of $R _ { M L E }$ towards a higher value of $\\tilde { E } _ { L a p l a c e }$ , resulting in higher Laplace energy. This adaptive behavior ensures that the MLE mechanism injects the appropriate amount of energy into features based on their volatility characteristics. High-kurtosis features, which are naturally more fluctuating, receive less added energy, while low-kurtosis features, which are naturally smoother, receive more energy to enhance their details. By minimizing $R _ { M L E }$ , the model generates finely detailed and stable signals, providing effective guidance for generative models in the absence of supervised information.\n\n# Experiments and Results\n\n# Experiment Dataset\n\nGiven the absence of a dedicated dataset for accelerometer over-range signals, we created a Low-cost Accelerometer Signal Enhancement Dataset (LASED) using 10 different smartphones equipped with built-in accelerometers, which are representative low-cost accelerometers [Jimenez et al. 2009]. The specifications of the smartphones and their internal sensors are detailed in Table 1, where the cost of these sensors does not exceed $\\$ 0.5$ . To evaluate our modelâ€™s robustness, we utilize only one type of smartphone for collecting training data, while the remaining nine smartphones are exclusively used for testing. This setup imposes a significant challenge, requiring the model to generalize across varying hardware specifications, thereby rigorously assessing its performance. Moreover, an eight-camera optical equipment (Nokov Mars2H) is employed to assist in motion capture. During the data collection process, each smartphone is subjected to vigorous shaking in multiple directions to induce signal overload that exceeded the measurement range of the accelerometers. This simulation replicates real-world scenarios where accelerometers encounter high dynamic forces and output overload signals. All experiments are implemented by Pytorch with NVIDIA RTX 4090 GPU and Intel(R) Xeon Gold 6330 CPU.\n\n# Evaluation Metrics\n\nAs the study of generating over-range accelerometer signals is relatively unexplored, there is a lack of metrics to evaluate the accuracy of the generated signals. We, therefore, propose two metrics, Clipped Signal Reconstruction Error (CSRE) and Zero-Velocity Residual Error (ZVRE), to assess the effectiveness of over-range reconstruction methods. For CSRE, the high-cost sensor signal $S _ { h c } ( t )$ is artificially clipped at multiple thresholds $\\tau$ to simulate the signal saturation phenomenon of low-cost sensors with different ranges, resulting in clipped signals $S _ { c l i p , \\tau } ( t )$ . The reconstruction method is then applied to these clipped signals, producing reconstructed signals $S _ { r e c o n , \\tau } ( t )$ . CSRE is calculated by comparing the reconstructed signals with the original unclipped signals by the formula:\n\nTable 1: The built-in sensor of some smartphones.   \n\n<html><body><table><tr><td>Dataset</td><td>Smartphone</td><td>Release</td><td>Sensor</td><td>Unit price</td></tr><tr><td>Training</td><td>HONORMagic 4</td><td>Feb 2022</td><td>LSM6DSR</td><td>$0.35</td></tr><tr><td rowspan=\"11\">Testing</td><td>HUAWEIP40</td><td>Mar 2020</td><td>LSM6DSM</td><td>$0.30</td></tr><tr><td>OPPO Reno 6</td><td>May 2021</td><td>ICM-40607</td><td>$0.28</td></tr><tr><td>HUAWEIP40Pro</td><td>Apr 2020</td><td>LSM6DSO</td><td>$0.33</td></tr><tr><td>Realme GT</td><td>Mar 2021</td><td>BMI160</td><td>$0.21</td></tr><tr><td>Xiaomi 11</td><td>Dec 2020</td><td>BHI260AB</td><td>$0.30</td></tr><tr><td>Lenovo Legion Phone</td><td>Aug 2020</td><td>ICM-42605</td><td>$0.20</td></tr><tr><td>VIVO T2x</td><td>May2022</td><td>LSM6DSO</td><td>$0.33</td></tr><tr><td>iPhone 13</td><td>Sep 2021</td><td>Undisclosed</td><td>/</td></tr><tr><td>iPhone 12</td><td>Oct 2020</td><td>Undisclosed</td><td>/</td></tr></table></body></html>\n\n$$\n\\mathrm { C S R E } _ { \\tau } = \\sqrt { \\frac { 1 } { N } \\sum _ { t = 1 } ^ { N } ( S _ { h c } ( t ) - S _ { r e c o n , \\tau } ( t ) ) ^ { 2 } }\n$$\n\nwhere $N$ is the total number of time frames.\n\nZVRE measures the physical plausibility of generated accelerometer signals. The physical property that the integral of the acceleration signal over transition period from rest to vigorous shaking and back to rest should be zero for each axis (x, y, and $\\boldsymbol { z }$ ) is essential for validating the physical accuracy of the generated signals. The ZVRE is calculated as the absolute value of the integrated acceleration, indicating the deviation from the expected zero velocity.\n\n$$\n\\mathrm { Z V R E } _ { \\mathrm { a x i s } } = \\left| \\int _ { 0 } ^ { T } a _ { a x i s } ( t ) d t \\right|\n$$\n\nwhere $T$ denotes the time \fperiod. This me\ftric is just zero when the reconstructed signals maintain the zero-velocity condition after periods of motion, thereby validating their physical plausibility. In addition to the proposed CSRE and ZVRE, we employ Allan variance [Pei et al. 2023] to evaluate the accuracy of acceleration signals under static conditions. Allan variance is a classical time-domain technique that provides the quantitative indicators of sensor signal quality, including quantization noise (QN), velocity random walk (VRW), and bias instability (BI).\n\n# Comparative Results\n\nRecent acceleration denoising methods, including optimized CNN (CNN-o) [Chen, Taha, and Chodavarapu 2022], GRU\n\nLSTM [Han et al. 2021], optimized GRU-LSTM (GRULSTM-o) [Boronakhin et al. 2022], and kNN [Engelsman and Klein 2023], rely on fully supervised training by framepaired high-cost and low-cost signals. However, collecting such paired data under high-dynamic conditions is impractical. To the end, we used clipped and unclipped high-cost signals to train these methods for generating over-range and high-quality signals. Additionally, MATLAB versions released after 2023 introduced an over-range signal reconstruction function based on polynomial fitting techniques, which is one of the few existing methods that directly tackle the issue of signal saturation. Consequently, we included it in our comparative study. Moreover, we introduced some of the latest signal enhancement methods applicable to IMUs for comparison [Yuan and Wang 2023]. All comparative methods were implemented strictly following the procedures described in their papers or using their open-source codes. The results are shown in Table 2.\n\nThe Clipped Signal Reconstruction Error is tested on clipped high-cost signals. When the clipping is minimal, such as at $\\tau = 1 5 g$ , model-driven methods perform well since they only need to fit the small clipped portions without altering the original signal. In contrast, deep learning models (except ours) tend to modify the entire input signal, occasionally resulting in a higher CSRE. However, as the clipping level increases, traditional model-driven methods struggle. They fail to effectively reconstruct larger clipped sections due to their simplistic fitting approach, leading to significant reconstruction errors. To illustrate this, we visualized the CSRE for different methods as $\\tau$ decreased from $1 5 \\mathrm { g }$ to $6 \\mathrm { g }$ , as shown in Fig. 4. It is evident that the CSRE of the proposed HEROS-GAN is much lower than all comparative methods, attributed to the identity loss. This loss preserves the non-clipped parts of the input high-cost signal, enabling accurate reconstruction of the clipped sections without altering the original signal structure, thus handling both minimal and severe clipping scenarios.\n\nThe Zero-Velocity Residual Error is tested on saturated low-cost signals. Fully supervised methods, trained with high-cost signals, attempt to emulate high-quality signal characteristics, achieving slight reductions in the ZVRE of the test low-cost signals. However, their lack of exposure to low-cost signals limits their effectiveness. In contrast, unsupervised learning methods trained with low-cost signals and model-driven methods never observe high-cost sensor signals, leaving them unaware of the physical plausibility, which causes significant velocity deviations after integration, making these methods ineffective for ZVRE reduction. To demonstrate this, we visualize the ZVRE of the x, y, and z axes for all comparative methods and the raw low-cost signal, as shown in Fig. 5. It can be observed that the HEROS-GAN framework outperforms all comparative methods due to its ability to observe both low-cost and highcost signals. Despite unpaired signals, our Optimal Transport Supervision mechanism exploits their potential correlations to provide the maximum supervisory information. Consequently, the enhanced signal accurately complies with physical laws, ensuring minimal velocity deviation after the Static-Dynamic-Static process.\n\nTable 2: Comparison of latest methods. Considering the dimension difference of indicators, we give the error reduction ratio relative to the raw signal in parentheses for convenient comparison. We bold the best and underline the 2nd best results.   \n\n<html><body><table><tr><td rowspan=\"2\" colspan=\"2\">Architecture</td><td colspan=\"2\">CSRE-/g(9.8m/sÂ²)</td><td rowspan=\"2\">ZVRE /m/s</td><td colspan=\"3\">Allan Variance Analysis</td></tr><tr><td>T =15g</td><td>T=6g</td><td>QN</td><td>VRW</td><td>BI 3.119</td></tr><tr><td colspan=\"3\">Raw signal (No processing)</td><td>0.562</td><td>1.981</td><td>350.78</td><td>1.205</td><td>1.917</td></tr><tr><td rowspan=\"3\">Drivel Learning</td><td>Machine EMD-kylmay tle</td><td>10.38 (-3.40)</td><td>1.871 (-569)</td><td>35.22(314)</td><td>0.491 (539)</td><td>0.576(70-08)</td><td>0.43 (-7949)</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Matlab 2023 CNN-0</td><td>0.321 (-42.9%)</td><td>1.779 (-10.2%)</td><td>361.12 (+3.0%)</td><td>1.211 (+0.5%)</td><td>1.906 (-0.6%)</td><td>3.109 (-0.3%)</td></tr><tr><td rowspan=\"6\">ä¸€ Data Supervised Driven</td><td>Fully</td><td>0.922 (+64.1%)</td><td>1.519 (-23.3%)</td><td>294.96 (-15.9%)</td><td>1.306 (+8.4%)</td><td>2.235 (+16.6%)</td><td>3.437 (+10.2%)</td></tr><tr><td>GRU-LSTM</td><td>0.791 (+40.8%)</td><td>1.742 (-12.1%)</td><td>317.78 (-9.4%)</td><td>1.297 (+7.6%)</td><td>2.139 (+11.6%)</td><td>3.531 (+13.2%)</td></tr><tr><td>GRU-LSTM-0</td><td>0.848 (50.9%)</td><td>1.587 (-19.9%)</td><td>310.4 (-11.5%)</td><td>1.375 (+14.1%)</td><td>2.203 (+14.9%)</td><td>3.746 (+20.1%)</td></tr><tr><td>kNN</td><td>0.739 (+31.5%)</td><td>1.697 (-14.3%)</td><td>339.83 (-3.1%)</td><td>0.988 (-18.0%)</td><td>1.545 (-19.4%)</td><td>2.717 (-12.9%)</td></tr><tr><td>Unsupervised</td><td>IMUDB</td><td>0.523 (-6.9%)</td><td>1.632 (-17.6%) 378.33 (+7.9%)</td><td>0.189 (-84.3%)</td><td>0.274 (-85.7%)</td><td>0.444 (-85.8%)</td></tr><tr><td>Weakly Supervised</td><td>HEROS-GAN (Ours)</td><td>0.199 (-64.6%)</td><td>0.329 (-83.4%)</td><td>21.05 (-94.0%)</td><td>0.057 (-95.3%)</td><td>0.06 (-96.9 %) 0.065 (-97.9%)</td></tr></table></body></html>\n\nAllan variance analysis evaluates the accuracy of static low-cost signals. Fully supervised methods trained on paired clipped and non-clipped high-cost signals do not perform well in this context. Since these methods have never encountered low-cost signals during training, they cannot effectively denoise and may even degrade the signal quality. Traditional model-driven methods exhibit some denoising capability. However, their limited fitting ability restricts their effectiveness. The unsupervised IMUDB method achieves notable denoising results, significantly reducing Allan variance metrics. However, its lack of exposure to high-cost signals prevents full exploitation of superior signal characteristics, resulting in suboptimal denoising performance. Our HEROS-GAN framework exhibits exceptional denoising capability, achieving the lowest Allan variance metrics and significantly improving static signal quality, thereby setting a new standard for accelerometer signal enhancement.\n\n# Ablation Study\n\nCycleGAN, which utilizes both low-cost and high-cost signals, performs relatively well in static evaluations since the static signal segments could be paired. However, its performance in CSRE and ZVRE is not well, indicating that modeling the mapping between unpaired data is challenging for CycleGAN. The MLE and OTS, respectively, enhance signal quality, each excelling in their own aspects. MLE is particularly effective in generating over-range signals, resulting in a lower $\\mathrm { C S R E } _ { \\tau = 6 g }$ (0.474) due to the ability of MLE to adaptively adjust the feature energy, i.e., increasing energy under high-dynamic conditions to overcome range limitations while decreasing energy under stable conditions to reduce noise. OTS excels in simulating high-cost signal characteristics to elevate inferior signals, leading to lower ZVRE, QN, VRW, and BI. Replacing OTS with L1 supervision, which forces unpaired signals into strict alignment, results in significantly poor performance, underscoring the necessity of flexible and adaptive supervision mechanisms like OTS. The HEROS-GAN combining MLE and OTS outperforms SOTA methods by an order of magnitude across all metrics.\n\n![](images/014aefffde99040f717c69630b70773f5ca6b7d19c51c7109ad9ea3f96778f73.jpg)  \nFigure 4: Visualization of CSRE for different methods as the clipping threshold $\\tau$ decreases from $1 5 g$ to $6 g$ .\n\n# Discussion\n\nThe proposed OTS module leverages optimal transport theory to explore potential consistencies between unpaired or weakly-paired data, providing as much supervisory information as possible for generative models and breaking the limitations of strictly paired data. The core idea of OTS lies in aligning features across different data distributions. In multimodal learning, OTS can align feature distributions across modalities, facilitating cross-modal generation, translation, and enhancement tasks. In domain adaptation, OTS can align features from different domains. In medical imaging analysis, where data distributions from different imaging devices (e.g., MRI and CT) vary significantly [Li et al. 2022a], OTS can align the feature distributions across devices, enabling diagnostic model transfer between devices. In robotic perception, OTS can align features from heterogeneous sensors or platforms, supporting multi-platform collaboration and knowledge transfer. In tasks such as remote sensing image processing, unsupervised representation learning, and cross-modal retrieval, the feature alignment capability of OTS can also play a critical role. Moreover, its ability to model optimal mappings between distributions could be extended to decision-making systems, such as reinforcement learning, where it could optimize the transfer of policies between agents operating in different environments. In summary, OTS provides soft yet strict supervision for weakly paired or even unpaired data and features, unlocking hidden consistencies between distributions and uncovering meaningful relationships.\n\n![](images/f4f129e066fdd31eceb6123751cd92e0c6403ccf54edc5a8fd7e651d0ac24c6f.jpg)  \nFigure 5: Visualization of the ZVRE for different methods and the raw low-cost signal across the x, y, and z axes.\n\nTable 3: Ablation experiments on the proposed modules.   \n\n<html><body><table><tr><td>Architecture</td><td>CSRE7=6g</td><td>ZVRE</td><td>QN</td><td>VRW</td><td>BI</td></tr><tr><td>w/o all (CycleGAN)</td><td>1.803</td><td>332.8</td><td>0.166</td><td>0.180</td><td>0.193</td></tr><tr><td>w/MLE</td><td>0.474</td><td>195.7</td><td>0.103</td><td>0.136</td><td>0.159</td></tr><tr><td>w/ OT</td><td>0.588</td><td>39.41</td><td>0.059</td><td>0.072</td><td>0.079</td></tr><tr><td>w/L1</td><td>2.091</td><td>433.9</td><td>1.337</td><td>2.532</td><td>3.796</td></tr><tr><td>w/MLE+OTS (HEROS-GAN)</td><td>0.329</td><td>21.05</td><td>0.057</td><td>0.060</td><td>0.065</td></tr></table></body></html>\n\nThe design of the MLE regularization term offers a powerful and flexible approach for controlling model behavior, with a wide range of potential applications in deep learning tasks. Its formulation can be simplified as $- \\log ( x ) -$ $\\alpha \\cdot \\log ( 1 - x )$ , which serves as a loss function to penalize extreme outputs in deep learning models. More importantly, the parameter $\\alpha \\in ( 0 , + \\infty )$ endows the model with the ability to regulate its output preferences. When $\\alpha$ approaches 0, as the regularization term decreases, the model tends to output values close to 1; conversely, when $\\alpha$ approaches $+ \\infty$ , the modelâ€™s output tends towards 0 as the regularization term decreases. By setting $\\alpha$ to reflect specific model characteristics, we can softly guide the modelâ€™s behavior, avoiding overly rigid constraints. For instance, in this work, $\\alpha$ is set to the kurtosis of the signal features, enabling the model to inject an appropriate amount of Laplacian energy, neither too much nor too little. In tasks like feature alignment or semantic consistency constraints, a suitable $\\alpha$ can be employed to softly regulate the similarity between features, facilitating more natural alignment across different modalities or tasks. Additionally, this regularization term can also be applied to soft adversarial training, where adjusting $\\alpha$ helps balance the model, preventing it from becoming overly biased towards a specific direction. In threshold selection or hyperparameter tuning, it allows the model to adaptively adjust thresholds or hyperparameters based on its intrinsic characteristics by the preference factor $\\alpha$ . In summary, this regularization term, with its capability for soft constraints, preserves flexibility while guiding the modelâ€™s learning process, demonstrating significant versatility and utility.\n\n# Conclusion\n\nThe widespread usage of low-cost accelerometers is often limited by their accuracy and range. Due to the lack of paired data, few studies utilize generative models to transfer low-cost accelerometer signals into high-cost equivalents. This paper proposes a HEROS-GAN for signal accuracy and range enhancement based on unpaired data of independently measured low-cost and high-cost accelerometer signals, which integrates with the Optimal Transport Supervision (OTS) and the Modulated Laplace Energy (MLE) modules. The OTS module leverages the optimal transport theory to explore optimal mapping between such unpaired data, thereby maximizing supervisory information. We provide a rigorous mathematical proof to ensure the existence of this optimal mapping and demonstrate that it can converge during training. Moreover, we mathematically prove that OTS can reduce the instability and oscillations of GAN, overcoming one of the key problems for GAN architecture. The MLE module calculates and adaptively adjusts the Laplace energy of features within the generator, promoting local changes and enriching signal details. Considering the absence of dedicated datasets, we release a Low-cost Accelerometer Signal Enhancement Dataset (LASED) in GitHub, providing the first data experimental platform for accelerometer range and accuracy enhancement. We also devise two metrics, Clipped Signal Reconstruction Error (CSRE) and ZeroVelocity Residual Error (ZVRE), to assess the accuracy and physical plausibility of the enhanced signals. Experimental results demonstrate that a CycleGAN combined with either OTS or MLE alone outperforms current SOTA methods in accelerometer signal enhancement with a tenfold improvement. The HEROS-GAN framework, integrating both OTS and MLE, achieves exceptional results, effectively doubling the accelerometer range while reducing signal noise by two orders of magnitude. The physical plausibility of the generated signals (evidenced by the low ZVRE) confirms the practical applicability of HEROS-GAN and sets a standard in acceleration signal processing.",
    "summary": "```json\n{\n  \"core_summary\": \"### ğŸ¯ æ ¸å¿ƒæ¦‚è¦\\n\\n> **é—®é¢˜å®šä¹‰ (Problem Definition)**\\n> *   ä½æˆæœ¬åŠ é€Ÿåº¦è®¡åœ¨ç°ä»£ç¤¾ä¼šä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†å…¶ç²¾åº¦ï¼ˆå™ªå£°ä¸¥é‡ï¼‰å’Œæµ‹é‡èŒƒå›´ï¼ˆé€šå¸¸ä»…Â±2gæˆ–Â±8gï¼‰å­˜åœ¨ä¸¥é‡é™åˆ¶ï¼Œæ— æ³•æ»¡è¶³é«˜åŠ¨æ€åº”ç”¨ï¼ˆå¦‚å·¥ä¸šè‡ªåŠ¨åŒ–éœ€è¦Â±16gï¼ŒåŒ»ç–—ç›‘æµ‹éœ€è¦æ£€æµ‹è¶…è¿‡10gçš„è·Œå€’äº‹ä»¶ï¼‰çš„éœ€æ±‚ã€‚\\n> *   è¯¥é—®é¢˜çš„é‡è¦æ€§åœ¨äºï¼šå·¥ä¸šçº§é«˜ç²¾åº¦åŠ é€Ÿåº¦è®¡å•ä»·é«˜è¾¾$10-$20ï¼Œé¡¶çº§å‹å·ï¼ˆå¦‚Xsensï¼‰ç”šè‡³è¶…è¿‡$1500ï¼Œè€Œä½æˆæœ¬ä¼ æ„Ÿå™¨ä»…$0.20-$0.50ã€‚é€šè¿‡ç®—æ³•æå‡æ€§èƒ½å¯å®ç°é«˜ç«¯åº”ç”¨çš„ä½æˆæœ¬åŒ–ã€‚\\n\\n> **æ–¹æ³•æ¦‚è¿° (Method Overview)**\\n> *   æå‡º**HEROS-GAN**æ¡†æ¶ï¼Œé¦–æ¬¡å°†ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰åº”ç”¨äºåŠ é€Ÿåº¦è®¡ä¿¡å·å¢å¼ºï¼Œé€šè¿‡**æœ€ä¼˜ä¼ è¾“ç›‘ç£ï¼ˆOTSï¼‰**å’Œ**è°ƒåˆ¶æ‹‰æ™®æ‹‰æ–¯èƒ½é‡ï¼ˆMLEï¼‰**æ¨¡å—ï¼Œåˆ©ç”¨éé…å¯¹æ•°æ®å®ç°ä½æˆæœ¬åˆ°é«˜æˆæœ¬ä¿¡å·çš„è½¬æ¢ã€‚\\n\\n> **ä¸»è¦è´¡çŒ®ä¸æ•ˆæœ (Contributions & Results)**\\n> *   **é¦–æ¬¡å°†æ·±åº¦å­¦ä¹ å¼•å…¥åŠ é€Ÿåº¦è®¡èŒƒå›´æ‰©å±•**ï¼šæ„å»ºé¦–ä¸ªåŠ é€Ÿåº¦è®¡ä¿¡å·å¢å¼ºæ•°æ®é›†LASEDï¼ˆå«æ•°ä¸‡æ ·æœ¬ï¼Œå·²å¼€æºï¼‰ã€‚\\n> *   **è®¾è®¡æœ€ä¼˜ä¼ è¾“ç›‘ç£ï¼ˆOTSï¼‰**ï¼šé€šè¿‡Sinkhornç®—æ³•æ±‚è§£ç‰¹å¾åˆ†å¸ƒæœ€ä¼˜æ˜ å°„ï¼Œåœ¨æ— é…å¯¹æ•°æ®ä¸‹å®ç°94.0%çš„ZVREé™ä½ï¼ˆ21.05 vs åŸå§‹350.78ï¼‰ã€‚\\n> *   **æå‡ºè°ƒåˆ¶æ‹‰æ™®æ‹‰æ–¯èƒ½é‡ï¼ˆMLEï¼‰**ï¼šåŸºäºç‰¹å¾å³°åº¦è‡ªé€‚åº”è°ƒèŠ‚èƒ½é‡æ³¨å…¥ï¼Œä½¿CSREåœ¨Ï„=6gæ—¶è¾¾0.329ï¼ˆæ¯”æœ€ä½³åŸºçº¿æå‡83.4%ï¼‰ã€‚\\n> *   **ç»¼åˆæ•ˆæœ**ï¼šå°†æµ‹é‡èŒƒå›´ä»8gæ‰©å±•åˆ°16gï¼ŒåŒæ—¶å°†ä¿¡å·å™ªå£°é™ä½**ä¸¤ä¸ªæ•°é‡çº§**ï¼ˆAllanæ–¹å·®æŒ‡æ ‡æ”¹å–„95%ä»¥ä¸Šï¼‰ã€‚\",\n  \"algorithm_details\": \"### âš™ï¸ ç®—æ³•/æ–¹æ¡ˆè¯¦è§£\\n\\n> **æ ¸å¿ƒæ€æƒ³ (Core Idea)**\\n> *   **åŒæ¨¡å—ååŒæœºåˆ¶**ï¼š\\n>     1.  **OTS**é€šè¿‡æœ€ä¼˜ä¼ è¾“ç†è®ºï¼ˆå…¬å¼1-2ï¼‰æŒ–æ˜éé…å¯¹æ•°æ®çš„æ½œåœ¨ç‰¹å¾ä¸€è‡´æ€§ï¼Œè§£å†³ç›‘ç£ç¼ºå¤±é—®é¢˜ã€‚\\n>     2.  **MLE**ï¼ˆå…¬å¼3-6ï¼‰é€šè¿‡æ‹‰æ™®æ‹‰æ–¯ç®—å­âˆ‡Â²é‡åŒ–ç‰¹å¾æ³¢åŠ¨ï¼Œç»“åˆå³°åº¦è‡ªé€‚åº”è°ƒèŠ‚èƒ½é‡æ³¨å…¥ï¼ˆÎºå‚æ•°ï¼‰ï¼Œçªç ´èŒƒå›´é™åˆ¶çš„åŒæ—¶æŠ‘åˆ¶å™ªå£°ã€‚\\n> *   **æœ‰æ•ˆæ€§åŸç†**ï¼šOTSçš„è¿è¾“æˆæœ¬å‡½æ•°c(f_Li,f_Hj)=e^(1-f_LiÂ·f_Hj)ç¡®ä¿ç‰¹å¾å¯¹é½çš„ç‰©ç†åˆç†æ€§ï¼›MLEçš„log(E)-Îºlog(1-E)æ­£åˆ™é¡¹å¼ºåˆ¶èƒ½é‡å¤„äºé€‚åº¦åŒºé—´ï¼ˆÎº=1æ—¶å¯¹ç§°æœ€å°ç‚¹åœ¨E=0.5ï¼‰ã€‚\\n\\n> **åˆ›æ–°ç‚¹ (Innovations)**\\n> *   **ä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”**ï¼š\\n>     *   ç¡¬ä»¶æ”¹è¿›æ–¹æ¡ˆæˆæœ¬é«˜æ˜‚ï¼ˆ$1500+ vs $0.5ï¼‰ã€‚\\n>     *   ä¼ ç»Ÿæ»¤æ³¢æ–¹æ³•ï¼ˆå¦‚Kalmanï¼‰ä¾èµ–å…ˆéªŒçŸ¥è¯†ï¼Œæ³›åŒ–æ€§å·®ã€‚\\n> *   **ä¸æ•°æ®é©±åŠ¨æ–¹æ³•å¯¹æ¯”**ï¼š\\n>     *   å…¨ç›‘ç£æ–¹æ³•ï¼ˆå¦‚CNN-oï¼‰éœ€å¸§çº§é…å¯¹æ•°æ®ï¼ˆå®é™…ä¸å¯å¾—ï¼‰ã€‚\\n>     *   CycleGANç¼ºä¹ç‰©ç†çº¦æŸå¯¼è‡´ZVREé«˜è¾¾332.8ã€‚\\n> *   **æœ¬æ–‡æ”¹è¿›**ï¼š\\n>     *   **OTS**ï¼šé€šè¿‡æœ€ä¼˜è¿è¾“æ˜ å°„Tå®ç°è·¨åŸŸç‰¹å¾è½¯å¯¹é½ï¼ˆå…¬å¼2ï¼‰ï¼Œæ¯”L1ç›‘ç£ï¼ˆZVRE=433.9ï¼‰æ›´ç¨³å®šã€‚\\n>     *   **MLE**ï¼šåŸºäºâˆ‡Â²hi(n)çš„èƒ½é‡è®¡ç®—ï¼ˆå…¬å¼3-4ï¼‰å’ŒÎº=å³°åº¦çš„è‡ªé€‚åº”è°ƒèŠ‚ï¼Œä½¿CSRE_6gä»1.803é™è‡³0.329ã€‚\\n\\n> **å…·ä½“å®ç°æ­¥éª¤ (Implementation Steps)**\\n> 1.  **æ•°æ®å‡†å¤‡**ï¼šä½¿ç”¨10æ¬¾æ™ºèƒ½æ‰‹æœºï¼ˆä¼ æ„Ÿå™¨å•ä»·â‰¤$0.5ï¼‰æ„å»ºLASEDæ•°æ®é›†ï¼Œå•è®¾å¤‡è®­ç»ƒ+è·¨è®¾å¤‡æµ‹è¯•ã€‚\\n> 2.  **OTSå®ç°**ï¼š\\n>     *   è®¡ç®—ä½/é«˜æˆæœ¬ä¿¡å·ç‰¹å¾F_L(x_L)âˆˆâ„^(NÃ—d)å’ŒF_H(x_H)âˆˆâ„^(NÃ—d)ã€‚\\n>     *   ç”¨Sinkhornç®—æ³•æ±‚è§£min_Î³âˆ«c(f_Li,f_Hj)dÎ³ï¼ˆå…¬å¼1ï¼‰ï¼Œå¾—åˆ°æ˜ å°„Tã€‚\\n>     *   é€šè¿‡L_OTS=ğ”¼[â€–F_G_L(x_L)-T(F_H)â€–Â²+â€–F_G_H(x_H)-Tâ»Â¹(F_L)â€–Â²]ä¼˜åŒ–ï¼ˆå…¬å¼2ï¼‰ã€‚\\n> 3.  **MLEå®ç°**ï¼š\\n>     *   è®¡ç®—ç‰¹å¾å±‚æ‹‰æ™®æ‹‰æ–¯èƒ½é‡E_Laplace=âˆ‘(âˆ‡Â²hi(n))Â²ï¼ˆå…¬å¼3-4ï¼‰ã€‚\\n>     *   è®¾è®¡æ­£åˆ™é¡¹R_MLE=-log(Ïƒ(E))-Îºlog(1-Ïƒ(E))ï¼ˆå…¬å¼5-6ï¼‰ï¼ŒÎº=å³°åº¦ã€‚\\n> 4.  **è”åˆè®­ç»ƒ**ï¼šç»“åˆCycleGANçš„å¯¹æŠ—æŸå¤±ã€OTSå’ŒMLEï¼Œç«¯åˆ°ç«¯ä¼˜åŒ–HEROS-GANã€‚\\n\\n> **æ¡ˆä¾‹è§£æ (Case Study)**\\n> *   **CSREæµ‹è¯•**ï¼šå°†é«˜æˆæœ¬ä¿¡å·åœ¨Ï„=15gâ†’6gé€æ­¥æˆªæ–­ï¼ŒHEROS-GANé‡æ„è¯¯å·®å§‹ç»ˆæœ€ä½ï¼ˆå›¾4ï¼‰ã€‚\\n> *   **ZVREéªŒè¯**ï¼šå¯¹x/y/zä¸‰è½´ç§¯åˆ†ï¼ŒåŸå§‹ä¿¡å·åå·®è¾¾350.78 m/sï¼ŒHEROS-GANé™è‡³21.05ï¼ˆå›¾5ï¼‰ã€‚\",\n  \"comparative_analysis\": \"### ğŸ“Š å¯¹æ¯”å®éªŒåˆ†æ\\n\\n> **åŸºçº¿æ¨¡å‹ (Baselines)**\\n> *   ä¼ ç»Ÿæ–¹æ³•ï¼šMATLAB 2023å¤šé¡¹å¼æ‹Ÿåˆã€EMD-kalman\\n> *   å…¨ç›‘ç£æ–¹æ³•ï¼šCNN-oã€GRU-LSTMã€GRU-LSTM-oã€kNN\\n> *   æ— ç›‘ç£æ–¹æ³•ï¼šIMUDB\\n\\n> **æ€§èƒ½å¯¹æ¯” (Performance Comparison)**\\n> *   **åœ¨CSRE_Ï„=6gä¸Š**ï¼šHEROS-GANè¾¾åˆ°0.329ï¼Œæ˜¾è‘—ä¼˜äºå¤šé¡¹å¼æ‹Ÿåˆï¼ˆ1.871ï¼‰å’ŒGRU-LSTM-oï¼ˆ1.587ï¼‰ï¼Œæ¯”æœ€ä½³åŸºçº¿IMUDBï¼ˆ1.632ï¼‰æå‡83.4%ã€‚\\n> *   **åœ¨ZVREä¸Š**ï¼šHEROS-GANä»…21.05ï¼Œè¿œä½äºIMUDBï¼ˆ378.33ï¼‰å’ŒGRU-LSTMï¼ˆ294.96ï¼‰ï¼Œæ¯”L1ç›‘ç£ï¼ˆ433.9ï¼‰æå‡95.1%ã€‚\\n> *   **åœ¨Allanæ–¹å·®ä¸Š**ï¼š\\n>     *   é‡åŒ–å™ªå£°ï¼ˆQNï¼‰ï¼š0.057ï¼ˆæ¯”åŸå§‹1.205é™95.3%ï¼‰ã€‚\\n>     *   é€Ÿåº¦éšæœºæ¸¸èµ°ï¼ˆVRWï¼‰ï¼š0.060ï¼ˆé™96.9%ï¼‰ã€‚\\n>     *   åç½®ä¸ç¨³å®šæ€§ï¼ˆBIï¼‰ï¼š0.065ï¼ˆé™97.9%ï¼‰ã€‚\\n> *   **è·¨è®¾å¤‡æ³›åŒ–æ€§**ï¼šä½¿ç”¨9æ¬¾æœªå‚ä¸è®­ç»ƒçš„æ™ºèƒ½æ‰‹æœºæµ‹è¯•ï¼Œæ€§èƒ½æ³¢åŠ¨<5%ã€‚\",\n  \"keywords\": \"### ğŸ”‘ å…³é”®è¯\\n\\n*   åŠ é€Ÿåº¦è®¡ä¿¡å·å¢å¼º (Accelerometer Signal Enhancement, ASE)\\n*   ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (Generative Adversarial Network, GAN)\\n*   æœ€ä¼˜ä¼ è¾“ç›‘ç£ (Optimal Transport Supervision, OTS)\\n*   è°ƒåˆ¶æ‹‰æ™®æ‹‰æ–¯èƒ½é‡ (Modulated Laplace Energy, MLE)\\n*   ä½æˆæœ¬ä¼ æ„Ÿå™¨ (Low-Cost Sensors, N/A)\\n*   ä¿¡å·è¿‡è½½æ¢å¤ (Over-Range Signal Recovery, N/A)\\n*   å·¥ä¸šè‡ªåŠ¨åŒ– (Industrial Automation, N/A)\\n*   åŒ»ç–—ç›‘æµ‹ (Medical Monitoring, N/A)\"\n}\n```"
}