{
    "source": "Semantic Scholar",
    "arxiv_id": "2412.07273",
    "link": "https://arxiv.org/abs/2412.07273",
    "pdf_link": "https://arxiv.org/pdf/2412.07273.pdf",
    "title": "Temporal-Aware Evaluation and Learning for Temporal Graph Neural Networks",
    "authors": [
        "Junwei Su",
        "Shan Wu"
    ],
    "categories": [
        "cs.LG",
        "cs.AI"
    ],
    "publication_date": "2024-12-10",
    "venue": "AAAI Conference on Artificial Intelligence",
    "fields_of_study": [
        "Computer Science"
    ],
    "citation_count": 0,
    "influential_citation_count": 0,
    "institutions": [
        "Hefei University of Technology",
        "University of Hong Kong"
    ],
    "paper_content": "# Temporal-Aware Evaluation and Learning for Temporal Graph Neural Networks\n\nJunwei $\\mathbf { S u } ^ { 2 , * }$ , Shan $\\mathbf { W } \\mathbf { u } ^ { 1 }$ ,\\*\n\n1School of Resources and Environmental Engineering, Hefei University of Technology 2School of Computing and Data Science, University of Hong Kong jwsu@cs.hku.hk, wus $@$ hfut.edu.cn\n\n# Abstract\n\nTemporal Graph Neural Networks (TGNNs) are a family of graph neural networks designed to model and learn dynamic information from temporal graphs. Given their substantial empirical success, there is an escalating interest in TGNNs within the research community. However, the majority of these efforts have been channelled towards algorithm and system design, with the evaluation metrics receiving comparatively less attention. Effective evaluation metrics are crucial for providing detailed performance insights, particularly in the temporal domain. This paper investigates the commonly used evaluation metrics for TGNNs and illustrates the failure mechanisms of these metrics in capturing essential temporal structures in the predictive behaviour of TGNNs. We provide a mathematical formulation of existing performance metrics and utilize an instance-based study to underscore their inadequacies in identifying volatility clustering (the occurrence of emerging errors within a brief interval). This phenomenon has profound implications for both algorithm and system design in the temporal domain. To address this deficiency, we introduce a new volatility-aware evaluation metric (termed volatility cluster statistics), designed for a more refined analysis of model temporal performance. Additionally, we demonstrate how this metric can serve as a temporal-volatility-aware training objective to alleviate the clustering of temporal errors. Through comprehensive experiments on various TGNN models, we validate our analysis and the proposed approach. The empirical results offer revealing insights: 1) existing TGNNs are prone to making errors with volatility clustering, and 2) TGNNs with different mechanisms to capture temporal information exhibit distinct volatility clustering patterns. Moreover, our empirical findings demonstrate that our proposed training objective effectively reduces volatility clusters in error.\n\n# 1 Introduction\n\nMany real-world problems and systems are naturally modeled as temporal graphs (also referred to as dynamic graphs), characterized by continuously changing relationships, nodes, and attributes. To address this temporal dynamic nature, Temporal Graph Neural Networks (TGNNs), the temporal counterparts to GNNs, have emerged as promising deep learning models capable of modelling timevarying graph structures (Kazemi et al. 2020; Skarding, Gabrys, and Musial 2021; Zhang et al. 2023; Xu et al. 2020a). Unlike their static counterparts, TGNNs excel at capturing temporal dependencies and learning temporal representations within the context of temporal graphs. Consequently, they are widely employed in applications such as traffic prediction (Zhao et al. 2019; Guo et al. 2019; Zhang et al. 2020), financial analysis (Wang et al. 2021a; Su, Wu, and Li 2024), social network (Zhang et al. 2021b), recommender systems (Kumar, Zhang, and Leskovec 2019), and climate modeling (Khodayar and Wang 2018).\n\nGiven their substantial empirical success, there is growing interest in TGNNs within the research community. However, most efforts have been concentrated on algorithm and system design, with various classes of TGNNs emerging based on their mechanisms for capturing temporal information (e.g., RNN-based, memory-based, and attention-based; see related work for more details). Conversely, the evaluation of TGNNs has received comparatively less attention. There are only a few benchmark studies on TGNNs that predominantly investigate how various combinations of learning settings and datasets impact the performance of TGNN models. Notably, these benchmarks typically utilize common instancebased evaluation metrics like Average Precision (AP) and Area Under the ROC Curve (AU-ROC), where each test sample is considered identically and independently. An intriguing finding from these benchmark studies is that almost all existing TGNNs demonstrate remarkable (and similar) performance when evaluated against these instance-based metrics. This uniformity in performance poses a significant challenge in model selection for practical applications, as distinguishing between models based on these metrics alone becomes difficult. Therefore, there is an urgent need to develop more nuanced evaluation metrics that can better capture the unique capabilities and efficiencies of different TGNN architectures.\n\nIn addition to model selection, this paper argues that instance-based evaluation metrics are insufficient and ineffective at capturing the temporal structure of the predictive behavior of TGNNs. Data samples in temporal graphs could exhibit temporal correlation, impacting the predictions made by TGNNs and introducing patterns such as volatility clustersâ€”periods where large fluctuations are grouped together. This aspect is crucial for the functionality of temporal algorithms and systems in TGNNs. For example, in financial trading algorithms or risk management systems, accurately measuring and predicting volatility clusters can be crucial for effective strategy deployment and risk assessment. Similarly, in fault-tolerant systems, understanding volatility clusters can aid in preemptively identifying periods of potential system stress or failure, thereby enabling proactive maintenance or system adjustments to prevent downtime. Adequate performance evaluation ensures that these systems are not only accurate but also robust and responsive under varying temporal dynamics. This, in turn, aids in optimizing operational efficiency, improving decision-making processes, and ensuring reliability in critical applications where timing and the evolution of data play a vital role. Therefore, developing and refining evaluation metrics that can effectively measure the performance of TGNNs is essential for advancing these technologies and their applications.\n\nContribution. This paper aims to spotlight an underexplored aspect of TGNNsâ€”the evaluation metrics. We examine and highlight the inadequacies of current evaluation metrics in capturing the temporal structures of TGNNs and propose a novel performance metric tailored to detect nuanced temporal information such as volatility clusters. The key contributions and findings of this paper are summarized and highlighted as follows\n\n1. We present a mathematical formulation of existing evaluation metrics alongside a formal definition aimed at measuring the expressiveness of these metrics. This foundational framework is crucial for analyzing evaluation metrics comprehensively and formalizing the limitations inherent in current TGNN evaluation approaches. Utilizing this framework, we formally prove that instance-based evaluation metrics such as AP and AU-ROC resemble a simple counting process and fail to capture temporal structures (e.g., volatility clusters) in the predictions of TGNNs (Theorem 3.1).\n\n2. Building on the insights from our analysis, we propose a novel evaluation metric, named volatility-cluster statistics (VCS). Inspired by Hopkins statistics (Hopkins and Skellam 1954), VCS serves as a complementary evaluation metric designed to detect and evaluate volatility clusters in the prediction errors of TGNNs. VCS offers crucial insights into the temporal structure of the prediction errors (error pattern) of TGNNs and helps differentiate the performance of various TGNN models.\n\n3. Beyond its use in evaluation, we demonstrate that the concept of VCS can also function effectively as a regularization technique to mitigate volatility clusters in errors with appropriate modifications. We introduce a method termed volatility-cluster-aware (VCA) learning, which is a smooth and differentiable extension of VCS. VCA helps mitigate volatility clusters in the prediction errors of TGNNs. This capability is particularly valuable in the design of systems and algorithms for critical areas such as fault-tolerant systems.\n\n4. We validate our findings and the effectiveness of our metrics through extensive empirical studies consisting of five datasets and six SOTA methods. Our empirical results reveal several key insights: 1) existing TGNNs tend to produce volatility cluster in errors, particularly in RNNbased and memory-based models; 2) different types of TGNNs manifest varying error patternsâ€”for instance, memory-based TGNNs generally exhibit clustered errors towards the end of the testing period, whereas RNNbased TGNNs tend to show them at the beginning. These observations indicate fundamental differences in how these models process temporal information and provide directions for model-specific improvements; 3) our proposed VCA learning objective serves as an effective regularization tool, making existing TGNNs less susceptible to volatility clustering in errors.\n\n# 2 Related Works\n\nTemporal Graph Neural Network. Temporal graph representation learning has garnered substantial attention in recent years, driven by the imperative to model and analyze evolving relationships and temporal dependencies within temporal graphs (we refer the reader to (Skarding, Gabrys, and Musial 2021; Kazemi et al. 2020) for more comprehensive surveys). TGNNs, as temporal counterparts to GNNs, have emerged as promising neural models for temporal graph representation learning(Sankar et al. 2020; Poursafaei et al. 2022; Xu et al. 2020a; Su, Zou, and Wu 2024b; Wang et al. 2021c; Kumar, Zhang, and Leskovec 2019; Trivedi et al. 2019; Zhang et al. 2023; Pareja et al. 2020; Trivedi et al. 2017; Xu et al. 2020b; Luo and Li 2022) and have shown SOTA performance in many temporal-related tasks. Roughly speaking, existing TGNNs can be categorized into three types based on the mechanism used for capturing temporal information: RNN-based (Trivedi et al. 2019), attention-based (Wang et al. 2021b), and memorybased TGNNs (Rossi et al. 2021). Due to its potential and practical significance, there has been a recent surge in both theoretical exploration (Souza et al. 2022) and architectural innovation (Rossi et al. 2021; Wang et al. 2021c; Kumar, Zhang, and Leskovec 2019; Trivedi et al. 2019; Zhang et al. 2023) related to TGNNs. In addition, there are works dedicated to optimizing both the inference and training efficiency of TGNNs, employing techniques such as incremental learning (Su et al. 2023; Su, Zou, and Wu 2024a), computation duplication (Wang and Mendis 2023), CPU-GPU communication optimization (Zhou et al. 2022), staleness (Sheng et al. 2024), and caching (Wang et al. 2021c). Despite all these efforts, the evaluation metrics of TGNNs remain underexplored. In this paper, we address this gap and focus on studying the evaluation metrics of TGNNs.\n\nEvaluation of TGNNs. Evaluation is core to machine learning research (Zhang et al. 2021a). Because of this, evaluation and benchmarking have been extensively studied in static graph representation learning (Dwivedi et al. 2023; Errica et al. 2019; Hu et al. 2020; Lv et al. 2021). Due to the dynamic nature of temporal graphs, properly evaluating temporal link prediction problems has been challenging and complicated with different issues as documented in (Junuthula, Xu, and Devabhaktuni 2018; Haghani and\n\n![](images/83a4d301ed46768d571e5ccbb904f38f46dcff895b4d0b873320a5bcb14f9b77.jpg)  \nFigure 1: The Learning Procedure of TGNNs. Fig. 1(a) depicts the learning procedure of TGNN. Data/events are split based on chronological order into training and testing/validation. During the training, data/events are further divided into temporal batches. The incoming batch serves as training samples for updating the model and embedding for the subsequent batch. Fig. 1(b) visualizes the training procedure and computation of TGNNs. Incoming events are served as positive samples and negative events are sampled from the rest of the graphs.\n\nKeyvanpour 2019; Junuthula, Xu, and Devabhaktuni 2016; Poursafaei et al. 2022; Huang et al. 2024; Yu et al. 2023). In particular, (Poursafaei et al. 2022; Huang et al. 2024; Yu et al. 2023) are recent benchmark studies focusing on TGNN evaluation on temporal link prediction. Their studies have revealed that learning settings, such as transductive vs. inductive and negative sampling strategies, play a critical role in properly evaluating TGNNs. In addition, these benchmarks reveal that almost all existing TGNN exhibit remarkable (and similar) performance with respect to the commonly used instance-based evaluation metric, rendering model selection challenging in practice. This has inspired and motivated the central research of this paper.\n\n# 3 Preliminary and Background\n\nIn this section, we provide a concise introduction to TGNNs. Due to space limitations, a more detailed description is available in the supplementary material for completeness. We use lowercase letters to denote scalars and graph-related objects, and lower and uppercase boldface letters to denote vectors and matrices, respectively.\n\nEvent-based Representation of Temporal Graphs. In this paper, we adopt the event-based representation of temporal graphs, as described in previous works (Skarding, Gabrys, and Musial 2021; Zhang et al. 2023). A temporal graph $\\mathcal { G }$ in this representation consists of a node set $ { \\mathcal { V } } ~ = ~ \\{ 1 , . . . , N \\}$ and an event set $\\mathcal { E } ~ = ~ \\{ e _ { i j } ( t ) \\}$ , where $i , j \\in \\mathcal { V }$ . The node set $\\nu$ represents the entities in the graphs. The event set $\\mathcal { E }$ represents a stream of events, with each edge $e _ { i j } ( t )$ corresponding to an interaction event between node $i$ and node $j$ at timestamp $t \\geq 0$ . Node features and edge features for $\\boldsymbol { v } _ { i }$ and $e _ { i j }$ are denoted by ${ \\bf f } _ { i } ( t )$ and $\\mathbf { f } _ { i j } ( t )$ , respectively. In the case of non-attributed graphs, we assume $\\bar { \\mathbf { f } _ { i } } ( t ) = \\dot { \\mathbf { 0 } }$ and $\\mathbf { f } _ { i j } ( t ) = \\mathbf { 0 }$ , representing zero vectors.\n\nTemporal Graph Neural Networks (TGNNs). TGNNs, extended from the standard GNN to the temporal graph, can be viewed as an embedding function (encoder) for finding the temporal representation of vertices in temporal graphs (Su, Zou, and Wu 2024b; Rossi et al. 2021). The learned embedding can then be used as input for different downstream tasks. A canonical formulation of the TGNN encoder is to extend the message-passing scheme from GNNs to include time information. The formulation of TGNNs for learning the representation of vertex $i$ is given by:\n\n$$\n\\begin{array} { r l } & { \\quad \\mathbf { h } _ { i } ( t ) = \\mathrm { e m b } ( \\{ \\mathbf { m } _ { i j } , j \\in \\mathcal { N } _ { i } ( t ) \\} ) , } \\\\ & { \\mathbf { m } _ { i j } ( t ) = \\mathrm { m s g } ( \\mathbf { h } _ { i } ( t ^ { - } ) , \\mathbf { h } _ { j } ( t ^ { - } ) , \\mathbf { f } _ { i j } ( t ) , \\mathbf { f } _ { i } ( t ) , \\mathbf { f } _ { j } ( t ) , \\Delta t ) , } \\end{array}\n$$\n\nwhere ${ \\bf h } _ { i } ( t ^ { - } )$ and ${ \\bf h } _ { j } ( t ^ { - } )$ are the embedding of nodes $i$ and $j$ before time $t$ (i.e., at the time of the previous interaction involving node $i$ or $j$ ), ${ \\bf m } _ { i j } ( t )$ is the message from vertex $j$ to $i$ at time $t$ generated from the event $e _ { i j } ( t ) , \\mathcal { N } _ { i } ( t )$ is the temporal neighbours of nodes $i$ up to time $t .$ , $h _ { i } ( t )$ is temporal embedding/representation of nodes $i$ at time $t$ , and $\\mathrm { m s g ( . ) }$ (e.g., MLP), and emb $( . )$ (e.g., GCN) are learnable functions. After obtaining the embeddings $h _ { i } ( t )$ and $h _ { j } ( t )$ in the prescribed manner, an extra simple MLP layer (or decoder in other forms) can be used for the down-stream tasks.\n\nTGNNs Training and Evaluation TGNNs are frequently trained in a self-supervised manner using link prediction tasks (Poursafaei et al. 2022; Huang et al. 2024), which are commonly conceptualized as a binary classification problem aimed at predicting whether a link will form between two nodes. Consequently, the performance of TGNNs is often evaluated with respect to their success in link prediction tasks. Therefore, in this paper, we concentrate our discussion on link prediction, though the analysis and arguments can be naturally extended to other downstream tasks such as node classification. More formally, we can assign labels for events $e _ { i j } ( t )$ , such that:\n\n$$\ny _ { i j } ( t ) = { \\left\\{ \\begin{array} { l l } { 1 } & { { \\mathrm { i f } } e _ { i j } ( t ) \\in \\mathcal { E } , } \\\\ { 0 } & { { \\mathrm { o t h e r w i s e } } . } \\end{array} \\right. }\n$$\n\nFor simplicity, we omit the specific node pair $i , j$ when referring to the event $e _ { i j } ( t )$ and index the event by its order of appearance in the corresponding set. Let $\\mathcal { \\bar { E } } _ { \\mathrm { t e s t } } = \\{ e _ { k } ( t _ { k } ) \\} _ { k = 1 , \\dots , M }$ , be a chronologically ordered sequence of $M$ test samples from the test period, $\\begin{array} { r l } { T _ { \\mathrm { t e s t } } } & { { } = } \\end{array}$ $[ t _ { 1 } , t _ { 2 } ] , i . e . , t _ { 1 } \\leq t _ { k } \\leq t _ { k + 1 } \\leq t _ { 2 }$ . Let $\\mathbf { Y } = \\{ y _ { 1 } , . . . , y _ { m } \\}$ , be the ground-truth labels of the given samples, and let $\\widehat { \\mathbf { Y } } = \\{ \\widehat { y } _ { 1 } , . . . , \\widehat { y } _ { m } \\}$ , be the predicted labels of the given sampbles bybthe TbGNN. Then, we can define the performance evaluation metric as a function $\\mu ( . )$ of the form:\n\n$$\n\\mu : \\mathbf { Y } \\times { \\widehat { \\mathbf { Y } } } \\times { \\mathcal { E } } \\mapsto \\mathbb { R } ^ { + } .\n$$\n\nIn other words, $\\mu$ takes in the prediction and the ground truth and maps them to a positive real value.\n\n# Limitation of Current Evaluation Metrics\n\nTo explore the limitation of the evaluation metric, we first define a measure of its capability. In this paper, we propose extending the idea of the expressive power of GNNs to characterize the ability of an evaluation metric by its expressivenessâ€”the capacity to differentiate between different predictions. More formally, we introduce the following definition.\n\nDefinition 1 (Expressiveness of Evaluation Metric). For two distinct predictions $\\widehat { \\mathbf { Y } } _ { 1 }$ and $\\widehat { \\mathbf { Y } } _ { 2 }$ , we say an evaluation metric $\\mu$ can differenti tbe $\\widehat { \\mathbf { Y } } _ { 1 }$ bd $\\widehat { \\mathbf { Y } } _ { 2 }$ if $\\widetilde { \\mu } ( \\mathbf { Y } , \\widehat { \\mathbf { Y } } _ { 1 } , \\mathcal { E } ) \\ \\neq$ $\\mu ( \\mathbf { Y } , \\widehat { \\mathbf { Y } } _ { 2 } , \\mathcal { E } )$ .\n\nAs noted, the most commonly used evaluation metrics for TGNNs are instance-based, such as AP and AU-ROC, where each test sample is considered identically and independently. More formally, this family of evaluation metrics is defined as follows:\n\nDefinition 2 (Instance-based Evaluation). For a given evaluation $\\mu ( \\mathbf { Y } , { \\hat { \\mathbf { Y } } } , { \\mathcal { E } } )$ , we say $\\mu ( . )$ is an instance-based evaluation metric  fbit can be expressed as,\n\n$$\n\\mu ( { \\bf Y } , \\widehat { \\bf Y } , \\mathcal { E } ) = g \\left( \\left\\{ f ( y _ { i } , \\widehat { y _ { i } } ) | y _ { i } , \\widehat { y _ { i } } \\in { \\bf Y } , \\widehat { \\bf Y } \\right\\} \\right) ,\n$$\n\nwhere $g$ is some set function and $f : \\mathbf { Y } \\times { \\widehat { \\mathbf { Y } } } \\mapsto \\mathbb { R } ^ { + }$ .\n\nThe following result shows the limitatbion of instancebased evaluation metrics:\n\nTheorem 3.1 (Failure of Instance-Based Evaluation). Let $\\widehat { \\mathbf { Y } } _ { 1 }$ and $\\widehat { \\mathbf { Y } } _ { 2 }$ be two distinct predictions for the set $\\mathcal { E }$ with gbround- buth $\\mathbf { Y }$ , and $\\mu ( . )$ is an instance-based evaluation metric. Then, we have that,\n\n$$\n\\mu ( \\widehat { \\mathbf { Y } } _ { 1 } , \\mathbf { Y } , \\mathcal { E } ) = \\mu ( \\widehat { \\mathbf { Y } } _ { 2 } , \\mathbf { Y } , \\mathcal { E } ) ,\n$$\n\nso long as,\n\n$$\n\\operatorname { H } ( \\mathbf { Y } , { \\widehat { \\mathbf { Y } } } _ { 1 } ) = \\operatorname { H } ( \\mathbf { Y } , { \\widehat { \\mathbf { Y } } } _ { 2 } ) ,\n$$\n\nwhere $\\begin{array} { r } { \\mathrm { H } ( \\mathbf { Y } , \\widehat { \\mathbf { Y } } ) = \\sum _ { k = 1 } ^ { | \\mathcal { E } | } \\mathbb { 1 } [ y _ { k } \\neq \\widehat { y } _ { k } ] . } \\end{array}$\n\nTheorem 3.1 demonstrates that instance-based evaluation metrics cannot differentiate predictions if the number of disagreements with the ground truth is the same. Essentially, such metrics reduce all diverse information (e.g., temporal information) of predictions to a mere disagreement count. This severely limits the expressiveness of these metrics, making them inadequate for capturing insightful information about predictions within the temporal process.\n\nVisualization Example. To further illustrate this, consider the examples in Fig. 2, which have identical numbers of errors and correct predictions. It is evident that the instancebased evaluation metric fails to differentiate these examples, as they exhibit the same predictive performance (i.e., the same amount of disagreement/errors). However, the patterns of errors in these examples are markedly different. Such variances in error distribution provide crucial insights into both the TGNN models and the systems they represent. For example, as previously discussed, the presence of a volatility cluster in errors is critical information for model selection in real-time fault-tolerant systems, where functionality is ensured if errors are evenly distributed. Thus, the inability to detect such error patterns can lead to catastrophic failures in many real-world algorithm and system designs. To address this issue, in the subsequent section, we introduce a novel evaluation metric and learning objective designed to detect and mitigate this type of volatility cluster in errors.\n\n# 4 Methodology\n\nBuilding on the previous discussion regarding the limitations of existing evaluation metrics, this section introduces a novel temporal-aware evaluation metric derived from the concept of Hopkins statistics (Banerjee and Dave 2004). Specifically, we focus on detecting volatility clusters within predictions, which have significant implications for algorithms and systems, as discussed earlier. Additionally, based on this proposed evaluation metric, we introduce a novel temporal-aware learning objective for TGNNs.\n\n# Volatility-Cluster Statistics (VCS)\n\nGiven a test period $T _ { \\mathrm { t e s t } }$ , let $\\mathbf { Y }$ and $\\hat { \\mathbf Y }$ represent the ground truth and the predictions of the mod lbon the test set, respectively. Let $\\mathcal { E } _ { \\mathrm { d i s g } }$ denote the set of disagreement events with cardinality $K$ and let $\\widehat { \\mathcal { E } } _ { \\mathrm { d i s g } }$ denote $k < K$ samples from $\\mathcal { E } _ { \\mathrm { d i s g } }$ . We first compu bthe sum of distances from the sampled disagreement set to the disagreement as:\n\n$$\n\\begin{array} { r l } & { \\mathrm { D } _ { \\mathrm { d i s g } } = \\displaystyle \\sum _ { e \\in \\widehat { \\mathcal { E } } _ { \\mathrm { d i s g } } } \\mathrm { d } ( e , \\mathcal { E } _ { \\mathrm { d i s g } } ) , } \\\\ & { \\mathrm { d } ( e , \\mathcal { E } _ { \\mathrm { d i s g } } ) = \\displaystyle \\operatorname* { m i n } \\left\\{ | t _ { e } - t _ { e ^ { \\prime } } | \\bigg | e ^ { \\prime } \\in \\mathcal { E } _ { \\mathrm { d i s g } } , e ^ { \\prime } \\neq e \\right\\} . } \\end{array}\n$$\n\n$\\mathrm { d } ( e , \\mathcal { E } _ { \\mathrm { d i s g } } )$ calculates the time difference between event $e$ and the closest event in the given set. Then, $\\mathrm { D _ { d i s g } }$ is a sum of such distances for the disagreement set. Next, we generate a\n\n![](images/74eb9976dff39d62e72f6177eab66bea3c56b90f99e3feaacf04b4b140abc735.jpg)  \nFigure 2: An illustration of different error patterns. Fig. 2(a) is the pattern for random error pattern where wrong predictions are randomly distributed across the time interval. Fig. 2(b) is the pattern for volatility cluster error where wrong predictions are clustered at a small time interval (the end of the temporal horizon in the example). Fig. 2(b) is the pattern for regular error where wrong predictions are evenly spaced. The shaded area in the plots indicates the accumulated count of errors.\n\nset $\\mathcal { E } _ { \\mathrm { r } }$ of $k$ events by uniformly randomly sampling from the test period $T _ { \\mathrm { t e s t } }$ . Similarly, we compute its distance to the disagreement as:\n\n$$\n\\mathrm { D } _ { \\mathrm { r } } = \\sum _ { e \\in { \\mathcal { E } } _ { \\mathrm { r } } } \\mathrm { d } ( e , { \\mathcal { E } } _ { \\mathrm { d i s g } } ) .\n$$\n\n$\\mathrm { D } _ { \\mathrm { r } }$ serves as a reference for the distance to the disagreement if the samples are randomly drawn. Then, we can compute relative statistics between the set $\\mathcal { E } _ { \\mathrm { d i s g } }$ and $\\mathcal { E } _ { \\mathrm { r } }$ as:\n\n$$\n\\mathcal { T } ( \\mathcal { E } _ { \\mathrm { d i s g } } , \\mathcal { E } _ { \\mathrm { r } } ) = \\frac { \\mathrm { D } _ { \\mathrm { r } } } { \\mathrm { D } _ { \\mathrm { r } } + \\mathrm { D } _ { \\mathrm { d i s g } } } ,\n$$\n\nwhere $\\mathrm { D } _ { \\mathrm { r } }$ and $\\mathrm { D } _ { \\mathrm { d i s g } }$ are described above. The formulation shows that ${ \\mathcal { T } } ( { \\mathcal { E } } _ { \\mathrm { d i s g } } , { \\mathcal { E } } _ { \\mathrm { r } } )$ compares the temporal distance between predictions relative to random sampling. The ratio format confines the value within the range of 0 to 1. The ${ \\mathcal { T } } ( { \\mathcal { E } } _ { \\mathrm { d i s g } } , { \\mathcal { E } } _ { \\mathrm { r } } )$ statistic provides insights into the distribution of data points. If $\\mathcal { T } ( \\mathcal { E } _ { \\mathrm { d i s g } } , \\mathcal { E } _ { \\mathrm { t e s t } } )$ is close to 1, it indicates that the data points are clustered, with the sum of distances from randomly generated points to their nearest neighbors being significantly larger than that from the sampled data points. Conversely, if $\\bar { \\mathcal { T } } ( \\mathcal { E } _ { \\mathrm { d i s g } } , \\mathcal { E } _ { \\mathrm { t e s t } } )$ is close to 0, it could suggest that the data points are regularly-spaced, resulting in smaller distances for randomly generated points compared to those from sampled data points. When $\\mathcal { T } ( \\mathcal { E } _ { \\mathrm { d i s g } } , \\mathcal { \\bar { E } } _ { \\mathrm { t e s t } } )$ approximates 0.5, it indicates a random distribution with no significant clustering or regular pattern, as both randomly generated points and sampled data points exhibit similar nearest neighbour distances.\n\nTo enhance interoperability and robustness against variance from sampling, we repeat the sampling steps multiple times and adjust based on the random sampling. The final VCS is computed as follows:\n\n$$\n\\begin{array} { r l r } & { } & { \\mathrm { V C S } = \\vert 1 / 2 - \\mathcal { T } ( \\mathcal { E } _ { \\mathrm { d i s g } } , \\mathcal { E } _ { \\mathrm { r } } , \\tau ) \\vert , } \\\\ & { } & { = \\left. \\frac { 1 } { 2 } - \\frac { 1 } { \\tau } \\sum _ { i = 1 } ^ { \\tau } \\frac { \\mathrm { D } _ { \\mathrm { r } } ^ { ( i ) } } { \\mathrm { D } _ { \\mathrm { r } } ^ { ( i ) } + \\mathrm { D } _ { \\mathrm { d i s g } } ^ { ( i ) } } \\right. . } \\end{array}\n$$\n\nwhere $\\tau$ is the number of repeated samples. Our empirical study suggests that $\\tau = 5$ provides a stable estimate in most cases.\n\n# Volatility-Cluster-Aware (VCA) Learning\n\nIn the previous section, we introduced a new statistical measure for detecting volatility clusters in the temporal dimension. We discussed how the error pattern of the system can have significant implications in real-time systems, especially concerning fault-tolerant aspects of development. Typically, real-time systems prefer more uniform error distributions. Thus, an important question arises: can we use the proposed measure to help TGNNs learn a model (weight) from the hypothesis space that exhibits a more uniform error pattern?\n\nA straightforward idea is to incorporate $\\mathcal { T } ( \\mathcal { E } _ { \\mathrm { d i s g } } , \\mathcal { E } _ { \\mathrm { t e s t } } , \\tau )$ as a regularization term in the learning objective. However, a technical challenge arises due to the non-differentiability of the distance function $\\mathrm { d } ( e , \\mathcal { E } )$ , which is due to the min operator. To address this, we propose the following modification with a smooth and differentiable version that mimics the min function:\n\n$$\n\\mathrm { d } _ { \\mathrm { s o f t } } ( e , \\mathcal { E } ) = - \\log \\left( \\sum _ { e ^ { \\prime } \\in \\mathcal { E } , e ^ { \\prime } \\ne e } \\exp ( - \\beta | t _ { e } - t _ { e ^ { \\prime } } | ) \\right) / \\beta ,\n$$\n\nwhere $\\beta$ is a positive parameter that controls the sharpness of the approximation. As $\\beta$ increases, the approximation becomes closer to the minimum function. This approach turns the non-differentiable minimum function into a differentiable function by summing over exponentially scaled, inverted distances,\n\n$$\n\\mathcal { T } _ { \\mathrm { s o f t } } ( \\mathcal { E } _ { \\mathrm { d i s g } } , \\mathcal { E } _ { \\mathrm { r } } ) = \\frac { \\widehat { \\mathrm { D } } _ { \\mathrm { r } } } { \\widehat { \\mathrm { D } } _ { \\mathrm { r } } + \\widehat { \\mathrm { D } } _ { \\mathrm { d i s g } } } ,\n$$\n\nwhere $\\widehat { \\mathrm { D } } _ { \\mathrm { r } }$ and $\\widehat { \\mathrm { D } } _ { \\mathrm { d i s g } }$ are defined similarly as before with the distanceb funct obn replaced with $\\operatorname { d } _ { \\mathrm { { s o f t } } } ( . )$ . We can then incorporate this into the learning process and term the modified objective VCA.\n\n$$\n\\widehat { \\mathcal { L } } ( \\widehat { \\mathbf { Y } } , \\mathbf { Y } ) = \\mathcal { L } ( \\widehat { \\mathbf { Y } } , \\mathbf { Y } ) + \\gamma \\left. \\frac { 1 } { 2 } - \\mathcal { T } _ { \\mathrm { s o f t } } ( \\mathcal { E } _ { \\mathrm { d i s g } } , \\mathcal { E } _ { \\mathrm { r } } ) \\right. ^ { 2 } ,\n$$\n\nwhere $\\mathcal { L } ( \\widehat { \\mathbf { Y } } , \\mathbf { Y } )$ is the standard loss function for training TGNNs (eb.g., cross-entropy), and $\\gamma$ is a hyper-parameter controlling the regularization effect. If the error pattern deviates from a uniform distribution, then VCA will incur a larger value, and consequently, the training objective will reflect a larger loss. Achieving a lower value with this new training objective is expected to improve the uniformity of the error distribution within the model.\n\n# 5 Empirical Study\n\nIn this section, we present an empirical study to further illustrate the problem addressed in this paper. The study aims to answer the following key questions:\n\n1. Do existing TGNNs exhibit volatility clusters in errors?   \n2. Do existing TGNNs exhibit different error distributions?   \n3. Is VCS effective in detecting volatility clusters in errors?   \n4. Can VCA mitigate volatility clusters in errors?\n\n# Experimental Settings\n\nDatasets and Baselines. We use five public dynamic graph benchmark datasets: Reddit, Wikipedia, MOOC, LastFM, and GDELT (Poursafaei et al. 2022). We evaluate six state-of-the-art TGNN models, with two models from each of the three categories of TGNNs mentioned: TGN (Rossi et al. 2021) & Tiger (Zhang et al. 2023) (memory-based TGNNs), TCL (Wang et al. 2021b) & TGAT (Xu et al. 2020a) (attention-based TGNNs), and JOIDE (Kumar, Zhang, and Leskovec 2019) & DyRep (Trivedi et al. 2019) (RNN-based TGNNs). We adopt the implementation of these baselines from (Zhou et al. 2022; Poursafaei et al. 2022; Huang et al. 2024).\n\nEvaluation Task and Metrics. Following the approaches outlined in (Poursafaei et al. 2022; Huang et al. 2024; Yu et al. 2023), we evaluate models for temporal link prediction, which involves predicting the probability of a link forming between two nodes at a specific time. We use a multi-layer perceptron (MLP) that takes the concatenated representations of two nodes as input and outputs the probability of a link. For evaluation metrics, we focus on AP and the proposed VCS. We train each model with and without VCA to observe the effect of our proposed learning objective. For all experiments, we follow the standard procedure and split datasets chronologically with a ratio of $7 0 \\% / 1 5 \\% / 1 5 \\%$ for training, validation, and testing, respectively. Each experiment is conducted with five independent trials, and the average results are reported\n\n# Experimental Results\n\nTemporal Error Pattern. Our first experiment aims to demonstrate the temporal error patterns of various models and how our proposed metrics can effectively differentiate and reveal insightful information regarding these patterns. Fig. 4 illustrates that different types of TGNNs exhibit distinct error pattern behaviours. Specifically, memorybased TGNNs tend to produce volatility clusters in errors toward the end of the test period, RNN-based TGNNs are more prone to errors at the beginning of the test period and attention-based TGNNs exhibit a more uniform distribution in errors. This temporal structure in the prediction errors of memory-based and RNN-based TGNNs is reflected by a larger VCS value in Table 1 . This confirms that existing TGNNs indeed generate volatility clusters in errors, and different TGNN mechanisms induce varying volatility patterns. Furthermore, this demonstrates that VCS is an effective measure for detecting volatility clusters in errors.\n\nEffectiveness of VCA. Our next experiment aims to demonstrate the effectiveness of our proposed learning objective, VCA, as defined in Eq. 4.4, in regulating the behavior of TGNNs. As shown in Table 1, TGNN models trained with our proposed objective significantly reduce volatility clusters in errors, as evidenced by decreased VCS values. The improvement in attention-based TGNNs (e.g., TCL & TGAT) is relatively small because these models already exhibit a fairly uniform error distribution. This confirms that VCA is indeed effective in mitigating volatility clusters in errors. Such a property can be particularly beneficial for critical real-time systems where fault tolerance is important, and a more uniformly distributed error is preferred.\n\nAblation Study. The final part of the empirical study focuses on the hyper-parameters of VCS and VCA. The key hyper-parameter in VCS is $\\tau$ , which represents the number of independent trials conducted to compute the reference distance for random errors. As shown in Fig. 4(a), we found that increasing $\\tau$ leads to a smaller variance in value but incurs a higher computational cost. However, we find that $\\tau = 5$ already provides a sufficiently robust estimation. The main hyper-parameter in VCA is $\\gamma$ in Eq.4.4, which controls the regularization effect of the proposed learning objective. Our experiment shows that increasing $\\gamma$ results in a more uniform error pattern but worsens predictive performance (smaller AP). Thus, there is a trade-off between achieving this uniform error distribution and maintaining predictive performance. This trade-off does not undermine the effectiveness of our proposed learning objective, as the primary goal is to make the error distribution more uniform. Whether this trade-off is favourable depends on the application scenario. However, as indicated in Table 1, $\\gamma = 0 . 1$ provides a significant improvement in VCS without significantly affecting the modelâ€™s accuracy.\n\n# 6 Discussion\n\nConclusion. We investigate the evaluation metrics for TGNNs. Specifically, we have identified the pitfalls and limitations of currently used instance-based measures, such as AP and AU-ROC, in capturing temporal structures in prediction errors, such as volatility clusters. To address this issue, we propose VCS, a metric that effectively captures volatility clusters in errors for TGNNs. Furthermore, we extend this proposed evaluation metric as a regularizer, introducing VCA to mitigate volatility clusters in errors.\n\nLimitation and Future Works. In this paper, we focus on volatility clusters in errors. Other important temporal structures, such as the time arrival of errors, are not captured by the current metric. This presents an interesting avenue for future exploration. Additionally, our study primarily concentrates on the temporal aspect of error distribution. A natural\n\n![](images/ce8eadd6c944e602b3d97ec12ff1f9184bc17c08c428d8655440ece699e70ffe.jpg)  \nFigure 3: An illustration of the error patterns across different types of TGNNs. The $\\mathbf { \\boldsymbol { x } }$ -axis represents the time during the test period, and the color density indicates the error density (number of errors per time unit). A higher density (redder) indicates more errors. As shown in the figures, memory-based TGNNs exhibit a higher error density toward the end of the testing period, while RNN-based TGNNs display a higher error density at the beginning of the testing period. Attention-based TGNNs, on the other hand, demonstrate a more uniform error distribution.\n\n<html><body><table><tr><td>Dataset</td><td colspan=\"2\">Reddit</td><td colspan=\"2\">Wikipedia</td><td colspan=\"2\">MOOC</td><td colspan=\"2\">LastFM</td><td colspan=\"2\">GDELT</td></tr><tr><td>Model/Metric</td><td>VCSâ†“</td><td>AP(%)â†‘</td><td>vCSâ†“</td><td>AP(%) â†‘</td><td>vCSâ†“</td><td>AP(%)â†‘</td><td>vCSâ†“</td><td>AP(%) â†‘</td><td>VCSâ†“</td><td>AP(%) â†‘</td></tr><tr><td>TGN</td><td>0.18Â±0.02</td><td>98.5Â±0.04</td><td>0.21Â±0.04</td><td>96.4Â±0.03</td><td>0.25Â±0.03</td><td>97.6Â±0.03</td><td>0.22Â±0.04</td><td>75.4Â±0.06</td><td>0.24Â±0.03</td><td>95.6Â±0.05</td></tr><tr><td>TGN-VCA</td><td>0.08Â±0.01</td><td>98.2Â±0.03</td><td>0.12Â±0.02</td><td>96.3Â±0.04</td><td>0.13Â±0.03</td><td>97.3Â±0.02</td><td>0.09Â±0.03</td><td>73.3Â±0.05</td><td>0.12Â±0.02</td><td>96.8Â±0.03</td></tr><tr><td>Tiger</td><td>0.23Â±0.01</td><td>97.5Â±0.08</td><td>0.23Â±0.03</td><td>94.8Â±0.06</td><td>0.30Â±0.02</td><td>95.1Â±0.04</td><td>0.23Â±0.03</td><td>77.7Â±0.05</td><td>0.23Â±0.03</td><td>97.5Â±0.03</td></tr><tr><td>Tiger-VCA</td><td>0.10Â±0.01</td><td>98.0Â±0.06</td><td>0.11Â±0.02</td><td>94.0Â±0.06</td><td>0.11Â±0.01</td><td>95.6Â±0.03</td><td>0.12Â±0.02</td><td>78.0Â±0.04</td><td>0.11Â± 0.01</td><td>97.0Â±0.05</td></tr><tr><td>JOIDE</td><td>0.19Â±0.03</td><td>96.5Â±0.05</td><td>0.25Â±0.04</td><td>95.3Â±0.04</td><td>0.21Â±0.03</td><td>97.5Â±0.08</td><td>0.20Â±0.03</td><td>72.5Â±0.06</td><td>0.27Â±0.04</td><td>96.8Â±0.05</td></tr><tr><td>JOIDE-VCA</td><td>0.09Â±0.02</td><td>96.8Â±0.03</td><td>0.11Â±0.03</td><td>94.8Â±0.05</td><td>0.11Â±0.02</td><td>97.8Â±0.06</td><td>0.10Â±0.02</td><td>72.8Â±0.07</td><td>0.13Â±0.03</td><td>97.0Â±0.04</td></tr><tr><td>DyRep</td><td>0.25Â±0.03</td><td>96.7Â±0.06</td><td>0.22Â±0.04</td><td>94.8Â±0.03</td><td>0.23Â±0.03</td><td>96.8Â±0.06</td><td>0.27Â±0.03</td><td>69.5Â±0.05</td><td>0.24Â± 0.04</td><td>97.8Â±0.03</td></tr><tr><td>DyRep-VCA</td><td>0.11Â±0.02</td><td>97.0Â±0.05</td><td>0.10Â±0.03</td><td>95.0Â±0.04</td><td>0.12Â±0.02</td><td>97.0Â±0.05</td><td>0.12Â±0.01</td><td>70.0Â±0.06</td><td>0.14Â±0.03</td><td>97.5Â±0.04</td></tr><tr><td>TCL</td><td>0.12Â±0.02</td><td>95.5Â±0.02</td><td>0.11Â±0.02</td><td>91.6Â±0.06</td><td>0.14Â±0.03</td><td>93.5Â±0.07</td><td>0.14Â±0.03</td><td>68.5Â±0.07</td><td>0.14Â±0.03</td><td>94.6Â±0.06</td></tr><tr><td>TCL-VCA</td><td>0.09Â±0.02</td><td>95.2Â±0.02</td><td>0.06Â±0.01</td><td>92.2Â±0.06</td><td>0.10Â±0.02</td><td>92.8Â±0.05</td><td>0.09Â±0.01</td><td>67.5Â±0.03</td><td>0.10Â±0.0</td><td>95.2Â±0.06</td></tr><tr><td>TGAT</td><td>0.13Â±0.02</td><td>95.8Â±0.03</td><td>0.10Â±0.01</td><td>92.3Â±0.03</td><td>0.14Â±0.03</td><td>94.3Â±0.03</td><td>0.13Â±0.03</td><td>70.1Â±0.05</td><td>0.12Â±0.03</td><td>93.3Â±0.03</td></tr><tr><td>TGAT-VCA</td><td>0.10Â±0.02</td><td>96.0Â±0.02</td><td>0.08Â±0.01</td><td>93.0Â±0.04</td><td>0.07Â±0.02</td><td>95.0Â±0.05</td><td>0.06Â±0.01</td><td>71.3Â±0.06</td><td>0.09Â±0.02</td><td>93.0Â±0.04</td></tr><tr><td>â–³VCS</td><td>0.09</td><td></td><td>0.09</td><td></td><td>0.1</td><td></td><td>0.1</td><td></td><td>0.09</td><td></td></tr></table></body></html>\n\nTable 1: The VCS of TGNNs with and without the VCA learning objective. The experiment follows the standard setting. Models labelled with .-VCA are trained using our proposed learning objective as defined in Eq. 4.4, with $\\tau = 5$ and $\\gamma = 0 . 1 . \\downarrow$ indicates that smaller values are better, while $\\uparrow$ indicates that larger values are better. The bolded entry indicate improvement with VCA. The last row $\\Delta$ shows the average improvement with VCA for each dataset. The results in this table collectively demonstrate that VCS can successfully detect volatility clusters in errors, and VCA is effective in mitigating them.\n\n![](images/5096225f68e81cc959216b851c2fa55bd0af0d4c89677ef8200155bc880ad9c4.jpg)  \nFigure 4: An illustration of the effects of the hyper-parameters $\\tau$ and $\\gamma$ on VCS and VCA. Fig. 4(b) and .4(c) demonstrate that as $\\gamma$ increases, VCS performance improves while AP decreases. Hence, $\\gamma$ serves as a control variable that manages the trade-off between VCS and AP. Fig. 4(a) shows that increasing $\\tau$ reduces the variance in the measure, but the marginal gain diminishes after $\\tau = 5$ .\n\napplication of TGNNs is in spatio-temporal networks, where vertices represent physical locations, incorporating a spatial dimension. It would be intriguing to explore whether similar concepts can be extended to examine the spatial aspects of TGNNs in spatio-temporal graph networks. This represents another promising area for future research.",
    "summary": "```json\n{\n  \"core_summary\": \"### ğŸ¯ æ ¸å¿ƒæ¦‚è¦\\n\\n> **é—®é¢˜å®šä¹‰ (Problem Definition)**\\n> *   è®ºæ–‡æ¢è®¨äº†æ—¶æ€å›¾ç¥ç»ç½‘ç»œï¼ˆTGNNsï¼‰è¯„ä¼°æŒ‡æ ‡çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯ç°æœ‰å®ä¾‹åŒ–è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚APå’ŒAU-ROCï¼‰æ— æ³•æ•æ‰é¢„æµ‹è¡Œä¸ºä¸­çš„æ—¶æ€ç»“æ„ï¼ˆå¦‚æ³¢åŠ¨èšé›†ï¼‰ã€‚è¿™ä¸€é—®é¢˜åœ¨å®æ—¶ç³»ç»Ÿï¼ˆå¦‚é‡‘èäº¤æ˜“ç®—æ³•æˆ–å®¹é”™ç³»ç»Ÿï¼‰ä¸­å°¤ä¸ºé‡è¦ï¼Œå› ä¸ºå‡†ç¡®æµ‹é‡å’Œé¢„æµ‹æ³¢åŠ¨èšé›†å¯¹ç­–ç•¥éƒ¨ç½²å’Œé£é™©è¯„ä¼°è‡³å…³é‡è¦ã€‚\\n\\n> **æ–¹æ³•æ¦‚è¿° (Method Overview)**\\n> *   è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ³¢åŠ¨èšé›†æ„ŸçŸ¥è¯„ä¼°æŒ‡æ ‡ï¼ˆVCSï¼‰å’Œä¸€ç§æ³¢åŠ¨èšé›†æ„ŸçŸ¥å­¦ä¹ ç›®æ ‡ï¼ˆVCAï¼‰ï¼Œç”¨äºæ£€æµ‹å’Œå‡è½»TGNNsé¢„æµ‹è¯¯å·®ä¸­çš„æ³¢åŠ¨èšé›†ã€‚\\n\\n> **ä¸»è¦è´¡çŒ®ä¸æ•ˆæœ (Contributions & Results)**\\n> *   **è´¡çŒ®1ï¼š** æå‡ºäº†VCSæŒ‡æ ‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ£€æµ‹TGNNsé¢„æµ‹è¯¯å·®ä¸­çš„æ³¢åŠ¨èšé›†ã€‚å®éªŒè¡¨æ˜ï¼ŒVCSèƒ½å¤ŸåŒºåˆ†ä¸åŒç±»å‹çš„TGNNsï¼ˆå¦‚RNN-basedå’Œmemory-basedæ¨¡å‹ï¼‰çš„è¯¯å·®æ¨¡å¼ã€‚\\n> *   **è´¡çŒ®2ï¼š** å°†VCSæ‰©å±•ä¸ºä¸€ç§å¯å¾®åˆ†çš„æ­£åˆ™åŒ–æŠ€æœ¯ï¼ˆVCAï¼‰ï¼Œç”¨äºè®­ç»ƒTGNNsä»¥å‡å°‘è¯¯å·®ä¸­çš„æ³¢åŠ¨èšé›†ã€‚å®éªŒè¯æ˜ï¼ŒVCAæ˜¾è‘—é™ä½äº†è¯¯å·®ä¸­çš„æ³¢åŠ¨èšé›†ï¼ˆVCSå€¼å¹³å‡é™ä½0.09-0.1ï¼‰ã€‚\\n> *   **è´¡çŒ®3ï¼š** é€šè¿‡å®è¯ç ”ç©¶å‘ç°ï¼Œç°æœ‰TGNNsï¼ˆå°¤å…¶æ˜¯RNN-basedå’Œmemory-basedæ¨¡å‹ï¼‰å€¾å‘äºäº§ç”Ÿæ³¢åŠ¨èšé›†è¯¯å·®ï¼Œè€ŒVCAèƒ½å¤Ÿæœ‰æ•ˆæ”¹å–„è¿™ä¸€ç°è±¡ã€‚\",\n  \"algorithm_details\": \"### âš™ï¸ ç®—æ³•/æ–¹æ¡ˆè¯¦è§£\\n\\n> **æ ¸å¿ƒæ€æƒ³ (Core Idea)**\\n> *   VCSçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡æ¯”è¾ƒé¢„æµ‹è¯¯å·®çš„æ—¶é—´åˆ†å¸ƒä¸éšæœºåˆ†å¸ƒçš„å·®å¼‚ï¼Œæ¥é‡åŒ–æ³¢åŠ¨èšé›†çš„ç¨‹åº¦ã€‚å…¶çµæ„Ÿæ¥æºäºHopkinsç»Ÿè®¡é‡ï¼Œé€šè¿‡è®¡ç®—è¯¯å·®äº‹ä»¶ä¹‹é—´çš„æ—¶é—´è·ç¦»æ¥è¯„ä¼°å…¶èšé›†æ€§ã€‚\\n\\n> **åˆ›æ–°ç‚¹ (Innovations)**\\n> *   **ä¸å…ˆå‰å·¥ä½œçš„å¯¹æ¯”ï¼š** ç°æœ‰è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚APå’ŒAU-ROCï¼‰æ˜¯å®ä¾‹åŒ–çš„ï¼Œæ— æ³•æ•æ‰è¯¯å·®çš„æ—¶æ€ç»“æ„ï¼ˆå¦‚æ³¢åŠ¨èšé›†ï¼‰ã€‚\\n> *   **æœ¬æ–‡çš„æ”¹è¿›ï¼š** VCSé€šè¿‡å¼•å…¥æ—¶é—´è·ç¦»çš„è®¡ç®—ï¼Œèƒ½å¤Ÿé‡åŒ–è¯¯å·®çš„æ—¶æ€åˆ†å¸ƒç‰¹æ€§ã€‚VCAè¿›ä¸€æ­¥å°†VCSæ‰©å±•ä¸ºå¯å¾®åˆ†çš„æ­£åˆ™åŒ–é¡¹ï¼Œç›´æ¥ä¼˜åŒ–æ¨¡å‹çš„è¯¯å·®åˆ†å¸ƒã€‚\\n\\n> **å…·ä½“å®ç°æ­¥éª¤ (Implementation Steps)**\\n> 1.  **VCSè®¡ç®—ï¼š** \\n>     *   ä»æµ‹è¯•é›†ä¸­æå–è¯¯å·®äº‹ä»¶é›†åˆã€‚\\n>     *   è®¡ç®—è¯¯å·®äº‹ä»¶ä¹‹é—´çš„æœ€å°æ—¶é—´è·ç¦»ï¼ˆ`d(e, E_disg)`ï¼‰ã€‚\\n>     *   ç”Ÿæˆéšæœºäº‹ä»¶é›†åˆä½œä¸ºå‚è€ƒï¼Œå¹¶è®¡ç®—å…¶ä¸è¯¯å·®äº‹ä»¶çš„è·ç¦»ï¼ˆ`D_r`ï¼‰ã€‚\\n>     *   é€šè¿‡æ¯”å€¼ç»Ÿè®¡é‡ï¼ˆ`T(E_disg, E_r)`ï¼‰é‡åŒ–æ³¢åŠ¨èšé›†ç¨‹åº¦ã€‚\\n> 2.  **VCAå®ç°ï¼š** \\n>     *   å°†VCSä¸­çš„æœ€å°å‡½æ•°æ›¿æ¢ä¸ºå¯å¾®åˆ†çš„soft-minå‡½æ•°ï¼ˆ`d_soft(e, E)`ï¼‰ã€‚\\n>     *   å°†VCSä½œä¸ºæ­£åˆ™åŒ–é¡¹åŠ å…¥æŸå¤±å‡½æ•°ï¼ˆ`LÌ‚(YÌ‚, Y) = L(YÌ‚, Y) + Î³|0.5 - T_soft(E_disg, E_r)|^2`ï¼‰ã€‚\\n\\n> **æ¡ˆä¾‹è§£æ (Case Study)**\\n> *   è®ºæ–‡æœªæ˜ç¡®æä¾›æ­¤éƒ¨åˆ†ä¿¡æ¯ã€‚\",\n  \"comparative_analysis\": \"### ğŸ“Š å¯¹æ¯”å®éªŒåˆ†æ\\n\\n> **åŸºçº¿æ¨¡å‹ (Baselines)**\\n> *   è®ºæ–‡è¯„ä¼°äº†å…­ç§TGNNæ¨¡å‹ï¼ŒåŒ…æ‹¬TGNã€Tigerï¼ˆmemory-basedï¼‰ã€JOIDEã€DyRepï¼ˆRNN-basedï¼‰ã€TCLå’ŒTGATï¼ˆattention-basedï¼‰ã€‚\\n\\n> **æ€§èƒ½å¯¹æ¯” (Performance Comparison)**\\n> *   **åœ¨VCSæŒ‡æ ‡ä¸Šï¼š** æœ¬æ–‡æå‡ºçš„VCAæ–¹æ³•åœ¨Redditæ•°æ®é›†ä¸Šå°†TGNçš„VCSå€¼ä»0.18é™ä½åˆ°0.08ï¼Œåœ¨Wikipediaæ•°æ®é›†ä¸Šä»0.21é™ä½åˆ°0.12ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒVCAå¹³å‡é™ä½äº†VCSå€¼0.09-0.1ã€‚\\n> *   **åœ¨APæŒ‡æ ‡ä¸Šï¼š** VCAå¯¹APçš„å½±å“è¾ƒå°ï¼Œä¾‹å¦‚TGNåœ¨Redditæ•°æ®é›†ä¸Šçš„APä»98.5%ç•¥å¾®ä¸‹é™åˆ°98.2%ï¼Œè¡¨æ˜VCAåœ¨å‡å°‘æ³¢åŠ¨èšé›†çš„åŒæ—¶ä¿æŒäº†æ¨¡å‹çš„é¢„æµ‹æ€§èƒ½ã€‚\\n> *   **åœ¨è¯¯å·®æ¨¡å¼ä¸Šï¼š** å®éªŒæ˜¾ç¤ºï¼Œmemory-based TGNNsçš„è¯¯å·®å€¾å‘äºèšé›†åœ¨æµ‹è¯•å‘¨æœŸæœ«å°¾ï¼ŒRNN-based TGNNsçš„è¯¯å·®èšé›†åœ¨æµ‹è¯•å‘¨æœŸå¼€å§‹ï¼Œè€Œattention-based TGNNsçš„è¯¯å·®åˆ†å¸ƒæ›´å‡åŒ€ã€‚\",\n  \"keywords\": \"### ğŸ”‘ å…³é”®è¯\\n\\n*   æ—¶æ€å›¾ç¥ç»ç½‘ç»œ (Temporal Graph Neural Networks, TGNNs)\\n*   æ³¢åŠ¨èšé›† (Volatility Clustering, N/A)\\n*   è¯„ä¼°æŒ‡æ ‡ (Evaluation Metrics, N/A)\\n*   æ­£åˆ™åŒ–æŠ€æœ¯ (Regularization Technique, N/A)\\n*   å®¹é”™ç³»ç»Ÿ (Fault-Tolerant Systems, N/A)\\n*   æ—¶é—´è·ç¦» (Temporal Distance, N/A)\\n*   å¯å¾®åˆ†ä¼˜åŒ– (Differentiable Optimization, N/A)\"\n}\n```"
}