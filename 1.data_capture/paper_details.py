import streamlit as st
import json
import re
from pathlib import Path
import sys

# å°†ä¸»ç›®å½•æ·»åŠ åˆ°sys.pathä»¥å¯¼å…¥app.pyä¸­çš„å‡½æ•°
# è¿™æ˜¯ä¸€ä¸ªåœ¨å¤šé¡µé¢åº”ç”¨ä¸­å…±äº«å‡½æ•°çš„å¸¸ç”¨æŠ€å·§
sys.path.append(str(Path(__file__).resolve().parents[1]))
try:
    from app import translate_text_api, rag_answer_question
except ImportError:
    st.error("æ— æ³•ä»ä¸»åº”ç”¨å¯¼å…¥APIå‡½æ•°ã€‚")
    st.stop()


st.set_page_config(page_title="è®ºæ–‡è¯¦æƒ…", layout="wide")

# --- 0. æ£€æŸ¥å’ŒåŠ è½½æ•°æ® ---
if 'selected_paper_path' not in st.session_state:
    st.error("è¯·å…ˆåœ¨ä¸»é¡µé€‰æ‹©ä¸€ç¯‡è®ºæ–‡ã€‚")
    st.page_link("app.py", label="è¿”å›ä¸»é¡µ", icon="ğŸ ")
    st.stop()

try:
    paper_path = Path(st.session_state['selected_paper_path'])
    with open(paper_path, 'r', encoding='utf-8') as f:
        paper_data = json.load(f)
except Exception as e:
    st.error(f"åŠ è½½è®ºæ–‡æ•°æ®å¤±è´¥: {e}")
    st.page_link("app.py", label="è¿”å›ä¸»é¡µ", icon="ğŸ ")
    st.stop()

# --- 1. é¡µé¢æ ‡é¢˜å’Œå…ƒæ•°æ® ---
st.page_link("app.py", label="è¿”å›ä¸»é¡µ", icon="ğŸ ")
st.title(paper_data.get('title', 'æœªçŸ¥æ ‡é¢˜'))

col1, col2, col3 = st.columns(3)
with col1:
    st.markdown(f"**âœï¸ ä½œè€…:** {', '.join(paper_data.get('authors', []))}")
with col2:
    st.markdown(f"**ğŸ—“ï¸ å‘è¡¨æ—¥æœŸ:** {paper_data.get('publication_date', 'N/A')}")
with col3:
    st.link_button("ğŸ”— ArXiv é¡µé¢", paper_data.get('link', '#'))
    st.link_button("ğŸ“„ PDF ä¸‹è½½", paper_data.get('pdf_link', '#'))

st.divider()


# --- 2. RAG é—®ç­”åŒºåŸŸ ---
st.header("â“ å¯¹è®ºæ–‡æé—® (RAG)")
with st.container(border=True):
    user_question = st.text_input("è¾“å…¥ä½ å…³äºè¿™ç¯‡è®ºæ–‡çš„é—®é¢˜:", placeholder="ä¾‹å¦‚ï¼šè¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†ä»€ä¹ˆæ¨¡å‹ï¼Ÿ")
    if st.button("æäº¤é—®é¢˜"):
        if user_question:
            with st.spinner("æ­£åœ¨æ€è€ƒç­”æ¡ˆ..."):
                answer = rag_answer_question(user_question, paper_data.get('paper_content', ''))
                st.info(answer)
        else:
            st.warning("è¯·è¾“å…¥ä¸€ä¸ªé—®é¢˜ã€‚")

st.divider()

# --- 3. è®ºæ–‡åŸæ–‡ä¸é€æ®µç¿»è¯‘ ---
st.header("ğŸ“– è®ºæ–‡åŸæ–‡ & é€æ®µç¿»è¯‘")

paper_content = paper_data.get('paper_content', 'æ— åŸæ–‡å†…å®¹ã€‚')

# ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŒ‰ Markdown æ ‡é¢˜åˆ†å‰²æ–‡ç« 
# re.split ä¼šä¿ç•™åˆ†éš”ç¬¦ï¼ˆæ ‡é¢˜ï¼‰ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å°†å®ƒä»¬é…å¯¹èµ·æ¥
sections = re.split(r'(\n#+ .*\n)', paper_content)

# ç¬¬ä¸€ä¸ªå…ƒç´ é€šå¸¸æ˜¯æ ‡é¢˜å‰çš„ç©ºå­—ç¬¦ä¸²æˆ–å¼•è¨€ï¼Œå•ç‹¬å¤„ç†
if sections[0].strip():
    st.markdown(sections[0])
    # ä¸ºæ²¡æœ‰æ ‡é¢˜çš„å¼•è¨€éƒ¨åˆ†ä¹Ÿæ·»åŠ ç¿»è¯‘æŒ‰é’®
    if st.button("ç¿»è¯‘å¼•è¨€éƒ¨åˆ†", key="translate_intro"):
         with st.spinner("æ­£åœ¨ç¿»è¯‘..."):
            translation = translate_text_api(sections[0])
            st.success("ç¿»è¯‘ç»“æœ:")
            st.markdown(translation)

# å¾ªç¯å¤„ç†æˆå¯¹çš„ "æ ‡é¢˜" å’Œ "å†…å®¹"
# ä»ç´¢å¼•1å¼€å§‹ï¼Œæ­¥é•¿ä¸º2
for i in range(1, len(sections), 2):
    header = sections[i].strip()
    content = sections[i+1].strip()
    
    with st.container(border=True):
        st.subheader(header)
        st.markdown(content)
        
        # ä½¿ç”¨å”¯ä¸€çš„keyæ¥é¿å…Streamlitçš„ "DuplicateWidgetID" é”™è¯¯
        button_key = f"translate_{paper_path.stem}_{i}"
        
        if st.button("ç¿»è¯‘æ­¤æ®µ", key=button_key):
            with st.spinner("æ­£åœ¨ç¿»è¯‘..."):
                translation = translate_text_api(content)
                st.success("ç¿»è¯‘ç»“æœ:")
                st.markdown(translation)