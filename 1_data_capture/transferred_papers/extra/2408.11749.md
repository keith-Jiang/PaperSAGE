# Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks

Yiyi Chen, Russa Biswas, Heather Lent, Johannes Bjerva

Department of Computer Science, Aalborg University, Copenhagen, Denmark yiyic, rubi, hcle, jbjerva@cs.aau.dk

# Abstract

Large Language Models (LLMs) are susceptible to malicious influence by cyber attackers through intrusions such as adversarial, backdoor, and embedding inversion attacks. In response, the burgeoning field of LLM Security aims to study and defend against such threats. Thus far, the majority of works in this area have focused on monolingual English models; however, emerging research suggests that multilingual LLMs may be more vulnerable to various attacks than their monolingual counterparts. While previous work has investigated embedding inversion over a small subset of European languages, it is challenging to extrapolate these findings to languages from different linguistic families and with differing scripts. To this end, we explore the security of multilingual LLMs in the context of embedding inversion attacks and investigate cross-lingual and cross-script inversion across 20 languages, spanning over 8 language families and 12 scripts. Our findings indicate that languages written in Arabic and Cyrillic scripts are particularly vulnerable to embedding inversion, as are languages within the Indo-Aryan language family. We further observe that inversion models tend to suffer from language confusion, sometimes significantly reducing the efficacy of an attack. Accordingly, we systematically explore this bottleneck for inversion models, uncovering predictable patterns attackers could leverage. Ultimately, this study aims to further the field’s understanding of the outstanding security vulnerabilities facing multilingual LLMs and raise awareness for the languages most at risk of negative impact from these attacks.

# Code — https://github.com/siebeniris/vec2text exp Models — https://huggingface.co/yiyic Extended version — https://arxiv.org/abs/2408.11749

# Introduction

Vector databases store texts encoded into embeddings, and represent a 1.5 billion USD market globally as of 2023, which is expected to grow to an impressive 4 billion within the next 5 years (Markets and Markets 2023). In more concrete contexts, services like Pinecone and Qdrant,1 store embeddings for retrieval in applications like retrievalaugmented generation (RAG) (Lewis et al. 2020). In RAG,

Target:J=-（Ly-syc"=-apcicecy-ce.   
Input: [0.3303 0.45454 0.3436... 0.2323 0.3433 0.3090 0.3192]   
Base   
Output: Eine sehr berühmte Möglichkeit dass Battlefield   
Activity entstanden ist. Battlefield Activity a few   
Corrector (Step1)   
Output: Es ist eine sehr brühmte Möglichkeit, dass Spiele   
entstanden. Eine sehr brühmte MMORPG.   
(Step50 + sbeam 8)   
Output: Es ist sehr beeindruckend, dass einige Spiele   
entstanden. Eine sehr beeindruckende Activity.

user queries are embedded via LLMs and sent to a vector database for semantic search, while large-scale embeddings of text data are also stored for semantic search. The security of this technology is increasingly critical for providers and customers depending on vector databases for their businesses. Presently, vector databases are known to have one outstanding security vulnerability: text embeddings can be reverted into original text, even without prior knowledge of the embedding model, thus constituting a major threat to privacy (Song and Raghunathan 2020; H¨ohmann, Rettinger, and Kugler 2021; Hayet, Yao, and Luo 2022; Morris et al. 2023; Li, Xu, and Song 2023; Chen, Lent, and Bjerva 2024). In other words, text embeddings are no more secure than plain text (Morris et al. 2023). A malicious actor needs only to intercept the vectors to carry out an embedding inversion attack, whereby potentially sensitive information is leaked.

As with most NLP problems, large English datasets have served as the primary focus of research on embedding inversion attacks. Emerging work, however, highlights how the field’s over-reliance on English comes at a grave cost to the general security of Large Language Models (LLMs). For example, Yong, Menghini, and Bach (2024) demonstrate how ChatGPT’s built-in safety features can be easily by-passed by prompting in lower-resourced languages, while OpenAI’s defences function as expected for English and other highlyresourced languages. Meanwhile, Wang et al. (2024a) show how low-resource languages can be weaponized to poison models in backdoor attacks against machine translation systems. In the context of embedding inversion attacks, security may also be compromised by failing to consider a diversity of languages, especially as vector database providers may leverage multilingual LLMs to serve clients around the globe. Chen, Lent, and Bjerva (2024) find that multilingual LLMs are more vulnerable to embedding inversion attacks than their monolingual counterparts. However, their study includes only four highly-resourced European languages, restricted to Latin script. Conclusions drawn over a small set of relatively homogeneous languages cannot be trivially extended to massively multilingual LLMs, thus stressing the need for investigations of embedding inversion attacks with languages of diverse linguistic families and varying scripts.

In this work, we explore the nuances of embedding inversion attacks against multilingual models across 20 languages from 8 language families written in 12 scripts. We find that the success of inversion attacks is largely influenced by combinations of language family and script, ultimately showing that some languages are more vulnerable to attacks than others. Beyond elucidating threats facing multilingual encoders for vector databases, we analyze a common hindrance to the performance of embedding inversion: language confusion, a term recently coined by Marchisio et al. (2024), defined as a limitation of LLMs where the models are often unable to consistently generate text in the user’s desired language, or the appropriate language given the context. Fig. 1 illustrates different vulnerability levels in inversion attacks and language confusion. Specifically, Arabic textual embeddings (input) are inverted by a model trained on German embeddings, with the final output producing a mostly coherent German sentence containing an English term. Language confusion is understood as an “erroneous behavior” across the whole of NLP, reported in LLM instruction tuning and is detrimental to generation performance in terms of intelligibility in general (Marchisio et al. 2024). We show that language confusion can be predicted and controlled for, unfortunately to the benefit of would-be attackers.

# Our contributions:

1. We explore the vulnerability of monolingual versus multilingual LLMs, including a wide variety of languages, and LLMs of differing architectures and training objectives, such that results can be better generalizable for modern massively multilingual LLMs.   
2. We investigate embedding inversion attacks across 8 language families, comparing within and across-family and find that the Indo-Aryan family was the most vulnerable. Notably, inverting Punjabi texts produces meaningful sentences only in the in-family training setting compared to training it independently.   
3. We examine attacks across 12 scripts, finding that scripts differ in vulnerability to inversion attacks. Our findings

indicate that Arabic and Cyrillic scripts were the most susceptible to attack. In-script training boosts Urdu inversion attack performance, doubling the BLEU score.

4. We identify language confusion as a bottleneck to crosslingual inversion attacks. A systematic investigation uncovers that language confusion can be predicted using various language characteristics, such as script and script-directionality. Moreover, the prediction of language confusion can directly aid attack performance.

# Related Work

Textual Embedding Inversion Inversion attacks on text embeddings have increased rapidly, with attack accuracy approaching $100 \%$ (Ho¨hmann, Rettinger, and Kugler 2021; Hayet, Yao, and Luo 2022; Li, $\mathtt { X u }$ , and Song 2023; Morris et al. 2023) whereas previously only $50 \mathrm { - } 7 0 \%$ of tokens were achievable (Song and Raghunathan 2020). However, progress has mainly focused on English, leaving the security of multilingual embedding models largely unexplored. The first study to explore embedding inversion attacks in a multilingual context is limited to European languages and Latin script, highlighting a significant gap in LLM security (Chen, Lent, and Bjerva 2024). Tokenization methods in multilingual LLMs disproportionately allocate subwords to Latin script (Wu and Dredze 2020), suggesting that embedding inversion attack success may differ across languages depending on script and language. Finally, another notable limitation of the study by Chen, Lent, and Bjerva (2024) is the reliance on parallel data. As LLMs are known to memorize information (Shokri, Stronati, and Shmatikov 2016; Carlini et al. 2018; Nasr, Shokri, and Houmansadr 2019), studies on exclusively parallel text preclude the opportunity to study information leakage across languages (Ki, Park, and $\ K i m \ 2 0 2 4 ,$ ). As a consequence, the field’s threat assessment of multilingual LLM’s may not capture the full severity.

Cross-Lingual and Cross-Script Transfer The majority of the world’s languages lack sufficient data for NLP applications (Joshi et al. 2020). Cross-lingual transfer offers a solution to this issue, as models trained on resource-rich languages can be applied to low-resource languages (Conneau et al. 2020; Hu et al. 2020). While some studies suggest that cross-lingual transfer is more effective within the same language families, other work points to sub-word evenness (SuE) as a more critical factor in successful transfer (Pelloni, Shaitarova, and Samardzic 2022). Furthermore, transferring knowledge to languages with unknown scripts has proven exceedingly difficult (Anastasopoulos and Neubig 2019), prompting exploration of transliteration to mitigate script-related challenges (Hermjakob, May, and Knight 2018; Murikinati, Anastasopoulos, and Neubig 2020). The implications of cross-lingual and cross-script transfer for LLM security warrant further investigation.

Language Confusion Language confusion is a significant limitation of LLMs, where a model cannot consistently generate text in the desired language or appropriate language given the context (Marchisio et al. 2024). This can result in full-response confusion, line-level confusion, and wordlevel confusion (Vu et al. 2022; Marchisio et al. 2024). In embedding inversion attacks, Chen, Lent, and Bjerva (2024) attributes language confusion to using a multilingual blackbox encoder. However, in this work, we find that language confusion can occur when with both a multilingual and monolingual black-box encoder. Language confusion as a vulnerability is also supported by recent work, whereby it has already been proven an effective weapon for jailbreaking state-of-the-art LLMs (Song et al. 2024).

# Methodology

In this work, we consider a scenario where a malicious attacker has illegitimate access to stolen embeddings and API access to the black-box encoder. To gauge the vulnerability of multilingual models against black-box inversion embedding attacks, we implement inversion attacks on a diverse setting of languages across language families and scripts. The attack scenario is formally defined as follows: given a text sequence $x$ and a black-box encoder $\phi$ , an external inversion model $\psi$ aims to recover the text $x$ from its embeddings $\phi ( x )$ . The objective can be formalized as such that:

$$
\psi ( \phi ( x ) ) \approx \phi ^ { - 1 } ( \phi ( x ) ) = x .
$$

Since sentence embeddings result from pooling token representations, the mapping $\phi ( x )$ is non-injective, making it impossible for the attacker model $\psi$ to precisely invert $\phi$ (Li, $\mathrm { X u }$ , and Song 2023). To learn the approximation of $\psi$ , we learn a distribution $p ( x | e ; \theta )$ from a given dataset to invert $e = \phi ( x )$ via maximum likelihood (Morris et al. 2023):

$$
\theta = \arg \operatorname* { m a x } _ { \hat { \theta } } E _ { x \sim D } \left[ p ( x \mid \phi ( x ) ; \hat { \theta } ) \right] .
$$

This forms a text-to-text generation task, resulting in the trained base model. However, this approach alone is insufficient. To improve the inversion performance, a corrector model is implemented, where $\phi$ is queried using the output of the base model, and new hypothesis embeddings $\hat { e } ^ { ( t ) } = \phi ( x ^ { ( t ) } )$ is computed in iteration $t$ with which a new correction text $x ^ { ( t + 1 ) }$ is generated. The corrector aims to find text $\hat { x }$ that maximizes cosine similarity with the target embedding $\phi ( x ) : { \hat { x } } = \arg \operatorname* { m a x } _ { x } \cos ( \phi ( x ) , e )$ . At step $( t + 1 )$ , the model concatenates the previous output ${ \hat { x } } ^ { ( t ) }$ , hypothesis embeddings $\hat { e } ^ { ( t ) }$ , and target embeddings $\hat { e } ^ { t }$ as in the equation (3) in the methodology section. The model is defined by marginalizing over intermediate hypotheses (Morris et al. 2023):

$$
p ( x ^ { ( t + 1 ) } | e ) = \sum _ { x ^ { ( t ) } } p ( x ^ { ( t ) } | e ) p ( x ^ { ( t + 1 ) } | e , x ^ { ( t ) } , \hat { e } ^ { ( t ) } )
$$

We train a corrector model (step1) where $x ^ { ( 1 ) }$ is the correction of $x ^ { ( 0 ) }$ , and apply further steps with beam search. Results are reported for the base model, corrector (step1), and after 50 steps with beam search (width 8).

Language Models Previous studies have explored language models $\phi$ , both monolingual such as GTRand multilingual such as multilingual-e5 (ME5) but the backbone of $\psi$ is the encoder-decoder T5 (Raffel et al. 2020), pre-trained on four Germanic and Romance languages in Latin script, i.e., English, German, Spanish and French. To explore languages across diverse settings of scripts, we employ multilingual T5 (MT5) as the external encoder-decoder to train the inversion model, pre-trained in 102 languages, including the above languages except Meadow Mari. ME5 is also used as our multilingual language black-box encoder, to experiment across settings. The vulnerability between monolingual and multilingual language models is also compared by adopting GTR as $\phi$ to train the inversion model in German, ALEPHBERT (Seker et al. 2022), Hebrew, and TEXT2VEC Chinese. This work uses LLMs sourced from Hugging Face (HF). 2.

Sentence Representations Prior research shows that BERT’s intermediate layers capture a hierarchy of linguistic information, with surface features in lower layers, syntactic features in the middle, and semantic features in the upper layers (Jawahar, Sagot, and Seddah 2019). Huang et al. (2021) find that averaging the first and last layers $( s ^ { [ 1 , 1 2 ] } = { \textstyle \frac { 1 } { 2 } } ( s ^ { 1 } + s ^ { 1 2 } ) )$ outperforms the [CLS] token and other layer combinations in downstream tasks like sentence semantics. We investigate the existing methods that use last hidden state, mean of all layers, and [CLS] in inversion tasks (Morris et al. 2023; Chen, Lent, and Bjerva 2024; Zhuang et al. 2024) and extend it with $s ^ { [ 1 , 1 2 ] }$ , revealing that $s ^ { [ 1 , 1 2 ] }$ delivers superior attack performance, which is used for model training and evaluation in this paper.

Languages To explore the scenarios of multi-script and multi-family inversion attacks, we curate languages written in diverse scripts in several language families. Eventually, we simulate the inversion attacks in 20 languages across 8 families and 12 scripts. We train inversion models and evaluate languages and the combinations of which, including 12 languages Arabic (Semitic; Latn), Urdu (Indo-Aryan; Arab), Kazakh (Turkic; Cyrl), 3), Mongolian (Mongolic, Cyrl), Hindi (Indo-Aryan; Deva), Gujarati (Indo-Aryan; Gujr), Punjabi (Indo-Aryan; Guru), Chinese (Sino-Tibetan; Hani), Hebrew (Semitic; Hebr), Japanese (Japonnic; Jpan), German (Germanic; Latn), and Turkish (Turkic; Latn). In addition, we evaluate on another languages Amharic (Semitic; Ethi), Sinhala (Indo-Aryan; Sinh), Korean (Koreanic; Hang), Finnish (Uralic; Latn), Hungarian (Uralic; Latn), Yiddish (Germanic; Hebr), Maltese (Semitic; Latn), and Meadow Mari (Uralic; Cyrl).4

Dataset We randomly sample clean and deduplicated data from CulturaX (Nguyen et al. 2024), a trillion token dataset in 167 languages. Due to data size limitations for certain languages, such as Indo-Aryan languages, i.e., Hindi, Gujarati, Punjabi and Urdu, we curate 600K samples for each language for training, while for other languages there are 1M samples for each train set, i.e., Arabic, Kazakh, Mongolian, Chinese, Hebrew, Japanese, German and Turkish. We consider 500 samples for each language in all the abovementioned 20 languages for evaluation.

Experimental Setup Each inversion model consists of a base and a corrector, each trained for 100 epochs with a learning rate of $2 e \mathrm { ~ - ~ } 5$ , epsilon of $1 e \mathrm { ~ - ~ } 6$ , and 1000 warmup steps on a constant schedule. Models use a batch size of 256 on data with 32 tokens and are trained on 4 AMD MI250 GPUs and 56 CPU cores using distributed training. The slowest model takes 4 days to complete in these settings. [Baselines] For each of the above-mentioned 12 languages, we train and evaluate inversion models using the corresponding data (ref. Table 1).   
[In-Script] To explore inversion attacks within scripts, we train and evaluate on language pairs written in Arabic, Cyrillic, Latin and Hani-Jpan scripts5 (ref. Table 3).   
[In-Family] Moreover, to better understand the transfer learning within language families in inversion attacks, we train languages in pairs from three language families, i.e., Semitic, Turkic and Indo-Aryan (ref. Table 4).   
[Control] As a control group, we train the combinations of language pairs from Turkic and Indo-Aryan language families (ref. Table 5).   
The same data samples used in the baseline models are applied to the in-script and in-family inversion model training. For the control group, we matched the number of samples to the smallest dataset.

Word Tokenization and Evaluation To measure the matching words between the target and inverted texts, we use word tokenizers according to the languages, Specifically, jieba6 (Chinese), Hebrew Tokenizer7 (Hebrew), Kiwipiepy (Lee 2024) (Korean), fugashi (McCann 2020) (Japanese), and NLTK Word Tokenizer (Bird and Loper 2004) for other languages. For evaluation, we use wordmatching metrics such as BLEU (Post 2018), ROUGE (Lin 2004), and Token F1 (TF1), which calculates the multi-class F1 score between predicted and actual tokens. And, cosine similarity (COS) is employed to compare the true and hypothesis embeddings.

Language Confusion While previous work in language confusion is directed at prompting in diverse languages using instruct models (Marchisio et al. 2024), our experiment is in the setup, where an inversion model inverts the language embeddings in diverse languages extracted from a black-box encoder. Suppose an inversion model is trained on a set of $n \in \mathbf { N }$ languages $L _ { s } = \{ l _ { 1 } , . . , l _ { n } \}$ , and the text embeddings to be inverted are in a set of $m \in \mathbf { N }$ languages $L _ { t } ~ = ~ \{ l _ { 1 } , . . , l _ { m } \}$ . In the context of textual embedding inversion, we investigate language confusion in two settings:

a) Monolingual generation, where the inversion model inverts the language embeddings in the languages included in training, i.e., $L _ { t } \subseteq L _ { s }$ ; b) Cross-lingual generation, where the languages of the target language embeddings are not included in the training data of the inversion model, i.e., $L _ { t } \not \subseteq L _ { s }$ and $L _ { t } \cap L _ { s } = \emptyset$ .

To model and predict patterns in language confusion, we leverage the following aspects in the context of the inversion attacks: i) Stages of evaluating inversion attacks, i.e., base, corrector (step1) and (Step $5 0 +$ sbeam 8); ii) Language Characteristics, such as Langauge Script (S), Language Family (F), Directionality of the Script $\left( \mathrm { L R } \right) ^ { 8 }$ , and Word Order of Subject, Object and Verb(WO) (Dryer and Haspelmath 2013); iii) COS; iv) Comparison of Languages in Train Data (T) and Evaluation Data with (i), (ii) and (iii).

As shown in Fig. 1, language confusion can happen at different levels, e.g., word level and line level. Because of loan words and code-switching as such, a mixture of languages can be contained in different levels of texts. To detect different levels of language confusion, we use off-the-shelf language identification (LID) tools.9 We define Line-level Language Confusion under the context of inversion security as the probabilities of the detected languages in which the inverted texts are decoded at line level, while Word-level Language Confusion is defined as such at word level. Using the language detector, we define the language space as the set including all the above-mentioned 20 languages and others (etc.). As illustrated in Fig. 2, using the inversion model trained on monolingual and multilingual embeddings with German to invert Chinese texts, during different stages, the embeddings in Chinese are inverted into texts in different proportions of English, German and other languages.

After removing missing values, we have 170 samples for monolingual LLMs as $\phi$ and 1789 samples for multilingual LLMs, across monolingual and cross-lingual generation settings. We split the data into $80 \%$ for training and $20 \%$ for testing and use Random Forest10 to train a regression model. This model predicts the probabilities of the languages in which the inverted embeddings are decoded based on the features described earlier (see details in SUPPL.). Our goal is to identify which features are more conducive to predicting language identities and to determine if there is a pattern between monolingual and multilingual LLMs.

# Results on Inversion Attacks

Baselines We train and evaluate inversion models on ME5 embeddings across 12 languages. As detailed in Table 1, the performance of attacking textual embeddings improves progressively from the base model to the corrector model (Step 1), and further with 50 steps and a beam search width of 8. An exception is observed with inverting Punjabi text embeddings, which achieve the highest performance in BLEU and TF1 at the base model but deteriorate significantly when using the corrector. Overall, multilingual embeddings are more susceptible to attacks in languages written in Cyrillic compared to those in Arabic, Latin, or Hebrew scripts, particularly in Haqniqdoq and Japanese scripts. Despite being trained on a smaller dataset, Indo-Aryan languages are more vulnerable than Chinese, Japanese, and Hebrew. This finding aligns with previous work by Wang et al. (2024b), which found that Hindi and Bengali suffered from more safety issues than other languages, in the context of adversarial attacks.

Table 2: MONO and MULTI evaluate Text Reconstruction with monolingual embeddings and multilingual embeddings respectively. The best results for metrics are in bold.   

<html><body><table><tr><td>Lang. (Script)</td><td>#Tok.</td><td>#Pred. Tok.</td><td>Tok. F1</td><td>BLEU</td><td>ROUGE</td><td>Cos</td></tr><tr><td>Arabic (Arab) Base Corrector (Step1)</td><td>13.48 13.48</td><td>13.27 13.02</td><td>40.06 43.66</td><td>17.31 19.12</td><td>92.93 92.96</td><td>0.9310 0.9292</td></tr><tr><td>(Step 50+sbeam8) Urdu (Arab) Base</td><td>13.48 15.03</td><td>13.17 14.77</td><td>48.18 49.71</td><td>22.93 20.86</td><td>94.15 78.57</td><td>0.9232 0.9612</td></tr><tr><td>Corrector (Step1) (Step 50+sbeam8) Kazakh (Cyrl) Base</td><td>15.03 15.03 13.35</td><td>14.72 14.85 13.16</td><td>51.64 54.66 53.12</td><td>22.76 25.04 30.69</td><td>79.27 80.19 86.39</td><td>0.9736 0.9712 0.9712</td></tr><tr><td>Corrector (Step1) (Step 50+sbeam8) Mongolian (Cyrl) Base</td><td>13.35 13.35 12.00</td><td>13.12 13.21 11.74</td><td>57.46 65.74 50.01</td><td>34.62 44.50 28.21</td><td>87.29 89.44 82.36</td><td>0.9794 0.9860 0.9818</td></tr><tr><td>Corrector (Step1) (Step 50+sbeam8) Hindi (Deva) Base</td><td>12.00 12.00 15.21</td><td>11.70 11.85 14.98</td><td>55.36 64.67 50.98</td><td>32.96 43.63 19.10</td><td>85.00 88.58 73.40</td><td>0.9523 0.9742 0.9576</td></tr><tr><td>Corrector (Step1) (Step 50+sbeam8) Gujarati (Gujr) Base</td><td>15.21 15.21 11.07</td><td>14.77 14.77 10.85</td><td>52.78 55.79 43.19</td><td>20.06 22.29 18.74</td><td>74.25 76.00 87.57</td><td>0.9443 0.9197 0.9787</td></tr><tr><td>Corrector (Step1) (Step 50+sbeam8) Punjabi (Guru) Base</td><td>11.07 11.07 11.07</td><td>10.71 10.81 10.97</td><td>45.51 48.17 59.65</td><td>20.15 22.35 31.10</td><td>87.65 88.43 91.39</td><td>0.9856 0.9893 0.9882</td></tr><tr><td>Corrector (Step1) (Step 50+sbeam8) Chinese (Hani) Base</td><td>11.07 11.07 5.81</td><td>21 21.00 6.06</td><td>0.03 0.03 27.84</td><td>0.43 0 16.73</td><td>0 0 81.82</td><td>0.7355 0.7190 0.9483</td></tr><tr><td>Corrector (Step1) (Step 50+sbeam8) Hebrew (Hebr)</td><td>5.81 5.81</td><td>5.88 5.74</td><td>28.33 29.2 38.89</td><td>17.12 17.50</td><td>82.29 83.35</td><td>0.9701 0.9543 0.9646</td></tr><tr><td>Base Corrector (Step1) (Step 50+sbeam8) Japanese (Jpan)</td><td>13.94 13.94 13.94</td><td>13.67 13.50 13.68</td><td>41.81 45.1</td><td>14.84 16.32 18.77</td><td>91.63 92.30 93.04</td><td>0.9588 0.9477</td></tr><tr><td>Base Corrector (Step1) (Step 50+sbeam8) German (Latn)</td><td>2.93 2.93 2.93</td><td>3.03 2.94 2.87</td><td>9.47 9.46 9.61</td><td>9.31 8.93 8.60</td><td>80.08 80.41 81.66</td><td>0.9496 0.9576 0.9630</td></tr><tr><td>Base Corrector (Step1) (Step 50+sbeam8) Turkish (Latn)</td><td>17.26 17.26 17.26</td><td>16.76 16.85 16.80</td><td>55.46 56.69 61.85</td><td>25.88 27.35 31.35</td><td>57.22 58.78 64.62</td><td>0.9460 0.9563 0.9982</td></tr><tr><td>Base Corrector (Step1) (Step 50+sbeam8)</td><td>14.66 14.66 14.66</td><td>14.36 14.26 14.30</td><td>44.05 46.33 50.38</td><td>18.15 20.62 24.51</td><td>49.40 52.51 57.51</td><td>0.9498 0.9650 0.9309</td></tr></table></body></html>

Table 1: Text Reconstruction in Multiple Languages, sorted by the alphabetic order of language scripts. For each language, the best performing TF1 and COS are underlined, and the best BLEU is bolded.   

<html><body><table><tr><td>Lang. (Script)</td><td colspan="2">Tok. F1</td><td colspan="2">BLEU</td><td colspan="2">COs</td></tr><tr><td></td><td>MONO</td><td>MULTI</td><td>MONO</td><td>MULTI</td><td>MONO</td><td>MULTI</td></tr><tr><td>Chinese (Hani) Base</td><td>21.87</td><td>27.84</td><td>6.53</td><td>16.73</td><td>0.8723</td><td>0.9484</td></tr><tr><td>Corrector (Step 1) (Step 50+sbeam 8)</td><td>22.05 21.75</td><td>28.33 29.2</td><td>6.19 6.01</td><td>17.12 17.50</td><td>0.8548 0.8576</td><td>0.9701 0.9543</td></tr><tr><td>Hebrew (Hebr) Base</td><td>34.17</td><td>38.89</td><td>8.99</td><td></td><td></td><td></td></tr><tr><td>Corrector (Step 1)</td><td>36.27</td><td>41.81</td><td>9.95</td><td>14.84 16.32</td><td>0.8601</td><td>0.9646 0.9588</td></tr><tr><td>(Step 50+sbeam 8)</td><td></td><td></td><td></td><td></td><td>0.8773</td><td></td></tr><tr><td></td><td>37.98</td><td>45.1</td><td>10.56</td><td>18.77</td><td>0.9018</td><td>0.9477</td></tr><tr><td>German (Latn)</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Base</td><td>39.86</td><td>55.46</td><td>15.07</td><td>25.88</td><td>0.7985</td><td>0.9460</td></tr><tr><td></td><td>39.83</td><td>56.69</td><td></td><td></td><td></td><td></td></tr><tr><td>Corrector (Step 1)</td><td></td><td></td><td>14.52</td><td>27.35</td><td>0.9083</td><td>0.9563</td></tr><tr><td>(Step 50+sbeam 8)</td><td>42.17</td><td>61.85</td><td>15.54</td><td>31.35</td><td>0.9718</td><td>0.9982</td></tr></table></body></html>

Monolingual vs. Multilingual LLMs To compare the vulnerability of monolingual embeddings and multilingual embeddings, we train and evaluate German, Hebrew, and

Chinese on both monolingual (MONO) and multilingual (MULTI) LLMs. While in Chen, Lent, and Bjerva (2024), with the same settings of MONO and MULTI, trained on English samples, the best reconstruction performance on MONO excels MULTI by $1 4 . 3 3 \%$ in BLEU and by $5 . 8 1 \%$ in TF1. While trained on German samples, inverting MONO embeddings under-performs across the metrics compared to MULTI, as shown in Table 2. Overall, while the performance improves steadily across languages across the phases of evaluations in both word matching metrics and cosine similarities, ME5 is more vulnerable compared to MONO LLMs with different architectures (see details of the LLMs in SUPPL.). Also consistent with the findings from Chen, Lent, and Bjerva (2024), the cosine similarities are uniformly higher for MULTI than MONO. Overall, German is more vulnerable in both monolingual and multilingual settings, compared to Chinese and Hebrew.

Attacking In-script Textual Embeddings Since crosslingual transfer learning is pervasive in multilingual NLP, and previous work has only touched upon Latin script in text embedding inversion, we investigate whether incorporating multiple languages in the same script would boost the inversion attack performance. Although the Japanese writing script has a more diverse set of forms (i.e., kanji and kana) compared to Chinese, they share a fair amount of vocabulary in the same script, in kanji and hanzi. To minimize the influence of transfer learning due to shared language families, the languages in each script are selected from different language families. As shown in Table 3, we train the inversion model in Arabic script with Arabic and Urdu, Cyrillic with Kazakh and Mongolian and Latin with German and Turkic, in addition to the Hani-Jpan combination with Chinese and Japanese. Overall, the inversion attack performances improve across languages when they are trained together with the same-script languages across stages, except in rare cases such as inverting German and Turkish embeddings with the base model. Language embeddings in Cyrillic are the most vulnerable compared to other scripts while Japanese and Chinese appear to be less vulnerable than other evaluated languages. Notably, the performance of attacking Urdu text embeddings is boosted notably by $1 0 0 \%$ in BLEU score and $3 9 . 3 7 \%$ in TF1 compared to the baseline. Arabic, Urdu, Kazakh and Turkish are further investigated in the scenarios of in-family inversion attacks. Overall, the inscript training improves performance more than in-family training, except for Turkish (ref. Table 3 and 4).

Table 3: Multilingual Text Reconstruction within Script. For each language, the best TF1 score is underlined, and the best BLEU score is bolded. The color box indicates the highest inversion boost compared to the baseline.   

<html><body><table><tr><td>Lang. (Script)</td><td></td><td>#Tok.</td><td>#Pred. Tok.</td><td>Tok. F1</td><td>BLEU</td><td>ROUGE</td><td>COS</td></tr><tr><td></td><td>Arabic orrector (Step1) (Step 50+sbeam8) Urdu Base Corrector (Step1)</td><td>13.48 13.48 15.03 15.03 15.03</td><td>13.37 13.30 14.93 14.83 14.90</td><td>41.91↑ 55.58个 61.39↑ 66.7个 76.18↑</td><td>17.97个 28.73个 31.05个 36.90↑ 50.13个</td><td>93.69 94.68 88.61 90.41 92.80</td><td>0.9416 0.9243 0.9735 0.9618</td></tr><tr><td></td><td>(Step 50+sbeam8) Chinese Base Corrector (Step1) (Step 50+sbeam8) Japanese Base Corrector (Step1) (Step 50+sbeam8)</td><td>5.81 5.81 5.81 2.93 2.93 2.93</td><td>6.08 5.90 5.71 2.94 2.84 2.94</td><td>28.79↑ 30个 31.66↑ 9.85个 10.63↑ 11.58↑</td><td>17.10个 18.01个 19.86↑ 9.41个 8.99↑ 10.25个</td><td>82.52 84.82 87.80 80.64 83.23 85.61</td><td>0.9832 0.9475 0.9549 0.9476 0.9535 0.9698</td></tr><tr><td></td><td>Kazakh Base Corrector (Stepl) (Step 50+sbeam8) Mongolian Base Corrector (Stepl) (Step 50+sbeam8)</td><td>13.35 13.35 13.35 12.00 12.00 12.00</td><td>13.17 13.08 13.21 11.75 11.67 11.82</td><td>54.29↑ 61个 72.37个 53.56↑ 59.74↑ 71.96↑</td><td>31.39个 37.62↑ 52.44 个 31.63↑ 37.47个 51.62个</td><td>87.08 89.83 92.58 85.14 87.15 91.22</td><td>0.9666 0.9682 0.9836 0.9863 0.9716 0.9777 0.9985</td></tr><tr><td></td><td>German Corrector Step1) (Step 50+sbeam8) Turkish Base Corrector (Step1) (Step 50+sbeam8)</td><td>17.26 17.26 14.66 14.66 14.66</td><td>16.90 16.96 14.47 14.30 14.39</td><td>53.56↓ 68.42↑ 42.96↓ 50.08↑ 59.68↑</td><td>24.20 37.66个 17.29↓ 23.36个 33.33个</td><td>55.35 71.11 48.97 56.26 66.35</td><td>0.9545 0.9958 0.9595 0.9637 0.9680</td></tr></table></body></html>

Attacking In-Family Text Embeddings In addition to script being a significant factor in enhancing inversion attack performance, we also investigate the impact of a shared language family in this context. We train and evaluate various language pairs selected from the Semitic, Turkic, and Indo-Aryan language families, as shown in Table 4. Overall, inversion attack performance in word-matching metrics improves for all languages across evaluation steps, with the exception of Gujarati at the corrector step1 and Hindi with the base model. Notably, the corrector model trained solely on Punjabi fails to produce meaningful output when inverting Punjabi text embeddings in the baseline scenario (ref. Table 1). However, when trained alongside other Indo-Aryan languages, the performance improves dramatically. For instance, when Punjabi is trained with Gujarati, the BLEU score for the corrector model at step 50 with a beam search width of 8 jumps from 0 to 52.89. Additionally, Turkish text embedding inversion performs better in in-family training compared to in-script training (ref. Table 3). Overall, training the embedding inversion model with languages from the same language family significantly enhances performance. This indicates the vulnerability of low-resource languages which are related to high-resource ones.

<html><body><table><tr><td></td><td>Lang. (Script)</td><td>#Tok.</td><td>#Pred. Tok.</td><td>Tok. F1</td><td>BLEU</td><td>ROUGE</td><td>COs</td></tr><tr><td></td><td>Arabic (Arab) Base (Sstep tor (Seap1) Hebrew (Hebr) Base Corrector (Step1)</td><td>13.48 13.48 13.94 13.94</td><td>13.34 13.14 13.65</td><td>42.75个 46.2 39.88↑</td><td>18.56↑ 20.97↑ 15.02↑</td><td>93.64 93.97 93.36</td><td>0.9434 0.9172 0.9583</td></tr><tr><td></td><td>(Step 50+sbeam8) Kazakh (Cyrl) Base Corrector (Step1) (Step 50+sbeam8) Turkish (Latn)</td><td>13.94 13.35 13.35 13.35</td><td>13.49 13.57 13.14 13.20 13.24</td><td>43.6个 48.4↑ 55.07个 61.07个 69.71↑</td><td>17.26↑ 20.30个 31.62↑ 37.85个 49.94↑</td><td>93.87 94.06 87.83 89.82 92.56</td><td>0.9707 0.9730 0.9755 0.9685 0.9815</td></tr><tr><td></td><td>Base Corrector (Step1) (Step 50+sbeam8) Hindi (Deva) Corector Sstpf)</td><td>14.66 14.66 14.66 15.21</td><td>14.41 14.34 14.41 15.02</td><td>45.32↑ 51.07个 59.58↑ 54.971</td><td>19.31↑ 23.96↑ 33.62个 19.47个</td><td>51.52 57.22 66.10 73.5</td><td>0.9399 0.9597 0.9683 0.9596</td></tr><tr><td></td><td>(Step 50+sbeam8) Gujarati (Gujr) Base Corrector (Step1) (Step 50+sbeam8) Hindi (Deva)</td><td>15.21 11.07 11.07 11.07</td><td>15.04 10.77 10.74 10.89</td><td>62.12个 43.91个 48.97个 56.08↑</td><td>28.72个 18.99↑ 22.12个 29.54个</td><td>79.20 88.82 89.52 91.42</td><td>0.9728 0.9824 0.9870 0.9925</td></tr><tr><td></td><td>Corrector Stp1) (Step 50+sbeam8) Punjabi (Guru) Base Corrector (Step1) (Step 50+sbeam8)</td><td>15.21 15.21 11.07 11.07 11.07</td><td>15.03 14.98 10.90 10.87 10.97</td><td>53.21个 62.31↑ 63.6个 68.1个 75.37个</td><td>20.6 28.89个 35.78↑ 40.61个 50.80个个</td><td>74.00 79.03 93.05 93.80 95.08</td><td>0.9476 0.9115 0.9872 0.9903 0.9967</td></tr><tr><td></td><td>Gujarati (Gujr) Corrector (Stepl) (Step 50+sbeam8) Punjabi (Guru) Base Corrector (Step1)</td><td>11:.7 11.07 11.07 11.07</td><td>10.81 10.84 11.00 10.90</td><td>4. 50.66↑ 63.43↑ 68.56个</td><td>19.471 24.22个 34.64↑ 41.07个</td><td>87.90 89.74 93.21 94.39</td><td>0.984 0.9880 0.9883 0.9887</td></tr><tr><td></td><td>(Step 50+sbeam8) Gujarati (Gujr) Corector (Stepl) (Step 50+sbeam8) Urdu (Arab) Base Corrector (Step1)</td><td>11.07 11.07 11.07 15.03</td><td>10.99 10.79 10.83 14.84</td><td>76.511个 45.42个 56.89个 54.63↑</td><td>52.89个 19.28个 30.34↑</td><td>95.43 87.62 90.55 83.28</td><td>0.9957 0.9763 0.9949 0.9621</td></tr><tr><td></td><td>(Step 50+sbeam8) Hindi (Deva) Corrector Stepl) (Step 50+sbeam8) Urdu (Arab) Base</td><td>15.03 15.03 15.21 15.21 15.03</td><td>14.78 14.84 15.08 14.98</td><td>57.69个 62.8↑ 5.23个 61.21个</td><td>27.35个 32.99个 18.84 27.93个</td><td>85.43 87.40 73.4 78.82</td><td>0.9709 0.9824 0.9477 0.9771</td></tr><tr><td></td><td>Corrector (Stepl) (Step 50+sbeam8) Punjabi (Guru) Corrector Stepl) (Step 50+sbeam8) Urdu (Arab) Base Corrector (Step1) (Step 50+sbeam8)</td><td>15.03 15.03 11.07 11.07 15.03 15.03</td><td>14.75 14.87 15.01 10.82 10.89 14.77 14.72</td><td>53.32↑ 57.19↑ 63.15个 38.99个 59.99个 52.14↑ 55.6个</td><td>23.87↑ 26.84个 32.81↑ 33.19个 30.86个 22.88↑</td><td>83.86 85.60 87.79 91.76 0.9218 81.98</td><td>0.9728 0.9683 0.9831 0.9878 0.9878 0.9689</td></tr></table></body></html>

Table 4: Text Reconstruction within Language Family. For each language, the best TF1 is underlined, and the best BLEU is bolded. The color box indicates the highest inversion boost compared to the baseline.

Control Group in Text Embedding Inversion To rule out the possibility that performance gains are merely due to an increased amount of training data compared to baseline models, we conduct experiments with a control group where languages from the Indo-Aryan and Turkic families are mixed. As shown in Table 5, when paired with Kazakh, the inversion performance of Indo-Aryan languages improves compared to the baseline, with the exception of Urdu when using corrector models. However, the improvement is not as significant as that observed with in-family training (ref. Table 4). Conversely, the performance of inverting Kazakh text embeddings diminishes with these combinations. A similar trend is observed in inversion models trained on combinations of Turkish and Indo-Aryan languages, except when using the combination of Turkish and Hindi text embeddings. In this case, the reconstruction of Turkish texts also improves performance in word-matching metrics, possibly due to overlapping vocabulary between Hindi and Turkish (Singh 2024). Overall, this rules out the size of the training data as the decisive factor in enhancing inversion attack performance; instead, shared script and language family are

Table 5: Text Reconstruction in Control Group. For each language, the best TF1 is underlined, the best BLEU is bolded.   

<html><body><table><tr><td>Lang.(Script)</td><td></td><td></td><td>#Tok.丨#Pred.Tok.|Tok.F1</td><td>BLEU</td><td></td><td>ROUGE</td><td>COs</td></tr><tr><td></td><td>Gujarati (Gujr) Base Corrector(Step1) (Step 50+sbeam8) Kazakh (Cyrl) Base</td><td>11.07 11.07 11.07 13.35</td><td>10.82 10.68 10.77 13.21</td><td>45.34个 49.03↑ 54.98↑</td><td>19.75↑ 22.94↑ 29.79个</td><td>88.21 90.25 91.38</td><td>0.9854 0.9804 0.9809</td></tr><tr><td></td><td>Corrector(Step1) (Step 50+sbeam8) Hindi (Deva) orrector(Step1)</td><td>13.35 13.35 15.21</td><td>13.09 13.14 14.97</td><td>49.34↓ 53.47↓ 60.4↓ 54.181</td><td>26.08↓ 30.31↓ 38.20↓ 19.001</td><td>85.22 87.05 89.89 74.00</td><td>0.9767 0.9800 0.9841 0.944</td></tr><tr><td></td><td>(Step 50+sbeam8) Kazakh (Cyrl) Base Corrector(Step1) (Step 50+sbeam8) Kazakh (Cyrl)</td><td>15.21 13.35 13.35 13.35</td><td>15.06 13.10 13.02 13.10</td><td>56.96↑ 48.01↓ 52.68↓ 59.38↓</td><td>23.99个 25.31↓ 30.18↓ 36.57↓</td><td>76.15 84.23 87.54 89.07</td><td>0.9502 0.9563 0.9729 0.9635</td></tr><tr><td></td><td>Base Corrector(Step1) (Step 50+sbeam8) Punjabi (Guru) Base Corrector(Step1) (Step 50+sbeam8)</td><td>13.35 13.35 13.35 11.07 11.07 11.07</td><td>13.06 13.09 13.04 11.04 10.93 10.95</td><td>48.34↓ 51.49↓ 56.8↓ 63.44个 65.92个 71.671个</td><td>25.60↓ 28.79↓ 34.49↓ 34.30↑ 37.28个 46.65 (↑)</td><td>84.63 84.97 86.12 92.94 93.89 95.19</td><td>0.9609 0.9662 0.9824 0.9880 0.9901 0.9942</td></tr><tr><td></td><td>Kazakh (Cyrl) orrector(Stepl) (Step 50+sbeam8) Urdu (Arab) Base Corrector(Step1) (Step 50+sbeam8)</td><td>13.35 13.35 15.03 15.03 15.03</td><td>13.00 21.00 14.81 21.00 21.00</td><td>46.87 0.2↓ 52.35↑ 0.08↓ 0.08↓</td><td>24.84 0.03↓ 22.58个 0.01↓ 0.01↓</td><td>84.18 0 83.44 0 0</td><td>0.9619 0.7528 0.9657 0.7687 0.7821</td></tr><tr><td></td><td>Gujarati (Gujr) Base Corrector(Step1) (Step 50+sbeam8) Turkish (Latn) Base Corrector(Step1) (Step 50+sbeam8)</td><td>11.07 11.07 11.07 14.66 14.66 14.66</td><td>10.75 10.74 10.86 14.42 14.37 14.44</td><td>42.64↓ 47.51个 54.49↑ 41.08↓ 45.07↓</td><td>18.84↑ 21.70个 28.19个 16.10↓ 19.37↓</td><td>87.55 89.16 91.61 46.29 51.09</td><td>0.9838 0.9849 0.9892 0.9437 0.9657</td></tr><tr><td></td><td>Hindi (Deva) Corrector(Ssepl) (Step 50+sbeam8) Turkish (Latn) Base Corrector(Step1)</td><td>15.21 15.21 14.66 14.66</td><td>15.00 15.00 14.49 14.26</td><td>50.17↓ 53.57t 61.34↑ 42.85↓ 44.69↓</td><td>24.29↓ 20.65 28.59个 17.11↓ 19.50↓</td><td>57.46 76.03 80.74 48.13</td><td>0.9593 0.9518 0.9917 0.9413 0.9738</td></tr><tr><td></td><td>(Step 50+sbeam8) Punjabi (Guru) Base Corrector(Step1) (Step 50+sbeam8) Turkish (Latn) Base Corrector(Step1) (Step 50+sbeam8)</td><td>14.66 11.07 11.07 11.07 14.66 14.66 14.66</td><td>14.35 10.91 10.56 10.87 14.28 14.31</td><td>51.08↑ 62.93↑ 38.58个 54.33↑个 41.97↓ 44.25↓</td><td>25.58个 34.19个 13.69个 25.37 (↑↑) 16.75↓ 18.89↓</td><td>58.27 92.68 88.89 92.28 47.29 50.71</td><td>0.9498 0.9878 0.9711 0.9904 0.9298 0.9445</td></tr><tr><td></td><td>Turkish (Latn) Corector(Step1) (Step 50+sbeam8) Urdu (Arab) Base Corrector(Step1) (Step 50+sbeam8)</td><td>14.66 14.66 15.03 15.03 15.03</td><td>14.45 14.4 14.39 14.74 14.70 14.86</td><td>49.2↓ 4.65 50.05↓ 53.79↑ 56.03↑ 61.6↑</td><td>23.52↓ 16.701 23.95↓ 23.51↑ 26.27↑ 31.77个</td><td>56.18 47.32 56.61 83.57 85.51 87.82</td><td>0.9463 0.9373 0.9083 0.9574 0.9632 0.9841</td></tr></table></body></html>

gtr_deu_Latn:cmn_Hani me5_deu_Latn:cmn_Hani Input - Base   
Step1   
50(8) / 0.0 0.5 1.00.0 0.5 1.0 Per.Lang.at Word Level Per.Lang.at Word Level gtr_deu_Latn:cmn_Hani me5_deu_Latn:cmn_Hani   
Input  
Base   
Step1   
50(8) 0.0 0.5 1.00.0 0.5 1.0 Per.Lang.at Line Level Per. Lang.at Line Level ? eng_Latn deu_Latn cmn_Hanioed

necessary contributors.

# Language Confusion Analysis

When GTR is used for the black-box encoder with German training data as depicted in Fig. 2 (left), the output languages at both word and line levels are a mix of German, English, and other languages, with proportions varying across different steps. However, with ME5 as the black-box encoder, the output is more likely to remain in the source language (i.e., German) at both levels. We also observe the target and hypothesis embeddings of inverted Chinese texts across different stages using inversion models trained on monolingual and multilingual embeddings in German. For multilingual embeddings, the target and hypothesis embeddings form distinct clusters, consistent with the findings that multilingual embeddings in different languages tend to occupy their respective subspaces. In contrast, for monolingual embeddings, the hypothesis embeddings are clustered together during inference steps, while at the base model stage, they are more sparsely distributed (see details in SUPPL.).

Patterns of Language Confusion This phenomenon of language confusion is pervasive and seems to be random at first. However, inversion attack results show there are strong correlations between the improved performance with training models using languages with shared scripts and language families. The language of training data, evaluation data, and different evaluation stages may serve as baseline variables for predicting language patterns, acting as control variables for the baseline model. In addition, shared language family and scripts and also the cosine similarity of the target and hypothesis embeddings play a role in language confusion. We use the combinations of COS, F, S, LR, LR(T), WO plus the variables from baseline, to predict the language of the inversion output using Random Forest Regression, with Mean

←MONO (Line Level) $\cdot$ MULTI (Line Level) $\cdot$ MULTI (Word Level)·MONO (Word Level) 3 师中 T

Squared Error (MSE) as evaluation metrics. As shown in Fig. 3, all combinations of control variables with COS predict languages with larger error for both monolingual and multilingual LLMs and also for both word and line levels, while consistently, the features such as F, S, LR, LR(T) and WO renders better predictions across LLMs and levels.

# Conclusion

Our work highlights the fact that vulnerabilities in multilingual embedding attacks disproportionately affect lowresource languages. This risk is exacerbated by the fact that language confusion, which can be exploited by attackers, is shown to be both predictable and solvable. We prove this by showing directly that attackers drastically increase the efficacy of their embedding inversion attacks, when specifically accounting for language confusion (i.e., by training on in-family and in-script languages), making it an appealing exploit for malicious actors to potentially leverage. In this context, we argue that a deeper understanding of language confusion, including its connection to linguistic characteristics, could offer critical insights into the mechanics of multilingual attacks. Ultimately, the security of LLMs and guarantees for safety for all end-users relies on the inclusion of diverse languages in LLM security research. Multilinguality poses unique challenges, and solutions offered for high-resource languages are not necessarily useful for those with fewer resources. Without prioritizing diversity in this emerging field, LLMs will remain vulnerable, with marginalized communities worldwide facing disproportionate risk as LLMs become more widespread.

# Ethics Statement

This work investigates attacks on multilingual embedding models and the phenomenon of language confusion, with the goal of highlighting vulnerabilities across languages representing diverse scripts and typologies. We encourage the community to incorporate a broader range of languages in NLP security research. Some languages we examine, such as Yiddish and Meadow Mari, are particularly vulnerable. To minimize potential harm, we do not train any attacks on these languages, instead focusing solely on evaluation to determine their current threat level. The language models used in this study are open-source, ensuring that this research does not pose an immediate threat to EaaS providers, who are likely using private models. Additionally, we do not experiment with sensitive data, ensuring that no real-world harm results from this work.

Computational Constraints Despite reducing the training data size for each inversion model by $60 \%$ to $80 \%$ , allowing us to investigate significantly more languages compared to previous studies (Morris et al. 2023; Chen, Lent, and Bjerva 2024), the computational overhead remains substantial. A key limitation of this work is the resourceintensive nature of the experiments, which required approximately 40,000 GPU hours. While expanding this research to include additional languages would further escalate computational costs, we strongly advocate prioritizing NLP security across diverse languages to ensure equitable advancements beyond English.

LLM’s Cross-lingual Vulnerabilities Defending multilingual LLMs has proven particularly challenging against attacks such as jailbreak (He et al. 2024), backdoor attacks (Wang et al. 2024a), and fine-tuning (Poppi et al. 2024). We echo these findings by examining multilingual LLMs in embedding inversion attacks across a linguistically diverse set of languages. A major finding of this work is that language confusion can be directly weaponized as an exploit against multilingual LLMs, and as such, we provide further analysis to better understand the underlying patterns of language confusion. However, the trade-off between LLM vulnerabilities and LLM performance still needs to be investigated thoroughly in multilingual settings to devise effective defense mechanisms, which we leave for future work.