# CareBot: A Pioneering Full-Process Open-Source Medical Language Model

Lulu Zhao1\*, Weihao Zeng2, Xiaofeng $\mathbf { S h i } ^ { 1 }$ , Hua Zhou1

1Beijing Academy of Artificial Intelligence (BAAI) 2School of Artificial Intelligence, Beijing University of Posts and Telecommunications llzhao $@$ baai.ac.cn

# Abstract

Recently, both closed-source and open-source LLMs have made significant strides, outperforming humans in various general domains. However, their performance in specific professional domains such as medicine, especially within the open-source community, remains suboptimal due to the complexity of medical knowledge. In this paper, we propose CareBot, a bilingual medical LLM, which leverages a comprehensive approach integrating continuous pre-training (CPT), supervised fine-tuning (SFT), and reinforcement learning with human feedback (RLHF). Our novel two-stage CPT method, comprising Stable CPT and Boost CPT, effectively bridges the gap between general and domain-specific data, facilitating a smooth transition from pre-training to fine-tuning and enhancing domain knowledge progressively. We also introduce DataRater, a model designed to assess data quality during CPT, ensuring that the training data is both accurate and relevant. For SFT, we develope a large and diverse bilingual dataset, along with ConFilter, a metric to enhance multi-turn dialogue quality, which is crucial to improving the model’s ability to handle more complex dialogues. The combination of high-quality data sources and innovative techniques significantly improves CareBot’s performance across a range of medical applications. Our rigorous evaluations on Chinese and English benchmarks confirm CareBot’s effectiveness in medical consultation and education. These advancements not only address current limitations in medical LLMs but also set a new standard for developing effective and reliable opensource models in the medical domain.

# Code — https://github.com/FlagOpen/CareBot

# Introduction

Recently, the advent of generative large language models (LLMs) like ChatGPT (Brown et al. 2020) and LLaMA (Touvron et al. 2023a,b) has revolutionized humancomputer interaction. These models excel at basic text understanding and complex problem-solving tasks, demonstrating capabilities akin to human understanding and reasoning. However, in industrial applications, the professionalism and cost-effectiveness of LLMs are more concerned. Although a series of closed-source models such as GPT-4 still perform well in specialized domains, considering the risk of data privacy, it is not convenient to use such APIs to handle domain-specific issues. In the open-source community, a lack of domain-specific knowledge often limits the performance of open-source models in specialized areas, such as medical (Yang et al. 2023a; Xiong et al. 2023; Labrak et al. 2024). The complexity and depth of medical knowledge present significant challenges for developing accurate and secure medical LLMs. Nonetheless, we believe that medical LLMs hold immense potential and can significantly contribute to diagnostic assistance, consultation, drug recommendation, and more. Thus, developing a fully opensource LLM tailored for the medical domain is of paramount importance.

Currently, there are several medical LLMs available in this domain . However, most of these models rely solely SFT (Zhang et al. 2023, 2024a; Han et al. 2023). As is wellknown, pre-training is a critical phase for learning domainspecific knowledge, and depending exclusively on SFT results in models that can only produce answers in a fixed format. Another approach attempts to integrate pre-training with SFT by converting pre-training data in specific domains into a unified format similar to SFT data, such as (instruction, output) pairs using GPT-3.5 (Chen et al. 2023). This method of synthesizing large amounts of data can lead to the inclusion of significant amounts of incorrect knowledge that aligns with GPT-4 but diverges from human expertise, as well as high data synthesis costs. Furthermore, Yang et al. (2023b) introduce Zhongjing for Chinese medicine, which employs to implement the pipeline training from pretraining, SFT, to RLHF. However, this approach involves two phases of transformation for the base model, which may lead to issues such as catastrophic forgetting or model degradation (Cheng, Huang, and Wei 2024). Additionally, previous efforts have predominantly focused on data construction during the SFT stage (Li et al. 2023a; Zhang et al. 2024b), while neglecting the importance of data construction during the CPT stage. Yet, a well-designed CPT data strategy is also crucial for inserting medical expertise into the model.

To address these challenges, we propose CareBot, a bilingual medical LLM based on LLaMA3-8B, designed to effectively assist doctors with diagnosis, provide personalized treatment plans, and support medical education. Our approach also implements the entire process from CPT,

SFT to RLHF. Most importantly, we develope a novel twostage CPT method, consisting of stable CPT and boost CPT. The stable CPT addresses the distribution discrepancy between general and domain-specific data, while boost CPT narrows the gap between pre-training and fine-tuning data. This method facilitates a smooth transition for the model from general data to domain-specific data, and finally to fine-tuning data, thereby enhancing its domain knowledge progressively. Recognizing that data quality is critical to model performance, we also design a data quality assessment model for CPT called DataRater. This model employs a comprehensive quality assessment standard, evaluating aspects such as grammatical accuracy, information density, semantic consistency, and domain-specific attributes. DataRater effectively mitigates data bias, ensuring CareBot’s performance and generalization capabilities in the medical domain. For SFT stage, we further construct a highly diverse medical SFT dataset, comprising single-turn and multi-turn medical dialogues, as well as medical subject knowledge multiple-choice questions, covering over $^ { 1 5 + }$ departments and $1 0 0 +$ disease specialties. Noted that this corpus is the largest open-source bilingual medical SFT dataset available. It supports a variety of medical applications, clinical tasks, and online consultations, significantly enhancing CareBot’s performance across multiple dimensions. Given the importance of data quality during the SFT stage(Zhou et al. 2023), we employ various selection methods. One key innovation is ConFilter, a metric designed to measure the correlation between multiple turns, which helps in filtering multi-turn dialogues. The inclusion of high-quality multiturn dialogues not only improves the model’s ability to understand user intent and generate relevant responses but also ensures a natural, smooth dialogue experience that enhances user comfort and satisfaction. Our SFT data is sourced partly from real-world medical diagnosis dialogues and partly from GPT-3.5 generated content. This combination ensures that the model delivers informative, clear, and logically consistent answers, while also providing professional and personalized consultations akin to those of medical experts. Finally, in the RLHF stage, we leverage GPT-4 to create positive and negative medical data pairs based on the SFT results. We then apply the Direct Preference Optimization (DPO) (Rafailov et al. 2023) algorithm to align the model’s output with human expression styles, providing personalized answers and recommendations, and enhancing overall user experience and satisfaction.

After extensive training and optimization, we successfully develope the CareBot. We rigorously evaluate the performance of our model using widely used Chinese and English benchmarks in medical domain. The experimental results demonstrate that CareBot excels in both medical consultation and teaching, validating that our constructed datasets significantly enhance the model’s performance across multiple dimensions. The main contributions of this paper are as follows: (1) We design a novel two-stage CPT strategy that progressively and stably integrates domain knowledge into the LLM, and effectively addresses data bias and language imbalances in the original pre-training data. (2) We propose DataRater, a model for assessing data quality during CPT, ensuring that the data used for CPT is of high quality. (3) We construct a comprehensive open-source medical SFT dataset with high data diversity and data quality. Additionally, we develope ConFilter, a metric for measuring the correlation between multiple turns, to ensure the quality of multi-turn dialogues. (4) We conduct experiments across multiple Chinese and English benchmarks to validate the effectiveness and reliability of our training strategy and datasets.

# Methodology Continue Pre-training

Data Collection and Decontamination To optimize the use of existing general data resources and minimize the cost of acquiring new medical-related data, we aim to extract medical-specific pre-training data from $1 5 \mathrm { T }$ widely-covered general corpus. These datasets include web content, encyclopedias, books, and academic papers, such as C4 (Raffel et al. 2023), Pile, Wudao, and PubMed, etc. To ensure the high quality of the domain-specific data, we implement a rigorous collection process that includes domain classification and quality assessment1.

Domain Classification Since the general pre-training corpus is sourced from diverse datasets and lacks clear domain labels, we first conduct domain classification to extract high-quality medical data. Specifically, we sample $4 0 \mathrm { k }$ data from general corpus and use GPT-4 to perform two rounds of domain labeling to enhance accuracy. Data with inconsistent labels across two rounds is removed, leaving us with $3 6 \mathrm { k }$ high-quality seed data. We observe that certain categories, such as artificial intelligence and computers, have long tails. To address this imbalance, we utilize GPT-4 to generate additional synthetic data for these long-tail categories. Finally, we design a domain classifier based on the bge- $\cdot \mathrm { m } 3 ^ { 2 }$ . We try a variety of multilingual pre-training models to train domain classifiers, details can be found in the Appendix A.

Rule-based Data Quality Filtering Quality filtering is a crucial step in processing pre-training corpus. To eliminate noisy data, we use a rule-based filtering solution, including rules for removing data with insufficient tokens, excessive special characters, toxic content, and private information.

LLM-based Data Quality Filtering By sampling and evaluating the data after rule filtering, we identify several issues: (1) The data includes advertising and marketing content, which could significantly skew the model’s output preferences; (2) The data contains grammatical errors, semantic inconsistencies, and spliced, unrelated content, as well as image and video clips. Such data is detrimental to model training as it provides minimal valuable information for autoregressive learning. To address these issues, we design a data quality assessment model, DataRater, to assess data quality in terms of grammatical accuracy, information density, semantic consistency, and domain relevance, and further filter out low-quality content. Specifically, we extract $2 0 \mathrm { k }$ data from the rule-based filtered data and score them twice using the GPT-4, ranging from 0 to 5. Data with a score discrepancy of about 2 points between the two assessments is removed, resulting in a final set of 15k high-quality training data. Finally, we train the DataRater based on the bge-m3. We also try a variety of multilingual pre-training models, details can be found in the Appendix B.

![](images/29cc5997571ef59a79b0a064aa6dca074f06124c9db0e34ff3b3c6bc5d67a3d7.jpg)  
Figure 1: The overall pipline of CareBot-Chat (RL), which includes the two-stage continue pre-training, supervised fine-tuning and the DPO process.

Training Strategy To gradually align the data distribution between pre-training and fine-tuning and minimize the loss of knowledge acquired during pre-training, we design a novel two-stage CPT strategy. This approach ensures a stable integration of medical knowledge into the LLM.

Stable CPT To balance medical domain knowledge with general knowledge, we first implement a Stable CPT stage, which ensures the model maintains and enhances its general language understanding while concentrating on medical information. In this stage, we combine a high-quality medical pre-training corpus with general data via the ratio as 19:1, with a token-level distribution of 1:9 for Chinese:English. We conduct adequate experiments to search both ratios, detailed results are available in the Appendix C.

Boost CPT To integrate medical knowledge during the model pre-training phase and facilitate a smooth transition to domain-specific tasks, we then design a Boost CPT phase. In this phase, we combine a very high-quality medical pretraining corpus with open-source medical SFT data at a 1:1 ratio, with a token-level distribution of 4:6 for Chinese:English. Notably, throughout these two phases, we progressively increase the proportion of Chinese data.

# Supervised Fine-Tuning

To enhance model’s ability to follow medical instructions and better adapt to specific medical scenarios, we conduct the SFT. This process involves using conversational-style data (comprising both queries and responses) to finetune the pretrained LLM. In the following sections, we will explore the details of data construction and training methods.

Data Construction Our SFT dataset comprises a diverse array of question types, including multiple-choice questions from medical exams, single-turn disease diagnoses, and multi-turn health consultations. It integrates data from seven publicly available sources: Chinese Medical Dialogue Data3, Huatuo26M (Li et al. 2023a), MedDialog (Zeng et al. 2020), ChatMed Consult Dataset (Tian et al. 2023), ChatDoctor (Li et al. 2023b), $\mathrm { C M B ^ { 4 } }$ , and MedQA (Jin et al. 2021). We preserve portions of authentic doctor-patient conversations and augment the dataset by rewriting the remaining content. For these rewrites, we use real-world medical scenarios as prompts and generate responses via GPT-4. We believe this ensures the diversity of the SFT dataset, which can help the CareBot better adapt to different types of medical problems and patient situations, thereby improving its performance in a variety of scenarios.

As stated in Zhou et al. (2023), a relatively small, highquality dataset can be sufficient for fine-tuning LLMs, our focus is on efficiently filtering ”good data” from massive data to achieve competitive performance with a minimal amount of data. Like standard data cleaning processes, our approach begins by removing duplicates and eliminating data associated with security concerns such as violence, bias, and pornography. In the following sections, we specifically introduce the data selection methods.

Single-turn Medical Dialogue Data Following Liu et al. (2024); Zeng et al. (2024), we believe that ”good data” should have a complex instruction and a high-quality response. Therefore, We adopt the approach from Deita (Liu et al. 2024), which scores each instance along two dimensions: instruction complexity score $c _ { i }$ and response quality score $q _ { i }$ . By multiplying $c _ { i }$ with $q _ { i }$ , we combine the complexity score and quality score to obtain a comprehensive score. Finally, we set a score threshold to select the most effective data instances in the massive data pool.

Multi-turn Medical Dialogue Data For multi-turn dialogues, we initially use Deita to compute the score $s _ { i }$ for each individual turn and then average these scores to derive the final score for the entire dialogue. However, we identify two specific challenges in multi-turn dialogues compared to single-turn dialogues: (1) The low correlation between different turns can negatively affect the relevance of earlier information for subsequent turns; (2) Excessive correlation between turns can lead to significant context duplication and redundant information. To address these issues, we propose the ConFilter method, which uses a score $C F$ based on cross-entropy loss, to assess the influence of historical information on each turn. The details of this approach are outlined as follows:

In the instruction-tuning process, the loss of a sample pair $( H , T )$ is calculated by continuously predicting the next tokens in the current turn $T$ given their previous tokens and the history information $H$ :

$$
L _ { \theta } ( t _ { i } | H ) = - \frac { 1 } { N } \sum _ { j = 1 } ^ { N } l o g P ( w _ { i } ^ { j } | H , w _ { i } ^ { 1 } , w _ { i } ^ { 2 } , . . . , w _ { i } ^ { j - 1 } ; \theta )
$$

where $H = \{ t _ { 1 } , t _ { 2 } , . . . t _ { i - 1 } \}$ , $t _ { i }$ is the current turn, $w _ { i } ^ { j }$ is the $j$ -th token in the $i$ -th turn, and $N$ is the number of tokens of the current turn. We define $L _ { \theta } ( t _ { i } | H )$ as the Conditioned Information Score, which measures the ability to generate the current turn under the guidance of corresponding historical information.

To measure the ability of LLM to generate this turn alone, we also define a Direct Information Score:

$$
L _ { \theta } ( t _ { i } ) = - \frac { 1 } { N } \sum _ { j = 1 } ^ { N } l o g P ( w _ { i } ^ { j } | w _ { i } ^ { 1 } , w _ { i } ^ { 2 } , . . . , w _ { i } ^ { j - 1 } ; \theta )
$$

We believe that the higher Direct Information Score may indicate that the turn is more challenging or complex. Finally, we try to estimate $C F$ by calculating the ratio between $L _ { \theta } ( t _ { i } )$ and $L _ { \theta } ( t _ { i } | H )$ .

$$
C F _ { \theta } ( H , T ) = \frac { L _ { \theta } ( t _ { i } | H ) } { L _ { \theta } ( t _ { i } ) }
$$

Here, if $C F > 1$ , it means historical information has a negative impact on current turn, that is, the correlation between contexts is very low. If $C F < 1$ , it means historical information has a positive impact on current turn, that is, the correlation between contexts is high. However, too small $C F$ means that the context is highly repeated and the information is highly redundant. We also set a threshold to filter the data.

# RLHF

We enhance the model’s capabilities using Direct Preference Optimization (DPO) (Rafailov et al. 2023) after the SFT stage. To align the model’s output with human preferences while preserving the foundational abilities gained during the CPT and SFT stages (Lu et al. 2024), we construct subjective preference data and objective preference data using samples that have the same distribution as the SFT dataset:

Subjective Preference Data We aim to construct dpo pairs where the chosen response aligns closely with human preferences. For each prompt, we first ask GPT-4 to respond as a professional and helpful doctor. Then, using GPT-4, we evaluate the superiority or inferiority of the our CareBotChat‘s response and GPT-4’s response. The evaluation considers four aspects: fluency, relevance, completeness, and proficiency in medical. We select the superior response as the chosen response for the dpo pair and the inferior response as the rejection response.

Objective Preference Data While RLHF can guide LLMs to align with human expectations, numerous studies show that this method can cause LLMs to forget abilities acquired during pre-training and SFT stages (Bai et al. 2022; Dong et al. 2023a), leading to an ”alignment tax” (Dong et al. 2023b; Sun et al. 2024). To mitigate this issue, we construct objective preference data. Specifically, for objective prompts with known ground truth answers, we consider the ground truth as the chosen response and randomly select incorrect answers from the remaining options as rejection responses. For instance, in multiple-choice questions, if the ground truth is option A, we randomly select from options B, C, and D to construct the rejection response.

# Experimental Setup

# Baselines

We conduct a comparative analysis of our model against most representative open-source medical LLMs including HuatuoGPT-7B (Zhang et al. 2023), Zhongjing-13B (Yang et al. 2023b), MedAlpaca-7B (Han et al. 2023), BioMistral7B (Labrak et al. 2024), and HuatuoGPT ll-7B (Chen et al. 2023). These models are specifically designed for medical applications, showcasing robust open-domain chat capabilities and applicability to various medical scenarios. Additionally, we also compare results from the closed-source model GPT-3.5-turbo. More details can be found in Appendix E.

# Medical Benchmark

We comprehensively evaluate CareBot’s medical capabilities from two aspects, one is medical concept knowledge, and the other is medical consultation ability. For medical concept knowledge, CareBot is evaluated using three popular Chinese medical benchmarks (CMB (Wang et al. 2024), CMMLU-Med (Li et al. 2024), C-Eval-Med (Huang et al. 2023)) and four English medical benchmarks (MedQA (Jin et al. 2021), MMLU-Med (Hendrycks et al. 2021), MedMCQA (Pal, Umapathi, and Sankarasubbu 2022), and PubMedQA (Jin et al. 2019) test set). Accuracy is served as the primary evaluation metric for this aspect. For singleturn medical consultation questions, we use the Huatuo26Mtest (Li et al. 2023a), evaluating responses via HuatuoEval (Chen et al. 2023) for pairwise comparisons.Additionally, multi-turn medical consultation questions are assessed using CMtMedQA (Yang et al. 2023b) and CMB-Clin (Wang et al. 2024). Consistent with Wang et al. (2024), the model’s responses are rated based on the fluency, relevance, completeness and medical proficiency of the reference answers. More details can be found in Appendix E.

Table 1: The results of five medical concept knowledge benchmarks. $\dagger$ means the result of 3-shot (consistent with the original paper) and others are 0-shot. All scores are averaged over three random runs. $\mathrm { \widetilde { p } } { < } 0 . 0 5$ under t-test)   

<html><body><table><tr><td rowspan="2">Models</td><td colspan="2">English</td><td colspan="2">Chinese</td><td></td></tr><tr><td>MedQA MMLU-Med</td><td>CMB</td><td>CMMLU-Med</td><td>C-Eval-Med</td><td>Avg.</td></tr><tr><td>ChatGPT</td><td>52.24</td><td>69.96 43.26</td><td>50.37</td><td>48.80</td><td>52.93</td></tr><tr><td>HuatuoGPT-7B</td><td>16.63</td><td>25.62 19.68</td><td>23.11</td><td>25.66</td><td>22.14</td></tr><tr><td>Zhongjing-13B</td><td>11.28 16.90</td><td>20.39</td><td>23.85</td><td>30.09</td><td>20.50</td></tr><tr><td>MedAlpaca-7B</td><td>49.74</td><td>62.72 23.29</td><td>25.38</td><td>27.43</td><td>37.71</td></tr><tr><td>Biomistral-7B</td><td>50.60t 59.08†</td><td>23.83</td><td>26.55</td><td>25.67</td><td>37.15</td></tr><tr><td>HuatuoGPTIl-7B</td><td>41.13 51.44</td><td>60.39</td><td>59.08</td><td>62.40</td><td>54.89</td></tr><tr><td>CareBot-Chat</td><td>63.71</td><td>71.53 52.50</td><td>56.42</td><td>63.72</td><td>61.58</td></tr><tr><td>CareBot-Chat (RL)</td><td>63.63</td><td>71.44 52.45</td><td>56.58</td><td>62.83</td><td>61.39</td></tr></table></body></html>

![](images/9b420364f8a9b147c5437bc80e14797a4b74c09d267131198b95568c811aced1.jpg)  
Figure 2: The performance of seven benchmarks for our CPT model, CareBot.

# Experimental Results for CPT

In Figure 2, we evaluate our CPT model, CareBot, on seven common medical benchmarks. Considering that our goal is to train a medical model that performs well in both Chinese and English, we strive to improve Chinese medical ability while ensuring that English medical ability of the model is slightly reduced. We observe that for English benchmarks (MMLU-Med, PubMedQA, MedQA, MedMCQA), the performance of CareBot (Stable CPT) and CareBot (Stable CPT & Boost CPT) shows a slight decrease. This is expected, given that the LLaMA-8B-base model already has strong English capabilities. However, for Chinese benchmarks (CEval-Med, CMMLU-Med, CMB), our models demonstrate significant improvements, with particularly notable gains in models trained using the two-stage approach. This confirms that our two-stage CPT strategy effectively integrates medical domain knowledge into the model, resulting in robust enhancements to its Chinese medical capabilities.

# Experimental Results for Alignment Results for Medical Concept Knowledge

We present the results from five widely used benchmarks in Table 1. For English benchmark MedQA, our model

CareBot-Chat outperforms ChatGPT by 11.47 points and BioMistral, the strongest open-source medical LLM, by $1 3 . 1 1 \%$ . For MMLU-Med, CareBot-Chat achieves a $1 . 5 7 \%$ improvement over ChatGPT and surpasses MedAlpaca by 8.81 points. For English benchmarks CMB and CMMLUMed, HuatuoGPT II emerges as the top-performing model and our model does not have an advantage over it. For CEval-Med, our CareBot only achieves competitive results with HuatuoGPT II. This is because CareBot is built on LLaMA3-8B, an LLM with inherent strengths in English. Therefore, its performance in Chinese aligns with expectations. Nevertheless, in terms of average scores, CareBotChat exceeds HuatuoGPT II, the leading open-source medical model, by $6 . 6 9 \%$ , and ChatGPT by $8 . 6 5 \%$ . These outcomes underscore CareBot’s exceptional performance in medical applications, establishing it as a significant contributor to the field of medical AI.

# Results for Medical Consultation Ability

Multi-turn Dialogue In Table 2 and 3, we present the results for the multi-turn dialogue benchmarks CMtMedQA and CMB-clin, respectively. Overall, the performance of two baselines is basically the same, with notable performance from HuatuoGPT and HuatuoGPT ll. Across four dimensions, fluency and proficiency scores are particularly high, indicating coherent responses and a solid grasp of medical terminology by the medical LLMs. However, relevance and completeness scores are lower, suggesting room for improvement in providing highly relevant and comprehensive answers tailored to specific questions. Our model, CareBotChat (RL), achieves strong performance across all dimensions, averaging scores of 4.58 and 4.31 respectively, with notable strengths in relevance and completeness. This underscores the effectiveness of our high-quality SFT dataset and our proposed multi-turn dialogue selection method, significantly enhancing the model’s contextual understanding and ensuring dialogue coherence and consistency. We further analyze the advantages of our models in multi-turn dialogues in Section Advantages of Multi-turn Dialogue.

Single-turn Dialogue Figure 3 (a) displays the comparison results between our CareBot-Chat and various baselines on the single-turn dialogue benchmark Huatuo26Mtest. It is evident that CareBot-Chat achieves comparable performance to ChatGPT and HuatuoGPT, indicating that the baseline HuatuoGPT performs similarly to ChatGPT under this evaluation framework. Moreover, our model significantly outperforms Zhongjing, MedAlpaca, and BioMistral. The lower performance of MedAlpaca and BioMistral can be attributed to their limited Chinese language capabilities and inadequate medical SFT data. It is noteworthy that Zhongjing, incorporating pre-training, SFT, and RLHF stages, performs poorly. This is likely due to the two training stages of the base model, leading to catastrophic forgetting or model degradation. Additionally, its instruction finetuning data is both limited and of inferior quality, which explains why a model with larger parameters than our CareBot performs substantially worse. However, we observe that our model only competes with HuatuoGPT ll-7B in the HuatuoEval framework. We will further discuss this phenomenon in Section Case Study. In Figure 3 (b), we also compare our CareBot-Chat (RL) model with other baselines, and basically achieve the same performance as CareBot-Chat.

Table 2: The scores of different models on CMtMedQA.   

<html><body><table><tr><td>Models</td><td>Fluency</td><td>Relevance</td><td>Completeness</td><td>Proficiency</td><td>Avg.</td></tr><tr><td>ChatGPT</td><td>4.94</td><td>4.21</td><td>3.98</td><td>4.04</td><td>4.29</td></tr><tr><td>HuatuoGPT-7B</td><td>4.94</td><td>3.28</td><td>3.22</td><td>4.19</td><td>3.91</td></tr><tr><td>Zhongjing-13B</td><td>2.26</td><td>1.68</td><td>1.62</td><td>2.63</td><td>2.05</td></tr><tr><td>MedAlpaca-7B</td><td>4.35</td><td>2.18</td><td>1.97</td><td>3.29</td><td>2.95</td></tr><tr><td>Biomistral-7B</td><td>4.48</td><td>2.45</td><td>2.17</td><td>3.55</td><td>3.16</td></tr><tr><td>HuatuoGPTIl-7B</td><td>4.96</td><td>3.41</td><td>3.47</td><td>4.27</td><td>4.03</td></tr><tr><td>CareBot-Chat</td><td>4.99</td><td>4.67</td><td>4.20</td><td>4.26</td><td>4.53</td></tr><tr><td>CareBot-Chat(RL)</td><td>4.96</td><td>4.70</td><td>4.31</td><td>4.34</td><td>4.58</td></tr></table></body></html>

Table 3: The scores of different models on CMB-Clin.   

<html><body><table><tr><td>Models</td><td>Fluency</td><td>Relevance</td><td>Completeness</td><td>Proficiency</td><td>Avg.</td></tr><tr><td>ChatGPT</td><td>4.78</td><td>3.75</td><td>3.77</td><td>4.01</td><td>4.08</td></tr><tr><td>HuatuoGPT-7B</td><td>4.69</td><td>3.25</td><td>3.08</td><td>4.00</td><td>3.76</td></tr><tr><td>Zhongjing-13B</td><td>3.14</td><td>2.14</td><td>1.89</td><td>3.11</td><td>2.57</td></tr><tr><td>MedAlpaca-7B</td><td>3.31</td><td>1.69</td><td>1.49</td><td>2.58</td><td>2.27</td></tr><tr><td>Biomistral-7B</td><td>3.79</td><td>2.10</td><td>1.82</td><td>3.09</td><td>2.70</td></tr><tr><td>HuatuoGPTIl-7B</td><td>4.75</td><td>3.43</td><td>3.43</td><td>4.22</td><td>3.96</td></tr><tr><td>CareBot-Chat</td><td>4.82</td><td>4.20</td><td>3.68</td><td>4.16</td><td>4.22</td></tr><tr><td>CareBot-Chat (RL)</td><td>4.74</td><td>4.28</td><td>4.01</td><td>4.21</td><td>4.31</td></tr></table></body></html>

# Analysis and Discussion

# One Stage CPT vs Two Stage CPT

Figure 4 illustrates the changes in Acc for the standard CPT (represented by the orange line) and our two-stage CPT method (shown with both the orange and blue lines). Initially, as the number of training tokens increases, the Acc rises but fluctuates significantly. After reaching 45B tokens, the Acc stabilizes around the LLaMA-8B-base level, indicating that the medical CPT has reached a relatively stable state. Introducing the Boost CPT stage results in a marked and consistent improvement in Acc. In contrast, continuing training with 20B additional tokens using the Stable CPT approach shows minimal changes in performance. These findings strongly demonstrate that our two-stage CPT method effectively facilitates a smooth transition from general knowledge to domain-specific knowledge, from English to Chinese, and from PT to SFT.

# Advantages of Multi-turn Dialogue

To investigate the reasons behind our model’s strong performance in multi-turn dialogues, we analyze the quality of each turn of responses, as shown in Table 4 (Appendix G). Our analysis reveals that, except for the first turn, CareBot-Chat’s average score was 0.25 lower than that of HuatuoGPT II. However, in subsequent turns, CareBot-Chat consistently outperforms HuatuoGPT II. Furthermore, our advantage becomes increasingly pronounced as the number of dialogue turns increases. Specifically, in terms of fluency and proficiency, our model performs comparably to HuatuoGPT II. In contrast, HuatuoGPT II’s performance in relevance and completeness significantly deteriorates with more turns, while CareBot-Chat maintains stable performance. This highlights CareBot-Chat’s superior capability in multi-turn dialogues, demonstrating its better understanding of dialogue context. We attribute this advantage to our carefully curated multi-turn dialogue SFT data, which retains dialogues with contextual relevance without excessive repetition. Additionally, Figure 10 and 11 in Appendix G provide comparisons of responses from CareBot-Chat and HuatuoGPT II in the same multi-turn dialogue, further confirming our model’s effectiveness. Notably, in the first turn, HuatuoGPT II’s response is longer and more detailed than ours. However, from the second turn, while HuatuoGPT II’s answers remain detailed, they become increasingly irrelevant and lack coherence with the ongoing dialogue. Generally, our results strongly indicate that CareBot-Chat has a significant advantage in multi-turn dialogues, demonstrating superior contextual understanding and coherence.

![](images/eaa7be563a4e377116e8712c64aa9949e83f68b437d0fc79b69656ba1498c5f1.jpg)  
Figure 3: Comparison of CareBot-Chat and CareBot-Chat (RL)’s predicted answers and other baselines’ predicted answers on single-turn dialogues from Huatuo26M-test.

# Effect on ConFilter

To evaluate the effectiveness of our multi-turn SFT data selection method, ConFilter, we conduct a comparative experiment. We finetune the pre-trained CareBot using two datasets: 110k high-quality multi-turn dialogues selected by ConFilter and 110k randomly selected samples from the original CMtMedQA dataset. As shown in Figure 5, both datasets achieve comparable fluency scores. However, in the other three dimensions, fine-tuning with the high-quality data significantly outperforms the randomly selected data. These results underscore the effectiveness of ConFilter in enhancing dialogue coherence and relevance by focusing on contextual correlations, thereby helping the model better understand and maintain conversation history.

# Case Study

Figure 3 (a) illustrates our Carebot does not hold a significant advantage over HuatuoGPT II. Here, we present a case study. As depicted in Figure 12 (Appendix H), we provide an example where the output of CareBot-Chat is deemed inferior to that of HuatuoGPT II under the HuatuoEval evaluation framework. However, upon closer examination, we found there are some issues in HuatuoGPT II’s response, particularly in the statement ”such as $100 \%$ skim milk or low-fat milk. These milks usually contain more protein and calcium, and have lower sugar and fat content.” Firstly, this statement itself is an hallucination, that is, skim milk or lowfat milk does not contain more protein and calcium, but only has lower fat content. Furthermore, medical professionals confirm that whole milk is more suitable for infants due to its nutritional benefits, including fats crucial for development. This aligns with responses generated by GPT-4. Additionally, HuatuoGPT II often includes repetitive content such as ”It is better to choose milk designed specifically for children,” which, despite mimicking a doctor’s tone and offering longer responses, sometimes lacks relevance and completeness. This approach occasionally introduces ambiguities.

![](images/9274bd70ab69195e033f65c7b9715c27d0576ba11766c1a2340d7b7ce9eefcf6.jpg)  
Figure 4: Comparison of the loss between our proposed twostage CPT and the plain CPT.

![](images/c9dca41a6a48733301e61f8bb978b74789928f5468527cc5e2a44c79b34e9da5.jpg)  
Figure 5: The comparison of the high-quality multi-turn dialogues selected by our ConFilter and the randomly selected multi-turn dialogues. These are all from CMtMedQA.

# Conclusion

In this paper, we propose CareBot, a bilingual medical LLM, which is designed to enhance medical diagnostics, treatment planning, and medical education. To bridge gaps between data with different distributions, we design a novel two-stage continuous pre-training (CPT) approach, i.e., stable CPT and boost CPT. A model for evaluating data quality during CPT, DataRater, is also proposed. Besides, we further present ConFilter for selecting high-quality multiturn dialogues, which is crucial to improving the model’s ability to handle more complex dialogues. CareBot’s performance, validated through extensive testing on Chinese and English medical benchmarks, demonstrates significant improvements in medical consultation and teaching, showcasing the effectiveness of its training strategies and datasets.