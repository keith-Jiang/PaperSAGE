# Relation Also Knows: Rethinking the Recall and Editing of Factual Associations in Auto-Regressive Transformer Language Models

Xiyu Liu1,2, Zhengxiao $\mathbf { L i u } ^ { 1 , 2 * }$ , Naibin $\mathbf { G u } ^ { 1 , 2 }$ , Zheng $\mathbf { L i n } ^ { 1 , 2 * }$ , Wanli $\mathbf { M } \mathbf { a } ^ { 3 }$ , Ji Xiang1, Weiping Wang1

1Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China 2School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China 3University of Electronic Science and Technology of China, Chengdu, China {liuxiyu, liuzhengxiao, gunaibin, linzheng, xiangji, wangweiping}@iie.ac.cn, uestc_wlma@163.com

# Abstract

The storage and recall of factual associations in auto-regressive transformer language models (LMs) have drawn a great deal of attention, inspiring knowledge editing by directly modifying the located model weights. Most editing works achieve knowledge editing under the guidance of existing interpretations of knowledge recall that mainly focus on subject knowledge. However, these interpretations are seriously flawed, neglecting relation information and leading to the over-generalizing problem for editing. In this work, we discover a novel relationfocused perspective to interpret the knowledge recall of transformer LMs during inference and apply it on single knowledge editing to avoid over-generalizing. Experimental results on the dataset supplemented with a new R-Specificity criterion demonstrate that our editing approach significantly alleviates over-generalizing while remaining competitive on other criteria, breaking the domination of subject-focused editing for future research.

# Code — https://github.com/sunshower-liu/RETS Extended version — https://arxiv.org/abs/2408.15091

# Introduction

Language models are often regarded as knowledge bases, storing factual associations in parameters which can be simply recalled through prompting (Petroni et al. 2019; Lester, Al-Rfou, and Constant 2021; Jiang et al. 2020; Roberts, Raffel, and Shazeer 2020; Petroni et al. 2020; Heinzerling and Inui 2021; Wang, Liu, and Zhang 2021). For instance, for the factual association shown in triplet <Marco Reus, citizen-of, $\mathbf { O } { > }$ with the subject Marco Reus and the relation citizen-of, the object O can be obtained from the next token prediction of GPT-like language models given the prompt "Marco Reus is a citizen of ". Recent works investigate where factual knowledge is stored and how the factual knowledge is extracted from auto-regressive transformer LMs, suggesting that the feedforward MLP sublayer performs as key-value memories which is the key component for the storing and recall of factual associations (Geva et al. 2021, 2022, 2023). The sight into the interpretation of auto-regressive transformer

![](images/7822d28dfc79e18a5d81827ae76fe4b6ff3a3b5575a6ef7fe68a30e58641d417.jpg)  
Figure 1: The over-generalizing problem. The circle in green denotes the correctly edited target entity and circles in red denote that the entities unrelated to target editing are also changed unexpectedly.

LMs makes renewing their knowledge by directly modifying the MLP weights possible, inspiring knowledge editing via the locate-then-edit paradigm that modifies the located weights (Yao et al. 2023; Meng et al. 2022a,b; Li et al. 2024a). This sort of methods provide convenience for altering the behavior of models permanently on a small amount of facts while ensuring least side-effects, especially meaningful in the era of large language models.

However, existing locate-then-edit methods suffer from various deficiencies (Li et al. 2024b; Hoelscher-Obermaier et al. 2023). We note an over-generalizing problem that is serious in practical applications where unrelated relationships of the target editing subject experience unexpected alterations during the editing of a certain factual association. For example, the wife and other relationships of Marco Reus predicted by the models will be changed to Britain-related attributes while ROME (Meng et al. 2022a) edits the citizenship of Marco Reus to Britain, as illustrated in Figure 1. This makes the contents generated by the edited models untrustworthy.

We conjecture that these locate-then-edit methods suffer from over-generalizing since they only focus on subjects and fail to take relations of factual associations into consideration during editing. Thus we firstly investigate what happens on relation tokens (e.g. "was born in") in knowledge recall during inference to understand why previous works fail to take relations into account. The interpretation of knowledge recall involves which positions of tokens and which layers of autoregressive transformer LMs primarily contribute to the prediction, and what interpretable information is encoded at the corresponding points. Through causal tracing (Meng et al. 2022a) for relations, we discover that the most contributing MLP and multi-head self attention MHSA sublayers for the propagation of relation representations appear at the last relation token. Furthermore, we analyze the trend of attributes rate and the target object ranking flow via the vocabulary lens (Geva et al. 2021) of hidden representations at the identified last relation token across layers. Through the analysis results, we conclude with the relation-focused interpretation of knowledge recall that relation-related attributes (i.e. relational knowledge) are aggregated from the first layer till middle-late layers at the last relation token and that the target object token is extracted from the aggregated relational knowledge. We also validate the importance of MLP over MHSA for the aggregation of relational knowledge by the decline of attributes rate after blocking the MLP and MHSA sublayers respectively during inference. According to the investigation results, we notice that the inference of relations takes place at the last relation token and practically completes in middle-late layers. However, previous works achieve editing via modification of MLP in the middle-early layer at the last subject token, earlier than the inference of relations is completed and also unable to attend to the last relation token behind due to the nature of auto-regressive transformer LMs. As a result, previous locate-then-edit methods fail to take relational knowledge into account and tend to modify no matter what relationships of the target editing subject, leading to the over-generalizing problem.

In order to take relations into consideration, we propose to edit under the guidance of the novel relation-focused interpretation that modifies the MLP in the end of aggregation of relational knowledge (i.e. in the middle-late layer at the last relation token). Although simply editing at this point can attend to the subject, it loses the specificity on predictions of prompts with the same relation but different subjects with target editing (i.e. neighborhood subject prompts). Therefore, to make the hidden representations of neighborhood subject prompts more distinguishable at this point, we add an optimization target to the deduction of the weight modification to enhance the difference between such neighborhood prompts, constraining the editing to the certain subject. To sum up, we propose the Relation-focused Editing for auto-regressive Transformer LMs with Subject constraints (RETS) method to solve the problem of over-generalizing in single knowledge editing initially and verify the reliability of the novel relation-focused interpretation.

For evaluation, we supplement the COUNTERFACT (Meng et al. 2022a) dataset with a new criterion Relation Specificity (i.e. R-Specificity) that measures the influence on unrelated facts of the edited subject. Experimental results on the supplemented dataset show that our editing method avoids over-generalizing by outperforming the state-of-theart locate-then-edit methods over $5 0 \%$ on Relation Specificity, while remaining competitive with the baselines on the previous criteria. Our strategy of single knowledge editing exhibits the most balanced performance overall and also validates the relation-focused interpretation on the recall of factual associations in auto-regressive transformer LMs, providing a novel perspective for future research on knowledge editing and the recall mechanism.

# Related Work

Interpretability of Transformer Language Models. We group the works that focus on the storage and recall mechanism of factual associations in GPT-like models (Zhao et al. 2024; Luo and Specia 2024; Kroeger et al. 2024) based on concerning where factual knowledge is stored and how the knowledge is retrieved during inference.

The works concerning the storage of factual associations localize the knowledge captured by different transformer components(Vaswani et al. 2017; Kobayashi et al. 2020; Geva et al. 2022, 2021), suggesting that MLP sublayers, also known as the Feed-Forward Networks, act as key-value memories that store the factual associations (Geva et al. 2021). They further point out that each key-value pair of the MLP works as a sub-update that updates the token representation additively (Geva et al. 2022). Meanwhile, the multi-head selfattention MHSA layer is commonly known for its importance in linguistic capabilities (Abnar and Zuidema 2020; Katz and Belinkov 2023; Kobayashi et al. 2024). These works provide a prerequisite for our preference to focus on MLP sublayers in knowledge recall.

The other works trace the information flow for the recall of factual associations during inference (Meng et al. 2022a; Geva et al. 2023; Hernandez et al. 2023). One of them reveals the distinct set of middle-early MLP layers that significantly contribute to the factual predictions during processing the last-subject token via causal mediation analysis (Meng et al. 2022a). Another work subsequently unveil that the representation at the last-subject position is enriched with subjectrelated attributes (i.e. subject knowledge) through middleearly MLP weights, but it ignores the existence of relational knowledge in knowledge recall (Geva et al. 2023). Although some researchers (Hernandez et al. 2023) notice the role of relation, they explain the computation of a subset of relations as a well-approximated single-linear transformation on the subject representation, still limited to the subject-focused perspective that predicted tokens are extracted from subject knowledge and relations only function to map the subject knowledge to prediction.

As far as we know, none of the existing works about the interpretation of knowledge recall pays attention to the humaninterpretable information of the relation representation, ignoring the relational knowledge. We are the first to explore the factual information recalled by the relation during inference.

Knowledge Editing. Knowledge editing methods intend to alter the behavior of language models within the domain related to the edited fact, avoiding side-effects on unrelated facts (Yao et al. 2023; Dai et al. 2022; De Cao, Aziz, and Titov 2021; Dong et al. 2022; Mitchell et al. 2022; Hase et al. 2023). A line of locate-then-edit methods are proposed with the support of the recall mechanisms mentioned above, localizing a decisive MLP weight in middle-early layers at the last-subject position and directly modify it through rank-one model editing ROME (Meng et al. 2022a) for each single factual association. MEMIT (Meng et al. 2022b) improve ROME to be applicable on numerous edits simultaneously by spreading the update evenly over several middle MLP sublayers while processing the subject representation. PMET (Li et al. 2024a) further obtains more precise FFN output at the last-subject position for editing by taking both MHSA and FFN information into consideration during optimization.

However, the state-of-the-art ROME-like methods primarily ignore the relation information while editing on the subject representation, exhibiting the deficiency of over-generalizing. Unlike these methods, we edit the auto-regressive transformer LMs on the relation representation while being able to take both the relation and the subject information into consideration.

# Exploring the Role of Relation in Knowledge Recall

We firstly explore what happens on relations in knowledge recall through causal tracing and the analyses on vocabulary lens of hidden representations.

# Background and Notation

We give a description on the propagation within autoregressive transformer LMs during inference.1 Given an input text, these auto-regressive transformer LMs tokenize the input sequence into $t _ { 1 } , t _ { 2 } , . . . , t _ { N }$ of length $N$ and embed them as vectors $h _ { 1 } ^ { 0 } , h _ { 2 } ^ { 0 } , . . . , h _ { N } ^ { 0 } \in \mathbb { R } ^ { d }$ via the embedding matrix $E \in \mathbb { R } ^ { | \nu | \times d }$ where the vocabulary size is $| \nu |$ . The models output the probability distribution of the next token $t _ { N + 1 } \in \mathbb { R } ^ { | \nu | }$ through transformer decoders of $L$ layers as follows:

$$
P ( t _ { N + 1 } | t _ { 1 } , t _ { 2 } , . . . , t _ { N } ) = \mathrm { s o f t m a x } ( \phi ( h _ { N } ^ { L - 1 } + a _ { N } ^ { L } + m _ { N } ^ { L } ) )
$$

where $h _ { N } ^ { L - 1 }$ is the residual hidden representation at $N$ -th token from the layer ahead $L$ -th layer, and $a _ { N } ^ { L }$ and $m _ { N } ^ { L }$ represent the outputs from $L$ -th MHSA and MLP sublayers respectively. $\phi$ is the prediction head, mostly the multiplication as $\phi ( x ) = E x$ or a trained linear layer. Generally, the hidden representation $h _ { i } ^ { l }$ , MLP output $m _ { i } ^ { l }$ and MHSA output $a _ { i } ^ { l }$ of layer $l \in { 1 , 2 , . . . , L }$ at token $t _ { i }$ are calculated as follows:

$$
h _ { i } ^ { l } = h _ { i } ^ { l - 1 } + a _ { i } ^ { l } + m _ { i } ^ { l }
$$

$$
a _ { i } ^ { l } = ( \sum _ { j = 1 } ^ { N } \alpha _ { i , j } ^ { l } { \bf v } ^ { l } ( h _ { j } ^ { l - 1 } ) ) W _ { O } ^ { l }
$$

$$
m _ { i } ^ { l } = W _ { D } ^ { l } \sigma ( W _ { U } ^ { l } I _ { i } ^ { l } ) , \mathbf { v } ( h _ { j } ^ { l - 1 } ) = h _ { j } ^ { l - 1 } W _ { V } ^ { l }
$$

where $W _ { U } ^ { l } ~ \in ~ \mathbb { R } ^ { d ^ { \prime } \times d }$ and $W _ { D } ^ { l } ~ \in ~ \mathbb { R } ^ { d \times d ^ { \prime } }$ are the upprojection and down-projection weights of the MLP with the inner dimension of $d ^ { \prime } . \sigma$ is the non-linear activation function. $I _ { i } ^ { l } \in \mathbb { R } ^ { d }$ is the input vector of the MLP sublayer which is often assigned to $( h _ { i } ^ { l - 1 } + a _ { i } ^ { l } )$ for most auto-regressive transformer LMs but is assigned to $h _ { i } ^ { l - 1 }$ for models with the parallel structure of MLP and MHSA. For the MHSA

\*rp 0.04 \*rp 0.015 fs fs   
ms 0.03 ms 0.010 ls 0.02 ls   
\* \*mfr 0.01 \* \*mfr 0.005 \*lr \*lr 0.00 0.000 0 5 10152025303540 0 5 10152025303540   
(a) AIER heatmap of MLP (b) AIER heatmap of MHSA

sublayer, $W _ { O } ^ { l } \in \mathbb { R } ^ { d \times d }$ is the input weight matrix and the attention weight $\alpha _ { i , j } ^ { l }$ is given by:

$$
\alpha _ { i , j } ^ { l } = \mathrm { s o f t m a x } ( \frac { \mathbf { q } ( h _ { j } ^ { l - 1 } ) \mathbf { k } ( h _ { j } ^ { l - 1 } ) ^ { T } } { \sqrt { d } } + M _ { j i } ^ { l } )
$$

$$
\mathbf { q } ( h _ { j } ^ { l - 1 } ) = h _ { j } ^ { l - 1 } W _ { Q } ^ { l } , \mathbf { k } ( h _ { j } ^ { l - 1 } ) = h _ { j } ^ { l - 1 } W _ { K } ^ { l }
$$

where $W _ { Q } ^ { l }$ , $\boldsymbol { W } _ { K } ^ { l }$ , $W _ { V } ^ { l } \in \mathbb { R } ^ { d \times d }$ are three projection matrices. $M _ { j i } ^ { l }$ is the attention mask from $j$ -th to $i$ -th hidden representation in auto-regressive models.

# Identifying Pivotal Positions of Relation

We start by identifying which positions of relation tokens primarily contribute to knowledge recall. Here we display the results of GPT2-XL (Radford et al. 2019) with 48 layers (1.5B parameters). The results of GPT-J (Wang 2021) with 28 layers (6B parameters) and Llama-2 (Touvron et al. 2023) with 32 layers (7B parameters) are displayed in Appendix D, which both show similar trends with that of GPT2-XL.

Method. We utilize causal tracing (Meng et al. 2022a) to measure the importance of each inner activation for the relation tokens through three runs: a clean run, a corrupted run and a corrupted-with-restoration run. In the clean run, a factual association prompt $< s$ , $r >$ is given to the model and the object $o$ is obtained from the output. All the clean internal activations (e.g. $m _ { i } ^ { l }$ at token position $i$ in layer $\it l \dot { \Delta }$ ) are cached during this run. Then, in the corrupted run, the embeddings of the relation $r$ is devastated by adding Gaussian noise $\mathcal { N } ( 0 , \gamma )$ to them as $\boldsymbol { r } ^ { \prime }$ and the intervened input is sent to the model to obtain the probability for the original object $o$ as $\mathbb { P } ( o | < s , r ^ { \prime } > )$ . At last, in the corrupted-with-restoration run, the corrupted input $< s$ , $r ^ { \prime } >$ is still sent to the model but the cached clean hidden states are restored sequentially during inference, resulting in the probability $\mathbb { P } ( o | < s , r ^ { \prime } > , x _ { i } ^ { l } )$ for the output of resuming the activation $x _ { i } ^ { l }$ . The difference between our relation-focused causal tracing and previous subject-focused causal tracing lies in the corrupted run, where we add Gaussian noise to the relation tokens $r$ as $\boldsymbol { r } ^ { \prime }$ instead of the subject tokens. Thus, the contribution of each activation, namely Indirect Effect of Relation (IER), is calculated as follows:

![](images/a89a8298bc6ac117c0a9498eac06366cb45758470dcd08f932ccef01a2a0fe11.jpg)  
FiFgiguruere3:2:TThehefafcatcutaulailnifnofromr amtiatoinondedtetceticotinononotnhtehveovcoacbaublaurlyarlyenlesnosfotfhethleaslta-rste-lraetilaotniorneprrepsrensteantitoatniofonrfoGrPGT2P-TX2-LXoLv.er(a1)0T0h0 parovemrapgtse. a(tat)ribTuhte sarvaetreasgoefatthtreibreuptreessreantteastiaosnshaoswshnoiwnnyienllyoewllobawrsb.a(rbs.) (Tb)heTahveearvaegreagatetraitbtruitbeustersatreatdeedcleicnlienaeta4t84-8t-hthlalyaeyrerwhihliel blbolocckikninggththeeMLPPoro rMHSSA susublbalayyere r ersepspecetcitviveleyl.y.( c()c )Thheeaavverearaggeer arannkikningsgsofo fththeetatragrgetetoobjbejcetcstsaannddr arannddoom totokkeensn.s

Ttahbalte a1c:tiAve raMgLePAsIuEbRlafyoerrds fafemraesnst fprosimt othnse oefatrloykelnasy.erTshet atbhberemviadtdiloen-slahterseitheaovfe the smaomdel,mienadniicnagtisnagstihnatFtihgeuruep2d.   

<html><body><table><tr><td rowspan="2">Position</td><td colspan="2">Average AIER(%)</td></tr><tr><td>GPT2-XL GPT-J</td><td>Llama-2</td></tr><tr><td>rp</td><td>0.03 0.03</td><td>0.01</td></tr><tr><td>fs</td><td>0.04 0.04</td><td>0.01</td></tr><tr><td>ms</td><td>0.04 0.04</td><td>0.02</td></tr><tr><td>ls</td><td>0.04 0.04</td><td>0.01</td></tr><tr><td>fr</td><td>0.06 0.06</td><td>0.01</td></tr><tr><td>mr</td><td>0.06 0.06</td><td>0.02</td></tr><tr><td>lr</td><td>2.23 3.15</td><td>0.06</td></tr></table></body></html>

$$
\mathbf { I E R } = \mathbb { P } ( o | < s , r ^ { \prime } > , m _ { i } ^ { l } ) - \mathbb { P } ( o | < s , r ^ { \prime } > )
$$

Results. Figure 2 shows the average indirect effect of relatio\*nrp(AIER) heatmaps 0o.0n4 MLP \*arpnd MHSA sublayer0.s f5or GPT2ms-XL. We note that f0o.0r3 both MmLs P and MHSA, the 0.m010ost signi\*fricant output representations a\*fre detected during inference lart the last-relation token (al\*slro the last input token). Surpris0in5g1l0y1,52t0h2e530A3I54E0R of relation pre0f5ix1e0s15(20"2r5p3"03i5n40Figure 2) cont(rai)buAtIeEsRlihttelaetmtoapthofe MprLePdictio(nb.) AIllEtRhhateatmattpeorfs fMoHr SthAe entire relation information is the hidden representation at the last-relation token. Appendix A shows the AIER heatmaps on some specific cases. For quantitative comparisons, the average AIER across layers for tokens of certain positions is shown in Table 1. The average AIER at the last-relation position is far beyond that at any other position. This indicates that the MLP and MHSA sublayers are most active at the last-relation token which is the decisive position that process the potential factual information of the relation representation. Moreover, we can tell from Figure 2(a) that active MLP sublayers amass from the early layers to the middle-late site of the model, indicating that the update process for the relation representation is of long duration and finishes at the middle-late layers. Therefore, we conclude that the inference of relations primarily takes place at the last relation token frAonmaelayrzliynlgaytehrse tLoemnisddolfe-Rlaeteprlaeyserns.

# Analyzing the Lens of Representations for Decisive RAefltaetriiodnenPtiofsyitnigonths

After identifying the decisive position that dominate the inference of relation tokens, we explore what interpretable information is encoded in the hidden representations at lastrelation position through the vocabulary lens (Geva et al. 20M2e1t,h2o0d2.3; FLourohalndwhSipcehciand2i0ca2t4e)sothnetheidmd.

Mofetih-tohdt.okeFno ra $h _ { i } ^ { l }$ aywehri cl,hwinedimcatpeisttthoethieddiesntrriebpurtieosnenptai iovne of $i$ -th token at layer $l$ , we map it to the distribiution $\mathbf { p } _ { i } ^ { l }$ over the vocabulary wilth the prediction head $\phi ( h _ { i } ^ { l } )$ which is the projection for predi ction at the output layer. Thus, the hidden represenrtiation $h _ { i } ^ { l }$ can be transformed into the ranking of tokens $r _ { i } ^ { l }$ over the voclabulary as followls:

$$
\mathbf { p } _ { i } ^ { l } = \mathrm { s o f t m a x } ( \phi ( h _ { i } ^ { l } ) )
$$

$r _ { i } ^ { l } = [ v _ { 1 } , v _ { 2 } , . . . , v _ { | \mathcal { V } | } ] \mathrm { ~ w h e r e ~ } \forall j > k , \ \mathbf { p } _ { i } ^ { l } ( v _ { j } ) > \mathbf { p } _ { i } ^ { l } ( v _ { k } )$ (o9l) Hveorcea, $v _ { j }$ asrtyanVdsacfcorrtdhiengtotokepn .thWati rhatnhkerda $j$ -ktihngisn, twhe awnhaloylez vtohceabhuildadreyn $\nu$ eapcrceosrednitnatgioton $\mathbf { p } _ { i } ^ { l }$ t. laWsit-hretlhaetiroan kpionsgitsi,owneNanaclcyozred the hidden representations at last-relation posiotion $N$ accordinfagctoua(il)atshseorciaantkiiong<osf, trh>e apcrreodsisctleadyeorbsje(icit) $o$ hgeivaettnritbhueteinspruat famcteutrailcas(sGoecvia eotn $< s , r >$ 3a)crfosrs tlhayeeresl(aiti)otnheratatcrribosutselsaryaetre mwethriich(mGeavsauretsatlh.e2s0e2m3a)nftoicr rtehleatredlnateisosnb $r$ awcereons sr lanydertsh, which measures theAsNemantic relatedne shsNbetween $r$ and the totopkreankteNd. oFkoernas $\mathbb { A } _ { N } ^ { l }$ fartoicmatnhde lceonsvoef $h _ { N } ^ { l }$ tatmtehaesluarset-mr elnat,iown token $t _ { N }$ . ForAaruetloatmioant c and convenient measurement, we cloaltlieocnt ar sveita $\mathbb { A } _ { r e l a t i o n }$ acoQnuteariyn Snegrv2i0c0eat(tsriebeutAepspfeonrdeiaxchBrfeolastaiomnp $r$ svioaf tWheikciodlalteac iQoune)rayndSetrhveicatet2r (bsuetesAraptpeeinsdciox $\mathbf { B }$ futoer sasmfpollelsoowfst:he collection) and the attributes rate is computed as follows:

$$
\mathbf { A R } ^ { l } = \frac { | \mathbb { A } _ { N } ^ { l } \cap \mathbb { A } _ { r e l a t i o n } ( r ) | } { | \mathbb { A } _ { N } ^ { l } | }
$$

wahtelraey $\mathbf { A } \mathbf { R } ^ { l }$ nisdthAerealtattriobnut(ers) riasttehoefstehteorfelattiroibnurtepsrresleantteadtiton atoflatyher $l$ pauntd $\mathbb { A } _ { r e l a t i o n } ( r )$ pit.s Itnheprsaecttiocfea,ttwriebsuetlescrtetloaptekd t=o $r$ otfotkhenisnipnutefaacchtulalyeprofomrptA.lNIn(spreaectAicpep,ewndeisxelCecftotroepx $k = 5 0$ tokens in each layer for $\bar { \mathbb { A } } _ { N } ^ { l }$ (see Appendix $\mathbf { C }$ for example).

Table 2: The percentage of facts where the objects are included in relation-related attributes and the Spearman rank coefficient $\rho \in [ - 1 , 1 ]$ between the average negative rankings of the objects and the average attributes rate.   

<html><body><table><tr><td>Model</td><td>Objects Included(%)</td><td>p</td></tr><tr><td>GPT2-XL</td><td>68</td><td>0.97</td></tr><tr><td>GPT-J</td><td>83</td><td>0.73</td></tr></table></body></html>

Results. Here we display the analysis results of GPT2-XL while the similar results of GPT-J can be found in Appendix E. Figure 3(a) presents the average attributes rates of the representation at last-relation position $h _ { N } ^ { l }$ across layers. It shows that the average attributes rate has been rising significantly from layer 0 (the first layer) till 36-th layer and become stable afterwards. This trend indicates that the representation at last-relation position accumulates relation-related attributes from the early layers to the middle-late layers of the models, which is in accordance with the occurrence of the active MLP sublayers in Figure 3(a).

To further explore the importance of MLP and MHSA for the accumulation of relational knowledge respectively, we observe the average drops of attributes rate at 48-th layer while canceling the updates from MLP sublayers or MHSA sublayers at the last token respectively, results shown in Figure 3(b). It shows that blocking MLP leads to a much more significant drop in attributes rate than blocking MHSA across layers at the last token, indicating that MLP plays a much more important role in the enrichment of relational knowledge. Figure 3(c) plots the average rankings of the target objects and random tokens in the vocabulary distributions induced at the last-relation position. We can tell from the line charts that the average rankings of the target objects has been rising from early layers to middle-late layers, while that of random tokens remains low in all layers in comparison. This indicates the target objects are promoted to the final prediction gradually since the first layer of the models. Table 2 shows the proportion of the 1000 facts where the correctly predicted objects are included in corresponding $\mathbb { A } _ { r e l a t i o n } ( r )$ and the Spearman rank correlation coefficient between the average negative rankings of the objects and the average attributes rate of the representations of the last-relation position across layers. For GPT2-XL (GPT-J), $6 8 \%$ $( 8 3 \% )$ of correctly predicted objects are included in the corresponding $\mathbb { A } _ { r e l a t i o n } ( r )$ and the Spearman rank coefficient is 0.97 (0.73), a strongly positive correlation between the extraction of the target objects and the accumulation of relation-related attributes. Thus, we conclude with the relation-focused interpretation that target objects are extracted from the relation-related attributes which are enriched at the last-relation token from early layers till middle-late layers and the MLP sublayers are essential in the update of relation representations. Under the guidance of this interpretation, we achieve editing by modifying the MLP sublayer in end of aggregation of relational knowledge (i.e. in the middle-late layer) with the relation representation (i.e. at the last-relation token) while taking subjects into account.

![](images/33760523806e192aa97c16dcd90e848dab886948ca65752e23178db6b85cbb08.jpg)  
Figure 4: Our RETS method based on the relation-focused recall of factual associations. We reveal that the last-relation representation encodes relation-related attributes (A) which are accumulated until middle-late layers and (B) the predicted object is extracted from these attributes. Based on this relation-focused interpretation, we propose the RETS knowledge editing method that (C) modifies the middle-late MLP sublayer with the constraints of the subject.

# Knowledge Editing from the Relation-focused Perspective

To further substantiate the importance of relational knowledge during inference, we apply the novel interpretation on knowledge editing to solve the over-generalizing problem.

# Method: RETS

We propose the Relation-focused Editing for auto-regressive Transformer models with Subject constraints (RETS) method that modifies the middle-late MLP sublayer with the hidden representation at the last-relation position while concerning the subject information, as illustrated in Figure 4. The representation of the last-relation position is selected for its abundant factual information and the ability to attend to the subject tokens ahead. we choose the middle-late MLP sublayer for modification after accomplishing the attributes accumulation, constrained by information propagated from the subject tokens.

We give the formulization of the RETS method here. Requested to alter a factual association $< s , r , o >$ to $< s , r , o ^ { * } >$ , we choose to manipulate the forward pass at last-relation position $p _ { r }$ by modifying the down-projection matrix $W _ { D } ^ { l _ { e } }$ of the MLP to $\tilde { W } _ { D } ^ { l _ { e } }$ in a middle-late layer $l _ { e }$ which is in the end of the accumulation of relation-related attributes. The editing target is achieved by injecting $( k _ { * } ^ { p _ { r } } , v _ { * } ^ { p _ { r } } )$ into the associative memory and optimizing the objective function as follows:

$$
\tilde { W } ^ { l _ { e } } k _ { * } ^ { p _ { r } } = v _ { * } ^ { p _ { r } }
$$

$$
| | \tilde { W } ^ { l _ { e } } K - V | | _ { F } ^ { 2 } + | | \tilde { W } ^ { l _ { e } } K _ { p _ { r } } - V _ { p _ { r } } | | _ { F } ^ { 2 }
$$

$$
\mathrm { m i n i m i z e } \ : | | W ^ { l _ { e } } K - V | | _ { F } ^ { 2 }
$$

where $k _ { * } ^ { p _ { r } }$ is the average input hidden representation of $W _ { D } ^ { l _ { e } }$ with several prefixed prompts of $< s , r >$ and $v _ { * } ^ { p _ { r } }$ is the outpwuhtevrectoproibs atihne davbeyr athge oipntpiumt zhaitdidoennproecperses e(nAtpatpieondioxf H).leThe firs∗t part of the objective function ensures tphre least chaDnge on the original key-value store $K = [ k _ { 1 } \mid k _ { 2 } \mid k _ { 3 } \mid \ldots ]$ and $\bar { V } = [ \ v _ { 1 } \ | \ \bar { \ v } _ { 2 } \ | \ v _ { 3 } \ | \ . . . \ ] . \ W ^ { l _ { e } }$ is the original associative memory that memorizes the mapping from $K$ to $V$ by Eqn. 13, solving as $W ^ { l _ { e } } K K ^ { T } = V \dot { K ^ { T } }$ . The n1ex|t p2a|rt 3of| the objective functio|n is |o em|phasize the constraint for unrelated subjects. Since the subjlect repTresentatioTn propagates to the inpoubtjevcetcitvoer $\sigma ( W _ { U } ^ { l } I _ { p _ { r } } ^ { l } )$ tofe $W _ { D } ^ { l _ { e } }$ ast $p _ { r }$ t(hrefcerornisntgrationtEfqonr.u3narenldat4e)d, wsuebcjoelcltes.ctSainscet tohfeisnupbujtevcte crteoprse $K _ { p _ { r } } = \{ k _ { 1 } ^ { p _ { r } } \mid k _ { 2 } ^ { p _ { r } } \mid k _ { 3 } ^ { p _ { r } } \mid \ldots \mid$ opfutseveecrtaolr promlptsl wiotfh dilfefeartent sruefbejrercitnsgatnodEtqhne.i3r acnodrr4e)- swpeoncdoillnegctoautspetutUofvpeirnctpourts $V _ { p _ { r } } = \mid v _ { 1 } ^ { p _ { r } } \mid v _ { 2 } ^ { p _ { r } } \mid v _ { 3 } ^ { p _ { r } } \mid \ldots \mid$ rfro...m] $m _ { p _ { r } } ^ { l }$ .evTehrauls ptrhoemfapcttsswoifthundrifefleartedn srsubjjectts1s r|ned2et |euir3edcotrhrelsepaostnadlitnegrnoautitopnutbvyecmtionrismVipzing= $| | \tilde { W } ^ { l _ { e } } K _ { p _ { r } } - V _ { p _ { r } } | | _ { F } ^ { 2 }$ .,. ]wfhreorem wmelpal.soThuasvet $W _ { ~ - } ^ { l _ { e } } K _ { p _ { r } } K _ { . p _ { r } } ^ { T } = V _ { p _ { r } } K _ { p _ { r } } ^ { T }$ bjfeocrttshaereo iegnisnuarleadstshoeclieatsitvealtmeernmaotiroy.n Bby ompitniimiiziing the˜olbejective funct2io,nwhietrhe all these constrailnets, we oTbtain the sTolutiron for $\tilde { W } ^ { l _ { e } }$ as the nceiawtivwe imghet $W _ { D } ^ { l _ { e } }$ (BseyeorAptpipmreinzdiinxg $\mathrm { H }$ hfeoprorbdjetcatiilvs)e:

![](images/fa5fb4d16d4fb528b54cdb05f0be593b9a1d50200a9b17072e421fdc5f587c7d.jpg)  
Fiigurre 5:: The perrfforrmance off RETS((purrplleliliness)) editiitingaattttheellaasts-tr-reellaatitionttokeennoonnddififfereerentn tl alayyeresrs $\mathbf { \bar { X } }$ -oamxipsa)rceodmwpitahreRdOwiMt R(oOraMngEe(loirnaen)gedliitine)g eatdithineglastt-tshuebljaesctt-stuobkjenctfotork5e0npfrorm5p0tsp.roStmdpdtse.viSattdiodneivsiastihonwins isnhoarwenasi.n areas.

$$
\begin{array} { r } { \tilde { W } ^ { l _ { e } } = W ^ { l _ { e } } + \Lambda ^ { p _ { r } } ( ( C + K _ { p _ { r } } K _ { p _ { r } } ^ { T } ) ^ { - 1 } k _ { * } ^ { p _ { s } } ) ^ { T } } \\ { \approx W _ { D } ^ { l _ { c } } + \Lambda ^ { p _ { r } } ( ( C + K _ { p _ { r } } K _ { p _ { r } } ^ { T } ) ^ { - 1 } k _ { * } ^ { p _ { s } } ) ^ { T } } \end{array}
$$

where $C = K K ^ { T }$ is the constant epsrtimparted w∗ith the unc(e1n4-) tered covaria≈ncWe Doc $k$ oΛnpra(s(liCce+ofKpWrikKipTe)di−a1ckoprsp)uTs and $\Lambda ^ { p _ { r } }$ is solved as $( v _ { * } ^ { p _ { r } } - W ^ { l _ { e } } k _ { * } ^ { p _ { r } } ) / ( ( C + \dot { K } _ { p _ { r } } K _ { p _ { r } } ^ { T } ) ^ { \dot { - } 1 } k _ { * } ^ { p _ { r } } ) ^ { T } k _ { * } ^ { p _ { r } }$ which is proportional to the gap between the initial outpupt visecstolr $W ^ { \bar { l } _ { e } } k _ { * } ^ { \bar { p } _ { r } }$ vparnd tkhWe ltearkgpret)/o(u(tCput+veKctorK $v _ { * } ^ { p _ { r } }$ .−1Tkhperl)iTnΛekapr mwehimcohryi $W ^ { l _ { e } }$ pios∗ratipop−nraolxtiomtah∗tedgbayp tbhetwmeoepdnrelthwpereingihtti $W _ { D } ^ { l _ { e } }$ .

# Experimenlt∗s

Baselines and DataSets. Our editing experimentsD are mEaxinpleyricomnednutcsted on GPT2-XL and GPT-J for each single factual association. We also eOvaulruaetde tihnegbeasxipcereidmiteintgspaereformance on Llama-2 (7B). To compare with, we choose the methods for editing each single factual association as our baselines, including Constrained Fine-Tuning $( \mathrm { F T + L } )$ (Zhu et al. 2020), the meta-learning method (MEND) (Mitchell et al. 2022) which learns the update of model weights with additional networks, ROME (Meng et al. 2022a) on the subject representation in the early site and the improved precise model editing (PMET) (Li et al. 2024a) which optimizes the parallel MHSA and MLP representations simultaneously.

For evaluation, we conduct experiments on 10, 000 (2, 000) samples of COUNTERFACT (Meng et al. 2022a) dataset for GPT2-XL (GPT-J), 1, 000 samples of COUNTERFACT for Llama-2 and 10, 000 samples of Zero-shot Relation Extraction (zsRE) (Levy et al. 2017; Meng et al. 2022a) for

GPT2-XL. We edit on the 36-th layer of GPT2-XL, 18-th layer of GPT-J and 23-th layer of Llama-2. For COUNTERFtrAacCtiTo,nw(ezsuRpEp)le(mLenvty heitsadl.a a2s0e1t7w; tMheungreelta eald. 2a0ct2s2oaf)  fhoer sGaPmTe2s-uXbjLe.ctWfeoreediatchontatrhge t ed-tithinlagyaenrdotfheGPcoTr2r-esXpLo,ndin-tgh metric Relation Specificity (R-Specificity) to measure the oFvAerC-gTe,nweerasliuzpipnlgempreonbt ltehims.dTatoasbetswpietchiufinc,regliavtedn ftahcetseodifttehde fsactm $< s _ { 1 } , r _ { 1 } , o _ { 1 } ^ { * } >$ raneadcthetaurngret aetdeidtifnagctanwdi thhtehecosrarmesepsounbdjienctg $< s _ { 1 } , r _ { 2 } , o _ { 2 } >$ ,atiwoen eSstp $\mathbb { P } [ o _ { 2 } ] > \mathbb { P } [ o _ { 1 } ^ { * } ]$ paesctihfieciRt-yS)pteocimfieciatsyurSecotrhe woivtehrt-hgeninerpaulti zpirnogmprtoobfl $< s _ { 1 } , r _ { 2 } >$ ,ecsopmecpiuftice,dgsivmeinlatrhley teoditthed efxaicstti<nsg ,mret,roic∗s>. aWned atlhseoutnersetltahtedofraigctinwailthmtehtreicssa imneclsudbijnecg t<he basic E>f,fiwcaectyestaccuracy Sco∗re sastothemeRa-sSuprectihfiec tsyu cSceosrse rwatiethotfhtearigneptutedpirtionmg,pthoef <Genera>l,izcaotimopnutaecdcusriamciylasrlcyorteoftohre generalization on the paraphrased statements, the renamed Sthuebjbeacst cSpEefcfiicfiacicty aSc-cSupreaciyfiScictoyreascctouramceyasucroerethfeorsuscpceecsi-s friactiteyofwtiatrhginetnediigtihnbgorwhitohod su∗bjects. Thewahdevraenceids tFhleu eonricgyianadl oCbojencstisotfe n<cy scor>e,sthmeeGaseunrertahleizqautiaolintyacocfugreanceyrsatceodref uflol texts. Higher scores indicate better performance for all metrics. For zsRE, the metics and evaluation results are displayed in Appendix G. Details for the construction of R-Specificity samples and detailed settings are presented in Appendix F.

Evaluation Results. Table 3 shows the evaluation results on COUNTERFACT. We observe that the existing mainstream editing methods exhibit at least one deficiency. Even though existing ROME-like methods (ROME and PMET) perform well on most criteria, they experience obvious failure on the Relation Specificity. Our RETS method outperforms the ROME-like methods over $3 0 \%$ on R-Specificity for both GPT2-XL and GPT-J while remaining competitive on other criteria, indicating that the relation-focused editing solves the over-generalizing problem for ROME initially. The evaluation result on recent Llama-2 also shows the same trend. The results on zsRE in Appendix G also demonstrate the comptehteitiRvOenMesEs-loifkeRmEeTtSh.odAsnoavnercdotalocnasRe-SofpeRciEfTicSitybefhoarvbiontgh correctly while ROME behaving erroneously on GPT2-XL is schriotwerniai,ninFdiigcuartein4g.

The ablation of the subject constraints for editing COUNTtiEonRrFeAsuCltTolneardescetno tLhlea $3 5 \%$ dalescoresahsoewosnthEenstiatmyeStprecnidf.icTithye froersuGltPsTo2-nXzLs,RwEhicnhAinpdpiecnatdeisx hGe aelfsfeoctdievemnoensstorfatehethseubcjoecmtcpoentisttirvaeintessforf tRhEeTreSl.atAionna-nfeocduosteadl ecadisteinogf.RDEeTspSitbe hoafvtihneg rceosrurletsctloyn  wGheinlerRaliOzaMtiEonbeahnadviEnngtietryroSnpeocuisfilcyitoynwGhPerTe2-RXELTiS lsohsoeswnabinouFti $2 0 \%$ 6a.nd $1 0 \%$ respectively compared with the subject-centered editing methods, RETS exhibits the most balanced performance with its simple way of combining the subject information into editing, which shows the potential of editing from relation-focused perspective. The trade-off of performance is decided by the editing position (the lastrelation token or the last-subject token) as expected. Editing at the last-relation position ensures minimal impact on unrelated relations (i.e. high R-Specificity) but loses much subject information (i.e. low S-Specificity), while the opposite is also true for editing at the last-subject position. The superiority of the relation-focused approach is that the decline of SSpecificity can be constrained by subject constraints whereas the subject-focused approach can hardly attend to the relations. Detailed discussions can be referred to Appendix J.

Table 3: The evaluation results on COUNERTFACT for GPT2-XL and GPT-J. The significantly failed values for the editing methods on basic criteria are underlined. "Score" shows the average value on the basic criteria: Efficacy, Generalization, SSpecificity and R-Specificity. "SC" stands for the subject constraints on our relation-focused editing. R-Specificity values for raw models are $1 0 0 . 0 \%$ since the criterion is constructed according to the top token predictions of the raw models. $^ { * } \mathrm { P M E T }$ is adjusted to accommodate to edit a single layer.   

<html><body><table><tr><td>Editor</td><td>Score</td><td>Efficacy</td><td></td><td>Generalization S-Specificity R-Specificity</td><td></td><td>Fluency</td><td>Consistency</td></tr><tr><td>GPT2-XL</td><td>55.9</td><td>21.0</td><td>24.1</td><td>78.6</td><td>100.0</td><td>626.8</td><td>34.7</td></tr><tr><td>FT-L</td><td>73.1</td><td>99.2</td><td>47.8</td><td>70.6</td><td>74.9</td><td>623.3</td><td>37.6</td></tr><tr><td>MEND</td><td>63.2</td><td>62.3</td><td>53.1</td><td>51.7</td><td>85.6</td><td>603.7</td><td>32.7</td></tr><tr><td>ROME</td><td>78.4</td><td>100.0</td><td>96.4</td><td>76.0</td><td>41.1</td><td>622.6</td><td>42.0</td></tr><tr><td>PMET*</td><td>79.3</td><td>99.2</td><td>94.3</td><td>76.0</td><td>47.6</td><td>622.7</td><td>41.8</td></tr><tr><td>RETS</td><td>79.7</td><td>100.0</td><td>71.5</td><td>68.6</td><td>78.5</td><td>577.4</td><td>32.6</td></tr><tr><td>-w/o SC</td><td>71.1</td><td>100.0</td><td>67.2</td><td>35.1</td><td>86.9</td><td>626.1</td><td>34.9</td></tr><tr><td>GPT-J</td><td>53.2</td><td>13.7</td><td>15.3</td><td>83.7</td><td>100.0</td><td>621.7</td><td>29.7</td></tr><tr><td>FT-L</td><td>79.3</td><td>99.6</td><td>47.4</td><td>80.1</td><td>89.1</td><td>622.5</td><td>35.3</td></tr><tr><td>MEND</td><td>75.3</td><td>96.8</td><td>51.2</td><td>53.8</td><td>99.2</td><td>620.4</td><td>32.2</td></tr><tr><td>ROME</td><td>81.7</td><td>99.9</td><td>99.0</td><td>79.4</td><td>48.5</td><td>620.5</td><td>42.7</td></tr><tr><td>PMET*</td><td>83.5</td><td>99.9</td><td>98.7</td><td>79.6</td><td>55.6</td><td>620.9</td><td>43.0</td></tr><tr><td>RETS</td><td>80.7</td><td>100.0</td><td>74.2</td><td>65.5</td><td>83.3</td><td>542.4</td><td>29.2</td></tr><tr><td>- w/o SC</td><td>74.1</td><td>100.0</td><td>82.0</td><td>23.7</td><td>90.7</td><td>618.1</td><td>34.9</td></tr><tr><td>Llama-2</td><td>52.8</td><td>13.8</td><td>16.1</td><td>81.2</td><td>100.0</td><td></td><td></td></tr><tr><td>FT-L</td><td>55.6</td><td>24.2</td><td>17.0</td><td>81.6</td><td>99.7</td><td></td><td></td></tr><tr><td>ROME</td><td>81.1</td><td>99.9</td><td>93.4</td><td>77.4</td><td>53.6</td><td>一</td><td>1</td></tr><tr><td>RETS</td><td>82.1</td><td>98.3</td><td>74.6</td><td>72.3</td><td>83.1</td><td>一</td><td></td></tr></table></body></html>

Table 4: An anecdotal example of the correct behavior for RETS and the incorrect behavior for ROME on GPT2-XL. Predictions in red denote unexpectedly changed answers.   

<html><body><table><tr><td>Editing Target: Lionel Messi is a native speaker of Chinese.</td></tr><tr><td>Original Model: [Target Prompt] Lionel Messi is a native speaker of [Prediction]Argentine [R-Specificity Prompt] Lionel Messi plays for the club called [Prediction]FCBarcelona</td></tr><tr><td>ROMEEdited: [Target Prompt] Lionel Messi is a native speaker of [Prediction] Chinese [R-Specificity Prompt] Lionel Messi plays for the club called [Prediction] Shanghai Shenhua RETSEdited:</td></tr><tr><td>[Target Prompt] Lionel Messi isa native speaker of [Prediction] Chinese [R-Specificity Prompt] Lionel Messi plays for the club called [Prediction]FC Barcelona</td></tr></table></body></html>

Layer Analysis. We test the effectiveness of RETS while editing on different layers and compare it with the behavior of ROME which edits at the last-subject token . Figure 5 plots the performance on four criteria (a,b,c,d) and the average scores (e) across layers. The performance of RETS vibrates before middle layers and become stable after middle-late layers, validating our interpretation of relation-focused knowledge recall that the object is attracted from relation-related attributes which are accumulated before middle-late layers. RETS editing on middle-late layers shows more balanced performance than editing on any layer at the last-subject token where relation information behind hardly propagates to.

# Conclusion

We discover the over-generalizing problem for previous subject-focused knowledge editing methods, and we solve this problem by further exploring the role of relations in knowledge recall. As a result, we unveil the factual information encoded for relations in auto-regressive transformer language models, and we propose the RETS single knowledge editing method based on the relation-focused interpretation. Our experiments demonstrate the effectiveness of RETS on solving the over-generalizing problem and provide the novel relation-focused perspective for future research on both the interpretation and editing of the auto-regressive transformer language models, breaking the domination of the subjectfocused perspective.

# Ethical Statement

The goal of our work is to investigate and renew the outdated or mistaken knowledge decoded in transformer language models. However, we recognize inherent risks associated with potential malicious applications like injecting harmful information. Therefore, we emphasize the importance that language models be sourced exclusively from reputable and trustworthy providers and carefully use the contents generated by these models.