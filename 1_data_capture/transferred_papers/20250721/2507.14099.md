# Context-Aware Behavior Learning with Heuristic Motion Memory for Underwater Manipulation

Markus Buchholz∗, Ignacio Carlucho∗, Michele Grimaldi∗, Maria Koskinopoulou∗ and Yvan R. Petillot∗ ∗School of Engineering & Physical Sciences, Heriot-Watt University, Edinburgh, UK

Abstract—Autonomous motion planning is critical for efficient and safe underwater manipulation in dynamic marine environments. Current motion planning methods often fail to effectively utilize prior motion experiences and adapt to realtime uncertainties inherent in underwater settings. In this paper, we introduce an Adaptive Heuristic Motion Planner framework that integrates a Heuristic Motion Space (HMS) with Bayesian Networks to enhance motion planning for autonomous underwater manipulation. Our approach employs the Probabilistic Roadmap (PRM) algorithm within HMS to optimize paths by minimizing a composite cost function that accounts for distance, uncertainty, energy consumption, and execution time. By leveraging HMS, our framework significantly reduces the search space, thereby boosting computational performance and enabling real-time planning capabilities. Bayesian Networks are utilized to dynamically update uncertainty estimates based on real-time sensor data and environmental conditions, thereby refining the joint probability of path success. Through extensive simulations and real-world test scenarios, we showcase the advantages of our method in terms of enhanced performance and robustness. This probabilistic approach significantly advances the capability of autonomous underwater robots, ensuring optimized motion planning in the face of dynamic marine challenges.

# I. INTRODUCTION

Effective motion planning in challenging underwater environments is critical, especially in scenarios like underwater construction or inspection, where nonlinear dynamics, unpredictable disturbances, and sensor noise complicate navigation. For instance, underwater welding [1, 2] requires precise and often repeated manipulator motions over extended operational periods in dynamic conditions. Traditional motion planning techniques—such as inverse kinematics and optimizationbased methods—are typically executed offline, which can hinder real-time responsiveness when unexpected changes occur [3–5]. Furthermore, repeatedly re-planning complex motion trajectories in such tasks using conventional methods can become computationally expensive and time-consuming.

Underwater Vehicle Manipulator System (UVMS) equipped with robotic manipulators (Fig. 1) have become essential assets for a variety of offshore and deep-sea applications, including inspection, maintenance, and complex manipulation tasks [6– 8]. These operations demand a high level of autonomy and efficiency, particularly in dynamic and unstructured underwater environments where conditions are highly unpredictable [9]. Furthermore, many AUV deployments involve tethered configurations, which introduce additional constraints on motion and maneuverability, requiring robust and adaptable planning algorithms [10–12]. Recent advancements have sought to address the limitations of traditional motion planning techniques by leveraging prior motion experiences and probabilistic reasoning to enhance autonomous decision-making. However, existing methods often struggle to balance computational efficiency with the ability to adapt to real-time environmental changes. For instance, Experience-Based Bidirectional RRT (EB-RRT) [13] utilizes stored experience graphs to accelerate path planning in semi-structured environments but lacks the capability for realtime adaptability and robust uncertainty handling. Similarly, learning-based approaches such as N2M2 [14] and HyperPlan [15] offer adaptability through reinforcement learning and hyperparameter optimization; meanwhile, trajectory optimization methods like CHOMP [16] and sampling-based techniques such as SANDROS [17] have been developed to refine path smoothness and address dynamic uncertainties. However, these approaches are often resource-intensive and less suited for real-time applications in dynamic settings.

![](images/1cd9160f1d3a490b77aa27b199cf2b893924e54f1bc0665ebbbfdb5e5a271ba7.jpg)  
Fig. 1: Experimental setup of the UVMS used during the experiments at our Heriot-Watt University Laboratory.

In contrast, sampling-based methods such as the Probabilistic Roadmap (PRM)[18] algorithm have become widely adopted for their ability to rapidly construct a collision-free graph of the robot’s configuration space by randomly sampling potential configurations. However, in cluttered environments—where obstacles create narrow passages and complex connectivity patterns—a higher number of samples is generally required to ensure that the roadmap is dense enough to capture the intricacies of the configuration space. This increase also enlarges the search space, leading to higher computational overhead. Traditional PRM combined with pure $\mathbf { A } ^ { * }$ search therefore faces a trade-off: while increasing max samples improves coverage and connectivity, it also tends to degrade real-time performance due to the expanded number of nodes that must be processed.

To address this challenge, we propose an Adaptive Heuristic Motion Planner (AHMP), an enhanced framework that augments the conventional PRM with Heuristic Motion Space (HMS). Our approach retains the extensive sampling benefits of PRM—ensuring robust coverage even when a high max samples is required—while mitigating the increased computational effort typically imposed on $\mathbf { A } ^ { * }$ search. HMS achieves this by caching and reusing previously computed motion plans, effectively creating a memory of high-value nodes. These cached experiences allow the planner to bypass large portions of the roadmap, thereby reducing the effective search space and yielding more stable and efficient performance in real-time. Furthermore, our integration of Bayesian Networks within HMS dynamically refines uncertainty estimates based on real-time sensor data and environmental conditions. This probabilistic reasoning is not solely focused on minimizing distance or cost but also on maximizing the likelihood of a path’s success. In this way, the system adapts to the inherent uncertainty of underwater environments by favoring pathways that are both short and reliably safe.

The key contributions of this research are:

1) The development of an HMS framework that leverages stored motion experiences to significantly reduce the effective search space in PRM.   
2) The integration of Bayesian Networks for dynamic uncertainty management, enabling probabilistic assessments that guide path selection.   
3) A novel hybrid approach that maintains robust roadmap connectivity—achieved by high max samples—while ensuring real-time performance through memory-based reuse of previously computed paths.

# II. RELATED WORK

Experience-based motion planning methods have demonstrated significant potential for accelerating repetitive tasks by reusing past solutions. For instance, Experience-based Bidirectional RRT (EB-RRT) [13] employs stored experience graphs and adaptive sampling techniques to enhance computational efficiency in semi-structured environments. However, its reliance on static experience graphs limits its adaptability to dynamic and uncertain scenarios. Similarly, Motion Memory [19] leverages past trajectories to bias sampling and accelerate motion planning in similar environments but struggles to generalize across different conditions or handle real-time uncertainties. While these frameworks successfully utilize past motion experiences, they do not integrate mechanisms for probabilistic reasoning or dynamic adaptation.

Additionally, the Experience-based Subproblem Planning (E-ARC) approach [20] tackles multi-robot motion planning by leveraging a database of precomputed solutions for lowerdimensional subproblems. E-ARC efficiently resolves local conflicts by retrieving relevant solutions from the database, significantly improving scalability in multi-robot scenarios. However, its reliance on subproblem decomposition makes it less suitable for environments with high-dimensional continuous planning requirements, such as those encountered in underwater manipulation tasks. Moreover, it does not incorporate probabilistic reasoning for handling dynamic uncertainties.

Another innovative method, the 3D-CNN-Based Heuristic Guided Task-Space Planner (HM-TS-RRT) [21], integrates taskspace planning with heuristic maps generated through deep learning. This framework excels in leveraging environmental information to guide exploration and exploitation, reducing planning time and improving success rates in complex environments. However, its dependence on pre-trained heuristic maps limits its adaptability to unstructured and dynamically changing environments, as it lacks mechanisms for real-time uncertainty updates.

Probabilistic frameworks, such as the Dynamic Bayesian Threat Assessment Framework [22] and the Bayes Adaptive MDP Model [23], have been effective in addressing uncertainties in motion planning. The former focuses on reactive threat assessment for unmanned underwater vehicles, while the latter emphasizes state transition modeling to optimize long-term decisions. However, these methods often lack mechanisms to leverage prior motion experiences, leading to increased computational costs for real-time operations. HMS bridges this gap by combining heuristic motion reuse with Bayesian reasoning, enabling both proactive and reactive planning to ensure safety and efficiency.

Learning-based methods, have advanced the adaptability of motion planning through reinforcement learning and algorithmic optimization [24]. N2M2 [14] leverages reinforcement learning to navigate unseen environments dynamically, but its reliance on extensive training datasets makes it resourceintensive and less suitable for resource-constrained underwater systems. Similarly, HyperPlan’s hyperparameter optimization approach is tailored for static planning problems [15], limiting its applicability in dynamic and uncertain scenarios. By avoiding the overhead of training while continuously updating motion heuristics in real time, HMS provides a lightweight and efficient alternative for underwater operations.

Recent research on multi-heuristic planning, exemplified by Multi-Heuristic $\mathbf { A } ^ { * }$ [25] and MR-MHA\* [26], has shown promise in high-dimensional spaces by combining diverse heuristics for pathfinding. While these methods improve computational efficiency, they do not incorporate memorybased reasoning or uncertainty updates, which are integral to the HMS framework. Furthermore, task-space planners such as the Task-Space Motion Primitive Framework [27] focus on geometric reasoning to navigate cluttered environments but lack the adaptability provided by probabilistic reasoning and dynamic memory updates.

Other novel approaches, such as vectorized sampling-based methods (e.g., Motions in Microseconds [26]) and semantic knowledge-based planning [28], focus on computational speed and contextual understanding, respectively. While these methods excel in specific applications, they are limited in their ability to adapt to dynamic environments and incorporate prior experiences.

![](images/319fd5bc3a939e4c0ba79dfe00a26a59e39358425053cf5b97fc6d3c9484986e.jpg)  
Fig. 2: Conceptual overview of the AHMP. The algorithm starts by building a PRM (Left). As more paths are explored, a memory of high value nodes is created which allows to reduce the search space. When new goals are introduced, the previous experience can be used to achieve faster and safer motion plans.

Unlike existing approaches that rely on static assumptions or precomputed maps, our proposed AHMP enables the transfer of heuristic motion spaces to unexplored environments through dynamic adaptation to environmental uncertainties. This integration of heuristic motion reuse with probabilistic updates creates a comprehensive framework that simultaneously achieves efficiency, adaptability, and safety, making it particularly effective for underwater robotic manipulation in dynamic and uncertain environments.

# III. METHODOLOGY

This section provides a description of the proposed methodology, the AHMP, which efficiently plans paths by building and reusing motion experiences. A high-level overview of the AHMP concept is illustrated in Fig. 2, followed by a detailed description of the algorithmic procedure.

# A. Overview

Motion planning with PRM is typically conducted in two stages. First, a PRM is constructed by randomly sampling up to max samples collision-free configurations and connecting them via feasible local paths. Then a search method, like $\mathbf { A } ^ { * }$ is used to find a suitable path. On difficult spaces or with high density of objects, a high max samples is used to ensure that narrow passages and intricate maneuvers can be captured, but it also increases the number of nodes that a graph-based search (e.g., A\*) must explore.

Rather than reducing the local density of PRM, we propose to create a hierarchy where we layer a HMS on top of PRM to store what we refer to as highway nodes. These nodes act as efficient shortcuts that complement the full, densely sampled PRM. Because the base roadmap is constructed with a high max samples, each highway path inherits the fine-grained resolution around obstacles, thus maintaining safe clearance. By focusing the $\mathbf { A } ^ { * }$ -based query on these highways, the search expands fewer nodes overall, which is crucial in to achieve fast and safe planning in large-scale or cluttered underwater environments.

The overall proposed framework is presented in Figure 3. The Adaptive Heuristic Motion Planner (AHMP) operates at two hierarchical levels: a High-Level Planner $\mathrm { ( H M S \mathrm { ~ + ~ } B N ) }$ layered on top of a low-level PRM. First, a PRM is constructed in the manipulator’s configuration space (or the combined vehicle-manipulator space). This involves sampling collisionfree configurations and connecting them with feasible local paths to form a graph. Then, a HMS repository, denoted as $\mathcal { H }$ , is built to store selected paths and frequently used sub-paths as motion primitives $\{ M _ { i } \} _ { i = 1 } ^ { n }$ . Each motion primitive $M _ { i }$ in HMS is associated with an uncertainty estimate $U _ { i }$ and other relevant execution metrics.

# B. System Architecture

A comprehensive system architecture, illustrating the integrated components and data flow, is depicted in Fig. 3. The system is designed for the BlueROV2 underwater vehicle platform [29] and the Reach Alpha 5 manipulator [30], forming the UVMS.

The architecture comprises three primary modules: the UVMS platform, the Motion Control module, and the Motion Planner module. The UVMS platform encapsulates the physical vehicle and its sensors, including a Camera for visual input and a suite of Sensors (DVL, IMU, sonar, etc.) for environmental awareness.

The Motion Control module receives trajectory commands from the Motion Planner and translates them into actuation signals. It consists of a cascaded PID controller for vehicle positioning and a dedicated manipulator motion controller, driven by an Inverse Kinematics (IK) solver, for precise joint angle management. The observations from the UVMS sensors, including visual and environmental data, are fed back to the Motion Control module to enable closed-loop control and trajectory optimization. The Motion Control module also receives an external signal, representing potential external disturbances or commands.

The Motion Planner module is the core of the proposed Adaptive Heuristic Motion Planner (AHMP). It incorporates a C-Space representation, a PRM with $\mathbf { A } ^ { * }$ search for path planning, and a HMS for storing and retrieving motion experiences. The HMS includes Cached motions and a BN. The observations from the UVMS sensors are used to update the BN, which in turn monitors system uncertainties and environmental conditions, allowing the AHMP to dynamically adapt its path planning. The environmental map, derived from sensor data, is used to update the HMS and refine the uncertainty estimates within the BN. The goal configuration provides the target for the Motion Planner. The AHMP generates optimized trajectories which are passed to the Motion Control module.

![](images/03ad35606cc398615623ca91adc5ba6fb3469ae55b5aa4caca3368e2c0c16a35.jpg)  
Fig. 3: The general architecture of a UVMS outlining the interaction among the manipulator (Reach Alpha 5), the underwater vehicle (BlueROV2), and the integrated motion control and planning.

The interconnected nature of these modules, facilitated by the exchange of signals such as observations, map, goal, and external, enables a closed-loop feedback system. This system empowers the UVMS to learn from experience, adaptively improve its motion primitives, and enhance both efficiency and reliability in underwater navigation and manipulation tasks.

# C. Adaptive Heuristic Motion Planner

The key objective of our method is to generate a safe path from the current state, C, to the end-effector goal configuration, $G = ( x _ { g } , y _ { g } , z _ { g } )$ .

Our method starts by constructing a PRM by randomly sampling up to max samples collision-free configurations and connecting them via feasible local paths. As previously stated, when the PRM is dense and queries are frequent, naive $\mathbf { A } ^ { * }$ can become computationally expensive due to its exponential

Require: $\mathcal { E }$ , s, $\{ g _ { i } \} = \{ g _ { 1 } , . . . , g _ { n } \}$ , HMS, BN, $\tau$   
Ensure: $\left\{ \Pi _ { i } \right\}$ : Paths from $s$ to each $g _ { i }$   
1: Initialize paths $\Pi _ { i }  \emptyset$ for all $g _ { i }$   
2: currentNode $ s$   
3: for each $g _ { i }$ in $\left\{ g _ { i } \right\}$ do   
4: Update BN with latest sensor data   
5: $\overset { \cdot } { o N o d e }  \arg \operatorname* { m a x } _ { u \in \mathrm { H M S } } \{ P ( u \mid g _ { i } , \mathrm { B N } ) : \mathrm { h e u r i s t i c } ( u , g _ { i } ) \leq \tau \}$   
6: if oNode $\neq - 1$ then   
7: $\Pi _ { \mathrm { H M S } }  \mathrm { H M S } [ \$ oNode].path   
8: $P a r t i a l A \gets \mathrm { A } ^ { * } ( \mathcal { E } , c u r r e n t N o d e , o N o d e )$   
9: $P a r t i a l B \gets \mathrm { A } ^ { * } ( \mathcal { E } , o N o d e , g _ { i } )$   
10: if PartialA.path $\neq \emptyset \ \wedge$ PartialB.path $\neq \emptyset$ then   
11: $\Pi _ { i }  P a r t i a l A .$ path $\| \Pi _ { \mathrm { H M S } } \|$ PartialB.path   
12: else   
13: $\begin{array} { l } { F u l l R e s u l t  \mathrm { A } ^ { * } ( { \mathcal { E } } , c u r r e n t N o d e , g _ { i } ) } \\ { \Pi _ { i }  F u l l R e s u l t . { \mathrm { p a t h } } } \end{array}$   
14:   
15: end if   
16: else   
17: $\begin{array} { l } { F u l l R e s u l t  \mathrm { A } ^ { * } ( { \mathcal { E } } , c u r r e n t N o d e , g _ { i } ) } \\ { \Pi _ { i }  F u l l R e s u l t . { \mathrm { p a t h } } } \end{array}$   
18:   
19: end if   
20: if $\Pi _ { i } \neq \emptyset$ then   
21: $\mathrm { H M S } [ g _ { i } ]  ( \Pi _ { i } , 1 . 0 )$ ▷ Cache new path   
22: for each $u$ in HMS do   
23: $p _ { \mathrm { n e w } } ( u ) \propto p _ { \mathrm { o l d } } ( u ) \times \exp \bigl ( - \alpha \| \Pi _ { i } \| \bigr )$   
24: end for   
25: Normalize $p _ { \mathrm { n e w } } ( u )$   
26: Update BN with new path data   
27: currentNode $ g _ { i }$   
28: end if   
29: end for   
return $\{ \Pi _ { i } \}$

complexity. To mitigate this issue, we layer the HMS on top of PRM to store highway nodes, key configurations frequently used in successful paths, and cached paths connecting them. These highway nodes act as efficient shortcuts that complement the full, densely sampled PRM.

When tasked with reaching a goal configuration $G \ =$ $( x _ { g } , y _ { g } , z _ { g } )$ , AHMP will first utilize PRM plus $\mathbf { A } ^ { * }$ to find an optimal trajectory. This expansion is only done when necessary, for example, on first expansions, thereby minimizing computational overhead. After generating initial trajectories, AHMP efficiently reuses precomputed paths stored in the HMS. A BN integrates data related to external environmental changes to probabilistically select the most optimal paths, ensuring both enhanced performance and robust adaptation. The evaluation of candidate HMS paths is based on the current environmental state $E$ . Specifically, for each stored motion primitive $M _ { i }$ , the probability of it leading to the goal $G$ given the environment $E$ is calculated as:

$$
\begin{array} { l } { P ( M _ { i } \mid G , E ) = \frac { P \left( G \mid M _ { i } , E \right) P \left( M _ { i } \mid E \right) } { P ( G \mid E ) } } \\ { \propto \frac { \exp \left( - \lambda U _ { i } \right) } { 1 + d ( M _ { i } , G ) } , } \end{array}
$$

where $d ( M _ { i } , G )$ is a distance metric in configuration space (joint or Euclidean space), and $\lambda$ is a confidence parameter. A threshold $\tau$ is used to define the maximum allowable distance from the goal within which HMS nodes are considered as potential approach points.

The BN used in our work is a Directed Acyclic Graph (DAG). The BN nodes $X _ { 1 } , \ldots , X _ { n }$ represent random variables, and its edges encode conditional dependencies. The joint distribution can be factorized as:

$$
P ( X _ { 1 } , \ldots , X _ { n } ) = \prod _ { i = 1 } ^ { n } P \bigl ( X _ { i } \mid \operatorname { P a } ( X _ { i } ) \bigr ) ,
$$

where $\operatorname { P a } ( X _ { i } )$ denotes the parents of $X _ { i }$ . By integrating the BN with HMS and the underlying PRM, the algorithm dynamically identifies and prioritizes those HMS nodes most likely to yield an optimal path under current conditions. This BNbased evaluation enhances both computational efficiency (by pruning less-promising expansions) and trajectory reliability (by favoring paths robust to disturbances).

The algorithm’s step-by-step procedure is detailed in the pseudocode provided in Algorithm 1. The algorithm takes as input the environment $( \mathcal { E } )$ , the starting state $( s )$ , a list of goal configurations $( \{ g _ { i } \} )$ , the HMS, BN, and a distance threshold $( \tau )$ . It outputs a list of paths $( \{ \Pi _ { i } \} )$ from the start to each goal.

In operation, for each goal, the algorithm first updates the BN with the latest sensor data. It then identifies the optimal approach node (oNode) within the HMS by selecting the node that maximizes the probability of reaching the goal, given the BN and ensuring it is within the distance threshold $\tau$ from the goal.

It then performs $\mathbf { A } ^ { * }$ search in two segments: from the current configuration $C$ to oNode, and from oNode to $g _ { i }$ . Should either of these partial searches fail, the algorithm reverts to a full $\mathbf { A } ^ { * }$ search directly from $C$ to $g _ { i }$ on the PRM. Following successful trajectory generation, the motion experience is cached in the HMS to facilitate future planning. The BN then updates the probabilities of these cached motions, incorporating the environmental impact and refining the selection of experiences most likely to yield optimal paths. This entire process ensures that the system adaptively leverages historical motion data to accelerate path planning while maintaining robustness through the underlying PRM and probabilistic evaluation.

# $D$ . Computation calculation

Utilizing PRM with a naive $\mathbf { A } ^ { * }$ can become computationally expensive due to its exponential complexity. The complexity in this case can be measured as $O ( b ^ { d } )$ , where $b$ is the branching factor and $d$ is the effective search depth. If an agent needs to reach $N$ distinct goals, naive repeated $\mathbf { A } ^ { * }$ on the PRM leads to a total time of $N \cdot O \left( b ^ { d } \right)$ . By contrast, our proposed method has a complexity of:

$$
N \cdot O ( \vert \mathrm { H M S } \vert ) + \sum _ { i = 1 } ^ { N } O \big ( b ^ { d _ { i } ^ { \prime } } \big ) ,
$$

![](images/c54506cc7703ea8a53d12e07ea5e4b6fb1eaa78d89ec255d015f21c77c5597ba.jpg)  
Fig. 4: Comparison of execution times for pure $\mathbf { P R M } + \mathbf { A } ^ { * }$ (marked by $\cdot _ { \mathrm { { o } } } ,$ ), RRT (marked by $\cdot \triangle ^ { , }$ ), AHMP (marked by $\mathbf { \partial } ^ { \bullet } \square ^ { \bullet } .$ ) across varying numbers of goals (horizontal axis). Colors indicate different max samples values: blue for 1,000, red for 5,000, violet for 10,000, and orange for 30,000.

where $| \mathrm { H M S } |$ is the size of the precomputed set of highways and $d _ { i } ^ { \prime } \ll d$ is the reduced effective depth. The ratio of times can be approximated as:

$$
\frac { T _ { \mathrm { A ^ { * } } } } { T _ { \mathrm { H M S } } } \approx \frac { b ^ { d } } { b ^ { d ^ { \prime } } }
$$

Hence, reusing cached paths in repeated or complex queries substantially mitigates the exponential blow-up otherwise encountered by naive $\mathbf { A } ^ { * }$ .

# IV. EXPERIMENTS

To validate the algorithm, we run experiments in a tank using a BlueROV2 equipped with a Reach Alpha 5 manipulator as presented in Fig. 1. Further experiments were conducted in simulation for comparative evaluation.

The algorithms evaluated in this section were implemented in $^ { C + + }$ with a kinematic solver integrated into the opensource Ceres Solver [31] library—and executed on a Linux Ubuntu 24.04 system equipped with an Intel(R) Core(TM) i9-14900K processor and $1 2 8 \mathrm { G B }$ of RAM.

# A. Comparative evaluation

We evaluated the performance of our proposed HMS algorithm, alongside baseline $\mathbf { A } ^ { * }$ and RRT approaches, within the UVMS simulation environment depicted in Fig. 3. This environment featured two red obstacles, creating a realistic scenario for assessing path planning capabilities. The performance was analyzed under varying values of the max samples parameter, which controls the number of collision-free nodes sampled via the PRM method, and max iter rrt for RRT, which dictates the number of iterations to grow the exploration tree. These parameters directly impact the roadmap’s coverage and the computational effort required for each path query. Our kinematic model addressed a 5DOF problem, comprising a 4DOF robot arm mounted on a 1DOF floating base. Each test was averaged over 5 runs to ensure statistical robustness.

Results presented in Fig. 4 show that when max samples is relatively low (e.g., 1,000) and the number of goals remains small, pure $\mathrm { P R M + A ^ { * } }$ can be slightly faster, as AHMP introduces overhead from maintaining a hierarchical memory and updating Bayesian probabilities. However, as max samples grows (e.g., to 5,000, 10,000, or even 30,000) and the number of goals increases, AHMP demonstrates clear advantages. Furthermore, RRT’s performance varied. At lower sample/iteration counts, it was sometimes faster, reflecting its ability to quickly find feasible solutions. However, at higher counts, both PRM-based methods (AHMP and $\mathbf { A } ^ { * }$ ) generally outperformed RRT, demonstrating superior solution quality and consistency. Notably, AHMP exhibited the most stable performance with increasing goal counts, showcasing the benefits of its cached path mechanism.

With reward to runtimes, pure $\mathrm { P R M } + \mathrm { A } ^ { * }$ scales almost linearly with increasing max samples and goal counts—rising from about 0.1613 s at 5,000 samples to 5.6457 s at 30,000 samples. On the other hand, AHMP exhibits significantly more stable performance, culminating in only 2.2045 s at 30,000 samples. This trend highlights the efficacy of the hierarchical caching mechanism in reducing the cost of searching through large, densely sampled roadmaps. This can be critical in cluttered environments, where higher max samples values are crucial for discovering feasible paths. These findings reaffirm that while $\mathbf { A } ^ { * }$ may be preferable for minimal sampling and few goals, the AHMP approach offers superior scalability and computational efficiency for navigating large-scale roadmaps with extensive goal sets. Furthermore, for robot manipulators operating in cluttered environments, such as our simulation, PRM-based methods are generally recommended over RRT. PRM builds a global roadmap that systematically samples the free configuration space, which is particularly advantageous when obstacles create narrow passages and complex connectivity that must be captured accurately.

# B. Experimental Results

The primary objectives of these experiments were to validate the effectiveness of the AHMP in a realistic underwater environment and to quantitatively compare its performance against established path planning algorithms, namely PRM and RRT. We aimed to demonstrate that the AHMP, by leveraging cached motion experiences and adaptive learning, could achieve comparable accuracy to PRM while offering significant advantages in terms of computational efficiency and robustness.

In these experiments, we evaluated the performance of the integrated AHMP approach for planning collision-free trajectories and compared it against both a baseline PRM and the RRT algorithm.

Experiments were conducted in a tank environment $3 . 5 \mathrm { m }$ $\mathrm { ~ x ~ } 3 . 0 \mathrm { ~ m ~ x ~ } 2 . 5 \mathrm { m } ,$ ) that provides a repeatable setup for testing.

In all tests, the vehicle operates in a stabilized ROV mode, ensuring that the motion of the manipulator is decoupled from the vehicle’s movement.

TABLE I: Mean Abs. Error Across Joints (10 Goals)   

<html><body><table><tr><td rowspan="2">Test</td><td colspan="2">PRM vs.HMS</td><td colspan="2">PRM vs. RRT</td></tr><tr><td>Mean[rad]</td><td>Std. [rad]</td><td>Mean [rad]</td><td>Std. [rad]</td></tr><tr><td>1</td><td>0.3522</td><td>0.3176</td><td>0.4651</td><td>0.4552</td></tr><tr><td>2</td><td>0.3658</td><td>0.2962</td><td>0.5156</td><td>0.4629</td></tr><tr><td>3</td><td>0.2757</td><td>0.4263</td><td>0.5494</td><td>0.4738</td></tr><tr><td>4</td><td>0.3287</td><td>0.2981</td><td>0.4838</td><td>0.5627</td></tr><tr><td>5</td><td>0.3867</td><td>0.4122</td><td>0.5397</td><td>0.4837</td></tr></table></body></html>

The experimental procedure is divided into two phases: i) HMS training phase, and ii) Goal execution phase. For the HMS Training Phase, we populate the HMS repository by sampling the manipulator’s joint space. A series of virtual goals (i.e., target configurations that are not physically reached) are used to populate the HMS space. This training phase allows the system to learn frequently traversed joint-space segments and to store corresponding motion primitives along with associated metrics such as uncertainty and time estimates.

In the Goal Execution Phase, new target configurations for the manipulator are generated. The algorithm then uses the enhanced PRM, augmented by the learned HMS data, to compute collision-free trajectories toward these goals. An overview of the experimental setup is given in Fig. 5.

The recorded joint trajectories for 10 consecutive goals of the manipulator are shown in Fig. 6. This figure compares the trajectories generated by the baseline PRM (green), the RRT algorithm (blue), and our proposed AHMP (red). As observed, the PRM-HMS trajectories closely follow the baseline PRM, demonstrating that our approach effectively replicates the reference motion. In contrast, the RRT trajectories exhibit noticeable deviations, particularly in joints b and d, which is indicative of its distinct exploration strategy.

We conducted five similar motions of these tests, and the average errors, computed as the difference between the recorded and planned trajectories, are summarized in Table I.

The errors between PRM and AHMP are relatively low, confirming the high fidelity of our method in replicating the PRM motion. Conversely, the errors between PRM and RRT are significantly higher, reflecting the fundamental differences in their path planning strategies.

Our findings demonstrate that the AHMP achieves a balance between accuracy and efficiency. The low error rates compared to PRM indicate that the AHMP can effectively replicate highquality paths, while the observed speed gains (not explicitly shown here but implied by the use of HMS) suggest a significant improvement in computational efficiency. These results validate AHMP as a robust and efficient motion planning solution for underwater robotics.

Across multiple trials with varying start and goal configurations, the system consistently showed low average error ( Table I), demonstrating reliable and repeatable performance in controlled conditions. This paired with the speed gain, makes our proposed methodology extremely useful for motion planning in complex marine environments.

![](images/4edfd1bb6cc23efe9de437a12fe65c69874ca9d5997eb8bb0b3656fcfbd159a2.jpg)  
Fig. 5: Snapshots from the experiments illustrate the progression of the UVMS motion. (a) initial position, (b), (c), and (d) show the active obstacle avoidance motion, and (e) depicts the UVMS reaching the target position.

![](images/dc08bed834fb70f7257af3448621907745c47ef259e6566277f8c2b1f382cbc4.jpg)  
Fig. 6: Joint position trajectories (10 consecutive goals performed by the UVMS) over time for four joints (b, c, d, e) comparing PRM (green), PRM-HMS (red), and RRT (blue).

# V. CONCLUSION

In this paper, we present an enhanced motion-planning framework for underwater manipulation that combines a HMS with a classical PRM. The HMS caches frequently used “highway” paths, significantly reducing search overhead for repeated goals—especially important for tasks like underwater spot welding. A BN refines uncertainty estimates in real-time, guiding the planner to reuse reliable paths under changing conditions. By maintaining a dense PRM, the system retains thorough coverage, yet avoids the computational blow-up of a large search space thanks to HMS shortcuts. Experiments using a BlueROV2 with a Reach Alpha 5 manipulator demonstrate that this approach yields consistent, collision-free trajectories, highlighting its effectiveness for multi-goal tasks in cluttered underwater environments.

Currently, the method has been validated over a set of experiments that mimic applications which require precise arm movements, i.e. for inspection or cleaning tasks that do not require extensive handling of objects. Future works include expanding AHMP to address more complex whole-body manipulation for tasks that involve grasping and manoeuvrability of objects in dynamic underwater environments.