# An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting

Xinyu Cao∗1 Bimal Adhikari∗2 Shangqing Zhao1 Jingxian $\mathrm { \Delta W u ^ { 2 } }$ Yanjun Pan2 $^ * \mathrm { C o }$ -First Authors 1University of Oklahoma, Norman, OK 2University of Arkansas, Fayetteville, AR 1{xinyu.cao-1, shangqing}@ou.edu 2{bimala, wuj, yanjunp}@uark.edu

Abstract—Radio frequency (RF) fingerprinting, which extracts unique hardware imperfections of radio devices, has emerged as a promising physical-layer device identification mechanism in zero trust architectures and beyond 5G networks. In particular, deep learning (DL) methods have demonstrated state-of-the-art performance in this domain. However, existing approaches have primarily focused on enhancing system robustness against temporal and spatial variations in wireless environments, while the security vulnerabilities of these DL-based approaches have often been overlooked. In this work, we systematically investigate the security risks of DL-based RF fingerprinting systems through an adversarial-driven experimental analysis. We observe a consistent misclassification behavior for DL models under domain shifts, where a device is frequently misclassified as another specific one. Our analysis based on extensive real-world experiments demonstrates that this behavior can be exploited as an effective backdoor to enable external attackers to intrude into the system. Furthermore, we show that training DL models on raw received signals causes the models to entangle RF fingerprints with environmental and signal-pattern features, creating additional attack vectors that cannot be mitigated solely through postprocessing security methods such as confidence thresholds.

Index Terms—Security, RF fingerprinting, Impersonation attacks, Deep learning

# I. INTRODUCTION

The proliferation of wireless devices and the expansion of beyond 5G networks have significantly increased the demand for reliable and secure device authentication methods. Radio frequency (RF) fingerprinting, which extracts the intrinsic hardware characteristics of radio devices, offers a promising physical-layer approach for device identification and authentication. RF fingerprinting is inherently difficult to forge or spoof, making it a valuable complement to traditional cryptographic-based security mechanisms. Due to its unique ability to distinguish devices based on their hardware signatures and its resistance to forgery, RF fingerprinting is envisioned as a key enabler for zero trust architectures and continuous device authentication and access control in 5G and beyond wireless networks [1], [2].

Recently, deep learning (DL)-based approaches have emerged as state-of-the-art techniques for RF fingerprint-based device identification, thanks to their superior performance and ease of deployment [3]–[10]. Most existing research in this area focuses on improving system robustness against temporal and spatial variations in wireless environments. For example, multi-day training [9], data augmentation [6], artificial amplification of hardware features [4], [7], novel neural network architectures [5], [8], and domain adaptation techniques such as transfer learning [10] have been introduced to improve robustness. Although these advances have strengthened the resilience of DL models for RF fingerprinting, the security aspects of these DL-based approaches have often been overlooked. Despite the fact that the RF fingerprint observed by a receiver is uniquely shaped by the pairwise characteristics of the transceiver pair, which makes it difficult to reproduce or replay, integrating DL models introduces a new attack surface that can potentially become the system’s weakest link.

In particular, we have observed a consistent misclassification behavior in such DL-based RF fingerprinting systems, where a given device is frequently identified as another specific one under domain shifts [3]–[10]. Figure 1 illustrates the typical performance of convolutional neural network (CNN)-based device identification systems using RF fingerprinting [4]–[8]. These systems commonly take raw received signals as input to a CNN trained to maximize classification accuracy. As shown in Fig. 1(a), the model performs effectively when evaluated on data collected at time $( t _ { 1 } )$ and location $( l _ { 1 } )$ as the training set. However, when tested on data gathered at a different time $( t _ { 2 } )$ or location $( l _ { 2 } )$ , performance often degrades significantly. The confusion matrix in Fig. 1(b) reflects this degradation and the consistent misclassification behavior: while some devices may still be correctly identified with high confidence, others are consistently misclassified, often into specific incorrect classes. For instance, device 2 is consistently misclassified as device 4 with a high probability (often exceeding $90 \%$ ) in Fig. 1(b). This misclassification behavior occurs because CNNs tend to learn features that are highly specific to the training domain, making it difficult to generalize across variations in the data distribution caused by changes in time, location, or environmental conditions. From a security perspective, however, this misclassification pattern can be exploited as an unintended backdoor, potentially enabling impersonation attacks for external adversaries and thereby undermining the system’s security.

In this work, we fill a fundamental gap between the promises of RF fingerprinting and the practical realities of deploying DL models in dynamic, adversarial wireless environments through a comprehensive, adversarial-driven experimental analysis. We consider practical replay and naive impersonation attacks executed by external adversaries with no additional knowledge or technological advantage beyond standard equipment. The main contributions of this work are threefold and summarized as three key remarks, illustrated in Fig. 2.

![](images/f1233a4cc55e3cfc25d40deb7ee3b1820105041d75d3d2c834077ed23ec6860c.jpg)  
Fig. 1: Illustration of typical performance of CNN-based device identification systems for four devices: (a) trained at time $t _ { 1 }$ and location $l _ { 1 }$ ; (b) tested at a different time $( t _ { 2 } )$ or location $( l _ { 2 } )$ .

• To the best of our knowledge, we are the first to systematically evaluate DL-based RF fingerprinting systems from a security perspective. Unlike prior works that primarily focus on classification accuracy and domain robustness, we reveal a critical and underexplored vulnerability: the consistent misclassification behavior of CNN models under domain shifts can be exploited an effective backdoor to enable external attackers to launch impersonation attacks and intrude into the system. • Our extensive in-lab experimental results show that CNNs trained on raw received signals inadvertently entangle hardware-specific, hard-to-forge RF fingerprints with easy-to-reproduce environmental and signal-pattern features. This entanglement further renders the system highly vulnerable to impersonation attacks, even when the attacker lacks prior knowledge or channel control. Our evaluation of a commonly used security patch based on softmax confidence thresholding for CNNs demonstrates that it provides insufficient protection against impersonation attacks. Our findings highlight that the vulnerability stemming from the CNN’s inability to disentangle hardware-specific features from spatiotemporal artifacts in wireless signals cannot be mitigated by post-processing techniques alone. Instead, carefully designed signal preprocessing methods are required to fully leverage the security potential of RF fingerprints.

The reminder of this paper is organized as follows: In Sec. II, we provide background and motivation for this work, followed by the system and threat models defined in Sec. III. Section IV describes the experimental setup, and Sec. V presents the security evaluation of the CNN-based RF fingerprinting system. We discuss potential future directions in Sec. VI and conclude the paper in Sec. VII.

![](images/cbb05308be11f81d45bb5c1055dd79bb24750a27afcfea0dc572a1277aaafed9.jpg)  
Fig. 2: The investigated CNN-based RF fingerprinting architecture.

# II. BACKGROUND AND MOTIVATION

# A. Input/Output Modeling with RF Fingerprints

The transmitted data, denoted as $x [ n ]$ , adheres to protocol standards and includes various components such as headers, preambles, and payloads. Due to unavoidable manufacturing imperfections in the transmitter’s hardware, such as filters, oscillators, and clocks, the emitted signal subtly deviates from the ideal. These deviations result in unique, device-specific signal characteristics, known as RF fingerprints. Common RF fingerprints include carrier frequency offset (CFO), inphase/quadrature (I/Q) imbalance, DC offset, phase noise, turnon transients, and error vector magnitude (EVM) [4]. These features are typically consistent over time for a given device and can be exploited for reliable identification.

Considering the effects of CFO, phase offset, and IQ imbalance at both the transmitter and receiver, as well as the wireless channel, and assuming that the $L$ -length channel is quasistatic over the duration of an OFDM symbol (i.e., allowing the channel to be modeled as time-invariant within the symbol duration) we can represent the time-domain baseband signal of an OFDM symbol at the receiver as [11]

$$
\begin{array} { r l } & { y [ n ] = \eta e ^ { - j \left( n \Delta \omega _ { R T } T _ { s } + \psi _ { R T } \right) } r [ n ] } \\ & { ~ + \kappa e ^ { j \left( n \Delta \omega _ { R T } T _ { s } + \psi _ { R T } \right) } r ^ { * } [ n ] + w [ n ] } \end{array}
$$

where $n = 0 , 1 , \ldots , N - 1 , T _ { s }$ is the sampling period of the OFDM system, and $w [ n ]$ is additive white Gaussian noise. $r [ n ] = \sum _ { l = 0 } ^ { L - 1 } h [ l ] x [ n - l ]$ , the composite time-varying $\mathrm { C S I } \ h [ l ] =$ $p _ { T } ( n T \dot { s } ) \stackrel { \textstyle > } { \otimes } g ( n T s , l T _ { s } ) \otimes p _ { R } ( n T s )$ includes the transmit filter $p _ { T } ( t )$ , the receive filter $p _ { R } ( t )$ , and the time-varying impulse response of the physical fading channel $g ( t , \tau )$ . The composite CFO is $\Delta \omega _ { R T } = \Delta \omega _ { R } - \Delta \omega _ { T }$ , and the composite phase offset is $\psi _ { R T } = \psi _ { R } - \psi _ { T }$ . The parameters $\eta = \left( \alpha _ { R } \alpha _ { T } + \beta _ { R } \beta _ { T } ^ { * } \right)$ , $\kappa =$ $( \alpha _ { R } \beta _ { T } + \beta _ { R } \alpha _ { T } ^ { * } )$ , where $\alpha _ { ( \cdot ) }$ and $\beta _ { ( \cdot ) }$ represent the effects of IQ imbalance of either the transmitter or the receiver. W.l.o.g, for the transmitter $\alpha _ { T } = \cos ( \Delta \phi _ { T } ) + j \epsilon _ { T } \sin ( \Delta \phi _ { T } )$ and $\beta _ { T } =$ $\epsilon _ { T } \cos ( \Delta \phi _ { T } ) - j \sin ( \Delta \phi _ { T } )$ , where $\epsilon _ { T }$ and $\Delta \phi _ { T }$ represent the amplitude and phase differences between the transmitter’s IQ branches.

Equation (1) shows that the RF fingerprint observed by a receiver such as an access point (AP) is uniquely shaped by the pairwise characteristics of the transceiver pair. As a result, it is generally considered difficult to reproduce or replay RF fingerprints. This is because any replaying device introduces its own hardware impairments, which distort the composite RF fingerprint perceived by the AP. Hence, the replay attack is widely believed to have limited effectiveness.

# B. Vulnerability Analysis

State-of-the-art DL-based RF fingerprinting and device identification approaches have primarily focused on enhancing system robustness against temporal and spatial variations in wireless environments [4]–[10]. However, these works often neglect thorough security evaluations of the systems themselves. Although the inherent uniqueness of RF fingerprints makes forging another device’s signal challenging, the DL model can become the system’s weakest link. Specifically, we observed a consistent misclassification behavior in DL models, where a device is frequently misclassified as another specific device under domain shifts, as illustrated in Fig. 1(b). This behavior can unintentionally introduce exploitable vulnerabilities. Despite the physical uniqueness of RF fingerprints making forgery difficult, this recurrent misclassification, shown in several prior works [4]–[8], creates a new attack surface that adversaries may exploit for impersonation attacks. This vulnerability exposes a critical gap in current DL-based RF fingerprinting research, i.e., the security implications of the learned feature representations remain insufficiently explored. To address this gap, in this work, we conduct a comprehensive, adversarial-driven experimental analysis by considering two straightforward and practical yet later proven effective attacks.

# III. SYSTEM AND THREAT MODELS

This section defines the system and threat models, including the two practical attacks that we use to evaluate the security of DL-based RF fingerprinting and device identification systems.

# A. RF Fingerprint-based Device Identification Systems

RF fingerprint-based device identification and management systems typically involve a receiver, usually a radio AP, that aims to identify and authenticate any transmitter attempting to establish a communication link. For instance, in 5G and beyond wireless networks, the base station (BS), which acts as a fixed receiver and serves as the AP to the network, must authenticate any user equipment (UE) attempting to connect. This process involves two main phases: fingerprinting and identification.

During the fingerprinting phase, the AP requires each transmitter to send signals in accordance with the communication protocol for a certain period during its first access attempt to the network. The AP can either process the received signal to explicitly extract RF fingerprints for input into a classification model, or directly input the received IQ samples into a model for classification. In this work, we adopt the second approach as in state-of-the-art systems, the AP directly feeds the raw IQ signals into a DL model such as a CNN for fingerprinting [4], [5], [8], [10]. An illustration of the investigated CNN-based RF fingerprinting architecture is shown in Fig. 2.

During the identification phase, when a transmitter seeks to connect to the AP, the AP collects its transmitted radio signals and performs identification with the pretrained DL model for RF fingerprinting. Based on the classification outcome, the AP either authenticates the device and permits connection establishment, or denies access.

# B. Threat Model

We consider an external attacker attempting to compromise an RF fingerprint-based device identification system. The attacker’s goal is to impersonate an authorized device in order to gain unauthorized access to the network. We assume a practical attacker with no additional knowledge or technological advantage beyond standard equipment. The attacker is located away from the AP and legitimate transmitters.

The attacker’s capabilities are limited to passively collecting signals emitted by the legitimate transmitters over the air during both the fingerprinting and identification phases. The attacker then either replays these captured signals or transmits synthesized signals from its own transmitter to bypass the DLbased device identification system. The attacker cannot control the communication channel between the AP and any legitimate transmitter, nor inject false data to disrupt the AP’s model training. We consider the following two attack scenarios:

Replay attack: The attacker records signals emitted by legitimate transmitters during the fingerprinting phase and replays them during the identification phase to fool the DLbased authentication system.

Naive impersonation attack: During the identification phase, the attacker simply transmits signals that mimic the format used by legitimate devices during CNN model training (e.g., preambles or random payloads) using its own transmitter.

# IV. IN-LAB EXPERIMENTAL SETUP

We conduct an adversarial-driven experimental study on a CNN-based device identification system using IQ samples collected from an in-lab testbed. The testbed consists of 6 USRP X300 SDRs, each equipped with a UBX-160 daughterboard operating at a center frequency of $5 . 7 8 \ \mathrm { G H z }$ and a sampling rate of $1 9 2 ~ \mathrm { K H z }$ . In each experiment, four of these USRPs act as legitimate transmitters (TXs), one as the attacker (Eve), and one as the AP. All devices are connected to the same host computer equipped with an AMD Ryzen 9 9950X CPU, 96 GB RAM, 6 TB storage, and an NVIDIA RTX 4090 GPU.

All transmitters emit IEEE 802.11a-compliant OFDM frames using QPSK modulation, generated via GNU Radio. Each transmitted frame has a fixed length and contains three OFDM symbols, including a header with CRC, a cyclic prefix, and payload data. Two types of frames are used: those with fixed payloads (referred to as repeated signals) and those with random payloads (referred to as random signals). The AP is a fixed-endpoint USRP that collects raw IQ samples from all transmitters. Eve is another fixed-endpoint USRP positioned approximately $2 \mathrm { m }$ away from the AP. During the fingerprinting phase, when the AP collects signals from each transmitter, Eve simultaneously records the raw IQ samples she receives.

All experiments are conducted in an indoor lab environment under non-line-of-sight (NLoS) conditions only, i.e., there is no direct path between any transmitter–receiver pair. The distances between transmitter–receiver pairs vary and can extend up to $1 8 \mathrm m$ . This NLoS setting introduces significant multipath fading and spatiotemporal channel fluctuations, providing sufficient data diversity for CNN training.

In each experiment, we collect three sets of 8 million IQ samples per transmitter at both the AP and Eve. This entire collection process is repeated two hours later. The initial dataset is used for training, while the second dataset is reserved for testing. The datasets used for system performance evaluation are categorized as the training set (TrS), the testing set (TeS), and the attacking set (AS), as detailed below.

• TrS 1: Collected on Day 1 at time $t _ { 1 }$ , with TXs sending   
random signals at location $l _ { 1 }$ . • TeS 1: Collected on Day 1 at time $t _ { 2 }$ , with TXs sending   
random signals at location $l _ { 2 }$ . TrS 2: Collected on Day 2 at time $t _ { 3 }$ , with TXs sending   
repeated signals at location $l _ { 4 }$ . TeS 2: Collected on Day 2 at time $t _ { 4 }$ , with TXs sending   
repeated signals at location $l _ { 4 }$ . AS 1: Collected by Eve alongside $\mathrm { T r S ~ 1 }$ . AS 2: Collected by Eve alongside $\mathrm { T r } \mathrm { \bf S \mathrm { \Theta } } 2$ .

The training and testing sets are collected by the AP, while the attacking sets are collected by Eve. Each training dataset is split into $70 \%$ for training and $30 \%$ for validation, while each testing dataset is used entirely for testing.

# V. PERFORMANCE EVALUATION

In this section, we evaluate the security of the CNNbased RF fingerprinting system for device identification against replay and naive impersonation attacks.

# A. Classifier Architecture

In this work, we adopt the CNN architecture presented in [5], which is a typical design consisting of eight layers including four convolutional layers followed by three fully connected (dense) layers. All input data are normalized using per-device standardization, where for each deice, we flatten its $\mathrm { I } / \mathrm { Q }$ data and fit using only that device’s data before being fed into the CNN model. For the input, a sliding window of frame size 4 is implemented that makes the input as $2 \times 2 5 6$ where the I and Q components of the signal are stored in two rows of matrix. Each of the convolutional layers uses 40 filters, where the first two have kernel sizes of $1 \times 7$ and $1 \times 5$ , respectively, each followed by a max-pooling layer that reduces the dimensionality to $2 \times 1 2 8 \times 4 0$ and $2 \times 6 4 \times 4 0$ , respectively. These are followed by a convolution layer of size $2 \times 7$ and max-pooling layer that further reduces the dimension to $2 \times 3 2 \times 4 0$ . Finally, a convolution layer of size $2 \times 5$ is implemented followed by a flattening layer, and the final feature maps are passed through three dense layers with 1024, 256 and 4 neurons, respectively. Dropout is applied after the flattening and first dense to help prevent overfitting. The final classification layer uses softmax activation to output probabilities over 4 classes. We use Adam optimizer with a learning rate of $1 \times 1 0 ^ { - 3 }$ to train the model.

![](images/28ce4e15de05d1b29309a57e107654470dcb25e6a7737e6fccbb1f27a70fa3f7.jpg)  
Fig. 3: Confusion matrix showing the classification accuracy of the CNN model trained on $\mathrm { T r } \mathsf { S \ 1 } \mathrm { : \Omega }$ (a) tested on TeS 1; (b) tested on AS 1.

# B. Experiment Results

As Eq. (1) shows, the received signal is a complex and nonlinear combination of multiple factors, including RF fingerprints, the time- and space-varying wireless channel, the transmitted signal, and AWGN. Although the CNN is intended to learn hardware-specific RF fingerprints only, when trained directly on raw IQ data, standard neural networks, which are typically designed to learn approximately linear or piecewise linear mappings, are not well suited to extract these features directly, especially in the absence of carefully designed, domainspecific signal preprocessing techniques. Hence, the model may fail to capture the correct latent representations associated with hardware impairments. To facilitate the analysis of system performance and security, we consider two types of transmitted frames, as described in Section IV. In the following, we evaluate the system using IQ samples collected under each of these two frame types, respectively.

1) Consistent misclassification behavior during domain shifts: We begin with the CNN trained using TrS 1 and test it on TeS 1 and AS 1, respectively, as existing works typically assume transmitters send random payloads [3]–[10]. Figure 3(a) shows that the device authentication accuracy of the trained model experiences a significant drop when tested on TeS 1 due to the domain shift, compared to the overall training accuracy of $9 9 . 9 5 \%$ . In other words, when there is a domain shift between the training and testing sets, we observe a misclassification behavior of the CNN similar to that reported in the literature. For example, device 4 is frequently identified as device 3 with a probability as high as $9 8 . 7 1 \%$ .

To verify whether this misclassification behavior of the model during domain shifts is consistent and allows Eve to easily penetrate the system by impersonating a legitimate transmitter, we show the success rate of the replay attack launched by Eve. In this untargeted attack, Eve attempts to impersonate any legitimate device by replaying AS 1. As illustrated in Fig. 3(b), we observe that Eve can successfully impersonate Devices 2, 3, and 4 with relatively high probabilities $( \geq 9 5 \% )$ )

and an overall untargeted impersonation attack success rate of $9 5 . 9 6 \%$ .

Prior works attribute the consistent misclassification behavior of the CNN to the similarity in wireless channels experienced by certain transmitter pairs. However, since the correlation coefficients of the channel state information (CSI) for each communication pair across TrS 1, TeS 1, and AS 1 are low (significantly below 0.5, as shown in Fig. 4), yet the misclassification behavior remains consistent, we conclude that this behavior is an inherent limitation of the CNN, caused by its lack of generalization during domain shifts.

Remark 1. The consistent misclassification behavior of the CNN-based device identification system is caused by the lack of generalization of the model during domain shifts, leaving the system vulnerable to untargeted impersonation attacks.

2) Entangled feature maps: We then consider the case when the CNN is trained with some publicly known, fixed, or lowentropy signals such as preambles, pilots, and headers and train the CNN with TrS 2. Surprisingly, when all the transmitters repeatedly transmit the same frame, the CNN model demonstrates robust and high classification accuracy despite domain shifts, as shown in Fig. 5(a), even when the signals are collected at significantly different times and locations, and the CSI in the training and testing data is temporally and spatially distinct, similar to that in Fig. 4.

Does this mean we can simply train the CNN to learn RF fingerprints from raw IQ samples by having transmitters send a fixed signal? Unfortunately, the results in Fig. 3(b) suggest that the CNN is not learning pure RF fingerprints. Instead, some environmental and location-dependent information associated with the receiver, patterns of the transmitted signals, and the RF fingerprints are jointly preserved in the neurons. Regardless of the transmitter’s location, the signal received by the AP, which is fixed in a limited space such as a lab, is likely to pass through a limited number of scatterers, resulting in some common signal paths, especially considering that channels in typical multipath environments are dominated by 3–5 path components [12], [13]. Hence, for a transmitter whose RF fingerprint the CNN has learned, the corresponding neurons are activated, enabling the CNN to correctly identify the transmitter with high confidence even if the channel conditions change dramatically, as shown in Fig. 5(a).

On the other hand, for a transmitter with an RF fingerprint unknown to the CNN, the received signal still tends to contain common environmental characteristics associated with the AP used during training. As a result, the neurons preserving the environmental and location-dependent information of the AP are activated, causing the AP to misclassify the signal as originating from an authorized transmitter with high confidence, as shown in Fig. 5(b).

To further verify this insight, we evaluate the system’s performance against a naive impersonation attack. We consider two scenarios in which Eve transmits either random or repeated signals, mimicking those of legitimate devices using her own transmitter. The success rates of these attacks are shown in

![](images/868ff74b5414d335d8caa999e0efd2d7c13b317a71b340a7a5ecdc6f44c5547f.jpg)  
Fig. 4: Correlation coefficient matrix for each communication pair: (a) between TrS 1 & TeS 1; (b) between TrS 1 & AS 1.

![](images/b2a8f4aa43fea39c029d5bfc9c1c64ed15322f57c792343942e0a7438f08f733.jpg)  
Fig. 5: Confusion matrix showing the classification accuracy of the CNN model trained on $\mathrm { T r } \mathbf { S } \ 2$ : (a) tested on TeS 2; (b) tested on AS 2.

Table I. We observe that when Eve transmits repeated signals identical to those of $\mathrm { T r } \mathrm { \bf S } \mathrm { \bf \Delta } 2$ , which the CNN model is trained on, the model continues to exhibit the consistent misclassification behavior. In other words, despite Eve’s RF fingerprints being distinct from those of the authorized transmitters, the model frequently misclassifies her signals as originating from a certain legitimate device. This misclassification is likely due to the model having learned not only RF fingerprints but also environmental and signal-pattern characteristics associated with the AP and transmitted frames, which dominate the model’s performance. In contrast, when Eve performs the naive impersonation attack using random signals, the highest misclassification rate significantly drops from $9 8 . 0 6 \%$ to $4 8 . 0 3 \%$ , further confirming that the transmitted signal pattern plays a key role in the model’s robustness and security.

TABLE I: Success rates of naive impersonation attacks   

<html><body><table><tr><td rowspan="2">Actual: Eve</td><td colspan="4">Predicted</td></tr><tr><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>repeated signals</td><td>1.86%</td><td>0</td><td>0.09%</td><td>98.06%</td></tr><tr><td>random signals</td><td>13.8%</td><td>0.49%</td><td>48.03%</td><td>37.68%</td></tr></table></body></html>

Remark 2. When the transmitted frame is deterministic, the CNN model trained with raw $I Q$ samples can partially learn RF fingerprints associated with transceivers. However, it also jointly learns environmental and location-dependent information associated with the receiver, as well as patterns in the transmitted signals. These entangled features within the trained CNN model provide significant attack opportunities for both untargeted and naive impersonation attacks.

3) Thresholding CNN with softmax confidence is insufficient: A straightforward approach to enhance the security of the CNN-based device identification system is to apply a threshold on the model’s softmax confidence scores, allowing it to reject signals from Eve as unknown. However, our study shows that this method does not improve the system’s resilience to replay or naive impersonation attacks, nor does it increase robustness against domain shifts.

TABLE II: Success and rejection rates of naive impersonation attacks against the CNN with softmax confidence   

<html><body><table><tr><td rowspan="2">Actual: Eve</td><td rowspan="2">Rejection</td><td colspan="4">Predicted</td></tr><tr><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>repeated signals</td><td>21.19%</td><td>0.44%</td><td>0</td><td>0.04%</td><td>99.52%</td></tr><tr><td>random signals</td><td>5.13%</td><td>11.77%</td><td>0.27%</td><td>52.4%</td><td>35.56%</td></tr></table></body></html>

Table II presents the success and rejection rates of naive impersonation attacks when a confidence threshold of 0.95 is applied to the CNN’s output class probabilities via softmax. When the highest softmax score falls below this threshold, the CNN rejects the input as unknown. Comparing the results from Tables I and II, we observe that although the CNN correctly rejects some attacks, the overall rejection rate remains low $( 2 1 . 1 9 \%$ when the transmitted signal pattern does not match, and $5 . 1 3 \%$ when Eve transmits repeated signals). The CNN’s performance on TeS 2 and AS 2 with softmax confidence is similar to that shown in Fig. 5, with a low rejection rate in both cases. We omit the detailed results here due to page limitations. Consequently, the model’s performance remains nearly unchanged, as the jointly learned environmental and location-dependent information, along with transmitted signal patterns, still provide significant attack opportunities for Eve.

Remark 3. The vulnerability caused by the lack of carefully designed signal preprocessing techniques for RF fingerprinting, combined with the limited capacity of neural networks to learn from complex and nonlinear wireless signals, means that applying post-processing security techniques such as a softmax confidence threshold to the CNN alone is insufficient to secure the system.

# VI. DISCUSSION

Our experimental findings necessitate the design of RF fingerprint estimation methods that can effectively disentangle device-specific hardware signatures from spatiotemporal channel and environmental artifacts. Special structures can be leveraged for estimating certain RF fingerprints, such as IQ imbalance, in a manner similar to how the CFO is estimated in WiFi standards using repeated symbols in synchronization words. Exploring hybrid models that integrate signal processing-based RF fingerprinting techniques with powerful DL architectures, such as embedding hardware impairment models or using generative models to simulate and enhance RF fingerprints, is also promising for providing robust and secure RF fingerprinting techniques. In our future work, we will design new signal processing techniques for RF fingerprinting and carefully integrate them with DL models to ensure system robustness and security.

# VII. CONCLUSION

We revisited CNN-based RF fingerprinting for device identification from a security perspective through an adversarialdriven experimental study. We demonstrated that although CNN models exhibit superior classification performance, they consistently show misclassification behaviors due to limitations in generalizing across temporal and spatial domain shifts in wireless signals. Attackers can exploit these behaviors to compromise the system through simple replay and naive impersonation attacks. Moreover, training CNNs with raw IQ samples causes the models to entangle RF fingerprints with environmental and signal-pattern features, creating additional attack vectors that cannot be mitigated by applying postprocessing security techniques to the CNN alone.