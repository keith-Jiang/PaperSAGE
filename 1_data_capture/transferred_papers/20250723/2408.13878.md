# Generalization of Graph Neural Networks is Robust to Model Mismatch

Zhiyang Wang1, Juan Cervin˜o2, Alejandro Ribeiro1

1University of Pennsylvania 2Massachusetts Institute of Technology zhiyangw@seas.upenn.edu, jcervino $@$ mit.edu, aribeiro@seas.upenn.edu

# Abstract

Graph neural networks (GNNs) have demonstrated their effectiveness in various tasks supported by their generalization capabilities. However, the current analysis of GNN generalization relies on the assumption that training and testing data are independent and identically distributed (i.i.d). This imposes limitations on the cases where a model mismatch exists when generating testing data. In this paper, we examine GNNs that operate on geometric graphs generated from manifold models, explicitly focusing on scenarios where there is a mismatch between manifold models generating training and testing data. Our analysis reveals the robustness of the GNN generalization in the presence of such model mismatch. This indicates that GNNs trained on graphs generated from a manifold can still generalize well to unseen nodes and graphs generated from a mismatched manifold. We attribute this mismatch to both node feature perturbations and edge perturbations within the generated graph. Our findings indicate that the generalization gap decreases as the number of nodes grows in the training graph while increasing with larger manifold dimension as well as larger mismatch. Importantly, we observe a trade-off between the generalization of GNNs and the capability to discriminate high-frequency components when facing a model mismatch. The most important practical consequence of this analysis is to shed light on the filter design of generalizable GNNs robust to model mismatch. We verify our theoretical findings with experiments on multiple real-world datasets.

# Introduction

Graph Neural Networks (GNNs) (Sandryhaila and Moura 2013; Kipf and Welling 2017; Gama et al. 2019), as a deep learning model on graphs, have been unarguably one of the most recognizable architectures when processing graphstructured data. GNNs have achieved notable performances in numerous applications, such as recommendation systems (Wu et al. 2022), protein structure predictions (Yin et al. 2023), and multi-agent robotic control (Gosrich et al. 2022). These outstanding results of GNNs depend on their empirical performances when predicting over unseen testing data. This is evaluated in theory with statistical generalization analysis, which quantifies the difference between the empirical risk (i.e. training error) and the statistical risk (i.e.

testing error) in deep learning theory (Kawaguchi, Kaelbling, and Bengio 2022). Recent works have focused on proving the generalization bounds of GNNs without any dependence on the underlying model responsible for generating the graph data (Scarselli, Tsoi, and Hagenbuchner 2018; Garg, Jegelka, and Jaakkola 2020; Verma and Zhang 2019). Generalization analysis on graph classification is studied in a series of works when graphs are drawn from random limit models (Ruiz, Chamon, and Ribeiro 2023; Maskey et al. 2022; Maskey, Kutyniok, and Levie 2024; Levie 2024). In (Wang, Cervino, and Ribeiro 2024), the authors study the generalization of GNNs over graphs generated from an underlying manifold on both node and graph levels. These works assume that the training and testing graphs are generated from the same underlying model. In practice, there are inevitable scenarios with generative model mismatch between testing and training graphs (Li et al. 2022). Hence, it is of crucial to demonstrate the generalization ability of GNNs remains robust to generative model mismatch. This would provide a promising assurance that GNNs can maintain outstanding generalizable performance even in noisy environments.

The model mismatch may stem from disturbances during the graph generation process from the manifold. Moreover, the underlying manifold model is prone to undergo alternations and fluctuations in practical situations. While we take into account the underlying model mismatches, they can be interpreted as perturbations within the generated graph domain. Figure 1a displays the original manifold and a graph derived from it. Figure 1b illustrates a mismatched manifold, which leads to edge perturbations in the generated graph. Figure 1c shows the interpretation of perturbed manifold function values, resulting in node feature perturbations in the generated graph.

We prove that the generalization of GNNs is robust to model mismatches based on the convergence of GNNs on generated graphs to neural networks on the manifold model (Wang, Ruiz, and Ribeiro 2024a), combined with the stability of the Manifold Neural Networks (MNNs) under manifold deformations (Wang, Ruiz, and Ribeiro 2024b). Implementing low-pass and integral Lipschitz continuous filters (Definition 2) allows us to bound the generalization gap under model mismatches. This bound decreases with the number of nodes in the training graph and increases with both the mismatch size and the manifold dimension. The key insight from the bound is that a more robust generalization necessitates the cost of failing to discriminate high spectral components in the graph data.

![](images/d2a46d275c1e7a99411e1159de3b253fb59a73cb155fea9ee6d49dc75beef14b.jpg)  
Figure 1: Example of model mismatch. (a) The original manifold with a generated graph based on sampled points $( P 1 , \cdots , P 6 )$ . (b) The mismatched manifold with the sampled points also shifted, resulting in a perturbed graph. (c) The manifold mismatch can be seen as the perturbation of manifold function values, which leads to perturbed node features on the generated graph.

Our main contributions are as follows:

1. We analyze the generalization of the GNNs when there exists a manifold model mismatch between the training data and testing data.   
2. We determine the manifold mismatch as perturbations on the generated graphs, both as node feature perturbations and edge perturbations.   
3. We propose that implementing continuity restrictions on the filters composing the GNN ensures the robust generalization in both node and graph classification tasks.   
4. We observe a trade-off between robust generalization and discriminability through the generalization bound.

We conduct experiments on real-world datasets to validate our theoretical findings.

# Related Works In-Distribution Generalization of GNNs

Existing works on the in-distribution generalization of GNNs fall in node and graph level tasks. For node classification tasks of GNNs, there are works providing a generalization bound of GNNs based on a Vapnik-Chervonenkis dimension (Scarselli, Tsoi, and Hagenbuchner 2018), algorithmic stability analysis (Verma and Zhang 2019; Zhou and Wang 2021), PAC-Bayesian analysis (Ma, Deng, and Mei 2021) and Rademacher complexity (Esser, Chennuru Vankadara, and Ghoshdastidar 2021). For graph classification tasks of GNNs, the authors prove the generalization bound via Rademacher complexity (Garg, Jegelka, and Jaakkola 2020) and PAC-Bayes analysis (Liao, Urtasun, and Zemel 2020; Ju et al. 2023). The authors consider a continuous graph limit model to analyze the generalization of GNNs on graph classification in (Maskey et al. 2022; Maskey, Kutyniok, and Levie 2024; Levie 2024). In (Wang, Cervin˜o, and Ribeiro 2024a), the authors prove the generalization of GNNs on graphs sampled from a manifold both for node and graph classification tasks. These works are considered only in the in-distribution case where the training and testing data are sampled from the same distribution.

# Out-of-Distribution Generalization of GNNs

Several works have extensively addressed the out-ofdistribution generalization of GNNs with graph enhancement methods. The authors in (Tian et al. 2024) propose a domain generalization framework for node-level tasks on graphs to address distribution shifts in node attribute distribution and graphic topology. In (Fan et al. 2023), the authors study the out-of-distribution generalization of GNNs on graph-level tasks with a causal representation learning framework. In (Li et al. 2022) the authors handle graph distribution shifts in complex and heterogeneous situations of GNNs with a nonlinear graph representation decorrelation method. The authors in (Yehudai et al. 2021) propose a size generalization analysis of GNNs correlated to the discrepancy between local distributions of graphs. In our novel approach, we conceptualize the generative model mismatch as a distribution shift. Our findings can be further generalized into a theoretical framework for GNNs in manifold domain shift scenarios. In such cases, the generalization gap is directly proportional to the distance between the manifold models. This extension is discussed in more detail within the supplementary material.

# GNNs and Manifold Neural Networks

Geometric deep learning has been proposed in (Bronstein et al. 2017) with neural network architectures on manifolds. The authors in (Monti et al. 2017) and (Chakraborty et al. 2020) provide neural network architectures for manifoldvalued data. In (Wang, Ruiz, and Ribeiro 2024b) and (Wang, Ruiz, and Ribeiro 2022), the authors define convolutional operation over manifolds and see the manifold convolution as a generalization of graph convolution, which establishes the limit of neural networks on large-scale graphs as manifold neural networks (MNNs). The authors in (Wang, Ruiz, and Ribeiro 2024a) further establish the relationship between GNNs and MNNs with non-asymptotic convergence results for different graph constructions.

# Neural Networks on Manifolds

Suppose there is a $d$ -dimensional embedded Riemannian manifold $\mathcal { M } \subset \mathbb { R } ^ { \mathsf { M } }$ which is compact, smooth and differentiable. A measure $\mu$ over $\mathcal { M }$ with density function $\rho : \mathcal { M } \to ( 0 , \infty )$ , which is assumed to be bounded as $0 < \rho _ { m i n } \leq \rho ( x ) \leq \rho _ { m a x } < \infty$ for each $x \in \mathcal { M }$ . Data supported over the manifold is defined as a scalar function $f : \mathcal { M } \to \mathbb { R }$ (Wang, Ruiz, and Ribeiro 2024b) mapping datum value $f ( x )$ to each point $x \in \mathcal { M }$ . The manifold with density $\rho$ is endowed with a weighted Laplace operator (Grigor’yan 2006), which generalizes the Laplace-Beltrami operator as

$$
\mathcal { L } f = - \frac { 1 } { 2 \rho } \mathrm { d i v } ( \rho ^ { 2 } \nabla f ) ,
$$

where div denotes the divergence operator of $\mathcal { M }$ and $\nabla$ denotes the gradient operator of $\mathcal { M }$ (Bronstein et al. 2017).

We consider square-integrable functions over $\mathcal { M }$ , denoted as use $L ^ { 2 } ( \dot { \mathcal { M } } )$ . The inner product of functions $f , g \in$ $L ^ { 2 } ( \mathcal { M } )$ is defined as

$$
\langle f , g \rangle _ { \mathcal { M } } = \int _ { \mathcal { M } } f ( x ) g ( x ) \mathrm { d } \mu ( x ) ,
$$

while the $L ^ { 2 }$ norm is defined as $\| f \| _ { \mathcal { M } } ^ { 2 } = \langle f , f \rangle _ { \mathcal { M } }$ .

Manifold convolution is defined by aggregating the heat diffusion process over $\mathcal { M }$ with operator $\mathcal { L }$ (Wang, Ruiz, and Ribeiro 2022, 2024b). With the input manifold function $f \in$ $L ^ { 2 } ( \mathcal { M } )$ , the manifold convolution $\mathbf { h } ( \mathcal { L } )$ is

$$
g ( x ) = \mathbf { h } ( \mathcal { L } ) f ( x ) = \sum _ { k = 0 } ^ { K - 1 } h _ { k } e ^ { - k \mathcal { L } } f ( x ) .
$$

Considering the frequency representation, the Laplace operator $\mathcal { L }$ has real, positive and discrete eigenvalues $\{ \bar { \lambda } _ { i } \} _ { i = 1 } ^ { \infty }$ as the Laplace operator is self-adjoint and positivesemidefinite. The eigenfunction associated with each eigenvalue is denoted as $\phi _ { i }$ , i.e. $\mathcal { L } \phi _ { i } = \lambda _ { i } \phi _ { i }$ . The eigenvalues are ordered as $0 = \lambda _ { 1 } \leq \lambda _ { 2 } \leq \lambda _ { 3 } \leq . . . _ { ! }$ , and the eigenfunctions are orthonormal and form the eigenbasis of $L ^ { 2 } ( \mathcal { M } )$ . When mapping a manifold function onto one of the eigenbasis $\phi _ { i }$ , we have the spectral component as $[ \hat { f } ] _ { i } = \langle f , \phi _ { i } \rangle _ { \mathcal { M } }$ . The manifold convolution can be written in the spectral domain point-wisely as

$$
[ \hat { g } ] _ { i } = \sum _ { k = 0 } ^ { K - 1 } h _ { k } e ^ { - k \lambda _ { i } } [ \hat { f } ] _ { i } .
$$

Hence, the frequency response of manifold filter is given by $\begin{array} { r } { \hat { h } ( \lambda ) = \sum _ { k = 0 } ^ { K - 1 } h _ { k } e ^ { - k \lambda } } \end{array}$ , depending only on the filter coefficients $h _ { k }$ and eigenvalues of $\mathcal { L }$ when $\lambda = \lambda _ { i }$ .

Manifold neural networks (MNNs) are built by cascading layers consisting of a bank of manifold filters and a pointwise nonlinearity function $\sigma : \mathbb { R }  \mathbb { R }$ , with the output of

each layer written as

$$
f _ { l } ( x ) = \sigma \Bigl ( { \bf h } _ { l } ( \mathcal { L } ) f _ { l - 1 } ( x ) \Bigr ) .
$$

To represent the MNN succinctly, we group all learnable parameters, and denote the mapping based on input manifold function $f \in L ^ { 2 } ( \mathcal { M } )$ to predict target function $g \in L ^ { 2 } ( \mathcal { M } )$ as $\Phi ( \mathbf { H } , \mathcal { L } , f )$ , where $\mathbf { H } ^ { \mathbf { \check { \phi } } } \in \mathcal { H } \subset \mathbb { R } ^ { \mathbf { \check { P } } }$ is a filter parameter set of the manifold filters. A positive loss function is denoted as $\ell ( \Phi ( \mathbf { H } , \mathcal { L } , f ) , g )$ to measure the estimation performance.

# Geometric Graph Neural Networks

Suppose we can access a discrete set of sampled points over manifold $\mathcal { M }$ . A graph $\mathbf { G }$ is generated based on a set of $N$ i.i.d. randoMmly sampled points XN = {x1N , x2N , · · · , xN } according to measure $\mu$ over $\mathcal { M }$ . Seeing these $N$ sampled points as nodes, edges connect every pair of nodes $( x _ { N } ^ { i } , \bar { x } _ { N } ^ { j } )$ is connected with weight value $[ \mathbf { W } _ { N } ] _ { i j }$ , ${ \bf W } _ { N } \in \mathbb { R } ^ { N \times N }$ determined by a function of their Euclidean distance $\Vert x _ { N } ^ { i } -$ $x _ { N } ^ { j } \|$ (Calder and Trillos 2022), explicitly written as

$$
[ \mathbf { W } _ { N } ] _ { i j } = \frac { \alpha _ { d } } { ( d + 2 ) N \epsilon ^ { d + 2 } } \mathbf { 1 } _ { [ 0 , 1 ] } \left( \frac { \| x _ { N } ^ { i } - x _ { N } ^ { j } \| } { \epsilon } \right) ,
$$

where $\alpha _ { d }$ is the volume of the $d$ -dimensional Euclidean unit ball and 1 represents an indicator function. Based on this, the graph Laplacian can be calculated as ${ \bf L } _ { N } = \mathrm { d i a g } ( { \bf W } _ { N } { \bf 1 } ) -$ ${ \bf W } _ { N }$ . On this generated graph, graph data values are sampled from the functions over manifold $\mathcal { M }$ (Wang, Ruiz, and Ribeiro 2022; Chew, Needell, and Perlmutter 2023). Consider the input and target functions $f , g \in L ^ { 2 } ( \mathcal { M } )$ , the sampled input and target functions $\mathbf { x } , \mathbf { y } \in L ^ { 2 } ( X _ { N } )$ over graph $\mathbf { G }$ can be written as

$$
[ \mathbf { x } ] _ { i } = f ( x _ { N } ^ { i } ) , \quad [ \mathbf { y } ] _ { i } = g ( x _ { N } ^ { i } ) .
$$

A convolutional filter on graph $\mathbf { G }$ can be extended from manifold convolution defined in (3) by replacing the Laplace operator with the graph Laplacian as

$$
\mathbf { y } = \mathbf { h } ( \mathbf { L } ) \mathbf { x } = \sum _ { k = 0 } ^ { K - 1 } h _ { k } e ^ { - k \mathbf { L } } \mathbf { x } .
$$

We observe that this formation is accordant with the definition of the graph convolution (Gama et al. 2019) with graph shift operator as $e ^ { - \mathbf { L } }$ . Replace $\mathbf { L }$ with eigendecomposition $\mathbf { L } = \dot { \mathbf { V } } \mathbf { A } \mathbf { V } ^ { H }$ , where $\mathbf { V }$ is the eigenvector matrix and $\pmb { \Lambda }$ is a diagonal matrix with eigenvalues of $\mathbf { L }$ as the entries. The spectral representation of this filter on $\mathbf { G }$ is

$$
\mathbf { V } ^ { H } \mathbf { h } ( \mathbf { L } _ { \tau } ) \mathbf { x } = \sum _ { k = 1 } ^ { K - 1 } h _ { k } e ^ { - \Lambda k } \mathbf { V } ^ { H } \mathbf { x } = \hat { h } ( \mathbf { \Lambda } ) \mathbf { V } ^ { H } \mathbf { x } .
$$

This analogously leads to a frequency response of this graph convolution, i.e. $\begin{array} { r } { \hat { h } ( \lambda ) = \sum _ { k = 0 } ^ { K - \bar { 1 } } h _ { k } \lambda ^ { \bar { k } } } \end{array}$ , relating the input and output spectral components point-wisely.

Neural networks on $\mathbf { G }$ is composed of layers consisting of graph filters and point-wise nonlinearity $\sigma$ , written as

$$
\begin{array} { r } { \mathbf { x } _ { l } = \sigma \Big ( \mathbf { h } _ { l } ( \mathbf { L } ) \mathbf { x } _ { l - 1 } \Big ) . } \end{array}
$$

The mapping from input graph data $\mathbf { x } \in L ^ { 2 } ( X _ { N } )$ to predict $\mathbf { y } \in L ^ { 2 } \hat { ( X _ { N } ) }$ is denoted as $\Phi ( \mathbf { H } , \mathbf { L } , \mathbf { x } )$ with $\mathbf { H } \in \mathcal { H } \subset \mathbb { R } ^ { P }$ which is trained to minimize the loss $\ell ( \Phi ( \mathbf { H } , \mathbf { L } , \mathbf { x } ) , \mathbf { y } )$ .

# Generalization of GNNs to Model Mismatch Manifold Model Mismatch

A mismatched model of manifold $\mathcal { M }$ is denoted as $\mathcal { M } ^ { \tau }$ where $\tau$ maps each point $x \in \mathcal { M }$ to a displaced $\tau ( x ) \in \mathcal { M } ^ { \tau }$ . We restrict this mismatch function class $\tau$ as it preserves the properties of $\mathcal { M }$ and denote the curvature distance between $x$ and the displaced $\tau ( x )$ as $\mathrm { d i s t } ( x , \tau ( x ) )$ . The mismatch $\tau$ induces a tangent map $\tau _ { * , x } : T _ { x } \mathcal { M } \to T _ { \tau ( x ) } \mathcal { M }$ which is a linear map between the tangent spaces $\left( \mathrm { T u } \ 2 0 1 1 \right)$ ). With the coordinate description over $\mathcal { M }$ , the tangent map $\tau _ { * , x }$ can be exactly represented by the Jacobian matrix $J _ { x } ( \tau )$ .

The manifold model mismatch can be seen as deformations to input manifold functions as shown in Figure 1c.

$$
\mathcal { L } f ( \tau ( x ) ) = \mathcal { L } f ^ { \prime } ( x ) , \qquad x \in \mathcal { M } .
$$

While the model mismatch can also be understood as deformations to the Laplacian operator as shown in Figure 1b.

$$
\mathcal { L } f ( \tau ( x ) ) = \mathcal { L } _ { \tau } f ( x ) , \qquad x \in \mathcal { M } .
$$

# Generalization of GNNs on node-level

The generalization analysis is restricted to a finitedimensional subset of $L ^ { 2 } ( \mathcal { M } )$ , i.e. the functions over the manifold are bandlimited as defined in Definition 1.

Definition 1 Function $f \in L ^ { 2 } ( \mathcal { M } )$ is bandlimited if there exists some $\lambda > 0$ such that for all eigenpairs $\{ \lambda _ { i } , \phi _ { i } \} _ { i = 1 } ^ { \infty }$ of the weighted Laplacian $\mathcal { L }$ when $\begin{array} { r l } { \lambda _ { i } } & { { } > ~ \lambda } \end{array}$ , we have $\langle \dot { f } , \phi _ { i } \rangle _ { \mathcal { M } } \dot { = } 0$ .

Assumption 1 (Lipschitz target function) The target function $g$ is Lipschitz continuous, i.e., $| g ( x ) ~ - ~ \bar { g } ( y ) | ~ \leq$ $C _ { g } d i s t ( x , y )$ , for all $x , y \in { \mathcal { M } }$ .

We further assume that the filters in MNN $\Phi ( \mathbf { H } , \mathcal { L } , \cdot )$ and GNN $\Phi ( \mathbf { H } , \mathbf { L } , \cdot )$ are low-pass and integral Lipschitz filters as defined in Definition 2. We note that this is a mild assumption as high frequency components on the graph/manifold implies that there exist functions with large variations in adjacent entries. This naturally generates instabilities that are more difficult to learn.

Definition 2 A filter is a low-pass and integral Lipschitz filter if its frequency response satisfies

$$
\begin{array} { r l } & { \left| \hat { h } ( \lambda ) \right| = \mathcal { O } \left( \lambda ^ { - d } \right) , \quad \lambda \to \infty , } \\ & { \left| \hat { h } ^ { \prime } ( \lambda ) \right| \leq C _ { L } \lambda ^ { - d - 1 } , \quad \lambda \in ( 0 , \infty ) . } \end{array}
$$

with $d$ denoted as the dimension of manifold $\mathcal { M }$ and $C _ { L }$ a positive continuity constant.

We note that with a smaller $\boldsymbol { C } _ { L }$ , the filter function tends to be smoother especially in the high-spectrum domain. The filters fail to discriminate different high spectral components with similar frequency responses given to them.

In the neural network architectures, we consider assumptions on both the nonlinear activation function and the loss function as presented in Assumption 2 and 3 respectively. We note that these are reasonable assumptions as most activations (e.g. ReLU, modulus, sigmoid) and loss functions (e.g. L1 regression, Huber loss, quantile loss).

Assumption 2 (Normalized Lipschitz activation functions) The activation function $\sigma$ is normalized Lipschitz continuous, i.e., $| \sigma ( a ) - \sigma ( b ) | \leq | a - b |$ , with $\sigma ( 0 ) = 0$ .

Assumption 3 (Normalized Lipschitz loss function) The loss function $\ell$ is normalized Lipschitz continuous, i.e., $| \ell ( y _ { i } , y ) - \ell ( y _ { j } , y ) | \leq | y _ { i } - y _ { j } | .$ , with $\ell ( y , y ) = 0$ .

The generalization gap is evaluated between the empirical risk over the discrete graph model and the statistical risk over the manifold model, which has been studied in both node-level and graph level in previous works when no model mismatch is considered (Wang, Cervin˜o, and Ribeiro 2024b,a).

Suppose the training graph $\mathbf { G }$ is generated from a manifold $\mathcal { M }$ . The empirical risk that we train the GNN to minimize is therefore defined as

$$
R _ { { \bf G } } ( { \bf H } ) = \frac { 1 } { N } \sum _ { i = 1 } ^ { N } \ell \left( [ \Phi ( { \bf H } , { \bf L } , { \bf x } ) ] _ { i } , [ { \bf y } ] _ { i } \right) .
$$

The statistical risk over mismatched manifold $\mathcal { M } _ { \tau }$ is

$$
R _ { { \mathcal { M } } ^ { \tau } } ( \mathbf { H } ) = \int _ { { \mathcal { M } } ^ { \tau } } \ell \left( \Phi ( \mathbf { H } , \mathcal { L } _ { \tau } , f ) ( x ) , g ( x ) \right) \mathrm { d } \mu _ { \tau } ( x ) .
$$

The generalization gap under model mismatch is

$$
G A _ { \tau } = \operatorname* { s u p } _ { \mathbf { H } \in \mathcal { H } } \left| R _ { \mathcal { M } ^ { \tau } } ( \mathbf { H } ) - R _ { \mathbf { G } } ( \mathbf { H } ) \right| .
$$

Theorem 1 Suppose a neural network is equipped with filters defined in Definition 2 and normalized nonlinearites (Assumption 2). The neural network is operated on a graph $\mathbf { G }$ generated according to (6) from $\mathcal { M }$ and a mismatched manifold $\mathcal { M } ^ { \tau }$ with a bandlimited (Definition $\jmath$ ) input manifold function. Suppose the mismatch $\tau : { \mathcal { M } } \to { \mathcal { M } }$ satisfies $d i s t ( x , \tau ( x ) ) \leq \gamma$ and $\| J _ { x } ( \tau ) - I \| _ { F } \leq \gamma$ for all $x \in \mathcal { M }$ . The generalization of neural network trained on $\mathbf { G }$ to minimize a normalized Lipschitz loss function (Assumption $^ 3$ ) holds in probability at least $1 - \delta$ that

$$
G A _ { \tau } \leq C _ { 1 } \frac { \epsilon } { \sqrt { N } } + C _ { 2 } \frac { \sqrt { \log ( 1 / \delta ) } } { N } + C _ { 3 } \left( \frac { \log N } { N } \right) ^ { \frac { 1 } { d } } + C _ { 4 } \gamma ,
$$

with $\epsilon \sim \bigg ( \frac { \log ( C / \delta ) } { N } \bigg ) ^ { \frac { 1 } { d + 4 } }$ , $C _ { 1 }$ scaling with $\boldsymbol { C } _ { L }$ , $C _ { 4 }$ scaling with $\boldsymbol { C } _ { L }$ and $C _ { g }$ . $C _ { 1 } ^ { \mathrm { ~ \ i ~ } }$ and $C _ { 3 }$ depend on the geometry of $\mathcal { M }$ .

Remark 1 This conclusion is ready to extend to multilayer and multi-feature neural network architectures, as the neural network is cascaded by layers of filters and nonlinearities. The generalization error propagates across layers, leading to an increase in the generalization gap of multi-layer and multi-feature GNNs with the size of the architecture, which we will further verify in simulations.

Theorem 1 indicates that the generalization of GNNs is robust to model mismatches, with the generalization gap decreasing with the number of nodes $N$ in the training graph. As more points are sampled from the manifold, the generated graph can better approximate the underlying manifold. This leads to a better generalization of the GNN to predict the unseen points over the manifold. The upper bound also increases with the dimension of the underlying manifold $d$ , as higher dimension indicates higher model complexity. Specifically, the generalization gap increases with the mismatch size $\gamma$ as the testing manifold is shifted more from the original manifold.

Remark 2 It is important to note that there is a tradeoff involved in designing GNNs: achieving better generalization often comes at the cost of reduced discriminability. Specifically, using a smaller $\boldsymbol { C } _ { L }$ leads to improved generalization and robustness by reducing generalization error. While this leads to smoother filter functions, which limits the GNN ability to discriminate between different spectral components. This reduced discriminability can negatively impact prediction performance. In essence, we can enhance better and more robust generalization capabilities of GNNs, but this improvement necessitates a compromise in their discriminative power.

# Extension to Graph Classification

The generalization ability of GNN can be extended from the node level to the graph level, which indicates the manifold classification with approximated graph classification.

Suppose we have manifolds $\{ \bar { \mathcal { M } } _ { k } ^ { \bar { \tau } _ { k } } \} _ { k = 1 } ^ { K }$ with dimension $d _ { k }$ under a mismatch $\tau _ { k }$ . Manifold $\mathcal { M } _ { k } ^ { \tau _ { k } }$ is labeled with $y _ { k } \in \mathbb { R }$ . The manifolds are smooth, compact, differentiable, and∈embedded in $\mathbb { R } ^ { \mathsf { M } }$ with measure $\mu _ { \tau _ { k } , k }$ . Each manifold $\mathcal { M } _ { k } ^ { \tau _ { k } }$ is equipped with a weighted Laplace operator $\mathcal { L } _ { \tau _ { k } , k }$ . Assume that we can access $N _ { k }$ randomly sampled points according to $\mu _ { k }$ over each manifold $\mathcal { M } _ { k }$ . Graphs generated based on these sampled points are denoted as $\{ \mathbf { G } _ { k } \} _ { k = 1 } ^ { K }$ with graph Laplacians $\{ \mathbf { L } _ { k } \} _ { k = 1 } ^ { K }$ . A GNN $\Phi ( { \bf H } , { \bf L } . , { \bf x } . )$ is trained on these graphs with $\mathbf { x } _ { k }$ denoted as the input data on graphs sampled from the data on manifolds ${ f _ { k } } ^ { \star } \in \ L ^ { 2 } ( \mathcal { M } _ { k } )$ . The output of the GNN is set as the average of the output values over all the nodes while the output of MNN $\Phi ( \bar { \bf H } , \mathcal { L } _ { \tau . , . , f . } )$ is the averaged value over the mismatched manifold. Loss function $\ell$ evaluates the performance of GNN and MNN by comparing the difference between the output label and the target label. The empirical risk that the GNN is trained to minimize is defined as

$$
R _ { { \bf G } } ( { \bf H } ) = \sum _ { k = 1 } ^ { K } \ell \left( \frac { 1 } { N _ { k } } \sum _ { i = 1 } ^ { N _ { k } } [ \Phi ( { \bf H } , { \bf L } _ { k } , { \bf x } _ { k } ) ] _ { i } , y _ { k } \right) .
$$

The statistical risk is defined based on the statistical MNN output and the target label over mismatched models as

$$
R _ { \mathcal { M } ^ { \tau } } ( \mathbf { H } ) = \sum _ { k = 1 } ^ { K } \ell \left( \int _ { \mathcal { M } _ { k } } \Phi ( \mathbf { H } , \mathcal { L } _ { \tau _ { k } , k } , f _ { k } ) ( x ) \mathrm { d } \mu _ { \tau _ { k } } ( x ) , y _ { k } \right) .
$$

The generalization gap is therefore

$$
G A _ { \tau } = \operatorname* { s u p } _ { \mathbf { H } \in \mathcal { H } } \left| R _ { \mathcal { M } ^ { \tau } } ( \mathbf { H } ) - R _ { \mathbf { G } } ( \mathbf { H } ) \right| .
$$

Theorem 2 Suppose the GNN and MNN with filters defined in Definition 2 and the input manifold functions are bandlimited (Definition 1). Suppose the mismatches $\tau _ { k } : \mathcal { M } _ { k } $

$\mathcal { M } _ { k }$ where $d i s t ( x , \tau _ { k } ( x ) ) \leq \gamma$ and $\| J _ { x } ( \tau _ { k } ) - I \| _ { F } \leq \gamma$ for all $x \in \mathcal { M } _ { k }$ for $k = 1 , 2 , \cdots K$ . Under Assumptions 2 and $3$ it holds in probability at least $1 - \delta$ that

$$
\begin{array} { r } { G A _ { \tau } \le \displaystyle \sum _ { k = 1 } ^ { K } \left( \displaystyle \frac { C _ { 1 } } { \sqrt { N _ { k } } } \epsilon _ { k } + C _ { 2 } \displaystyle \frac { \sqrt { \log ( 1 / \delta ) } } { N _ { k } } \right) + } \\ { C _ { 3 } \displaystyle \sum _ { k = 1 } ^ { K } \left( \displaystyle \frac { \log N _ { k } } { N _ { k } } \right) ^ { \frac { 1 } { d _ { k } } } + K C _ { 4 } \gamma , } \end{array}
$$

with $\begin{array} { r } { \epsilon _ { k } \sim \left( \frac { \log \left( C / \delta \right) } { N _ { k } } \right) ^ { \frac { 1 } { d _ { k } + 4 } } } \end{array}$ , $C _ { 1 }$ and $C _ { 4 }$ scaling with $\displaystyle \mathit { C _ { L } }$ . $C _ { 1 }$   
and $C _ { 3 }$ depend on the geometry of $\mathcal { M }$ .

Theorem 2 indicates that a graph with large enough points sampled from each underlying manifold can approximately predict the label for mismathed manifolds. This shows that GNN trained over these generated graphs can generalize to classify unseen graphs generated from mismatched manifold models. The generalization gap on the graph level also decreases with the number of sampled points over each manifold. The generalization gap increases with the dimensions of the manifolds and the size of deformations. A similar trade-off phenomenon can also be observed.

# Experiments

# Node Classification with Arxiv Dataset

In this section, we showcase the generalization properties of a trained GNN on a real-world dataset, OGBN-Arxiv (Wang et al. 2020). The graph has 169, 343 nodes and 1, 166, 243 edges, representing the citation network between computer science arXiv papers. The node features are 128 dimensional embeddings of the title and abstract of each paper (Mikolov et al. 2013). The objective is to predict which of the 40 categories the paper belongs to. We consider two types of perturbations to model the impact of the underlying manifold model mismatch – node and edge perturbations.

In all cases, we train the GNN on the original graph, and we evaluate it on the perturbed graph. The generalization gap is measured by the difference between the training accuracy and the perturbed testing accuracy. For node perturbations, we randomly zero out a percentage of the 128 dimensional embeddings for all the points in the dataset. Theoretically, that corresponds to modifying the underlying scalar function $f$ (see equation (11)). For the edge perturbation, we randomly remove a percentage of the existing edges in the graph. This corresponds to perturbing the Laplace operator $\mathcal { L }$ (see equation (12)). We run these experiments for a varying number of nodes, by partitioning the training set in $\{ 1 , 2 , 4 , 8 , . . . 5 1 2 , 1 0 2 4 \}$ partitions. We train the GNN with the cross-entropy loss, for 1000 epochs, using 0.005 learning rate, ADAM optimizer (Kingma and Ba 2014), and no weight decay with ReLU non-linearity. The purpose of the experiments is to show that GNN with more layers and hidden units has a larger generalization gap under the same perturbation level. We further verify the relationship between the generalization gaps and the logarithm of the number of nodes in the graphs as indicated in Theorem 1.

70 Layers 4, Hidden 64 70 Layers 4, Hidden 64 Layers 4, Hidden 128 Layers 4, Hidden 128   
50 60 Layers 43, Hidden 26546 Layers 3, Hidden 128 50 60 Layers 43, Hidden 26546 Layers 3, Hidden 128   
2340 Layers 32, Hidden 26546 Layers 2, Hidden 128 2340 Layers 32, Hidden 26546 Layers 2, Hidden 128 . Layers 2, Hidden 256 . Layers 2, Hidden 256 10 10 AAs 0 10 20 30 40 50 60 70 80 90 10 20 30 40 50 60 70 80 90 Perturbed values (%) Perturbed values (%) (a) 90941 nodes (b) 2841 nodes

![](images/c1ce559f672e52f3c34ec2bc1a5b3c3e62e908e21dac58b8bf4a684bd7e1ea51.jpg)  
Figure 2: Generalization gap as a function of the percentage of perturbed feature values in node feature perturbation.   
Figure 3: Generalization gap as a function of the percentage of perturbed edges values in node removal perturbation

In Figure 2 we can see the generalization gap as a function of the perturbation level for different GNN architectures. In these two figures, we confirm that GNNs with fewer layers and fewer hidden units are more robust to changes in the underlying manifold. This can be seen as the black lines (2 layers), are below both the red (3 layers) and the blue lines(4 layers). Intuitively, this can be attributed to overfitting the training set, given that more capacity in the GNN translates into a better training set accuracy. We also showcase that if the number of nodes in the training set is larger, the GNN is more robust to changes on the graph, given that the generalization gap increases more slowly in the GNN trained with 90941 nodes (Figure 2a), than in the one trained with 2841 nodes (Figure 2b). In Figure 3, we plot the generalization gap as a function of the perturbation magnitude for a GNN with 3 (Figure 3a), and 4 layers (Figure 3b). In both cases, the GNN with the largest number of hidden units is at the top, thus indicating that a larger generalization gap as indicated in Remark 1.

Figure 4 shows the generalization gaps of GNNs under node feature perturbations and edge perturbations decrease approximately linearly with the number of nodes in the logarithmic scale while increasing with the perturbation sizes. In Figure 4a and 4b, we show the generalization gap of a 3 layered GNN with 256 hidden units as a function of the number of nodes in the training set under node feature perturbation and edge removal perturbation, respectively. Each color in the figure represents a different perturbation level, going from less perturbation ( $1 6 \%$ darker blue) to higher perturbation ( $7 2 \%$ lighter yellow). As can be seen in the plot, the GNNs generalization degrades as the perturbation level increases. Aligning with our theory, the generalization gap is linear with respect to the logarithm of the number of nodes. This is also true when the perturbation level increases.

# Graph Classification with ModelNet Dataset

We evaluate the generalization gap of GNNs on graph level with the ModelNet10 dataset (Wu et al. 2015). The dataset contains 3991 meshed CAD models from 10 categories for training and 908 models for testing. For each model, discrete points are uniformly randomly sampled from all points of the model to form the graphs. Each point is characterized by the 3D coordinates as features. Each node in the graph can be modeled as the sampling point and each edge weight is constructed based on the distance between each pair of nodes. The input graph features are set as the coordinates of each point, and the weights of the edges are calculated based on the Euclidean distance between the points.

![](images/fc7f8d8ec823c0361e3da9ec5853469cf505217c4934ff251bd75cd3c8cc39b5.jpg)  
Figure 4: Generalization gap for edge and node perturbation for the Arxiv dataset for a 3 layered, 256 feature GNN.

![](images/35dc1c17a9cfc82fac49641cf11b7604a4e9b720d009454a4a39b928503ab20c.jpg)  
Figure 5: Generalization gap as a function of number of nodes in the Point Cloud Classification.

The mismatched point cloud model adds a Gaussian random variable with mean $\gamma$ and variance $2 \gamma$ to each coordinate of every sampled point. This can be seen as the underlying manifold mismatch. We calculate the generalization gap by training GNNs on graphs with $N = 4 0$ sampled points, and plotting the differences between the testing accuracy on the trained graphs sampled from normal point clouds and the testing accuracy on the graphs sampled from deformed point clouds with perturbation level $\gamma$ . We implement Graph Neural Networks (GNN) with 1 and 2 layers with a single layer containing $F _ { 0 } = 3$ input features which are the 3d coordinates of each point, $F _ { 1 } = 6 4$ output features and $K = 5$ filter taps. While the architectures with 2 layers has another layer with $F _ { 2 } = 3 2 \$ features and 5 filter taps. We use the ReLU as nonlinearity. All architectures also include a linear readout layer mapping the final output features to a binary scalar that estimates the classification. Figure 5a shows the generalization gaps for GNNs with or without Lipschitz continuity assumptions of the graph filters. We observe that the continuity assumptions imposed on the graph filters help to improve the generalization capabilities as Theorem 2 shows. Figure 5b shows the results of GNNs on different number of nodes. We can see that the generalization gaps of GNNs scale with the size of the GNN architectures and scale with the size of mismatch. Figure 5b also shows that the generalization gap decreases with the number of nodes.

# Conclusion

We showed that the robustness of GNN generalization to model mismatch from a manifold perspective. We focused on graphs derived from manifolds, and we established that GNNs equipped with low-pass and integral Lipschitz graph filters exhibit robust generalization. This generalization extends to previously unseen nodes and graphs derived from mismatched manifolds. Notably, we identified a tradeoff between the robust generalization and discriminability of GNNs. We validate our results both on node-level and graphlevel classification tasks with real-world datasets.