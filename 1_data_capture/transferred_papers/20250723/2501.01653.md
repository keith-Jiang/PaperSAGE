# Look Back for More: Harnessing Historical Sequential Updates for Personalized Federated Adapter Tuning

Danni Peng1, Yuan Wang1, Huazhu $\mathbf { F u } ^ { 1 }$ , Jinpeng Jiang2, Yong Liu1, Rick Siow Mong $\mathbf { G o h } ^ { 1 }$ , Qingsong Wei1

1Institute of High Performance Computing (IHPC), Agency for Science, Technology and Research (A\*STAR), Singapore 2EVYD Technology dannip@ihpc.a-star.edu.sg, wang yuan $@$ ihpc.a-star.edu.sg, hzfu@ieee.org, jinpeng.jiang $@$ evydtech.com, liuyong@ihpc.a-star.edu.sg, gohsm $@$ ihpc.a-star.edu.sg, wei qingsong $@$ ihpc.a-star.edu.sg

# Abstract

Personalized federated learning (PFL) studies effective model personalization to address the data heterogeneity issue among clients in traditional federated learning (FL). Existing PFL approaches mainly generate personalized models by relying solely on the clients’ latest updated models while ignoring their previous updates, which may result in suboptimal personalized model learning. To bridge this gap, we propose a novel framework termed pFedSeq, designed for personalizing adapters to fine-tune a foundation model in FL. In pFedSeq, the server maintains and trains a sequential learner, which processes a sequence of past adapter updates from clients and generates calibrations for personalized adapters. To effectively capture the cross-client and crossstep relations hidden in previous updates and generate highperforming personalized adapters, pFedSeq adopts the powerful selective state space model (SSM) as the architecture of sequential learner. Through extensive experiments on four public benchmark datasets, we demonstrate the superiority of pFedSeq over state-of-the-art PFL methods.

# Introduction

In recent years, federated learning (FL) (McMahan et al. 2017) has attracted growing research interest for enabling privacy-preserving collaborative model training. However, due to data heterogeneity among clients (i.e. data from different clients are non-IID or unbalanced), it is difficult to develop a one-fits-all global model that performs well on all clients’ local distributions. To address this, personalized federated learning (PFL) (Smith et al. 2017) has emerged. Unlike traditional FL, which develops a single best model for the collective goal, PFL allows each client to have a unique personalized model tailored specifically to the local objective (Li et al. 2021a; Fallah, Mokhtari, and Ozdaglar 2020). Through the collaborative learning scheme, PFL further enables the personalized models to benefit from knowledge sharing across clients, striking a balance between individualization and generalization for enhanced local performance (Kulkarni, Kulkarni, and Pant 2020; Kairouz et al. 2021).

Recently, as large foundation models (FMs) demonstrate impressive capabilities across various tasks, there has seen a rise in research synergizing FL and FMs (Zhuang, Chen, and Lyu 2023). One of the most popular ways of empowering FL with FMs is through parameter-efficient adapter tuning (e.g., LoRA (Hu et al. 2021)), also known as federated adapter tuning (Li et al. 2024; Woisetschla¨ger et al. 2024). This new FL paradigm allows clients to leverage a powerful, pre-trained FM while only fine-tuning and sharing the lightweight adapters with the server, enabling enhanced performance with minimal on-client computation and communication costs. It also opens up opportunities to tailor PFL methods for fine-tuning FM with adapters. For example, leveraging FL for collaborative fine-tuning while personalizing the adapters to better align the representations of pre-trained FM with the local needs of clients (Yi et al. 2023; Xie et al. 2024; Yang et al. 2024).

![](images/39478aedc29e75c575048caa6fa92a88f46049083797a5107efd702857095e32.jpg)  
Figure 1: Comparison between (a) existing PFL methods and (b) our approach. Instead of leveraging only the latest updates, our approach accounts for past learning trajectories by modeling cross-client and cross-step relations in previous steps, providing a broader view for identifying the consistent trends for learning more robust personalized adapters.

However, a common limitation of existing PFL and efforts tailored for FM adapter tuning is that they rely solely on the updates received in the most recent round to develop personalized models, while the potentially valuable information contained in previous updates is either underutilized or completely discarded. This can easily lead to noisy and suboptimal solutions, jeopardizing performance when applied to federated adapter tuning personalization. If we view the development of a personalized adapter for a client as an optimization process, focusing only on the latest updates is akin to performing simple gradient descents. By incorporating information from previous updates—much like using momentum in optimization—the learning process accounts for a broader range of past trajectories and uncovers the consistent trends, leading to more robust and reliable personalized solutions at convergence. Hence, in this work, we are motivated to design a framework that accounts for past learning trajectories to develop enhanced personalized adapters. To illustrate, Figure 1 shows the adapter update trajectories of two clients over three rounds of local tuning and communication. As depicted in Figure 1a, existing PFL methods typically rely only on the interactions among the latest updates to produce personalized adapters, which can lead to less robust and undeterministic solutions by only referencing the current states. In contrast, our approach aims to model the interactions among clients at each past update step, as well as the dependencies across various steps, as shown in Figure 1b, which provides a broader perspective for identifying the consistent update patterns, enabling more robust learning and development of more superior personalized adapters.

Specifically, we propose a novel PFL framework termed pFedSeq for improving personalized federated adapter tuning by exploiting knowledge from clients’ past sequential updates. This is achieved through two main processes at the server during each communication round: (1) standard model aggregation using a traditional FL algorithm to obtain a global adapter (e.g., FedAvg (McMahan et al. 2017)), and (2) leveraging a Sequential Learner to process the sequence of clients’ adapter updates collected at the server and output personalized calibrations to adjust the global adapter for clients’ individual needs. To enable flexible modeling of the cross-client and cross-step relations in the sequence, we employ a learnable hypernetwork for the sequential learner, which is jointly trained at the server by optimizing the personalized adapters toward clients’ local objectives. By using the received adapter updates as a proxy for gradients on local losses, the training of sequential learner can be efficiently performed at server without accessing clients’ local data.

Selecting a suitable architecture for the sequential learner is a non-trivial task. To facilitate effective capture of crossclient and cross-step relations, we propose to employ the selective state space model (SSM) (Gu and Dao 2023) as our sequential learner. Selective SSM is a recurrence-based model introduced recently for efficient sequence modeling. It enjoys both effective performance with time-dependent selectivity and efficient computations with linear scaling. To capitalize on its design features, we form the step-wise inputs by concatenating clients’ updates from the same round and processing them in a recurrence mode. With that, the cross-client interactions at different steps can be captured in the time-dependent module parameters, and the sequential processing allows the cross-step dependencies to be captured in the consolidated hidden states.

To summarize, our contributions are as follows:

• We propose a novel PFL framework, pFedSeq, for personalizing federated adapter tuning for clients. By leveraging knowledge from the previous updates, pFedSeq generates enhanced personalized adapters which better tailor large FMs’ representations to clients’ local needs.

• We collaboratively train a sequential learner at the server to capture useful cross-client and cross-step relations in the sequential updates, achieving effective personalized adapter generation by adopting Selective SSM as the learner architecture.

• We evaluate our pFedSeq rigorously on four largescale benchmark datasets (i.e., CIFAR-100, TinyImageNet, DomainNet, and Omniglot), and show that our pFedSeq outperforms ten state-of-the-art PFL methods by up to $5 . 3 9 \%$ .

# Related Work

Traditional FL algorithms (McMahan et al. 2017; Li et al. 2020; Karimireddy et al. 2020) following the one-modelfits-all paradigm often suffer from degraded performance on clients’ local data in the face of severe data heterogeneity. Recently, personalized FL (PFL) has attracted much attention, which develops customized models to accommodate the diverse needs of clients (Mansour et al. 2020). Generally, efforts in PFL fall under four categories:

(1) Meta-learning-based methods. By drawing an analogy between FL and meta-learning (Jiang et al. 2019), this approach jointly develops a global model from which the personalized models can be effectively fine-tuned with just a few local steps. Per-FedAvg (Fallah, Mokhtari, and Ozdaglar 2020) adopts the spirit of MAML (Finn, Abbeel, and Levine 2017) and jointly learns a global initialization by optimizing for one-step gradient updates. pFedMe (T Dinh, Tran, and Nguyen 2020) further allows multiple updates in the inner loop and optimizes a Moreau envelope objective.

(2) Personalized-aggregation-based methods. This line of methods produces personalized models by learning clientspecific aggregation weights to combine models from other clients. FedFomo (Huang et al. 2021) and FedAMP (Zhang et al. 2021) leverage a rule-based approach to compute weights based on the pair-wise distance between clients’ models. APPLE (Luo and Wu 2022) and FedALA (Zhang et al. 2023) adopt a learning-based approach to optimize the personalized weights directly on clients’ local objectives. FedDPA (Yang et al. 2024) was introduced recently, focusing on addressing test-time distribution shifts by combining global and personalized adapters through dynamic weighting for federated adapter tuning.

(3) Personalized-network-based methods. This approach develops a personalized model independently for each client while drawing on the general knowledge through various forms of global sharing. FedRep (Collins et al. 2021) and FedBN (Li et al. 2021b) locally update parts of the network that are sensitive to data distributions (e.g., the classification head or the batch-norm layers), while sharing the rest to leverage the common representations. Ditto (Li et al. 2021a) trains full personalized models locally, using a proximal term to regularize distance from the global model. PerAda (Xie et al. 2024) was recently introduced for federated adapter tuning. It leverages proximal regularization similar to Ditto, while further incorporating knowledge distillation to facilitate information sharing.

pFedLoRA (Yi et al. 2023) encourages efficient sharing for model-heterogeneous PFL through lightweight adapters.

(4) Hypernetwork-based methods. As opposed to solely relying on model aggregation for information sharing, this approach outlines a new way of federation by jointly training a hypernetwork using feedback returned from clients (e.g., the model updates). The hypernetwork is trained to directly generate personalized model parameters based on some inputs. Since it is only trained and maintained at the server, a high-capacity, complex network can be adopted for enhanced diversity of the models generated without concern about the communication costs. pFedHN (Shamsian et al. 2021) is a pioneering work that leverages this approach to generate personalized models for clients based on the learnable client descriptor vectors. L2C (Li et al. 2022) and pFedLA (Ma et al. 2022) utilize hypernetwork to learn personalized aggregation weights. pFedPG (Yang, Wang, and Wang 2023) focuses on federated prompt learning and trains a hypernetwork for personalized prompt generation. PeFLL (Scott, Zakerinia, and Lampert 2024) and FedL2P (Lee et al. 2023) condition on clients’ local statistics and train a hypernetwork to output personalized models or update strategies.

Our work, by collaboratively training a sequential learner, falls under the hypernetwork-based methods. Different from the existing works, we propose to generate personalized adapters by leveraging clients’ previous updates. In other related fields concerning multi-task/distribution learning similar to FL, past gradient updates are commonly used to enhance task representations (Zenke, Poole, and Ganguli 2017; Flennerhag et al. 2018; Peng and Pan 2023) or to derive relations among different parties (Yu et al. 2020; Mansilla et al. 2021). In the realm of FL, (Ji et al. 2019) utilizes previous clients’ updates to produce global model via an RNNbased aggregator. However, the potential of leveraging previous updates for PFL still remains unexplored. Our work fills this gap by developing a method to extract useful crossclient and cross-step relations from past updates, producing personalized adapters that better suit clients’ local specifics.

# Method

# Preliminaries

Problem Setup. In a typical $\mathrm { F L }$ setup involving $N$ clients and a central server, each client $\textit { i } \in \ [ N ]$ has its own private data $\mathcal { D } _ { i }$ . Traditional FL (e.g., FedAvg (McMahan et al. 2017)) seeks to learn a global model $\phi _ { g }$ that performs well across all clients: $\begin{array} { r } { \operatorname* { m i n } _ { \phi _ { g } } \sum _ { i = 1 } ^ { N } \mathcal { L } ( \mathcal { D } _ { i } ; \bar { \phi _ { g } } ) } \end{array}$ , where $\mathcal { L }$ is an arbitrary loss function. However, this one-model-fits-all scheme may fail when data heterogeneity is severe among clients. PFL addresses this by relaxing the single-model constraint and learning $N$ personalized models $\{ \phi _ { i } \} _ { i = 1 } ^ { N }$ , each tailored specifically to a client, while also benefiting from the federation by drawing knowledge from global model $\phi _ { g }$ :

$$
\begin{array} { r } { \operatorname* { m i n } _ { \{ \phi _ { i } \} _ { i = 1 } ^ { N } , \phi _ { g } } \sum _ { i = 1 } ^ { N } \mathcal { L } ( \mathcal { D } _ { i } ; \phi _ { i } , \phi _ { g } ) . } \end{array}
$$

Personalized Federated Adapter Tuning. Adopting adapter tuning in PFL provides a computation- and communication-efficient solution for clients to harness the power of large FMs. Let $F ^ { * } ( \cdot )$ denote a fixed, pre-trained foundation model backbone (e.g., ViT (Dosovitskiy et al. 2020)), which remains locally at clients. A chosen adapter (e.g., LoRA), denoted by $a _ { \theta } ( \cdot )$ parameterized by $\theta$ , as well as the classification head $h _ { \omega } ( \cdot )$ parameterized by $\omega$ , are tuned at the client to adapt the fixed backbone to local distributions. Since only the adapter and the head are updated and shared with the server, without loss of generality, we define the global and personalized models as $\phi _ { g } ~ = ~ ( \theta _ { g } , \omega _ { g } )$ and $\phi _ { i } = \left( \theta _ { i } , \omega _ { i } \right)$ . The individual loss of client $i$ is computed by:

$$
\begin{array} { r } { \mathcal { L } ( \mathcal { D } _ { i } ; \phi _ { i } , \phi _ { g } ) : = \sum _ { ( \boldsymbol { x } , \boldsymbol { y } ) \in \mathcal { D } _ { i } } l ( h _ { \omega _ { i } , \omega _ { g } } ( F ^ { * } ( \boldsymbol { x } ) + a _ { \theta _ { i } , \theta _ { g } } ( \boldsymbol { x } ) ) , \boldsymbol { y } ) . } \end{array}
$$

# pFedSeq Framework

In this section, we present our pFedSeq framework, designed for personalizing federated adapter tuning. Following (Collins et al. 2021; Yang, Wang, and Wang 2023), we update the classification head locally without sharing with the server to better preserve the client-specific knowledge, and apply pFedSeq to generate the personalized adapters.

An overview of pFedSeq is shown in Figure 2. At each communication round, pFedSeq performs local adapter tuning at the clients and sends the adapter updates to the server. The server then conducts personalized adapter generation with the sequential learner by processing the sequence of past updates collected from clients. Meanwhile, the server also performs sequential learner optimization using the new updates received from the clients as feedback for training. We now introduce each process in detail.

Local Adapter Tuning at Client. Suppose we are at the $t$ -th local training round of client $i$ . Upon receiving the personalized adapter $\theta _ { i } ^ { t - 1 }$ generated by the server in the previous round, we update $\theta _ { i } ^ { t - 1 }$ and $\boldsymbol { \omega } _ { i } ^ { t - 1 }$ jointly on local data $\mathcal { D } _ { i }$ for several local epochs to obtain $\tilde { \theta } _ { i } ^ { t }$ and $\omega _ { i } ^ { t }$ . Note that $\boldsymbol { \omega } _ { i } ^ { t - 1 }$ is not generated by the server and is restored from the previous local update at client $i$ . Also, to be differentiated from the personalized adapter $\theta _ { i } ^ { t }$ generated by the server, we use $\tilde { \theta } _ { i } ^ { t }$ to denote the adapter updated locally. We then compute the adapter update $\Delta _ { i } ^ { t } : = \tilde { \theta } _ { i } ^ { t } - \theta _ { i } ^ { t - 1 }$ and send it to the server.

Personalized Adapter Generation at Server. To generate personalized adapters, two processes are carried out at the server: (1) aggregating clients’ updated adapters to produce a global adapter, and (2) using the sequential learner to process clients’ past updates and output personalized calibrations for tailoring the global adapter to each client.

Specifically, after the $t$ -th communication round, server receives adapter updates {∆it}iN=1 from N clients. To compute the globally aggregated adapter, we need to obtain the clients’ updated adapters $\{ \tilde { \theta } _ { i } ^ { t } \} _ { i = 1 } ^ { N }$ . To avoid doubling the communication costs, we can compute $\{ \tilde { \theta } _ { i } ^ { t } \} _ { i = 1 } ^ { N }$ directly using the adapter updates received from the clients and the personalized adapters $\{ \theta _ { i } ^ { t - 1 } \} _ { i = 1 } ^ { N }$ generated at the server in the previous round, i.e., $\tilde { { \theta } } _ { i } ^ { t } = { \theta } _ { i } ^ { t - 1 } + \Delta _ { i } ^ { t }$ , $\forall i \in [ N ]$ . By using the classic FedAvg (McMahan et al. 2017) for aggregation, we obtain the global adapter $\tilde { \theta } _ { g } ^ { t }$ at the $t$ -th round:

$$
\begin{array} { r } { \tilde { \theta } _ { g } ^ { t } = \sum _ { i = 1 } ^ { N } \frac { \left| \mathcal { D } _ { i } \right| } { \sum _ { i ^ { \prime } = 1 } ^ { N } \left| \mathcal { D } _ { i ^ { \prime } } \right| } \tilde { \theta } _ { i } ^ { t } . } \end{array}
$$

Local Adapter Tuning PersonalizedAdapterGeneration Client Server Client Sequential {X}2 △t-2 △t-1 △t Client 1 Client Updated Updates Adapters clients 1 -³---2 -2---2K- t-1 V 旺 旺 n 旺 旺 2 t-2 ^t-2 Backbone Adapter ? △t-2 △-1 △ Client 2 Global 时 Aggregated ? 0t-3 ->-2 -2 ->-1 时-1 時 Adapter Sequential {Y}2 ? + ? Learner update 中 -1 四 Cuent> -3 -2

Simultaneously, we utilize a sequential learner, which is a hypernetwork, to generate personalized calibrations from the sequential updates. Specifically, at the $t$ -th round, we construct the input to sequential learner by first stacking $\{ \Delta _ { i } ^ { j } \} _ { i = 1 } ^ { N }$ across $N$ clients for each $j \in [ t ]$ collected at the server, forming $\Delta ^ { j } = [ \Delta _ { 1 } ^ { j } , \cdots , \Delta _ { N } ^ { j } ] \in \mathbb { R } ^ { D \times N }$ , where $D$ is the dimensionality of the adapter’s parameters. We then concatenate $\{ \Delta ^ { j } \} _ { j = 1 } ^ { t }$ across $t$ steps, forming the sequence input matrix $\Delta ^ { 1 : t } = [ \Delta ^ { 1 } , \cdots , \Delta ^ { t } ] \in \mathbb { R } ^ { D \times N \times t }$ . The sequential learner, denoted by $\operatorname { S e q L e a r n e r } ( \cdot ; \psi )$ parameterized by $\psi$ , outputs the personalized calibrations $\pmb { \xi } ^ { t } = [ \xi _ { 1 } ^ { t } , \cdot \cdot \cdot , \xi _ { N } ^ { t } ] \in$ RD×N for the N clients by taking in the sequence input ∆1:t:

$$
\begin{array} { r } { \pmb { \xi } ^ { t } = \mathrm { S e q L e a r n e r } ( \Delta ^ { 1 : t } ; \psi ) . } \end{array}
$$

Note that by treating $D$ as the batch dimension, we employ one SeqLearner $( \cdot ; \psi )$ to capture the cross-client and cross-step relations for all parameters of an adapter. Hence, the size of $\mathrm { S e q L e a r n e r } ( \cdot ; \psi )$ is independent of the adapter size $D$ and only depends on the number of clients $N$ and the sequence length $t$ . For better expressivity, we assign one SeqLearner $( \cdot ; \psi )$ to learn the parameters of the adapter attached to each layer of the backbone (e.g., ViT-B/16 contains 12 layers (Dosovitskiy et al. 2020)).

Finally, we obtain the personalized adapters $\lbrace \boldsymbol { \theta } _ { i } ^ { t } \rbrace _ { i = 1 } ^ { N }$ for the $t$ -th round by adding $\{ \xi _ { i } ^ { t } \} _ { i = 1 } ^ { N }$ to the global adapter $\tilde { \theta } _ { g } ^ { t }$ :

$$
\begin{array} { r } { \theta _ { i } ^ { t } = \tilde { \theta } _ { g } ^ { t } + \xi _ { i } ^ { t } , \ \forall i \in [ N ] . } \end{array}
$$

The personalized adapters $\{ \theta _ { i } ^ { t } \} _ { i = 1 } ^ { N }$ are sent to the clients for the next round of local training.

Sequential Learner Optimization at Server. Since the objective of the sequential learner is to generate effective personalized calibrations that perform well on clients’ local data, we optimize the parameters $\psi$ of SeqLearner $( \cdot ; \psi )$ by:

$$
\begin{array} { r } { \operatorname* { m i n } _ { \psi } \sum _ { i = 1 } ^ { N } \mathcal { L } ( \mathcal { D } _ { i } ; \boldsymbol { \theta } _ { i } ) , } \end{array}
$$

Sequential Learner Optimization ht-1 Optimization Inference △△ 1 △t-²△-²△5-²△t-1△-1△5-1△t△△ Proj. Bt   
ht Learuer Obt- Learuer ht Learuer ht Discr. At 55151 ct 强弦發   
Sequential △△△ →Forward pass 强柒缘 + Learner ←--Backwardpass ht Selective SSM Client1 Client 2 Client 3 (a) (b)

where $\theta _ { i } = \tilde { \theta } _ { g } + \xi _ { i } = \tilde { \theta } _ { g } + ( \mathrm { S e q L e a r n e r } ( \Delta ; \psi ) ) _ { : , i } .$ Using chain rule, the gradient update for $\psi$ from each client $i$ is given by $\nabla _ { \psi } \mathcal { L } ( \mathcal { D } _ { i } ; \theta _ { i } ) = ( \nabla _ { \psi } \xi _ { i } ) ^ { \top } \nabla _ { \theta _ { i } } \mathcal { L } ( \mathcal { D } _ { i } ; \theta _ { i } )$ (note that $\nabla _ { \xi _ { i } } \theta _ { i } = \mathbb { I } ,$ ). Following (Shamsian et al. 2021; Scott, Zakerinia, and Lampert 2024), we approximate $\nabla _ { \theta _ { i } } \mathcal { L } ( \mathcal { D } _ { i } ; \theta _ { i } )$ using the adapter update $\Delta _ { i }$ received from client $i$ . This is equivalent to replacing a single gradient step on $\theta _ { i }$ with multiple gradient update steps, which has been shown to achieve better and more stable convergence (Shamsian et al. 2021).

Specifically, at the $t$ -th round, we receive adapter updates $\{ \Delta _ { i } ^ { t } \} _ { i = 1 } ^ { N }$ from clients. Recall that these are the updates from the previous round’s personalized adapters $\{ \theta _ { i } ^ { t - 1 } \} _ { i = 1 } ^ { N }$ , i.e., $\Delta _ { i } ^ { t }$ is the proxy for gradient evaluated at $\theta _ { i } ^ { t - 1 }$ , indicating the optimization direction at $\theta _ { i } ^ { t - 1 }$ . Hence, we use $\{ \Delta _ { i } ^ { t } \} _ { i = 1 } ^ { N }$ as the signal to adjust $\{ \theta _ { i } ^ { t - 1 } \} _ { i = 1 } ^ { N }$ , which constitutes $\{ \xi _ { i } ^ { t - 1 } \} _ { i = 1 } ^ { N }$ generated by inputting ∆1:t−1 (i.e., sequence until $t - 1 )$ to SeqLearner $( \cdot ; \psi )$ . Formally, we compute the update $( \Delta \psi ) ^ { t }$ for $\psi$ at the $t$ -th round by:

$$
\begin{array} { r l } & { ( \Delta \psi ) ^ { t } = \sum _ { i = 1 } ^ { N } ( \nabla _ { \psi } \xi _ { i } ^ { t - 1 } ) ^ { \top } \Delta _ { i } ^ { t } , } \\ & { \quad \quad \quad \mathrm { w h e r e } \xi _ { i } ^ { t - 1 } = ( \mathrm { S e q L e a r n e r } ( \Delta ^ { 1 : t - 1 } ; \psi ) ) _ { : , i } . } \end{array}
$$

After updating SeqLearner $( \cdot ; \psi )$ , we perform inference to generate $\{ \xi _ { i } ^ { t } \} _ { i = 1 } ^ { N }$ by inputting $\Delta ^ { 1 : t }$ (including the latest update $\Delta ^ { t }$ ) to SeqLearner $( \cdot ; \psi )$ , as described in (2). The optimization and inference processes of sequential learner at the $t$ -th round are illustrated in Figure 3a.

Remarks. To avoid infinitely growing sequence length as the number of update rounds increases, we cap the sequence input at a maximum length $L$ , i.e., (2) becomes:

$$
\pmb { \xi } ^ { t } = \left\{ \begin{array} { l l } { \mathrm { S e q L e a r n e r } ( \Delta ^ { 1 : t } ; \psi ) } & { \mathrm { f o r } t \le L } \\ { \mathrm { S e q L e a r n e r } ( \Delta ^ { t - L + 1 : t } ; \psi ) } & { \mathrm { f o r } t > L } \end{array} \right.
$$

Also, to ensure that $\mathrm { S e q L e a r n e r } ( \cdot ; \psi )$ generates reliable personalized adapters for the next round of local update for stable convergence, we set a warm-up period $W$ to sufficiently train SeqLearner $( \cdot ; \psi )$ before putting it into use. That is, for the first $W$ rounds, the server only updates SeqLearner $( \cdot ; \psi )$ without using it to generate the personalized calibrations, and only the global adapter $\tilde { \theta } _ { g } ^ { t }$ is sent to clients during the warm-up period. Algorithm 1 in Appendix A summarizes the workflow.

# Sequential Learner using Selective SSM

In this section, we introduce an instantiation of the sequential learner using Selective SSM as the learner architecture. Selective SSM is recently introduced for efficient sequence modeling (Gu and Dao 2023). In terms of modeling crossclient and cross-step relations, the selection mechanism of Selective SSM allows cross-client interactions at different steps to be captured in the input-dependent parameters. At the same time, the recursive processing effectively abstracts the cross-step dependencies in the internal hidden states.

Given a sequence input $\pmb { \Delta } ^ { t - L + 1 : t } \in \mathbb { R } ^ { D \times N \times L }$ of length $L$ , Selective SSM generates output $\pmb { \xi } ^ { j } \in \mathbb { R } ^ { D \times N }$ at each step $j \in [ t - L + 1 : t ]$ by taking in the previous step hidden state $h ^ { j - 1 } \in \mathbb { R } ^ { D \times N \times M }$ and the current step input $\bar {  { \Delta } } ^ { j } \in \mathbb { R } ^ { D \times N }$ , where $M$ is an expanded latent dimension. The step-wise modular operation is formulated as follows:

$$
h ^ { j } = \bar { \bf A } ^ { j } h ^ { j - 1 } + \bar { \bf B } ^ { j } \Delta ^ { j } , \quad \xi ^ { j } = { \bf C } ^ { j } h ^ { j } ,
$$

where $\bar { \mathbf { A } } ^ { j } , \bar { \mathbf { B } } ^ { j } \in \mathbb { R } ^ { D \times N \times M }$ are discretized parameters, and $\mathbf { C } ^ { j } \in \mathbb { R } ^ { D \times M }$ is a projection matrix, all obtained by conditioning on the current step input $\Delta ^ { j }$ (a concatenation of $N$ clients’ updates), i.e., $\bar { \mathbf { A } } ^ { j } = \bar { s } _ { \bar { \mathbf { A } } } ( \Delta ^ { j } ) , \bar { \mathbf { B } } ^ { j } = s _ { \bar { \mathbf { B } } } ( \Delta ^ { j } ) , \mathbf { C } ^ { j } =$ $s _ { \mathbf { C } } ( \Delta ^ { j } )$ (detailed formulations in (Gu and Dao 2023)). Note that we input a sequence $\Delta ^ { t - L + 1 : t }$ into Selective SSM, and optimize or perform inference only on the final-step output $\xi ^ { \frac { \dag } { t } }$ . Figure 3b illustrates a step module of Selective SSM.

Following (Gu and Dao 2023), we incorporate a 1D convolution and a residual connection before and after the Selective SSM, forming a Mamba block. A detailed description of our architecture is included in Appendix B.

# Experiments Experimental Setup

Datasets and Heterogeneity Scenarios. We evaluate our ${ \tt p F e d S e q }$ on four benchmark datasets covering three different data heterogeneity scenarios. For label-skew scenario, we use CIFAR-100 (Krizhevsky et al. 2009) which consists of 60,000 images from 100 classes, and Tiny-ImageNet (Chrabaszcz, Loshchilov, and Hutter 2017) which consists of 110,000 images from 200 classes. For both datasets, we simulate label-skew heterogeneity by distributing data in each class over 10 clients with a Dirichlet distribution $D i r ( 0 . 1 )$ , following (Yang, Wang, and Wang 2023; Zhang et al. 2023). For feature-skew scenario, we consider DomainNet, which involves 600,000 images from 345 classes across 6 domains (i.e., Clipart, Infograph, Painting, Quickdraw, Real, and Sketch). Following (Li et al. 2021b), we use the top ten most frequent classes for experiments, simulating feature skew across clients by treating each domain as a client (i.e., $N = 6 \AA$ ). Furthermore, we consider a real-world heterogeneous scenario where data are collected from actual clients. We adopt Omniglot, which contains images of 1,623 characters from 50 alphabets, handwritten by 20 different individuals. We treat each individual as a client (i.e., $N = 2 0$ ) and predict the alphabet to which a character belongs.

Baselines. We compare the performance of pFedSeq against 12 baselines, including 2 traditional methods and 10 state-of-the-art PFL methods. For traditional baselines, we consider Local and classic FedAvg, where the former performs local adapter tuning only without sharing information with other clients, while the latter aggregates a global adapter and a global head to share with all clients. For PFL baselines, we include meta-learning-based methods Per-FedAvg (Fallah, Mokhtari, and Ozdaglar 2020) and pFedMe (T Dinh, Tran, and Nguyen 2020); personalizedaggregation-based methods APPLE (Luo and Wu 2022) and FedALA (Zhang et al. 2023); personalized-networkbased methods FedRep (Collins et al. 2021), Ditto (Li et al. 2021a), and PerAda (Xie et al. 2024); and hypernetworkbased methods pFedHN (Shamsian et al. 2021), pFedLA (Ma et al. 2022), and PeFLL (Scott, Zakerinia, and Lampert 2024). All methods are evaluated on clients’ local test sets, and the final result is computed by averaging over all clients.

Implementation Details. For fair comparisons, we adapt all compared methods to the same federated adapter tuning setup, where we adopt ViT-B/16 (Dosovitskiy et al. 2020) pre-trained on ImageNet21k (Deng et al. 2009) as the fixed backbone $F ^ { * }$ and fine-tune LoRA adapter (Hu et al. 2021). We implement all methods by tuning and sharing only the LoRA and the classification head using the respective PFL algorithms. For all datasets, the number of communication rounds $T$ is set to 80. At each round, the clients perform adapter tuning for 1 local epoch using SGD optimizer with a batch size of 32. The local learning rate is set to 0.05 for Omniglot and 0.005 for other datasets. For our pFedSeq, we adopt a 2-layer Mamba as our sequential learner and set the expanded state dimension $M$ to 16. We train our sequential learner using Adam optimizer with learning rate 0.001, similarly for other hypernetwork-based methods. For all datasets, we set the number of warm-up rounds $W$ to 10 and tune the maximum sequence length $L$ in $\{ 5 , 1 0 , 1 5 , 2 0$ , $2 5 , 3 0 \}$ . All experiments are conducted on NVIDIA A100 GPUs with 40GB memory. We repeat each experiment with 3 seeds and report the mean and standard deviation. More implementation details can be found in Appendix C.

Table 1: Performance comparison on four datasets. For fair comparisons, all methods are adapted to the same federated adapter tuning setup (i.e., fine-tuning fixed ViT with LoRA).   

<html><body><table><tr><td rowspan="2">Method</td><td colspan="2">Label-Skew</td><td>Feature-Skew</td><td>Real-World</td></tr><tr><td colspan="2">CIFAR-10O Tiny-ImageNet DomainNet Omniglot</td><td></td><td></td></tr><tr><td>Local FedAvg</td><td>92.94±0.02 87.36±0.12</td><td>92.52±0.11 87.98±0.19</td><td>78.67±0.15 78.19±0.19</td><td>38.36±0.24 37.87±0.84</td></tr><tr><td colspan="5">Meta-Learning-Based</td></tr><tr><td rowspan="2">Per-FedAvg pFedMe</td><td>93.68±0.08</td><td>93.28±0.03</td><td></td><td>80.62±0.67 40.73±0.40</td></tr><tr><td>93.35±0.10</td><td>93.62±0.04</td><td>81.71±0.28</td><td>41.90±0.44</td></tr><tr><td colspan="5">Personalized-Aggregation-Based</td></tr><tr><td>APPLE</td><td>93.38±0.08</td><td>93.23±0.01</td><td>80.34±0.81</td><td>40.35±0.72</td></tr><tr><td>FedALA</td><td>93.73±0.02</td><td>93.30±0.02</td><td>81.17±0.76</td><td>39.86±0.46</td></tr><tr><td colspan="5">Personalized-Network-Based</td></tr><tr><td>FedRep Ditto</td><td>94.06±0.11</td><td>93.01±0.18</td><td>81.31±0.48</td><td>38.04±0.10</td></tr><tr><td>PerAda</td><td>93.87±0.05</td><td>93.46±0.02</td><td>80.74±0.90</td><td>41.18±0.46</td></tr><tr><td></td><td>93.91±0.07</td><td>93.43±0.02</td><td>80.93±0.85</td><td>41.72±0.53</td></tr><tr><td colspan="5">Hypernetwork-Based</td></tr><tr><td>pFedHN</td><td>94.46±0.37</td><td>93.51±0.18</td><td>81.98±0.40</td><td>42.48±0.19</td></tr><tr><td>pFedLA</td><td>93.42±0.21</td><td>93.37±0.11</td><td>80.26±0.20</td><td>41.27±0.55</td></tr><tr><td>PeFLL</td><td>94.41±0.05</td><td>93.70±0.26</td><td>82.42±0.17</td><td>42.98±0.18</td></tr><tr><td>pFedSeq</td><td>95.30±0.09</td><td>94.30±0.08</td><td>84.63±0.24</td><td>45.25±0.16</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>

# Baseline Comparison

Table 1 compares the performance of pFedSeq against baselines applied to the same federated adapter tuning setup. On all the four datasets, our pFedSeq achieves the highest performance, with significant margins of $\{ 0 . 8 4 \%$ , $0 . 6 \%$ , $2 . \dot { 2 } 1 \%$ , $2 . 2 7 \% \}$ over the second-best performer (i.e., pFedHN or PeFLL). Notably, we observe greater gains for DomainNet and Omniglot characterized by distinct domain discrepancies across clients. This demonstrates the efficacy of our method in personalizing adapters to better adjust the backbone representations for different styles or feature distributions. Throughout Table 1, we observe that all PFL methods outperform Local and FedAvg, indicating their effectiveness in balancing global and local knowledge. As compared to meta-learning and personalized-network methods, which drive the personalized adapters too closely to the global model (through common initialization or regularization), our pFedSeq directly produces diverse personalized calibrations that better adjust the global adapter to clients’ local specifics, leading to better results. Unlike aggregation-based methods, which linearly combine clientspecific adapters, pFedSeq leverages the non-linearity of a hypernetwork to model the complex client relations and achieves better knowledge transfer. A closer look at Table 1 reveals that hypernetwork-based methods, such as pFedHN, PeFLL, and our pFedSeq, outshine other types of methods, demonstrating the advantages of using hypernetworks to directly produce small-sized adapters. Our pFedSeq, by using the sequential learner to capture the cross-client and cross-step relations, further outperforms the existing

CIFAR-100 Tiny-ImageNet 0.96 0.94 0.94 Local 0.92 Local FedAvg FedAvg Per-FedAvg Per-FedAvg APPLE FedRep 0.88 APPLE FedRep PerAda PerAda 0.86 PeFLL PeFLL pFedSeq (Ours) 0.86 pFedSeq (Ours) 0.84 0 102030 40 5060 7080 01020304050607080 Communication rounds Communication rounds

hypernetwork-based methods. More discussions on baseline comparisons are included in Appendix D.

In Figure 4, we show the learning curves of pFedSeq and compared baselines over 80 communication rounds for CIFAR-100 and Tiny-ImageNet (the plots for DomainNet and Omniglot are included in Appendix D). For clearer visualization, we only present the curves of representative baselines under each PFL category. From the plots, we can see that our pFedSeq (blue line) begins to outperform all the baselines at around the 25-th round. Though our pFedSeq shows similar performance to FedRep (green line) during the warm-up phase (i.e., the first 10 rounds), where only the global adapter is sent out for clients’ local evaluation, we observe rapid improvement once pFedSeq begins to use the personalized adapters generated by the stably trained sequential learner, quickly surpassing all baselines in the next 15 rounds. The accelerated learning demonstrates the advantages of leveraging previous update steps for deriving more robust and superior personalized adapters, which enables a positive feedback loop between enhanced local updates and better generated personalized adapters, facilitating faster learning and improved performance at convergence.

# Analysis of pFedSeq

In this section, we first conduct experiments to verify the effectiveness of the various design components of pFedSeq. Then, we provide detailed analysis of the impact of the maximum sequence length $L$ on the performance of pFedSeq.

Effectiveness of Key Components. We examine how the three key components of pFedSeq (i.e., global aggregation, cross-step modeling, cross-client modeling) contribute to its overall performance by introducing three variants: variant A removes global aggregation from pFedSeq and uses the sequential learner to generate personalized adapters directly instead of personalized calibrations; variant B eliminates cross-step modeling by using only the latest updates from all clients to generate personalized calibrations, equivalent to setting $L = 1$ ; variant C eliminates cross-client modeling by generating the personalized calibration for a client using only that client’s sequential updates.

As shown in Table 2, we see that removing global aggregation results in the largest performance drops: $0 . 8 9 \%$ for CIFAR-100 and $1 . 9 6 \%$ for DomainNet, signifying the importance of directly leveraging the knowledge sharing through the global adapter. Also, we note that even without global aggregation, variant A performs comparably to the strongest baselines (e.g., pFedHN and PeFLL), which shows the effectiveness of the cross-step and cross-client modeling for directly generating the personalized adapters. Next, we see that removing either cross-step or cross-client modeling leads to significant performance drops on both datasets: $0 . 6 4 \%$ and $0 . 9 \%$ for CIFAR-100, and $1 . 5 3 \%$ and $0 . 7 8 \%$ for DomainNet, indicating the importance of taking into account both and exploiting their coupled effects in our design. In addition, we observe that both variants B and C surpass the strongest baselines on the two datasets, which shows that even when considered individually, either crossstep or cross-client modeling is effective for generating enhanced personalized adapters.

Table 2: Performance of variants with individual key components removed from pFedSeq.   

<html><body><table><tr><td>Variant</td><td>global aggregation</td><td>cross-step modeling</td><td>cross-client modeling</td><td>CIFAR-100 DomainNet</td><td></td></tr><tr><td>A</td><td></td><td>√</td><td>√</td><td>94.41±0.11</td><td>82.67±0.26</td></tr><tr><td>B</td><td>√</td><td>X</td><td>√</td><td>94.66±0.08</td><td>83.10±0.36</td></tr><tr><td>C</td><td>√</td><td>√</td><td>X</td><td>94.40±0.12</td><td>83.85±0.23</td></tr><tr><td>pFedSeq</td><td>√</td><td>√</td><td>√</td><td>95.30±0.09</td><td>84.63±0.24</td></tr></table></body></html>

Table 3: Performance of variants using different architectures for the sequential learner.   

<html><body><table><tr><td>Variant</td><td>Learner Architecture</td><td>CIFAR-100</td><td>DomainNet</td></tr><tr><td>D</td><td>MLP</td><td>94.32±0.17</td><td>81.25±0.56</td></tr><tr><td>E</td><td>LSTM</td><td>94.69±0.23</td><td>82.77±0.36</td></tr><tr><td>pFedSeq</td><td>Selective SSM</td><td>95.30±0.09</td><td>84.63±0.24</td></tr></table></body></html>

Effectiveness of Learner Architecture. To verify our choice of using Selective SSM as the sequential learner, we further introduce two variants using different architectures. First, variant D employs an MLP-based network similar to (Shamsian et al. 2021) for the sequential learner, where the sequence of inputs are concatenated along a single dimension (i.e., $\pmb { \Delta } ^ { t - L + 1 : t } \ \in \ \mathbb { R } ^ { D \times ( N \times L ) } )$ and passed into the MLP network. Note that this architecture can only process fixed-length sequences. As shown in Table 3, using an MLP learner leads to performance drops of $0 . 9 8 \%$ for CIFAR100 and $3 . 3 8 \%$ for DomainNet. The decline is mainly attributed to the less effective structure of MLP for modeling sequence inputs, leading to instability of training (as can be observed in Figure 9 in Appendix D). As for the second architecture, variant E utilizes the classical LSTM (Hochreiter and Schmidhuber 1997) for the learner. Similar to Selective SSM, LSTM is capable of modeling variablelength sequences. However, it reuses the same cell for all the steps without selectivity, making it less capable of discerning valuable context information from different steps. Table 3 shows that using an LSTM learner leads to performance declines of $0 . 6 1 \%$ on CIFAR-100 and $1 . 8 6 \%$ on Domain

![](images/db01bae11eb899877212d8ba5f3aa69714c2db578971dc9e6fa660c7889d61a8.jpg)  
Figure 5: Performance of pFedSeq by varying the maximum sequence length $L$ on Omniglot.

Net. The less satisfactory performance of variants $\mathrm { ~ D ~ }$ and E on two datasets demonstrates the superiority of using Selective SSM to model the cross-client and cross-step dependencies for more effective personalization.

Impact of Maximum Sequence Length $L$ . We investigate the impact of $L$ by varying it in a more fine-grained range $\{ 1 , 3 , 5 , 7 , 9 , 1 1 , 1 3 , 1 5 \}$ on Omniglot dataset. The results are plotted in Figure 5, where the dotted line indicates the performance of the strongest baseline PeFLL as a reference. From the plot, we can clearly observe an increasing trend in the performance of pFedSeq as the maximum sequence length $L$ increases. As compared to modeling only on the latest updates (i.e., $L = 1 \dot { }$ ), modeling on a longer sequence of previous updates (i.e., $L = 1 5$ ) results in $1 . 1 7 \%$ increase in the performance of $\mathtt { p F e d S e q }$ . This further confirms the effectiveness of our approach in modeling previous sequential updates. Moreover, the performance appears to plateau at a certain level, with further increases in $L$ yielding minimal improvements. This may be because earlier updates that are too distant from the present offer less relevant information, making them less useful for generating personalized adapters for the next update round. To achieve the best trade-off between computational cost and performance, we tune $L$ to find the elbow point where the performance starts to plateau. Overall, our pFedSeq outperforms PeFLL even with $L = 1$ , signifying the effectiveness of our choice of architecture in generating personalized calibrations, and our global aggregation process for explicitly leveraging the global knowledge. A plot of the learning curves for different values of $L$ is included in Appendix D.

# Conclusion

In this paper, we propose a novel pFedSeq framework for personalizing federated adapter tuning by exploiting knowledge from clients’ previous updates. Our $\mathtt { p F e d S e q }$ introduces a sequential learner jointly trained across all clients at the server to capture the cross-client and cross-step relations from the sequential updates, and output effective personalized adapters. For the learner architecture, we employ the powerful Selective SSM to leverage its sequence modeling capabilities. Extensive experiments on four benchmark datasets demonstrate the superiority of pFedSeq over ten state-of-the-art PFL methods and verify the effectiveness of its various components through rigorous studies.