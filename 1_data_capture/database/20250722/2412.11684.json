{
    "source": "Semantic Scholar",
    "arxiv_id": "2412.11684",
    "link": "https://arxiv.org/abs/2412.11684",
    "pdf_link": "https://arxiv.org/pdf/2412.11684.pdf",
    "title": "Runtime Analysis for Multi-Objective Evolutionary Algorithms in Unbounded Integer Spaces",
    "authors": [
        "Benjamin Doerr",
        "Martin S. Krejca",
        "Gunter Rudolph"
    ],
    "categories": [
        "cs.NE"
    ],
    "publication_date": "2024-12-16",
    "venue": "AAAI Conference on Artificial Intelligence",
    "fields_of_study": [
        "Computer Science"
    ],
    "citation_count": 1,
    "influential_citation_count": 0,
    "institutions": [
        "Laboratoire d’Informatique (LIX)",
        "CNRS",
        "École Polytechnique",
        "Institut Polytechnique de Paris",
        "TU Dortmund University"
    ],
    "paper_content": "# Runtime Analysis for Multi-Objective Evolutionary Algorithms in Unbounded Integer Spaces\n\nBenjamin Doerr1, Martin S. Krejca1, Gu¨ nter Rudolph2\n\n1Laboratoire d’Informatique (LIX), CNRS, ´Ecole Polytechnique, Institut Polytechnique de Paris, Palaiseau, France 2Department of Computer Science, TU Dortmund University, Dortmund, Germany {first-name.last-name}@polytechnique.edu, guenter.rudolph $@$ tu-dortmund.de\n\n# Abstract\n\nRandomized search heuristics have been applied successfully to a plethora of problems. This success is complemented by a large body of theoretical results. Unfortunately, the vast majority of these results regard problems with binary or continuous decision variables – the theoretical analysis of randomized search heuristics for unbounded integer domains is almost nonexistent. To resolve this shortcoming, we start the runtime analysis of multi-objective evolutionary algorithms, which are among the most successful randomized search heuristics, for unbounded integer search spaces. We analyze single- and full-dimensional mutation operators with three different mutation strengths, namely changes by plus/minus one (unit strength), random changes following a law with exponential tails, and random changes following a powerlaw. The performance guarantees we prove on a recently proposed natural benchmark problem suggest that unit mutation strengths can be slow when the initial solutions are far from the Pareto front. When setting the expected change right (depending on the benchmark parameter and the distance of the initial solutions), the mutation strength with exponential tails yields the best runtime guarantees in our results – however, with a wrong choice of this expectation, the performance guarantees quickly become highly uninteresting. With powerlaw mutation, which is an essentially parameter-less mutation operator, we obtain good results uniformly over all problem parameters and starting points. We complement our mathematical findings with experimental results that suggest that our bounds are not always tight. Most prominently, our experiments indicate that power-law mutation outperforms the one with exponential tails even when the latter uses a nearoptimal parametrization. Hence, we suggest to favor powerlaw mutation for unknown problems in integer spaces.\n\n# Introduction\n\nFor more than thirty years, the mathematical runtime analysis of randomized search heuristics has supported the design and analysis of these important algorithms, both in single- and in multi-objective optimization (Neumann and Witt 2010; Auger and Doerr 2011; Jansen 2013; Zhou, Yu, and Qian 2019; Doerr and Neumann 2020). While in practice heuristics are successfully employed for all types of decision variables, the mathematical analysis is mostly concentrated on binary or continuous variables. Discrete spaces with more than two variable values are considered far more infrequently. Theoretical works include runtime analyses for evolutionary algorithms, ant-colony optimizers, and estimation-of-distribution algorithms on categorical variables, e.g., Scharnow, Tinnefeld, and Wegener (2004); Baswana et al. (2009); Sudholt and Thyssen (2012); Doerr, Happ, and Klein (2012); Ben Jedidia, Doerr, and Krejca (2024); Adak and Witt (2024). The theoretical research for cardinal variables was started by Doerr, Johannsen, and Schmidt (2011); Doerr and Pohl (2012); Ko¨tzing, Lissovoi, and Witt (2015) with analyses how the $( 1 + 1 )$ EA optimizes multi-valued linear functions. Doerr, Doerr, and Ko¨tzing (2018, 2019) showed that for multi-valued variables larger mutation rates can be advantageous. Submodular functions with multi-valued discrete domain were studied by Qian et al. (2018a,b). We are only aware of two analyses for search spaces consisting of unbounded integer variables. The first is (Rudolph 2023), which is a single-objective analysis of subproblems of a multi-objective problem. The second is (Harder et al. 2024), which considers a singleobjective problem and shows the benefit of larger mutation rates. We are not aware of any true multi-objective works with multi-valued variables, despite considerable recent theoretical research on multi-objective heuristics (Zheng, Liu, and Doerr 2022; Dang et al. 2023; Cerf et al. 2023; Do et al. 2023; Dinot et al. 2023; Zheng and Doerr 2024; Zheng et al. 2024; Bian et al. 2024; Ren et al. 2024).\n\nSince multi-objective optimization is an area where heuristics, in particular, evolutionary algorithms, are intensively used and with great success (see, e.g., the famous NSGA-II algorithm (Deb et al. 2002) with more than 50 000 citations on Google Scholar), we start in this work the mathematical runtime analysis for truly multi-objective optimization problems in unbounded integer search spaces. For the benchmark problems proposed by Rudolph (2023), we analyze the performance of the simple evolutionary multi-objective optimizer (SEMO) (Laumanns et al. 2002) and the Global SEMO (GSEMO) (Giel 2003), the two most prominent evolutionary algorithms in the runtime analysis of multi-objective evolutionary algorithms. Our objective is to understand, via theoretical means, what are suitable mutation operators for unbounded integer domains. We propose three natural operators, changing variables (i) by plus or minus one (unit mutation strength), (ii) by a random value drawn from a symmetric distribution with exponential tails, and (iii) by a random value drawn from a symmetric power-law distribution.\n\nWe conduct an extensive mathematical runtime analysis for these two algorithms with the three mutation operators (with general parameters, where applicable) on the benchmark with general width parameter $a$ of the Pareto front for a general initial solution $\\bar { x } ^ { ( 0 ) }$ . Our results, presented in more detail later in this work when all ingredients are made precise, indicate the following. All algorithm variants can compute the full Pareto front of our benchmark problem in reasonable time. The unit mutation strength, not surprisingly can lead to a slow progress towards the Pareto front when the initial solution is far, but it also results in a slow exploration of the Pareto front after having reached it. The performance with the exponential-tail mutation strength depends heavily on the variance parameter $q$ (which is essentially the reciprocal of the expected absolute change). With an optimal choice of $q$ , depending on the benchmark parameter $a$ and the starting solution $\\bar { x } ^ { ( 0 ) }$ , this operator leads to the best performance guarantee among our results. However, our runtime guarantees strongly depend on the relation of $q$ , $a$ , and $x ^ { ( 0 ) }$ ; hence a suboptimal choice of $q$ can quickly lead to very weak performance guarantees. The power-law mutation strength is a good one-size-fits-all solution. Being an essentially parameter-less operator, it achieves a good performance uniformly over all values of $a$ and $x ^ { ( 0 ) }$ , clearly beating the unit mutation strength for larger instances or distances of the starting solution from the Pareto front.\n\nWe complement our theoretical results by an empirical analysis, aimed to understand how tight our guarantees are. We observe that the best-possible parameter regime for the exponential-tail mutation is within the range of our mathematical findings. However, surprisingly, the exponential-tail mutation is not able to outperform the power-law mutation, even with a near-optimal parametrization of the former. This suggests that our bounds for the power-law mutation are not tight. In fact, our experiments indicate that the actual expected runtime for this operator in the considered setting is linear in the size of the Pareto front, whereas our guarantees bound it by a polynomial with an exponent between 1 and 2, depending on the parametrization of the operator. We speculate that the actual linear runtime is a result of the complex population dynamics, which, to the best of our knowledge, have not been studied in the detail necessary for an improvement in any theoretical study of the (G)SEMO algorithms.\n\nOverall, our work shows that standard heuristics with appropriate mutations can deal well with certain multiobjective problems with unbounded integer decision variables. We strongly suggest the parameter-less power-law operator, as it has shown the best performance empirically and also has a uniformly good performance guarantee in a wide range of situations in our theoretical findings.\n\nOur proofs are in the full version Doerr et al. (2024a).\n\n# Preliminaries\n\nThe natural numbers $\\mathbb { N }$ include 0. For $a , b \\in \\mathbb { R }$ , let $[ a . . b ] =$ $[ a , b ] \\cap \\mathbb { N }$ , define $[ a ] : = [ 1 . . a ]$ , and let $\\mathbb { N } _ { \\geq a } = [ a , \\infty ) \\cap \\mathbb { N }$ .\n\nAlgorithm 1: Algorithmic framework for evolutionary multi-objective minimization of a given $d$ - objective function $f \\colon  { \\mathbb { Z } ^ { n } } \\to  { \\mathbb { R } ^ { d } }$ . The framework requires an initial individual $x ^ { ( 0 ) } \\in \\mathbb { Z } ^ { n }$ and a mutation operator “mutation”. If this operator modifies exactly one position, the resulting algorithm is the SEMO. If it modifies each position randomly and independently, the resulting algorithm is the GSEMO.\n\n1 $P ^ { ( 0 ) } = \\{ x ^ { ( 0 ) } \\}$ ;   \n2 $t \\gets 0$ ;   \n3 while termination criterion not met do   \n4 choose $x ^ { ( t ) }$ from $P ^ { ( t ) }$ uniformly at random;   \n5 $y ^ { ( t ) } \\gets \\mathrm { m u t a t i o n } ( x ^ { ( t ) } ) ;$ ;   \n6 ${ Q } ^ { ( t ) } \\gets P ^ { ( t ) } \\setminus \\{ z \\in P ^ { ( t ) } \\colon f ( y ^ { ( t ) } ) \\preceq f ( z ) \\} ;$   \n7 if $\\nexists z \\in Q ^ { ( t ) } \\colon f ( z ) \\prec f ( y ^ { ( t ) } )$ then   \n$P ^ { ( t + 1 ) }  Q ^ { ( t ) } \\cup \\{ y ^ { ( t ) } \\}$ ;   \n8 else $P ^ { ( t + 1 ) }  Q ^ { ( t ) }$ ;   \n9 $t \\gets t + 1$ ;\n\nGiven $n , d \\in  { \\mathbb { N } } _ { \\geq 2 }$ , we call $f \\colon  { \\mathbb { Z } ^ { n } } \\to  { \\mathbb { R } ^ { d } }$ a $d$ -objective function, which we aim to minimize. We call a point $x \\in \\mathbb { Z } ^ { n }$ an individual, and $f ( x )$ the objective value of $x$ . For $i \\in$ $[ n ]$ and $j \\in [ d ]$ , let $x _ { i }$ denote the $i$ -th component of $x$ , and let $f _ { j } ( x )$ denote the $j$ -th component of $f ( x )$ .\n\nThe objective values of a $d$ -objective function $f$ follow a weak partial order, denoted by $\\preceq$ . For all $u , v \\in \\mathbb { R } ^ { d }$ , we say that $u$ weakly dominates $v$ $( u \\preceq v )$ if and only if for all $i \\in$ $[ d ]$ , we have $u _ { i } \\leq v _ { i }$ . We say that $u$ strictly dominates $v ( u \\prec$ $v$ ) if and only if at least one of these inequalities is strict. We extend this notation to individuals, where a dominance holds if and only if it holds for the respective objective values.\n\nWe consider the minimization of $f$ , that is, we are interested in $\\preceq$ -minimal images. The set of all objective values that are not strictly dominated, that is, the set $F ^ { \\ast } : = \\{ f ( y ) \\in$ $\\mathring { \\mathbb { R } } ^ { d } \\ | \\ y \\in \\mathbb { Z } ^ { n } \\wedge \\mathring { \\mathbb { H } } \\bar { x } \\in \\mathbb { Z } ^ { n } \\colon f ( x ) \\prec f ( y ) \\}$ , is the Pareto front of $f$ . Furthermore, the individuals that are mapped to the Pareto front, that is, the set $f ^ { - 1 } ( F ^ { * } )$ , is the Pareto set of $f$ .\n\n# Algorithmic Framework\n\nWe consider the framework of evolutionary multi-objective minimization (Algorithm 1), aimed at finding the Pareto front of a given $d _ { \\ l }$ -objective function. The algorithm acts iteratively and maintains a multi-set of individuals (the population) that are not strictly dominated by any of the so-far found individuals. In each iteration, the algorithm creates a new individual $y$ from a random individual from the population by applying an operation known as mutation. Afterward, all individuals weakly dominated by $y$ are removed from the population, and $y$ is added if it is not strictly dominated by any of the remaining individuals in the population.\n\nMutation. We consider single- and full-dimensional mutation. Either acts on a parent $x \\in \\mathbb { Z } ^ { n }$ , requires a distribution $D$ on $\\mathbb { Z }$ (the mutation strength; see also Runtime Analysis), and returns an offspring $y \\in \\mathbb { Z } ^ { n }$ .\n\nSingle-dimensional mutation chooses a single component $i \\in [ n ]$ as well as an independent sample $Z \\sim D$ and then sets $y _ { i } = x _ { i } + Z$ . All other components remain unchanged, that is, for all $j ~ \\in ~ [ n ] \\setminus \\{ i \\}$ , it holds that $y _ { j } ~ = ~ x _ { j }$ . Algorithm 1 with single-dimensional mutation results in the SEMO algorithm (Laumanns et al. 2002). Full-dimensional mutation does the following independently for each component $i \\in [ n ]$ of $x$ : With probability $1 / n$ , draw an independent sample $Z _ { i } \\sim D$ , and set $y _ { i } = x _ { i } + Z _ { i }$ . With the remaining probability, set $y _ { i } = x _ { i }$ . Hence, in expectation, exactly one component of $x$ is changed, while any number of components may be changed. Algorithm 1 with full-dimensional mutation results in the global SEMO (GSEMO) (Giel 2003).\n\nRuntime. The runtime of Algorithm 1 is the (random) number of function evaluations until the objective values of the population contain the Pareto front. We do not re-evaluate individuals, but equal individuals are separately evaluated. That is, the initial individual is evaluated once, and the algorithm evaluates exactly one solution (namely $y ^ { ( t ) }$ ) each iteration. Hence, the runtime is 1 plus the number of iterations until the Pareto front is covered.\n\n# Benchmark Problem\n\nWe consider the following bi-objective benchmark function, introduced by Rudolph (2023). Given a parameter $a \\in \\mathbb { N }$ , the function $\\mathcal { \\dot { f } } \\colon  { \\mathbb { Z } ^ { n } } \\to  { \\mathbb { N } ^ { 2 } }$ is defined as\n\n$$\nx \\mapsto { \\binom { \\left| x _ { 1 } - a \\right| + \\sum _ { i \\in [ 2 . . n ] } \\left| x _ { i } \\right| } { \\left| x _ { 1 } + a \\right| + \\sum _ { i \\in [ 2 . . n ] } \\left| x _ { i } \\right| } } .\n$$\n\nThis function aims at minimizing the distance to two target points, which is the same idea present in similar benchmarks (ONEMAX and ONEMINMAX (Giel and Lehre 2010)) that are used as initial problems for related settings.\n\nThe Pareto set and front of $f$ satisfy (Rudolph 2023)\n\n$$\n\\begin{array} { r l } & { X ^ { * } = \\{ ( k , 0 , \\ldots , 0 ) ^ { \\top } \\in \\mathbb { Z } ^ { n } \\mid k \\in [ - a , a ] \\cap \\mathbb { Z } \\} } \\\\ & { \\ F ^ { * } = \\{ ( k , 2 a - k ) ^ { \\top } \\in \\mathbb { N } ^ { 2 } \\mid k \\in [ 0 . . 2 a ] \\} . } \\end{array}\n$$\n\nWe note that $| F ^ { * } | = 2 a + 1$ , as this value plays a crucial role in our analyses (Runtime Analysis).\n\nUseful Properties of the Benchmark Problem We study useful properties of $f$ , partially in the context of Algorithm 1. Throughout this section, we assume that $a \\in \\mathbb { N }$ and that $n \\in \\mathbb { N } _ { \\geq 2 }$ . When we consider an instance of Algorithm 1, we allow for arbitrary mutation.\n\nLemma 1 shows when a solution whose first coordinate is not in $( - a , a )$ is comparable (w.r.t. $f$ ) to any other point.\n\nLemma 1. Let $x \\in \\mathbb { Z } ^ { n }$ and $y \\in \\mathbb { Z } _ { \\geq a } \\times \\mathbb { Z } ^ { n - 1 }$ such that   \n$f _ { 1 } ( x ) \\leq f _ { 1 } ( y )$ . Then $f ( x ) \\preceq f ( y )$ . Similarly, let $x \\in \\mathbb { Z } ^ { n }$ and $y \\in \\mathbb { Z } _ { \\leq - a } \\times \\mathbb { Z } ^ { n - 1 }$ such that   \n$f _ { 2 } ( x ) \\leq f _ { 2 } ( y )$ . Then $f ( x ) \\preceq f ( y )$ .\n\nLemma 1 implies that the population has at most one solution with its first component at most $- a$ and at most one with its first component at least $a$ , formalized below.\n\nLemma 2. Let $t \\in \\mathbb { N } .$ . Then $| P ^ { ( t ) } \\cap ( \\mathbb { Z } _ { \\geq a } \\times \\mathbb { Z } ^ { n - 1 } ) | \\leq 1$ and $| P ^ { ( t ) } \\cap ( \\mathbb { Z } _ { \\leq - a } \\times \\mathbb { Z } ^ { n - 1 } ) | \\leq 1$ .\n\nLemma 3 shows that the algorithm contains at most one solution per $x _ { 1 }$ -value in $[ - a . . \\bar { a } ]$ .\n\nLemma 3. Let $t \\in \\mathbb { N }$ , and let $i \\in [ - a . . a ]$ . Then $| P ^ { ( t ) } \\cap$ $( \\{ i \\} \\times \\mathbb { Z } ^ { n - 1 } ) | \\leq 1$ .\n\nThe bounds on the population size from Lemmas 2 and 3 imply the following bound on the overall population size.\n\nLemma 4. Let $t \\in \\mathbb { N } .$ . Then $| P ^ { ( t ) } | \\leq 2 a + 1$ .\n\nLemma 5 shows that the dominance of two points implies an order with respect to the L1-norm of the two points.\n\nLemma 5. Let $x , y \\in \\mathbb { Z } ^ { n }$ . If $f ( x ) \\preceq f ( y )$ , then $\\| x \\| _ { 1 } \\leq$ $\\| y \\| _ { 1 }$ .\n\nLemma 5 implies that the minimum L1-norm of the population of the algorithm cannot increase over time. The following lemma formalizes this property. It is the main driving force of our theoretical analyses in Runtime Analysis.\n\nLemma 6. Let $t \\in \\mathbb { N }$ , and let $z ^ { * } \\in P ^ { ( t ) }$ be such that $\\begin{array} { r } { \\Vert z ^ { * } \\Vert _ { 1 } ~ = ~ \\operatorname* { m i n } _ { z \\in P ^ { ( t ) } } \\Vert z \\Vert _ { 1 } } \\end{array}$ . Moreover, assume for the offspring that $\\| y ^ { ( t ) } \\| _ { 1 } > \\| z ^ { * } \\| _ { 1 }$ . Then $z ^ { * } \\in P ^ { ( t + 1 ) }$ .\n\nOptimization Dynamics The lemmas above show that the dynamics of Algorithm 1 on $f$ are restricted to individuals with their first component in $[ - a + 1 . . a - 1 ]$ as well as at most two individuals with their first component at most $- a$ or at least $a$ , respectively. Since Lemma 5 shows that the L1- norm of such individuals cannot increase, their distance to the Pareto cannot increase either. Thus, if improvements occur, the population eventually covers the entire Pareto front.\n\n# Runtime Analysis\n\nWe analyze the expected runtime of Algorithm 1 instantiated as the SEMO and as the GSEMO (Algorithmic Framework) when optimizing function $f$ (Benchmark Problem). We assume for $f$ implicitly that $a \\in \\mathbb { N }$ and that $n \\in \\mathbb { N } _ { \\geq 2 }$ .\n\nWe consider three different mutation strengths, each characterized by a law over $\\mathbb { Z }$ : the uniform law over $\\{ - 1 , 1 \\}$ , a law with an exponential tail, and a power-law.\n\nAlthough the mutation strength greatly affects the expected runtime of the algorithm, our analyses follow the same general outline. Each analysis is split into two phases. The first phase considers the time until the algorithm contains the all-0s vector, which is part of the Pareto front $F ^ { * }$ of $f$ . The second phase considers the remaining time until the objective values of the population contain $F ^ { * }$ . The total runtime bound is then the sum of the bounds of both phases.\n\nFor the first phase, we use that the minimum L1-distance of the population to the all-0s vector never increases (Lemma 6). Formally, we define a potential function that measures this distance, and we utilize tools introduced below for deriving the expected runtime for this phase.\n\nThroughout our analyses, we use that the population consists by Lemma 4 of at most $2 a + 1$ individuals. This results in a probability of at least $1 / ( 2 a + 1 )$ for choosing a specific individual for mutation and, thus, in an expected time of $2 a + 1$ for making such a choice. In addition, the probability to change exactly one component of a solution is for both algorithms in the order of $1 / \\bar { n }$ . Combining this with the choice for a specific individual yields an overall waiting time of about $( 2 a + 1 ) n$ , which all of our results have in common.\n\nThe speed of each phase is heavily determined by the mutation strength, leading to different analyses.\n\n# Mathematical Tools\n\nVariable drift theorems translate information about the expected progress of a random process into bounds on expected hitting times. This concept was independently developed by Mitavskiy et al. (2009) and Johannsen (2010). The following variant is from Doerr et al. (2020, Theorem 6).\n\nTheorem 7 (Discrete variable drift, upper bound). Let $( X _ { t } ) _ { t \\geq 0 }$ be a sequence of random variables in $[ 0 . . n ]$ , and let $T$ be the random variable that denotes the earliest point in time $t \\geq 0$ such that $X _ { t } = 0$ . Suppose that there exists a monotonically increasing function $\\bar { h \\colon [ n ] \\to \\mathbb { R } _ { 0 } ^ { + } }$ such that $\\mathrm { E } [ X _ { t } - X _ { t + 1 } \\mid X _ { t } ] \\geq h ( \\bar { X _ { t } } )$ holds for all $t < T$ . Then\n\n$$\n\\begin{array} { r } { \\operatorname { E } [ T \\mid X _ { 0 } ] \\leq \\sum _ { i \\in [ X _ { 0 } ] } \\frac { 1 } { h ( i ) } . } \\end{array}\n$$\n\nAdditive drift is a simplification of variable drift to the case that the expected progress of a random process is bounded by a constant value. It dates back to a theorem by He and Yao (He and Yao 2004). The following simplified version is from Ko¨tzing and Krejca (2019, Theorem 7).\n\nTheorem 8 (Additive drift, unbounded search space). Let $( X _ { t } ) _ { t \\in \\mathbb { N } }$ be random variables over $\\mathbb { R } _ { \\geq 0 }$ , and let $\\begin{array} { l l } { T } & { = } \\end{array}$ $\\operatorname* { i n f } \\{ t \\in \\mathbb { N } \\mid X _ { t } = 0 \\}$ . Furthermore, suppose that there is some value $\\delta \\in \\mathbb { R } _ { > 0 }$ such that for all $t < T$ holds that $\\operatorname { E } [ X _ { t } - X _ { t + 1 } \\mid X _ { t } ] \\geq \\delta$ . Then $\\begin{array} { r } { \\mathrm { E } [ \\check { T } \\mid X _ { 0 } ] \\leq \\frac { X _ { 0 } } { \\delta } } \\end{array}$ .\n\n# Unit-Step Mutation\n\nUnit-step mutation uses the uniform law over $\\{ - 1 , 1 \\}$ . When modifying the value $x _ { i } \\in \\mathbb { Z }$ of an individual $x$ , then $x _ { i }$ is increased by 1 with probability $\\textstyle { \\frac { 1 } { 2 } }$ and else decreased by 1.\n\nOur main result for unit-step mutation is Theorem 9, showing that the expected runtime of the SEMO and the GSEMO scales linearly in the L1-norm of the initial solution $x ^ { ( 0 ) }$ (plus $2 a { \\cdot }$ ), and linearly in the dimension $n$ and the radius $a$ of the Pareto front of $f$ . The linear scaling in $a n$ is due to waiting to make progress, as discussed at the start of Runtime Analysis. The linear scaling in $\\| x ^ { ( 0 ) } \\| _ { 1 }$ is due to the first phase, as the mutation changes a component by only 1 and needs to cover a distance of $\\| \\boldsymbol { x } ^ { ( 0 ) } \\| _ { 1 }$ . Then, since the mutation changes a component only by 1, an additional time linear in $a$ is required for covering the entire Pareto front.\n\nTheorem 9. Consider the SEMO or the GSEMO with unitstep mutation optimizing $f$ , given $x ^ { ( 0 ) }$ . Let $T = \\operatorname* { i n f } \\{ t \\in \\mathbb { N } \\mid$ ${ \\cal F } ^ { * } \\subseteq f ( { \\cal P } ^ { ( t ) } ) \\}$ . Then $\\begin{array} { r } { \\operatorname { E } [ T \\mid x ^ { ( 0 ) } ] \\le 2 n ( 2 a + 1 ) ( \\| x ^ { ( 0 ) } \\| _ { 1 } + } \\end{array}$ $2 a )$ ) for the SEMO, and $\\begin{array} { r } { \\mathrm { E } [ T \\mid x ^ { ( 0 ) } ] \\leq 2 e n ( 2 a + 1 ) ( \\| x ^ { ( 0 ) } \\| _ { 1 } + } \\end{array}$ $2 a )$ ) for the GSEMO.\n\nThe following lemma bounds the expected time of the first phase. In each iteration, we have the same probability to improve the solution that is closest in L1-distance to the all-0s vector, resulting in a linear bound in the distance $\\| x ^ { ( 0 ) } \\| _ { 1 }$ .\n\nLemma 10. Let $T _ { 1 } = \\operatorname* { i n f } \\{ t \\in \\mathbb { N } \\mid ( 0 , \\ldots , 0 ) ^ { \\top } \\in P ^ { ( t ) } \\} .$ . Then $\\operatorname { E } [ T _ { 1 } \\mid x ^ { ( 0 ) } ] \\leq 2 n \\cdot ( 2 a + 1 ) \\cdot \\| x ^ { ( 0 ) } \\| _ { 1 }$ for the SEMO, and $\\operatorname { E } [ T _ { 1 } \\mid x ^ { ( 0 ) } ] \\leq 2 e n \\cdot ( 2 a + 1 ) \\cdot \\| x ^ { ( 0 ) } \\| _ { 1 }$ for the GSEMO.\n\nThe next lemma bounds the expected time of the second phase. Since the mutation only changes components by 1, starting from the all-0s vector, the Pareto front is covered in a linear fashion, expanding to either side. Hence, the resulting time is linear in the size of the Pareto front $( 2 a + 1 )$ as well as in the inverse of the probability to choose a specific individual and mutate it correctly (in the order of an).\n\nLemma 11. Let $S \\in \\mathbb { N }$ be a (possibly random) iteration such that $P ^ { ( S ) }$ contains the individual $( 0 , \\ldots , 0 ) ^ { \\top }$ , and let $T _ { 2 } = \\operatorname* { i n f } \\{ t \\in \\mathbb { N } \\mid t \\geq S \\wedge F ^ { * } \\subseteq f ( P ^ { ( t ) } ) \\} - S$ . Then $\\mathrm { E } [ T _ { 2 } \\ | \\ S , x ^ { ( 0 ) } ] \\ \\leq \\ 2 n \\cdot ( 2 a + 1 ) \\cdot 2 a$ for the SEMO, and $\\operatorname { E } [ T _ { 2 } \\mid S , x ^ { ( 0 ) } ] \\leq 2 e n \\cdot ( 2 a + 1 ) \\cdot 2 a$ for the GSEMO.\n\n# Exponential-Tail Mutation\n\nExponential-tail mutation utilizes a symmetric law with exponential tails, parameterized by a value $q \\in ( 0 , 1 )$ . For a random variable $Z$ following this law, for all $k \\in \\mathbb { Z }$ holds\n\n$$\n\\begin{array} { r } { \\operatorname* { P r } [ Z = k ] = \\frac { q } { 2 - q } ( 1 - q ) ^ { | k | } . } \\end{array}\n$$\n\nWe call this law a bilateral geometric law (Rudolph 1994).\n\nOur main result for exponential-tail mutation is Theorem 12, which is clearly separated into the two phases of our analysis. Besides the common factor of an from making progress, as discussed at the beginning of this section, the expected runtime strongly depends on the mutation parameter $q$ . We discuss the two terms in the following in detail.\n\nTheorem 12. Let $c \\in \\mathsf { \\Gamma } ( 0 , 1 )$ be constant. Consider the SEMO or the GSEMO with exponential-tail mutation with $q \\in ( 0 , c )$ optimizing $f _ { ; }$ , given $x ^ { ( 0 ) }$ . Let $T = \\operatorname* { i n f } \\{ t \\in \\mathbb { N } \\mid$ ${ \\cal F } ^ { * } \\subseteq f ( { \\cal P } ^ { ( t ) } ) \\}$ . Then there is a sufficiently large constant $C$ such that for both the SEMO and the GSEMO holds that\n\n$$\n\\begin{array} { l } { { \\displaystyle \\operatorname { E } [ T \\mid x ^ { ( 0 ) } ] = C \\Big ( a n \\Big ( \\frac { n } { q } + \\| x ^ { ( 0 ) } \\| _ { 1 } q } } \\\\ { { \\displaystyle \\quad \\quad + \\operatorname* { m a x } \\Big \\{ \\frac { \\ln ( a + 1 ) } { a q } , a q + \\ln ( a + 1 ) \\Big \\} \\Big ) \\Big ) . } } \\end{array}\n$$\n\nOur analysis is based on the following elementary result about the bilateral geometric law.\n\nLemma 13. Let $Z$ be a bilateral geometric random variable with parameter $q \\in ( 0 , 1 )$ . Let $z \\in \\mathbb { N } ,$ , and let $Z _ { z }$ be the random variable defined by $Z _ { z } = Z$ , i $r _ { 0 } \\leq Z \\leq z$ , and $Z _ { z } = 0$ otherwise. Then $\\begin{array} { r } { E [ Z _ { z } ] = \\frac { 1 - q } { q ( 2 - q ) } ( 1 - ( 1 - q ) ^ { z } ( 1 + z q ) ) } \\end{array}$ . Especially, for all constants $C \\in ( 0 , 1 )$ , there is a constant $K \\in \\mathbb { R } _ { > 0 }$ such that for all $q \\leq C$ and all $z \\in \\mathbb { N }$ , we have\n\n$$\n\\begin{array} { r } { \\mathrm { E } [ Z _ { z } ] \\geq K \\operatorname* { m i n } \\{ z ^ { 2 } q , \\frac { 1 } { 4 q } \\} . } \\end{array}\n$$\n\nWe utilize Lemma 13 in our proofs by estimating by how much a component of an individual chosen for mutation is improved. Since certain changes can be too large, we consider such progress to be 0. All other values are acceptable. Hence, we consider overall only a subset of values of the bilateral geometric law, which is well reflected in the lemma.\n\nWe now tend to the analysis of Theorem 12. The first phase is separated into two regimes, depending on how close the minimum L1-distance of the population is to the all-0s vector. If this distance is at least in the order of $n / q$ , the expected distance covered by a successful mutation is in the order of $1 / q$ , leading to the term $\\| \\boldsymbol { x } ^ { ( 0 ) } \\| _ { 1 } q$ (in addition to the factor of an from the waiting time for an improving mutation). Once the population gets closer than $n / q$ to the all-0s vector, the progress is slowed down and essentially driven by unit changes, resulting in the term $n / q$ .\n\nLemma 14. Let $T _ { 1 } = \\operatorname* { i n f } \\{ t \\in \\mathbb { N } \\mid ( 0 , \\ldots , 0 ) ^ { \\top } \\in P \\}$ . Then\n\n$$\n\\operatorname { E } [ T _ { 1 } \\mid x ^ { ( 0 ) } ] \\leq { \\frac { ( 2 a + 1 ) e n } { K } } { \\Big ( } { \\frac { n \\pi ^ { 2 } } { 6 q } } + 4 \\| x ^ { ( 0 ) } \\| _ { 1 } q { \\Big ) } ,\n$$\n\nwhere $K$ is the constant from Lemma $^ { 1 3 }$ .\n\nThe expected runtime of the second phase depends on how $1 / q$ compares to $a$ . We split the runtime into two parts. The first part concerns covering a subset of the Pareto front that chooses individuals that are roughly $1 / q$ apart, resulting in about aq intervals of roughly equal size. If $1 / q > 2 a + 1$ , then we consider the entire Pareto front as a single interval.\n\nThe second part concerns covering all intervals. Since uncovered points in each interval are at most apart by about $1 / q$ , we wait for such a rate to be chosen. This can happen for any interval, leading to independent trials. We then use a Chernoff-like concentration bound that provides us with a runtime bound that holds with high probability. Via a restart argument, this bound is turned into an expectation. The concentration bound yields the logarithmic factors.\n\nLemma 15. Assume that at some time $t _ { 2 }$ , the population of the algorithm contains the solution $( 0 , \\ldots , 0 )$ . Let $T _ { 2 } =$ $\\operatorname* { i n f } \\{ t \\in \\mathbb { N } \\mid F ^ { * } \\subseteq f ( P ^ { ( t _ { 2 } + t ) } ) \\}$ the additional number of iterations until the Pareto front is computed. Then there is $a$ sufficiently large constant $C \\in \\mathbb { R } _ { > 0 }$ such that\n\n$$\n\\operatorname { E } [ T _ { 2 } ] = C { \\Big ( } a n \\operatorname* { m a x } { \\Big \\{ } { \\frac { \\ln ( a + 1 ) } { a q } } , a q + \\ln ( a + 1 ) { \\Big \\} } { \\Big ) } .\n$$\n\n# Power-Law Mutation\n\nPower-law mutation utilizes a symmetric power-law, parameterized by the power-law exponent $\\beta \\in ( 1 , 2 )$ and defined via the Riemann zeta function $\\zeta$ . For a random variable $Z$ following this law, it holds for all $k \\in \\mathbb { Z } \\backslash \\{ 0 \\}$ that\n\n$$\n\\operatorname* { P r } [ Z = k ] = | k | ^ { - \\beta } / \\big ( 2 \\zeta ( \\beta ) \\big ) .\n$$\n\nThis operator, introduced by (Doerr et al. 2017), was shown to be provably beneficial in various settings (Friedrich, Quinzan, and Wagner 2018; Corus, Oliveto, and Yazdani 2021; Antipov, Buzdalov, and Doerr 2022; Dang et al. 2022; Doerr and $\\mathrm { Q u } \\ 2 0 2 3$ ; Doerr and Rajabi 2023; Doerr, Krejca, and $\\mathrm { V u } 2 0 2 4$ ; Krejca and Witt 2024).\n\nOur main result for power-law mutation is Theorem 16. Similar to the result for mutation strengths with exponential tails (Theorem 12), the expected runtimes of both phases are well separated. We explain the details for each phase below.\n\nTheorem 16. Consider the SEMO or the GSEMO with power-law mutation with constant $\\beta \\in ( 1 , 2 )$ optimizing $f$ , given $x ^ { ( 0 ) }$ . Let $T = \\operatorname* { i n f } \\{ t \\in \\mathbb { N } \\mid F ^ { * } \\subseteq f ( P ^ { ( t ) } ) \\}$ . Then for both the SEMO and the GSEMO, it holds that\n\n$$\n\\begin{array} { r l } & { \\mathrm { E } [ T \\mid x ^ { ( 0 ) } ] } \\\\ & { \\le ( 2 a + 1 ) \\cdot 2 e n \\zeta ( \\beta ) \\bigg ( 2 ^ { 1 / ( 2 - \\beta ) } + 2 \\frac { 2 - \\beta } { \\beta - 1 } \\| x ^ { ( 0 ) } \\| _ { 1 } ^ { \\beta - 1 } \\bigg ) } \\\\ & { \\quad + 4 \\ln ( 2 ) e n \\frac { \\zeta ( \\beta ) ( \\beta - 1 ) } { 1 - ( 3 / 2 ) ^ { 1 - \\beta } } \\frac { 1 } { \\left( 1 - 2 ^ { 1 - \\beta } \\right) ^ { 2 } } ( 2 a + 1 ) ^ { \\beta } } \\\\ & { \\quad + \\left( 2 a + 1 \\right) \\cdot 2 e n \\zeta ( \\beta ) \\big ( \\ln ( a + 1 ) + 1 \\big ) . } \\end{array}\n$$\n\nWe make use of the following theorem, which estimates sums of monotone functions via a definite integral. This is useful, as our analyses involve many possible values for how to improve a specific individual. These cases lead to sums over of powers of $- \\beta$ , as the values follow a power-law. Integrating such a polynomial is easier than determining the exact value of the discrete sum. The theorem below shows that we make almost no error when considering the integral.\n\nTheorem 17 ((Cormen et al. 2001, Inequality (A.12))). Let $g : \\mathbb { R } \\to \\mathbb { R }$ be a monotonically non-increasing function, and let $\\alpha , \\beta \\in \\mathbb { R }$ with $\\alpha \\le \\beta$ . Then\n\n$$\n\\begin{array} { r } { \\int _ { \\alpha } ^ { \\beta + 1 } g ( x ) \\mathrm { d } x \\leq \\sum _ { x = \\alpha } ^ { \\beta } g ( x ) \\leq \\int _ { \\alpha - 1 } ^ { \\beta } g ( x ) \\mathrm { d } x . } \\end{array}\n$$\n\nWe now consider Theorem 16. The expected runtime of the first phase, besides the factor $a n$ , is of order $\\| \\boldsymbol { x } ^ { ( 0 ) } \\| _ { 1 } ^ { \\beta - 1 }$ . Ignoring the factor $a n$ , this is because the algorithm makes an improvement of size $k$ with probability $k ^ { - \\breve { \\beta } }$ and has up to about $\\| x ^ { ( t ) } \\| _ { 1 }$ choices for an improvement. This leads to an expected improvement of $k ^ { 1 - \\beta }$ per component of $\\| x ^ { ( t ) } \\| _ { 1 }$ . Integrating this expression results in an overall expected improvement of order $\\| \\boldsymbol { x } ^ { ( t ) } \\| _ { 1 } ^ { 2 - \\beta }$ . By the variable drift theorem (Theorem 7), estimating the sum via an integral, this translates to an overall runtime of order $\\| \\boldsymbol { x } ^ { ( 0 ) } \\| _ { 1 } ^ { \\beta - \\bar { 1 } }$ .\n\nLemma 18. Let $T _ { 1 } = \\operatorname* { i n f } \\{ t \\in \\mathbb { N } \\mid ( 0 , \\ldots , 0 ) ^ { \\top } \\in P ^ { ( t ) } \\} .$ Then\n\n$$\n\\begin{array} { r l } & { \\mathrm { E } [ T _ { 1 } \\mid x ^ { ( 0 ) } ] } \\\\ & { \\leq ( 2 a + 1 ) \\cdot 2 e n \\zeta ( \\beta ) \\Big ( 2 ^ { 1 / ( 2 - \\beta ) } + 2 \\frac { 2 - \\beta } { \\beta - 1 } \\| x ^ { ( 0 ) } \\| _ { 1 } ^ { \\beta - 1 } \\Big ) . } \\end{array}\n$$\n\nThe second phase advances in several steps. In each step, the number of points covered on the Pareto front of $f$ roughly doubles and is spread evenly across the Pareto front. If the maximum distance of consecutively uncovered points is $\\ell$ , the probability to create a new point is at least $\\ell ^ { 1 - \\beta }$ . At the beginning, since we assume that we only have a single point on the Pareto front, $\\ell$ is in the order of $a$ , and the probability to choose the correct point and mutate it correctly is in the order $1 / ( a n )$ . Hence, the waiting time for the first step is in the order of ${ n a ^ { \\beta } }$ , which dominates the remaining time, as the each additional point on the Pareto front increases the chance of creating a new one. Since the length of the Pareto front is not a power of 2, our result below has two terms. The first one bounds the time that the doubling procedure above covers at least half of the Pareto front. The second term bounds the time to cover the remaining points.\n\nTable 1: Means and standard deviations in percent of 1st hitting time (phase 1), Pareto set cover time (phase 2), and total runtime (# evaluations of $f$ ) for scenario 1 for the GSEMO optimizing $f$ with the mutation operators: unit-step (U), exponential-tail $( \\mathrm { E } )$ , and power-law (P). Column $1 / q$ refers to the step size of parameter $q$ of E. For P, we chose $\\begin{array} { r } { \\dot { \\mathcal { \\beta } } = \\frac { 3 } { 2 } } \\end{array}$ . The runs were started with $a = 2 0 0$ and $x ^ { ( 0 ) } = ( 0 , 1 0 0 a )$ , with 50 independent runs per row for $n = 2$ .   \n\n<html><body><table><tr><td>1/q</td><td>1st hit</td><td>cover</td><td>total</td></tr><tr><td>U E 5</td><td>510 006± 25</td><td>342 916±44</td><td>852 922±11</td></tr><tr><td rowspan=\"5\">10</td><td>73 034± 8</td><td>23115±31</td><td>96148±10</td></tr><tr><td>25288± 9</td><td>18 346±25</td><td>43 634±11</td></tr><tr><td>20 9028± 8</td><td>15 050±22</td><td>24078±14</td></tr><tr><td>50 2810± 11</td><td>15 237±18</td><td>18 048±16</td></tr><tr><td>100 1604± 34</td><td>18 401±24</td><td>20 004±23</td></tr><tr><td rowspan=\"3\">200 500</td><td>1613± 63</td><td>24295±20</td><td>25 908±20</td></tr><tr><td>3 544±104</td><td>43 693±20</td><td>47 236±23</td></tr><tr><td>1301± 47</td><td>14 263±16</td><td>15 565±15</td></tr></table></body></html>\n\nLemma 19. Let $S \\in \\mathbb { N }$ be a (possibly random) iteration such that $P ^ { ( S ) }$ contains the individual $( 0 , \\ldots , 0 ) ^ { \\top }$ , and let $T _ { 2 } = \\operatorname* { i n f } \\{ t \\in \\mathbb { N } | t \\geq S \\wedge F ^ { * } \\subseteq f ( P ^ { ( t ) } ) \\} - S$ . Then\n\n$$\n\\begin{array} { r l } & { \\mathrm { E } [ T _ { 2 } \\mid S , x ^ { ( 0 ) } ] } \\\\ & { \\quad \\le 4 \\mathrm { l n } ( 2 ) e n \\frac { \\zeta ( \\beta ) ( \\beta - 1 ) } { 1 - ( 3 / 2 ) ^ { 1 - \\beta } } \\frac { 1 } { \\left( 1 - 2 ^ { 1 - \\beta } \\right) ^ { 2 } } ( 2 a + 1 ) ^ { \\beta } } \\\\ & { \\quad \\quad + \\left( 2 a + 1 \\right) \\cdot 2 e n \\zeta ( \\beta ) \\bigl ( \\ln ( a + 1 ) + 1 \\bigr ) . } \\end{array}\n$$\n\n# Empirical Analysis\n\nWe aim to assess how far our theoretical upper bounds are from actual, empirical values. We also aim to understand whether the exponential-tail law actually has a parametrization that is favorable to the power-law mutation, as suggested by our theoretical results. To this end, we first discuss what runtime behavior we expect, based on our theoretical bounds. Then we explain our experimental setup and discuss and present our findings. For the sake of simplicity, we only consider the GSEMO here, as it is the more general algorithm, although benchmark $f$ is simple enough such that the SEMO would also be sufficient. We note that when optimizing $f$ , the expected runtime of the GESMO should be worse by a factor of at most $e$ compared to the SEMO. Our code is publicly available (Doerr, Krejca, and Rudolph 2024b).\n\nSimilar to our discussion at the start of Runtime Analysis, we split the run of the GSEMO into two phases: The first phase counts the number of function evaluations until the population contains an individual on the Pareto front for the first time. The second phase counts the remaining number of function evaluations until the Pareto front is covered.\n\nTheoretical considerations. In order to compare our theoretical results easily, we assume that the L1-norm of the initial point $x ^ { ( 0 ) }$ is in the order of the parameter $a$ of benchmark $f$ . Furthermore, we assume that the problem size $n$ is constant, as we consider small values for $n$ in our experiments, due to the search space being unbounded in any case. Then the expected runtime for unit-step mutation (Theorem 9) is in the order of $a ^ { 2 }$ . For exponential-tail mutation with parameter $q$ (Theorem 12), it is in the order of $\\begin{array} { r } { a ^ { 2 } q + a \\operatorname* { m a x } \\{ \\frac { \\ln ( a + 1 ) } { a q } , a q + \\ln ( a + 1 ) \\} } \\end{array}$ . Last, for power-law mutation with power-law exponent $\\beta$ (Theorem 16), it is in the order of $a ^ { \\hat { \\boldsymbol { \\beta } } }$ . We see that choosing $\\textstyle q \\ = \\ { \\frac { 1 } { a } }$ minimizes the maximum expression for the runtime of the exponentialtail mutation, resulting in a runtime bound in the order of $a \\ln ( a )$ . For this setting, the exponential-tail mutation is fastest and has a quasi-linear runtime. It is followed by the runtime of power-law mutation, which is a polynomial with degree of $\\beta$ , which is between 1 and 2. Last, we have the unit-step mutation with a quadratic runtime.\n\n![](images/6cc22587a625a9db71b4666d7673a31bd1f667d77e278829809e4c4ce20c2430.jpg)  \nFigure 1: The results of scenario 2. Average evaluations of $f$ for varying $a$ for the GSEMO optimizing $f$ with the mutation operators: unit-step (diamonds), exponential-tail (cross diamonds) with $\\begin{array} { l l l } { { \\frac { 1 } { q } } } & { { = } } & { { \\frac { a } { 4 } } } \\end{array}$ , and power-law (triangles) with $\\begin{array} { r } { \\beta = \\frac { 3 } { 2 } } \\end{array}$ . Each point is based on 50 independent runs, with $x ^ { ( 0 ) } = ( 0 , 1 0 0 a )$ . The dotted lines depict the std. deviations.\n\nExperimental setup. We aim to recreate a setting as described above, placing an emphasis on both phases though, as we do not know how tight our theoretical bounds actually are. To this end, we choose $n = 2$ and $x ^ { ( 0 ) } = ( 0 , 1 0 0 a ) \\overset { \\cdot } { = } :$ $( 0 , y _ { 0 } )$ . Furthermore, we choose $\\begin{array} { r } { \\beta = \\frac { 3 } { 2 } } \\end{array}$ , which is generally a good choice (Doerr et al. 2017). Our choice for $n$ is based on all of our results holding for any value of $n \\in  { \\mathbb { N } } _ { \\geq 2 }$ , and a smaller choice of $n$ lets us run more experiments. Nonetheless, we note that we consider larger values of $n$ in the full version, and the observations are qualitatively the same as they are for $n = 2$ , just with an even clearer distinction between the different mutation operators.\n\nWe consider two different scenarios: The first scenario aims to determine a good value $q$ for the exponential-tail mutation. To this end, we choose $a \\ = \\ 2 0 0$ as well as $\\frac { 1 } { q } ~ \\in ~ \\{ 5 , 1 0 , 2 0 , 5 0 , 1 0 0 , 2 0 0 , 5 0 0 \\}$ , which covers a broad, quickly increasing, thus diverse, range of values for $\\textstyle { \\frac { 1 } { q } }$ .\n\nFor each parameter combination of each scenario, we log the number of function evaluations of 50 independent runs, always for both phases, even for identical parameter values.\n\nThe second scenario observes the runtime behavior of all three mutation operators with respect to $a$ , given a good value for $q$ determined by scenario 1. We choose $y _ { 0 } = 1 0 0 a$ .\n\nFirst scenario. Table 1 depicts our results. For unit stepmutation, we see that it is by far the worst operator for either phase. For exponential-tail mutation, we see that the choice of $q$ has an apparently convex impact on the runtime for both phases, with the minimum taken over different values of $q$ . This conforms mostly with our theoretical insights, where a too small value of $\\textstyle { \\frac { 1 } { q } }$ takes needlessly long (like in the case of unit steps), but a too large value of $\\textstyle { \\frac { 1 } { q } }$ requires too wait long for actually useful values to appear. While we expected the choice $\\textstyle { \\frac { 1 } { q } } \\doteq a = 2 0 0$ to be best, it is actually $\\begin{array} { r } { \\frac { 1 } { q } \\overset { \\cdot } { = } 5 0 } \\end{array}$ This is mostly due to our theoretical considerations ignoring constant factors and due to the term $\\ln ( a + 1 )$ in the runtime being multiplicative in one case and additive in the other.\n\nMore surprisingly, the mean runtime of the power-law mutation for either of the two phases is better than the mean of the exponential-tail distribution for any of our choices of $1 / q$ . This suggests that our runtime estimates are not tight.\n\nSecond scenario. Given the results from the first scenario, we fix $\\textstyle { \\frac { 1 } { q } } = { \\frac { a } { 4 } }$ here. We now range $a$ from 20 to 200 in steps of 20. Our results are depicted in Figure 1.\n\nWe see that the runtime for exponential-tail mutation is essentially linear, which is what we expected. However, we also see that the runtime for power-law mutation is roughly linear, which is far better than our theoretical bounds.\n\nOne explanation for this discrepancy is that our theoretical analyses always assume that the algorithm’s population is maximal, that is, it contains $2 a + 1$ individuals. This assumption seems to be too pessimistic, given preliminary empirical results. In phase 1, if a mutation performs a larger change to an individual, this new individual is likely to strictly dominate multiple solutions in the current population, thus reducing the population size. This potentially speeds up the first phase. In phase 2, for similar reasons, the initial population can be small and only grows large once almost the entire Pareto front is covered. Working with smaller populations in between can reduce the runtime of the second phase.\n\n# Conclusion\n\nIn this work, we initiated the runtime analysis of multiobjective evolutionary algorithms for unbounded integer spaces. To this end, we considered variants of the wellknown SEMO and GSEMO algorithms. For each algorithm, we analyzed three different distributions of their mutation strengths. We derived runtime guarantees for a simple biobjective problem with Pareto front of size $\\Theta ( a )$ . Our theoretical results show a complex parameter landscape, depending on the different characteristics of the problem – namely, the problem size and $a$ – and of the algorithm – namely, the mutation strength.\n\nFor all reasonable problem parameter choices, the unitstep mutation is the worst update strength, since the progress in each dimension is always bounded by the lowest possible value. The comparison of the other two mutation strengths is more delicate. Our theoretical results suggest that the exponential-tail mutation can outperform the power-law mutation if its parameter $q$ is chosen carefully with respect to the problem parameters. However, in our experiments the power-law mutation always gave results superior to the exponential-tail mutation using a tuned parameter. Moreover, our experiments indicate a linear total runtime for both the exponential-tail and the power-law mutation (for certain parameter settings), which is a better runtime behavior for the power-law algorithm than what our upper bounds guarantee. We speculate this is a consequence of our pessimistic assumption of the algorithms’ population size always being maximum. However, we note that, to the best of our knowledge, this is how essentially any theoretical consideration of the (G)SEMO up to date operates, for example (Bian, Qian, and Tang 2018; Doerr and Zheng 2021; Dang et al. 2023). Overall, our empirical analysis indicates that either our theoretical guarantees are not tight for the power-law algorithm or that the asymptotic effects are only witnessed for larger problem sizes, noting that our empirical observations seem to hold even more clearly for larger values of $n$ . In any case, as both our theoretical and empirical results indicate that the power-law mutation has the best expected runtime for a wide range of problem parameters and starting points, and it does not require a careful parameter choice, our general recommendation is to prefer this algorithm for the optimization of problems with unbounded integer variables and no further problem-specific knowledge.\n\nAn interesting next step is to analyze whether our theoretical bounds are tight. We speculate that a more careful study of the algorithms’ population dynamics is required. Theoretical analyses of this level of detail have not been conducted for the (G)SEMO so far. Hence, more refined analysis techniques than the state of the art seem to be necessary.\n\nAnother interesting direction is to prove lower bounds for our considered settings. Such analyses can shed more light onto certain behavioral aspects of the algorithms, and they require a deeper understanding of the dynamics of the population size. Thus, they are challenging to derive but can lead to insights that suggest how to improve our upper bounds.\n\nIn addition, it would be interesting to analyze other multiobjective evolutionary algorithms, e.g., the very prominent NSGA-II (Deb et al. 2002) as well as the NSGA-III (Deb and Jain 2014), SPEA2 (Zitzler, Laumanns, and Thiele 2001), and the SMS-EMOA (Beume, Naujoks, and Emmerich 2007). Moreover, these algorithms have a more complex procedure of updating their population in comparison to that of the (G)SEMO. This can further prove more challenging. However, a comparison to other multi-objective algorithms would greatly improve our current theoretical knowledge of the unbounded integer domain.\n\n# Acknowledgments\n\nThis research benefited from the support of the FMJH Program Gaspard Monge for optimization and operations research and their interactions with data science.",
    "summary": "```json\n{\n  \"core_summary\": \"### 🎯 核心概要\\n\\n> **问题定义 (Problem Definition)**\\n> *   论文首次系统性地分析了多目标进化算法（MOEAs）在无界整数空间中的运行时性能，填补了现有理论研究在无界整数域上的空白。\\n> *   该问题的重要性在于为实际应用中广泛存在的无界整数优化问题（如组合优化、参数调优等）提供了理论支持，并指导了变异算子的选择。\\n\\n> **方法概述 (Method Overview)**\\n> *   论文通过数学分析和实验验证，比较了SEMO和GSEMO算法在无界整数空间中采用三种变异算子（单位步长、指数尾、幂律）的运行时性能。\\n\\n> **主要贡献与效果 (Contributions & Results)**\\n> *   **理论创新：** 首次证明了幂律变异在无界整数空间中的优越性，其运行时上界为多项式时间（定理16），而实验显示实际性能接近线性。\\n> *   **实践价值：** 实验表明幂律变异在参数敏感性（无需调参）和全局搜索能力上均优于指数尾变异（表1），即使后者使用最优参数配置。\\n> *   **基准建立：** 提出了一个具有明确帕累托前沿（大小`2a+1`）的基准问题，为后续研究提供了测试标准。\",\n  \"algorithm_details\": \"### ⚙️ 算法/方案详解\\n\\n> **核心思想 (Core Idea)**\\n> *   通过控制变异步长的概率分布（单位步长、指数尾、幂律），平衡算法的局部开发和全局探索能力。幂律变异因其重尾特性，能同时兼顾大跳变和小步长调整。\\n\\n> **创新点 (Innovations)**\\n> *   **与先前工作的对比：** 先前研究（如Doerr et al. 2011, 2018）仅关注有界离散空间，而本文首次将运行时分析扩展到无界整数域。\\n> *   **本文的改进：** 设计了参数无关的幂律变异算子（定义见Runtime Analysis节），其理论性能不受初始解距离`‖x⁽⁰⁾‖₁`和帕累托前沿宽度`a`的影响。\\n\\n> **具体实现步骤 (Implementation Steps)**\\n> 1.   初始化：种群`P⁽⁰⁾`仅包含初始解`x⁽⁰⁾`（算法1第1-2行）。\\n> 2.   迭代优化：\\n>      - 随机选择个体`x⁽ᵗ⁾`并应用变异算子（第4-5行）。\\n>      - 更新种群：移除被`y⁽ᵗ⁾`弱支配的个体，并添加非支配解（第6-8行）。\\n> 3.   终止条件：当种群覆盖帕累托前沿`F*`时停止（定义见Preliminaries节）。\\n\\n> **案例解析 (Case Study)**\\n> *   基准问题`f: ℤⁿ → ℕ²`（公式见Benchmark Problem节）的帕累托前沿为`F* = {(k, 2a-k) | k∈[0..2a]}`，其大小`|F*|=2a+1`直接决定了算法收敛难度。\",\n  \"comparative_analysis\": \"### 📊 对比实验分析\\n\\n> **基线模型 (Baselines)**\\n> *   单位步长变异（Uniform over {±1}）\\n> *   指数尾变异（Bilateral geometric law with parameter `q`）\\n> *   幂律变异（Power-law with exponent `β=1.5`）\\n\\n> **性能对比 (Performance Comparison)**\\n> *   **在收敛速度上：** 幂律变异的实际运行时（图1）接近线性，显著优于理论预期（多项式时间），且比最优调参的指数尾变异（`1/q=a/4`时）快约15%（表1）。\\n> *   **在参数敏感性上：** 指数尾变异的最优参数`q`需满足`1/q ∝ a`（定理12），而幂律变异无需调参即达到最佳性能（实验部分结论节）。\\n> *   **在鲁棒性上：** 当初始解距离帕累托前沿较远（`‖x⁽⁰⁾‖₁=100a`）时，幂律变异的优势更明显（图1），其理论运行时仅与`‖x⁽⁰⁾‖₁`的`β-1`次方相关（定理16）。\",\n  \"keywords\": \"### 🔑 关键词\\n\\n*   多目标进化算法 (Multi-Objective Evolutionary Algorithm, MOEA)\\n*   运行时分析 (Runtime Analysis, N/A)\\n*   无界整数优化 (Unbounded Integer Optimization, N/A)\\n*   幂律变异 (Power-Law Mutation, N/A)\\n*   指数尾分布 (Exponential-Tail Distribution, N/A)\\n*   帕累托前沿 (Pareto Front, N/A)\\n*   全局搜索 (Global Search, N/A)\\n*   理论计算机科学 (Theoretical Computer Science, N/A)\"\n}\n```"
}