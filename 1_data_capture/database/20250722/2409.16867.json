{
    "source": "Semantic Scholar",
    "arxiv_id": "2409.16867",
    "link": "https://arxiv.org/abs/2409.16867",
    "pdf_link": "https://arxiv.org/pdf/2409.16867.pdf",
    "title": "Multi-objective Evolution of Heuristic Using Large Language Model",
    "authors": [
        "Shunyu Yao",
        "Fei Liu",
        "Xi Lin",
        "Zhichao Lu",
        "Zhenkun Wang",
        "Qingfu Zhang"
    ],
    "categories": [
        "cs.AI"
    ],
    "publication_date": "2024-09-25",
    "venue": "AAAI Conference on Artificial Intelligence",
    "fields_of_study": [
        "Computer Science"
    ],
    "citation_count": 12,
    "influential_citation_count": 1,
    "institutions": [
        "City University of Hong Kong",
        "Southern University of Science and Technology"
    ],
    "paper_content": "# Multi-Objective Evolution of Heuristic Using Large Language Model\n\nShunyu Yao1, \\* Fei Liu1, \\* Xi Lin1, Zhichao ${ \\bf L u } ^ { 1 }$ , Zhenkun Wang2, †, Qingfu Zhang1, †\n\n1Department of Computer Science, City University of Hong Kong, Hong Kong, China 2School of System Design and Intelligent Manufacturing, Southern University of Science and Technology, Shen Zhen, China {shunyuyao8, fliu36}-c@my.cityu.edu.hk, {xilin4, zhichao.lu}@cityu.edu.hk, wangzhenkun $9 0 @$ gmail.com, qingfu.zhang $@$ cityu.edu.hk\n\n# Abstract\n\nHeuristics are commonly used to tackle various search and optimization problems. Design heuristics usually require tedious manual crafting with domain knowledge. Recent works have incorporated Large Language Models (LLMs) into automatic heuristic search, leveraging their powerful language and coding capacity. However, existing research focuses on the optimal performance on the target problem as the sole objective, neglecting other criteria such as efficiency and scalability, which are vital in practice. To tackle this challenge, we propose to model the heuristic search as a multiobjective optimization problem and consider introducing additional practical criteria beyond optimal performance. Due to the complexity of the search space, conventional multiobjective optimization methods struggle to effectively handle LLM-based multi-objective heuristic search. We propose the first LLM-based multi-objective heuristic search framework, Multi-objective Evolution of Heuristic (MEoH), which integrates LLMs in a zero-shot manner to generate a nondominated set of heuristics to meet multiple design criteria. We design a new dominance-dissimilarity mechanism for effective population management and selection, which incorporates both code dissimilarity in the search space and dominance in the objective space. MEoH is demonstrated in two well-known combinatorial optimization problems: the online Bin Packing Problem (BPP) and the Traveling Salesman Problem (TSP). The results indicate that a variety of elite heuristics are automatically generated in a single run, offering more trade-off options than the existing methods. It successfully achieves competitive or superior performance while improving efficiency up to 10 times. Moreover, we also observe that the multi-objective search introduces novel insights into heuristic design and leads to the discovery of diverse heuristics.\n\n# Code — https://github.com/Optima-CityU/LLM4AD\n\n# 1 Introduction\n\nHeuristics are commonly used in solving optimization and decision-making problems in a variety of fields, including engineering (Bozorg-Haddad, Solgi, and Lo´aiciga 2017), industry (Silver 2004), and economics (Vasant 2012). Unlike exact methods, heuristics offer practical alternatives for finding sub-optimal solutions within a reasonable time cost (Pearl 1984) and are particularly adept at handling complex problems with diverse attributes and constraints. However, developing effective heuristics typically requires expert knowledge and involves laborious trial-and-error manual crafting, presenting a significant challenge for real-world applications.\n\nTo address this challenge, much effort has been devoted to automating the design of heuristics (Pillay and Qu 2021). These efforts can be broadly classified into three categories: heuristic configuration (Ramos et al. 2005; Visheratin, Melnik, and Nasonov 2016), heuristic selection (Tang et al. 2014; Xu, Hoos, and Leyton-Brown 2010), and heuristic composition (Burke et al. 2010; Drake et al. 2020; Pillay and Qu 2018). Despite the successful creation of novel heuristics, the effectiveness of these heuristics still heavily relies on algorithmic components crafted by human experts (Drake et al. 2020).\n\nIn recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities in algorithm design (Liu et al. 2024b). The integration of LLMs with Evolutionary Computation (EC) has enabled the automatic generation and refinement of heuristics along with their corresponding code implementations (Liu et al. 2024a; RomeraParedes et al. 2024; Ye et al. 2024). The designed heuristics achieved competitive performance with minimized human design and model training. However, all existing LLMbased evolutionary heuristic search methods focus on a single objective regarding the optimized performance of the target problem (Ma et al. 2023; Nasir et al. 2024; Liu et al. 2024a; Romera-Paredes et al. 2024; Zhang et al. 2024; Yao et al. 2024; van Stein and Ba¨ck 2024; Li et al. 2024; Zeng et al. 2024; Mao et al. 2024; Ma et al. 2024). Other important heuristic design criteria, such as heuristic complexity (Ausiello et al. 2012) and code readability (Buse and Weimer 2009), which could be vital in practice, are often neglected. Although some studies have attempted to optimize multiple objectives by combining them into a single objective function, resulting in a single heuristic, the conflicting nature of diverse objectives often makes it challenging to find a single heuristic that satisfies all simultaneously. The exploration of effective methods for searching a set of nondominated heuristics in a single run remains unexplored.\n\nIn this study, we model the automatic heuristic design as a multi-objective optimization problem (Dre´o 2009) and propose the first LLM-based multi-objective heuristic search framework, termed Multi-objective Evolution of Heuristic (MEoH), to effectively search for a set of non-dominated heuristics in a single run. The contributions of this paper are as follows:\n\n• We propose an LLM-based automated heuristic design framework to consider the heuristic design from a multiobjective optimization perspective.   \n• We propose a dominance-dissimilarity mechanism to enhance diversity and improve search efficiency by considering both the dominance relationships in the objective space and the dissimilarity of heuristics in the search space.   \n• We demonstrate the superiority compared with the counterpart of single-objective LLM-based automated heuristic design on two classical optimization problems: the Traveling Salesman Problem (TSP) and the online Bin Packing Problem (BPP).\n\n# 2 Related Works\n\n# 2.1 Automated Heuristic Design\n\nAutomated heuristic design methods can be broadly classified into automated heuristic configuration, automated heuristic selection, and automated heuristic composition (Pillay and $\\mathrm { Q u } \\ 2 0 2 1 )$ ). The first category involves using optimization methods and machine learning techniques (Ramos et al. 2005; Visheratin, Melnik, and Nasonov 2016) to automatically adjust the parameters within a given algorithm framework (Agasiev and Karpenko 2017). The second category focuses on automatically choosing a suitable heuristic for each specific instance from a pool of existing heuristics (Tang et al. 2014; Xu, Hoos, and LeytonBrown 2010). The third category combines various algorithmic elements to create novel heuristics (Burke et al. 2010; Drake et al. 2020; Pillay and Qu 2018). While these methods have shown promise in enhancing the automation of heuristic design and improving performance, they still heavily rely on human-designed algorithmic components.\n\n# 2.2 LLM-based Automated Heuristic Design\n\nLarge language models have shown remarkable performance across a variety of tasks and exhibit promising zeroshot capabilities in linguistic processing and code generation. The use of LLMs in automated heuristic design is still in its early stages (Liu et al. 2024b). For example, FunSearch (Romera-Paredes et al. 2024) leverages LLMs to generate and improve code implementations of heuristics based on EC frameworks, achieving state-of-the-art results in mathematical and combinatorial optimization problems. EoH (Liu et al. 2024a) evolves both idea descriptions and code implementations of heuristics simultaneously, leading to competitive performance in a more efficient manner. This $_ \\mathrm { E C + L L M }$ approach has been successfully applied in heuristic and function design across various tasks such as reward function design (Ma et al. 2023), molecular design (Wang et al. 2024), network design (Mao et al. 2024), and Bayesian optimization (Yao et al. 2024). While effective heuristics are developed, they often focus solely on performance for specific target instances, overlooking other crucial objectives like efficiency and complexity.\n\n# 2.3 Multi-objective Heuristic Design\n\nHeuristic design can be modeled as a multi-objective optimization problem. Dre´o (2009) consider automated heuristic design as a multi-objective problem to design a set of nondominated heuristics to balance optimality and efficiency. SRace (Zhang, Georgiopoulos, and Anagnostopoulos 2013) employs a racing algorithm to automatically choose machine learning models based on multiple objectives. Furthermore, MO-ParamILS (Blot et al. 2016) extends the singleobjective heuristic configuration framework ParamILS to handle multiple objectives. Multi-objective genetic programming has also been utilized in heuristic search (Schmidt and Lipson 2009; Vladislavleva, Smits, and Den Hertog 2008; Fan et al. 2024). However, they still demand existing hand-crafted primitives for defining and generating heuristics.\n\n# 3 Preliminaries\n\n# 3.1 Multi-objective Optimization\n\nA Multi-objective Optimization Problem (MOP) can be defined as\n\n$$\n\\operatorname* { m i n } _ { \\pmb { x } \\in \\mathcal { X } } f ( \\pmb { x } ) = ( f _ { 1 } ( \\pmb { x } ) , f _ { 2 } ( \\pmb { x } ) , \\dots , f _ { M } ( \\pmb { x } ) ) ,\n$$\n\nwhere $\\chi$ represents the search space, $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ is a decision vector, and $\\pmb { f } ( \\pmb { x } )$ is an $M$ -objective vector to optimize. A non-trivial MOP cannot be solved by a single decision vector, and we have the following definitions for multi-objective optimization:\n\nPareto Dominance: Let $\\pmb { x } _ { a } , \\pmb { x } _ { b } \\in \\mathcal { X }$ , $\\scriptstyle { \\mathbf { { \\vec { x } } } } _ { a }$ is said to dominate $\\scriptstyle { \\mathbf { { \\mathit { x } } } } _ { b }$ $( { \\pmb x } _ { a } \\ \\prec \\ { \\pmb x } _ { b } )$ if and only if $f _ { i } ( { \\pmb x } _ { a } ) \\leq f _ { i } ( { \\pmb x } _ { b } ) , \\forall i \\in$ $\\{ 1 , 2 , \\ldots , M \\}$ and $f _ { j } ( \\pmb { x } _ { a } ) < f _ { j } ( \\pmb { x } _ { b } ) , \\exists j \\in \\{ 1 , 2 , . . . , M \\}$ .\n\nPareto Optimality: A decision vector ${ \\pmb x } ^ { * } \\in \\mathcal { X }$ is Paretooptimal if there does not exist $\\pmb { x } ^ { \\prime } \\in \\mathcal { X }$ dominates $\\boldsymbol { x } ^ { * }$ , i.e., $\\pmb { \\operatorname { \\mathbb { \\hat { x } } } } \\mathbf { x } ^ { \\prime } \\in \\mathcal { X }$ such that $\\mathbf { x } ^ { \\prime } \\prec \\mathbf { x } ^ { * }$ .\n\nPareto Set/Front: The set of all Pareto-optimal decision vectors is called the Pareto Set (PS), and its mapping in the objective space is called the Pareto Front (PF).\n\nIn this paper, we investigate multi-objective heuristic design. The decision vector $\\scriptstyle { \\mathbf { { \\vec { x } } } }$ indicates the heuristic and the $M$ -objective vector represents different criteria measuring different aspects of the performance of heuristics (e.g., optimal performance and complexity).\n\n# 3.2 Multi-objective Evolutionary Algorithms\n\nMulti-objective Evolutionary Algorithms (MOEAs) are among the most commonly used methods to solve MOPs. MOEAs work by maintaining a population of $N$ candidate individuals that evolve iteratively through genetic operators like crossover and mutation. There are three main paradigms for MOEAs: the dominance-based approach (Deb et al.\n\n![](images/11f214250d5ac3906aa6866af8c0c14432980f3ddf313290d681f2a40e3342f0.jpg)  \nFigure 1: Comparison to human design and existing LLM-based heuristic design (a) manual heuristic design by human experts, (b) single-objective LLM-based heuristic design (e.g., FunSearch and EoH), and (c) our proposed multi-objective heuristic design (MEoH).\n\n2002), the decomposition-based approach (Zhang and Li   \n2007), and the indicator-based approach (Zitzler and Ku¨nzli   \n2004).\n\n# 4 Methodology\n\n# 4.1 Framework\n\nMulti-objective Evolution of Heuristic (MEoH) is a fusion of LLMs and multi-objective evolutionary optimization for effective multi-objective heuristic design. As illustrated in Algorithm 1, MEoH begins with population initialization, where the population comprises heuristics, and progressively improves the population using MOEA until the termination condition is satisfied, to obtain a set of non-dominated heuristics that represent trade-offs among multiple objectives. Throughout each iteration, MEoH generates offspring using search operators. These operators are implemented through LLMs and predefined prompts to create offspring based on the selected parents from the population. New offspring are added to the population and population management is utilized to update the population to keep its size, with a focus on maintaining diversity and convergence. The dominance-dissimilarity mechanism is utilized in both parent selection and population management. Detailed explanations of each of these components will be provided in the subsequent sections.\n\nMEoH advances existing LLM-based heuristic design by extending the single-objective approach (Romera-Paredes et al. 2024; Liu et al. 2024a) to the multi-objective scenarios and designing a set of non-dominated heuristics in a single run. Moreover, unlike directly combining MOEA and LLM-based heuristic search, MEoH introduces a unique dominance-dissimilarity measure to navigate the complex and discrete heuristic search space, overcoming challenges faced by conventional MOEAs like NSGA-II (Deb et al. 2002) and MOEA/D (Zhang and Li 2007).\n\n# 4.2 Dominance-dissimilarity Mechanism\n\nTraditional MOEAs (Deb et al. 2002; Zhang and Li 2007) and single-objective LLM-based heuristic design meth\n\n# Algorithm 1: MEoH\n\n1: Input: Population size $N$ ; Maximum number of itera  \ntions $T$ , Parent selection size $d$ ; Initial population $P _ { 0 }$ ;   \nPre-trained LLM $\\mathcal { L }$ .   \n2: Output: Approximate Pareto-set $P ^ { * }$ .   \n3: if $P _ { 0 } = \\varnothing$ then   \n4: fo $\\begin{array} { c } { \\mathbf { r } \\ i = 1 , \\dots , N \\ \\mathbf { d o } } \\\\ { \\mathbf { \\phi } _ { o } \\gets \\operatorname { G e n e r a t i o n } ( \\mathcal { L } ) ; } \\\\ { \\mathbf { \\phi } _ { P _ { 0 } } \\gets P _ { 0 } \\cup o } \\end{array}$   \n5:   \n6:   \n7: end for   \n8: end if   \n10: 9: for f $t = 1 , \\dots , T$ $\\begin{array} { r l } & { t = 1 , \\ldots , L \\ \\mathbf { 0 } } \\\\ & { \\mathbf { p r } \\ i = 1 , \\ldots , N \\mathbf { d o } } \\\\ & { P _ { p a r e n t }  \\mathrm { P a r e n t S e l e c t i o n } ( P _ { t - 1 } , d ) ; } \\\\ & { o  \\mathrm { S e a r c h } ( \\mathcal { L } , P _ { p a r e n t } ) ; } \\\\ & { P _ { t - 1 }  P _ { t - 1 } \\cup o } \\end{array}$ do   \n11:   \n12:   \n13:   \n14: end for   \n15: $\\mathbf { } P _ { t } \\gets$ PopulationManagemen $( P _ { t - 1 } , N )$   \n16: end for   \n17: ${ \\cal P } ^ { * }  { \\cal P } _ { T }$\n\nods (Romera-Paredes et al. 2024; Liu et al. 2024a) lack effective diversity maintenance strategies for multi-objective automated heuristic design. To address this, we propose a novel dominance-dissimilarity mechanism that considers both objective space dominance and heuristic search space dissimilarity.\n\nDominance Measure in Objective Space: In the objective space, the Pareto dominance relationship between each pair of heuristics is evaluated, which is widely used in MOEAs (Zitzler and Thiele 1998; Deb et al. 2002).\n\nDissimilarity Measure in Search Space: In the search space, the heuristics are represented through natural language descriptions and implemented in Python code. We evaluate the dissimilarity between code segments. Notably, there are various techniques available for this purpose, and we choose to utilize the widely adopted Abstract Syntax Tree (AST) (Neamtiu, Foster, and Hicks 2005). The AST converts the code segment to an abstract syntactic structure (Baxter et al. 1998). And the similarity of code $a$ and code $b$ can be calculated based on the tree structures following Ren et al. (2020):\n\n$$\n\\mathrm { S i m _ { A S T } } ( a , b ) = \\mathrm { C o u n t _ { c l i p } } ( \\mathrm { T r e e } _ { a } ) / \\mathrm { C o u n t } ( \\mathrm { T r e e } _ { b } ) ,\n$$\n\nwhere $\\mathrm { C o u n t } ( \\mathrm { T r e e } _ { b } )$ is the number of subtrees of ${ \\mathrm { T r e e } } _ { b }$ , and $\\mathbf { C o u n t _ { \\mathrm { c l i p } } ( T r e e } _ { a } \\mathbf { ) }$ is the number of subtrees of $\\mathrm { T r e e } _ { a }$ that are matched the ${ \\mathrm { T r e e } } _ { b }$ . The AST similarity value ranges from 0 to 1, with 0 indicating complete dissimilarity between the two code segments and 1 signifying identical code segments. This quantitative approach enables the assessment of structural similarity between code segments, facilitating the comparison and evaluation of heuristics based on their code implementations.\n\nDominance-dissimilarity Score: As illustrated in Figure 2, to determine the dominance-dissimilarity of each heuristic in the population, the dissimilarity, i.e., the negative AST similarity, between each pair of heuristics is calculated and stored in a matrix. Concurrently, in the objective space, the dominance relationship between each pair of heuristics is captured and represented as a mask with the same size as the dissimilarity matrix. Specifically, only the dominance relationship is considered, while all other relationships are masked. Subsequently, the masked dissimilarity matrix is aggregated column-wise. The resulting dominance-dissimilarity score vector encapsulates both dominance and diversity aspects to guide parent selection and population management in the subsequent steps. The details can be found in Appendix A.\n\n# 4.3 Heuristic Representation\n\nSimilar to Liu et al. (2024a), each heuristic in MEoH is composed of three elements: a description in plain language, a code snippet in a specific format, and a fitness score.\n\nThe description is a brief linguistic explanation generated by LLMs that conveys the main idea. The code snippet is the actual implementation of the heuristic. In the experiments, we opted to use Python functions for implementation. The code snippet must include the 1) function name, 2) input variables, and 3) output variables for clarity. The fitness is evaluated on a set of instances for the specific target problem. Example heuristics can be found in Appendix H.\n\n# 4.4 Heuristic Generation\n\nInitial Heuristic Generation The initial population of MEoH is comprised of heuristics. These heuristics can be generated by leveraging a LLM with a predefined generation prompt or by using human-designed existing heuristics. In order to fully demonstrate the capability of MEoH in designing competitive heuristics, we let LLM generate all the heuristics in both the initiation and evolution processes.\n\nOffspring Heuristic Generation The parent selection is the first step of generating offspring, in which a set of parent heuristics $P _ { p a r e n t }$ are selected from the current population. To consider both convergence and diversity in the heuristic search process, the dominance-dissimilarity score is utilized to guide the probability of parent selection. A higher dominance-dissimilarity score indicates a lower likelihood of being dominated or a more diverse code segment, making it preferable. The parents are selected with probability proportional to their dominance-dissimilarity scores. The details can be found in Appendix A.\n\nThe selected parent heuristics serve as samples in the prompt to instruct LLM in generating offspring heuristics. We employ five different search operators with diverse prompt strategies adapted from EoH (Liu et al. 2024a) to produce offspring heuristics. The details of these prompts can be found in Appendix G.\n\n# 4.5 Population Management\n\nAs the offspring generated through search operations are incorporated into the population, the size of the population gradually increases. In order to ensure a consistent population size and update the population effectively, a population management strategy is proposed. The dominancedissimilarity score is utilized for this purpose. Specifically, the heuristics in the population are sorted based on their dominance-dissimilarity score and the worst heuristics are removed to ensure that only the most promising individuals are retained within the population, as detailed in Appendix A. By employing this strategy, the population is continually refined to maintain a high-quality and diverse set of individuals, enhancing the overall efficiency and effectiveness of the evolutionary process.\n\n# 5 Experiments\n\n# 5.1 Experimental Settings\n\nProblems & Implementation Details We demonstrate MEoH on two representative combinatorial optimization problems:\n\n1) Online Bin Packing Problem: In online Bin Packing Problem (BPP) (Seiden 2002), a set of items, each with its own weight, needs to be packed into bins with a predetermined capacity. The objective of the BPP is to minimize the total number of bins required to accommodate all the items. In an online scenario, items are packed as they are received without prior knowledge. The generated heuristics are evaluated on 5 Weibull instances with 5, 000 items (referred to as 5k), and the capacity of bins is 100.\n\nWe inherit the settings from Romera-Paredes et al. (2024) to design constructive heuristics for aligning the arriving items to the appropriate bins. The designed heuristics involve a function scoring the bins, where the input includes the arriving item size and the remaining capacities of the bins. The item will be assigned to the bin with the highest score.\n\n2) Travelling Salesman Problem: In Traveling Salesman Problem (TSP) (Reinelt 2003), the objective is to find the shortest route that visits all given nodes exactly once and returns to the starting node. In this work, we evaluate the fitness of designed heuristics during evolution on 64 instances with 100 nodes. The coordinate of each node is randomly sampled from [0, 1] (Kool, van Hoof, and Welling 2018).\n\nThe Guided Local Search (GLS) framework is employed (Voudouris, Tsang, and Alsheddy 2010) to iteratively\n\nDissimilarity Dominance Search Space Objective Space Code1 Code2 ≺ 1 1 0 -0.5 2 -0.4 3 -0.9 4 -0.2 5 f→ C 2 -0.4 0 -0.3 -0.6 -0.6 Code3 3 -0.5 -0.2 0 -0.7 -0.1 Code5 Code4 4 -0.7 -0.7 -0.6 0 -0.4 𝑓𝑓1   \n0.3 Probability 5 -0.3 -0.5 -0.2 -0.5 0 New Population   \n0.02.25 山 ෍ 0 0 -0.3 0 -0.8 1 2 4 3 5   \n0.15   \n0.1 0 0 0 -0.3 -0.8   \n0.05 Parent Selection Population Management 0 四 四 Code1 Code2 Code4 C\n\nimprove the solution quality following (Liu et al. 2024a). GLS iteratively performs two steps: 1) local search and 2) perturbation. Until the stop criterion is satisfied, the best solution obtained throughout the iterations is considered the final solution. We aim to design a heuristic to update the distance matrix in the perturbation step.\n\nThe experimental parameter settings are as follows: the number of generations is 20, and the population size is 20 and 10 for online BPP and TSP, respectively. Each crossover operator selects 5 parent heuristics to reproduce the offspring heuristics. The number of iterations and running time in the GLS for TSP is limited to $1 , 0 0 0$ and 60 seconds, respectively.\n\nEnvironments To ensure fairness and consistency, all experiments in this study were conducted on a computer equipped with an Intel Core i7-11700 processor and 32GB of memory. GPT3.5-turbo is employed as the per-trained LLM, with each experiment repeated three times to ensure the robustness and reliability of the results.\n\n# Performance Metric\n\nObjectives 1) Optimal Gap: We use the optimal gap to baseline as the first objective (e.g., the gap between the number of bins used in designed heuristics to the lower bound of bin number). 2) Efficiency: The running time of heuristics is used as the second objective to reflect the efficiency of heuristics.\n\nMetric 1) Hypervolume: The Hypervolume(HV) is a commonly used metric in multi-objective optimization. It provides a comprehensive assessment of convergence and diversity of the approximate Pareto front without the ground truth Pareto front (Audet et al. 2021). A larger HV value indicates a better performance. 2) IGD: The Inverted Generational Distance(IGD) measures the quality of the generated approximate Pareto front in relation to the reference set. Here the reference set is the nondominated set derived from the union of all generated heuristics. A lower IGD value is preferred, which indicates better convergence and diversity, implying that the generated population is closer to the reference set. The detailed formulation of the two metrics can be found in Appendix D.\n\nBaseline Methods In this study, our primary focus lies in exploring LLM-based automated heuristic design approaches. Consequently, we compare the two closest related works, namely FunSearch (Romera-Paredes et al. 2024) and EoH (Liu et al. 2024a). The details can be found in Appendix C.\n\n# 5.2 Experimental Results\n\nConvergence Analysis The curve of HV and IGD for the heuristic populations generated in each iteration on BPP are displayed in Figure 3(b) and (c), respectively. As EoH only pursues optimal gaps without considering diversity, the HV and IGD become worse as the evolution progresses. In contrast, MEoH systematically takes into account both the optimal gap and running time. As a result, MEoH achieves notably higher HV and lower IGD, indicating significantly better multi-objective trade-off results. Figure 4(b) and (c) provide more evidence on TSP. MEoH converges faster and clearly outperforms EoH in terms of HV and IGD. Additionally, the average dominance-dissimilarity score is shown in Figure 3 (d) and Figure 4 (d). Results demonstrate the superiority of MEoH and the efficiency of our dominancedissimilarity mechanism in maintaining population diversity. The details can be found in Appendix F.\n\nPareto Fronts Figure 3(a) and Figure 4(a) compare the non-dominated heuristics of the final population obtained by MEoH and EoH. Results show that 1) MEoH generates a diverse set of heuristics with different trade-offs over the two objectives. In contrast, EoH only finds similar heuristics that cover a much smaller region in the objective space. 2) The heuristics obtained from MEoH can significantly reduce the running time (up to 10 times) when achieving a similar optimal gap.\n\nPerformance Measurement 1) BPP: To comprehensively evaluate the performance of our MEoH in more general cases, we test FunSearch, EoH, and MEoH on various problem instances with different sizes and capacities. The problem sizes in our test include 5k, 10k, and $1 0 0 \\mathrm { k }$ , and the capacities of the bins are set at 100 and 500. Each test set consists of five instances sampled from Weibull distribution (Romera-Paredes et al. 2024). The average gap with reference to the relaxation lower bound $l b$ and the running time are shown in Table 1. For the in-distribution instances, i.e., the bin capacity is 100, all of these three frameworks exhibit promising performance in terms of the optimal gap, and the running time of MEoH heuristics are significantly less than the counterparts of FunSearch and EoH, especially in largesize instances, i.e., BPP100k. MEoH heuristics achieve competitive performance compared to EoH but do so in significantly less running time (up to 10 times faster). In contrast, for out-distribution instances, i.e., the bin capacity is 500, the performance of FunSearch heuristics drastically deteriorates in terms of the optimal gap. On the other hand, both EoH and MEoH heuristics exhibit promising performances in such scenarios. Notably, MEoH demonstrates a balanced tradeoff between the optimal gap and running time, showcasing its effectiveness in handling out-distribution instances efficiently.\n\n![](images/a0579dd0946c11988c2d520b1f9a387f645a866a9b377257f46b0682decd9d85.jpg)  \nFigure 3: Comparations of EoH and MEoH on BPP5k.\n\n![](images/84a4d10164efda045837b2cabcadf029b401086003a0c771517177609402f7bd.jpg)  \nFigure 4: Comparations of EoH and MEoH on TSP100.\n\n2) TSP: We evaluate these three methods on randomly generated TSP instances comprising 100, 500, and 1, 000 nodes and a variety of TSP instances with up to 1, 002 nodes from TSPLIB (Reinelt 1991). Table 2 and Table 3 display the gap compared to the best-known solution (for the randomly generated instances, the best-known solutions are obtained using the Concorde solver (Applegate et al. 2006))\n\nTable 1: Results of in- and out-of-distribution BPP.   \n\n<html><body><table><tr><td rowspan=\"2\">Weibull</td><td colspan=\"2\">FunSearch</td><td colspan=\"2\">EoH</td><td colspan=\"2\">MEoH</td></tr><tr><td>Gap</td><td>Time/s</td><td>Gap</td><td>Time/s</td><td>Gap</td><td>Time/s</td></tr><tr><td>5k C100</td><td>0.802%</td><td>0.728</td><td>0.753%</td><td>1.362</td><td>1.387%</td><td>0.191</td></tr><tr><td>10k C100</td><td>2.595%</td><td>2.128</td><td>0.537%</td><td>5.128</td><td>0.651%</td><td>0.650</td></tr><tr><td>100k C100</td><td>3.319%</td><td>195.734</td><td>0.391%</td><td>502.938</td><td>0.080%</td><td>59.078</td></tr><tr><td>Avg.</td><td>2.239%</td><td>66.197</td><td>0.560%</td><td>169.809</td><td>0.706%</td><td>19.973</td></tr><tr><td>5k C500</td><td>29.494%</td><td>0.750</td><td>0.100%</td><td>1.672</td><td>0.351%</td><td>0.100</td></tr><tr><td>10kC500</td><td>47.734%</td><td>2.459</td><td>0.125%</td><td>6.337</td><td>0.473%</td><td>0.306</td></tr><tr><td>100k C500</td><td>53.640%</td><td>259.094</td><td>0.099%</td><td>646.828</td><td>0.410%</td><td>22.078</td></tr><tr><td>Avg.</td><td>43.623%</td><td>87.434</td><td>0.108%</td><td>218.279</td><td>0.411%</td><td>7.495</td></tr></table></body></html>\n\nand the corresponding running times. As shown in Table 2, FunSearch and MEoH (Best) heuristics exhibit promising performance on TSP100 and TSP500 instances. In general, MEoH provides a set of heuristics that enable trade-offs between optimality and efficiency. As shown in Table 3, for smaller instances (up to 200 nodes), the MEoH heuristics demonstrate superior performance in terms of both the optimal gap and running time. For larger instances (201 to 1, 002 nodes), MEoH still outperforms in running time, although slightly lagging behind EoH in terms of the optimal gap. The details can be found in Appendix E.\n\n# 5.3 Comparison to Conventional MOEAs\n\nIn this section, we evaluate the impact of our proposed dominance-dissimilarity mechanism on the optimization process and compare to two representative MOEAs: NSGAII (Deb et al. 2002) and MOEA/D (Zhang and Li 2007).\n\nTable 2: Results of in- and out-of-distribution randomly generated TSP.   \n\n<html><body><table><tr><td rowspan=\"3\"></td><td colspan=\"2\">TSP100</td><td colspan=\"2\">TSP500</td><td colspan=\"2\">TSP1000</td></tr><tr><td>Gap</td><td>Time/s</td><td>Gap</td><td>Time/s</td><td>Gap</td><td>Time/s</td></tr><tr><td rowspan=\"2\">FunSearch EoH</td><td>0.100%</td><td>1.452</td><td>1.525%</td><td>27.598</td><td>2.344%</td><td>161.124</td></tr><tr><td>0.113%</td><td>22.434</td><td>1.750%</td><td>43.541</td><td>2.524%</td><td>262.603</td></tr><tr><td>MEoH(Best)</td><td>0.109%</td><td>1.373</td><td>1.733%</td><td>30.945</td><td>4.208%</td><td>26.844</td></tr><tr><td>MEoH(Fast)</td><td>3.690%</td><td>0.175</td><td>4.402%</td><td>3.306</td><td>4.536%</td><td>21.900</td></tr></table></body></html>\n\nTable 3: Results of small and large TSPLIB instances.   \n\n<html><body><table><tr><td rowspan=\"3\">TSPLIB</td><td colspan=\"2\">FunSearch</td><td colspan=\"2\">EoH</td><td colspan=\"2\">MEoH</td></tr><tr><td>Gap</td><td>Time/s</td><td>Gap</td><td>Time/s</td><td>Gap</td><td>Time/s</td></tr><tr><td>Avg. (0-200)</td><td>0.050%</td><td>3.418</td><td>0.093%</td><td>25.917</td><td>0.018%</td><td>2.354</td></tr><tr><td>Avg. (201-1002)</td><td>1.535%</td><td>419.613</td><td>1.376%</td><td>1515.992</td><td>1.50%</td><td>355.754</td></tr></table></body></html>\n\nTable 4: Two top heuristics designed by MEoH.   \n\n<html><body><table><tr><td>一</td><td colspan=\"2\">TSPLIB</td><td colspan=\"2\">BPPC100</td></tr><tr><td></td><td>Gap</td><td>Time/s</td><td>Gap</td><td>Time/s</td></tr><tr><td>FunSearch</td><td>0.050%</td><td>3.418</td><td>2.239%</td><td>66.197</td></tr><tr><td>EoH</td><td>0.093%</td><td>25.917</td><td>0.560%</td><td>169.809</td></tr><tr><td>MEoH (Best)</td><td>0.018%</td><td>2.354</td><td>0.706%</td><td>19.973</td></tr><tr><td>MEoH (Fast)</td><td>3.563%</td><td>0.138</td><td>4.326%</td><td>6.533</td></tr></table></body></html>\n\n![](images/e4d7e5463c41ab4204cfd0ac39d062c190d7e28cc3733b4b7308b5bfec2396fa.jpg)  \nFigure 5: Comparison to conventional MOEAs on BPP.\n\n![](images/014e864b494ab131901f2d01a72cd9b736783c596d9a6b696026983f18211fa7.jpg)  \nFigure 6: Comparison to conventional MOEAs on TSP.   \nFigure 7: Comparations of the non-dominated heuristics generated by MEoH and the any-time performance of the best heuristic generated by EoH (termed as $\\mathrm { E o H } ^ { * }$ ) on TSP.\n\nFigure 5 and Figure 6 depict the results on BPP and TSP, respectively. MEoH can obtain the best HV and IGD. Our findings highlight the effectiveness of our dominancedissimilarity mechanism, which integrates considerations from both the search and objective spaces, in improving the optimization process.\n\nPareto…Front 2000 20 1500 EoH \\* MEoH 1000 500 100 0 \\* 7.8 7.9 8.0 Gap\n\n# 5.4 Comparison to Any-time Performance\n\nThe performance of a single heuristic at any given time can provide a set of heuristics that offer different trade-offs between optimal gap and running time. For instance, reducing the number of iterations in GLS from 1, 000 to 100 results in a decrease in running time but a deterioration in the optimal gap. By comparing the heuristics generated by MEoH to the best heuristic produced by EoH, we can further illustrate the benefits of multi-objective heuristic design. We evaluate the performance of the best EoH heuristic with varying numbers of iterations. Figure 7 demonstrates that the heuristics generated by MEoH outperform those of EoH. Even the best EoH heuristic with 100 iterations falls short in terms of running time and optimal gap compared to all MEoH heuristics. Additionally, while the best EoH heuristic with 2, 000 iterations can achieve competitive optimality, it lags behind in running time by approximately 20 times.\n\n# 6 Conclusion, Limitation, and Future Work\n\nConclusion This paper develops a novel framework, termed MEoH, for LLM-based multi-objective automatic heuristic design. We propose a dominance-dissimilarity mechanism for effective search in the discrete and complex heuristic space. We demonstrate MEoH on two widelystudied combinatorial optimization problems to optimize both heuristics’ optimal gap and running time. Results show that MEoH significantly outperforms existing LLM-based heuristic design methods including FunSearch and EoH in producing trade-off heuristics over multiple objectives. The efficiency can be increased dramatically up to 10 times with a close optimal gap. Moreover, additional ablation studies and visualization of the evolution process validate the superiority of MEoH over conventional MOEAs and the effectiveness of the proposed dominance-dissimilarity mechanism in multi-objective automatic heuristic design.\n\nLimitation and Future Work Although we have demonstrated the effectiveness of MEoH primarily on two objectives, and three objectives in Appendix I, we aim to investigate the performance of MEoH on many-objective cases and a broader range of heuristic design tasks.\n\n# Acknowledgments\n\nThis work was supported by the Research Grants Council of the Hong Kong Special Administrative Region, China (GRF Project No. CityU 11215622), the National Natural Science Foundation of China (Grant No. 62106096 and Grant No. 62476118), the Natural Science Foundation of Guangdong Province (Grant No. 2024A1515011759), the National Natural Science Foundation of Shenzhen (Grant No. JCYJ20220530113013031).",
    "summary": "```json\n{\n  \"core_summary\": \"### 🎯 核心概要\\n\\n> **问题定义 (Problem Definition)**\\n> *   论文解决的核心问题是自动化启发式设计中的多目标优化挑战。现有基于大型语言模型（LLM）的启发式搜索方法仅关注单一目标（如最优性能），而忽略了效率、可扩展性等其他关键实践标准。\\n> *   该问题的重要性在于：多目标优化能够为实际应用提供更多权衡选项，例如在组合优化问题（如装箱问题和旅行商问题）中同时优化解决方案的质量和计算效率。\\n\\n> **方法概述 (Method Overview)**\\n> *   论文提出了一种名为“多目标启发式进化（MEoH）”的框架，首次将LLM与多目标进化算法结合，通过零样本方式生成一组非支配启发式，以满足多个设计标准。\\n\\n> **主要贡献与效果 (Contributions & Results)**\\n> *   **贡献1：** 提出了一种基于LLM的多目标启发式搜索框架MEoH，能够自动生成一组非支配启发式。\\n> *   **贡献2：** 设计了一种新的“支配-差异性”机制，结合目标空间中的支配关系和搜索空间中的代码差异性（基于抽象语法树AST），有效管理种群多样性。\\n> *   **贡献3：** 在装箱问题（BPP）和旅行商问题（TSP）上的实验表明，MEoH生成的启发式在保持竞争性能的同时，效率提升高达10倍。具体数据：在BPP100k实例上，MEoH的运行时间为59.078秒，而EoH为502.938秒；在TSP100实例上，MEoH的Gap为0.109%，运行时间为1.373秒，而EoH的Gap为0.113%，运行时间为22.434秒。\",\n  \"algorithm_details\": \"### ⚙️ 算法/方案详解\\n\\n> **核心思想 (Core Idea)**\\n> *   MEoH的核心思想是将启发式设计建模为多目标优化问题，利用LLM生成和优化启发式代码，同时通过支配-差异性机制平衡收敛性和多样性。\\n> *   该方法有效的原因是：LLM能够生成高质量的启发式代码，而支配-差异性机制确保了种群在目标空间和搜索空间中的多样性，避免了早熟收敛。\\n\\n> **创新点 (Innovations)**\\n> *   **与先前工作的对比：** 现有LLM-based启发式设计方法（如FunSearch和EoH）仅优化单一目标，无法生成多目标权衡的启发式集合。\\n> *   **本文的改进：** MEoH引入多目标优化框架，并通过支配-差异性机制在目标空间（支配关系）和搜索空间（代码差异性）中同时优化，从而生成多样化的非支配启发式。\\n\\n> **具体实现步骤 (Implementation Steps)**\\n> 1.  **种群初始化：** 使用LLM生成初始启发式种群。\\n> 2.  **支配-差异性评分：** 计算每个启发式在目标空间中的支配关系和搜索空间中的代码差异性（基于抽象语法树AST）。\\n> 3.  **父代选择：** 根据支配-差异性评分选择父代启发式。\\n> 4.  **子代生成：** 使用LLM和多种搜索操作符生成子代启发式。\\n> 5.  **种群管理：** 根据支配-差异性评分更新种群，保留高质量且多样化的启发式。\\n> 6.  **终止条件：** 达到最大迭代次数后，输出近似Pareto前沿。\\n\\n> **案例解析 (Case Study)**\\n> *   论文未明确提供此部分信息。\",\n  \"comparative_analysis\": \"### 📊 对比实验分析\\n\\n> **基线模型 (Baselines)**\\n> *   FunSearch（Romera-Paredes et al. 2024）\\n> *   EoH（Liu et al. 2024a）\\n\\n> **性能对比 (Performance Comparison)**\\n> *   **在超体积（Hypervolume, HV）上：** MEoH在装箱问题（BPP）上的HV显著高于EoH，表明其生成的启发式在收敛性和多样性上更优。\\n> *   **在逆世代距离（Inverted Generational Distance, IGD）上：** MEoH在旅行商问题（TSP）上的IGD值低于EoH，说明其生成的启发式更接近参考Pareto前沿。\\n> *   **在运行时间上：** MEoH生成的启发式在BPP和TSP上的运行时间比EoH快高达10倍，同时保持竞争性的最优间隙（optimal gap）。具体数据：在BPP100k实例上，MEoH的运行时间为59.078秒，而EoH为502.938秒；在TSP100实例上，MEoH的运行时间为1.373秒，而EoH为22.434秒。\\n> *   **在分布外泛化性上：** 在BPP的分布外实例（bin容量为500）中，MEoH和EoH的性能显著优于FunSearch，后者在最优间隙上表现大幅下降。具体数据：在BPP5k C500实例上，FunSearch的Gap为29.494%，而MEoH为0.351%。\",\n  \"keywords\": \"### 🔑 关键词\\n\\n*   多目标优化 (Multi-Objective Optimization, MOO)\\n*   启发式设计 (Heuristic Design, N/A)\\n*   大型语言模型 (Large Language Model, LLM)\\n*   进化计算 (Evolutionary Computation, EC)\\n*   装箱问题 (Bin Packing Problem, BPP)\\n*   旅行商问题 (Traveling Salesman Problem, TSP)\\n*   支配-差异性机制 (Dominance-Dissimilarity Mechanism, N/A)\\n*   抽象语法树 (Abstract Syntax Tree, AST)\"\n}\n```"
}