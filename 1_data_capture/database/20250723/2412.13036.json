{
    "source": "Semantic Scholar",
    "arxiv_id": "2412.13036",
    "link": "https://arxiv.org/abs/2412.13036",
    "pdf_link": "https://arxiv.org/pdf/2412.13036.pdf",
    "title": "Open-Set Heterogeneous Domain Adaptation: Theoretical Analysis and Algorithm",
    "authors": [
        "Thai-Hoang Pham",
        "Yuanlong Wang",
        "Changchang Yin",
        "Xueru Zhang",
        "Ping Zhang"
    ],
    "categories": [
        "cs.LG"
    ],
    "publication_date": "2024-12-17",
    "venue": "AAAI Conference on Artificial Intelligence",
    "fields_of_study": [
        "Computer Science"
    ],
    "citation_count": 0,
    "influential_citation_count": 0,
    "institutions": [
        "The Ohio State University"
    ],
    "paper_content": "# Open-Set Heterogeneous Domain Adaptation: Theoretical Analysis and Algorithm\n\nThai-Hoang Pham1,2, Yuanlong Wang1,2, Changchang ${ \\bf Y i n } ^ { 1 , 2 }$ , Xueru Zhang1, Ping Zhang1,2\n\n1Department of Computer Science and Engineering, The Ohio State University, USA 2Department of Biomedical Informatics, The Ohio State University, USA pham.375,wang.16050,yin.731,zhang.12807,zhang.10631 @osu.edu\n\n# Abstract\n\nDomain adaptation (DA) tackles the issue of distribution shift by learning a model from a source domain that generalizes to a target domain. However, most existing DA methods are designed for scenarios where the source and target domain data lie within the same feature space, which limits their applicability in real-world situations. Recently, heterogeneous DA (HeDA) methods have been introduced to address the challenges posed by heterogeneous feature space between source and target domains. Despite their successes, current HeDA techniques fall short when there is a mismatch in both feature and label spaces. To address this, this paper explores a new DA scenario called open-set HeDA (OSHeDA). In OSHeDA, the model must not only handle heterogeneity in feature space but also identify samples belonging to novel classes. To tackle this challenge, we first develop a novel theoretical framework that constructs learning bounds for prediction error on target domain. Guided by this framework, we propose a new DA method called Representation Learning for OSHeDA (RLOSHeDA). This method is designed to simultaneously transfer knowledge between heterogeneous data sources and identify novel classes. Experiments across text, image, and clinical data demonstrate the effectiveness of our algorithm.\n\n# 1 Introduction\n\nMachine learning (ML) techniques have achieved unprecedented success over the past decades in numerous areas (LeCun, Bengio, and Hinton 2015). However, ML systems are often built on the assumption that training and testing data are independent and identically distributed, which is commonly violated in real-world applications where the environment changes during model deployment. Existing works have shown that the performance of ML models often deteriorates due to distribution shifts between training and testing data (Ben-David et al. 2010; Quin˜onero-Candela et al. 2022). To learn a model robust under distribution shifts, domain adaptation (DA) (Ben-David et al. 2010; Mansour, Mohri, and Rostamizadeh 2009) has been proposed to transfer knowledge from a source domain that possesses abundant labeled data to a different but relevant target domain.\n\nExisting DA methods, however, typically assume a homogeneous scenario where the source and target domains have the same feature and label spaces. Consequently, they may fail when the source and target domain data lie in different spaces. For example, heterogeneous feature space is common in biomedical domains in which medical terms undergoes continuous evolution, leading to the retirement of outdated terms (e.g., ICD-9 coding system) and the introduction of novel ones (e.g., ICD-10 coding system) (Grief et al. 2016). In such cases, acquiring training data that seamlessly aligns with target domain’s feature space can be impractical or excessively costly. Heterogeneous domain adaptation (HeDA) methods have emerged to handle the heterogeneity observed in distinct feature spaces, which often vary significantly between domains (Li et al. 2020; Zhao et al. 2022).\n\n![](images/5ad2a020dd902950d3ac10419f66d71ee3337f743e7588128b4b39d3a3bd21fb.jpg)  \nFigure 1: A motivating example about OSHeDA in the context of screening diseases using electrocardiogram (ECG) data. While digital ECGs comprise the majority of labeled data for training ML models for disease screening, physical or paper ECGs remain prevalent worldwide. Thus, the transfer of knowledge from digital ECG datasets is essential to support the training of ML models that analyze paper ECGs. Moreover, ML systems must effectively manage rare abnormalities (indicated with gray boxes), which may not be available in training data, to prevent misdiagnosis.\n\nDespite the significant successes achieved by these HeDA methods, they face a major limitation: current HeDA techniques can only address heterogeneity in feature space and are inadequate when there is a mismatch in both feature and label spaces. This limitation restricts the practical application of HeDA methods in many real-world scenarios because neglecting label mismatch, such as new classes emerging in the target domain, can lead to negative transfer effects from the source to the target domains (Liu et al. 2019).\n\nTo overcome this limitation, this study explores a new DA scenario called open-set heterogeneous domain adaptation (OSHeDA). In OSHeDA, ML methods must not only manage heterogeneity in feature space between source and target domains but also identify samples belonging to novel classes in the target domain. Figure 1 illustrates a real example from clinical applications for this novel learning scenario. In this instance, the adaptation process aims to transfer knowledge from digital electrocardiogram (ECG) to paper ECG formats (heterogeneous). Moreover, ML models for ECG-based diagnosis must also detect rare abnormalities that were not included in the training data (open-set).\n\nTo address the challenge of feature and label mismatch in OSHeDA, we first develop a novel theoretical analysis that constructs learning bounds for the prediction error of ML models on the target domain. Guided by this theoretical analysis, we then design a novel representation learning method named Representation Learning for Open-Set Heterogeneous Domain Adaptation (RL-OSHeDA). This method is proposed to transfer knowledge between heterogeneous data sources and identify novel class simultaneously. Unlike existing HeDA methods, RL-OSHeDA transfer knowledge from source to target domains by aligning representations between source and target domains for known classes while also enforcing the representations of novel class in target domains to move apart from the known classes of the source and target domains. To effectively identify samples from novel class within unlabeled data, RLOSHeDA optimizes a non-negative risk estimator for openset and employs pseudo labeling to enrich the labeled data.\n\nIn summary, the contributions of our work are as follows:\n\n• We conduct a theoretical analysis to establish learning bounds in the OSHeDA scenario. This analysis emphasizes the importance of minimizing the distance between source and target domains for known classes, while maximizing the separation from unknown classes. Moreover, we investigate the impact of pseudo-label and the nonnegative risk estimator for open-set in OSHeDA. • Motivated by the theoretical results, we propose a novel algorithm (RL-OSHeDA) based on representation learning to transfer knowledge from source to target domains. • We conduct experiments on real data from clinical, computer vision, and natural language processing domains to validate the effectiveness of our method for OSHeDA.\n\n2013; Li et al. 2013; Hoffman et al. 2014). In contrast, semisupervised HeDA methods require only a small number of labeled target domain data and utilize unlabeled instances from the target domain to facilitate transfer (Yao et al. 2020; Li et al. 2020; Fang et al. 2022; Zhao et al. 2022; Yao et al. 2019). Finally, unsupervised HeDA methods operate without any labeled target data, relying solely on unlabeled instances and labeled source data to align cross-domain feature representations (Shen and Guo 2018; Li et al. 2018; Zou et al. 2018). However, successful transfer in unsupervised settings depends on specific assumptions about domain relationships (Liu, Zhang, and Lu 2020).\n\nOpen-Set Domain Adaptation (OSDA). OSDA represents a realistic and challenging scenario in DA where the target domain includes instances whose classes are not observed in the source domain, alongside a shift in feature distribution between the two domains. In contrast to the OSHeDA, OSDA assumes a homogeneous feature space between the source and target domains. Existing approaches for OSDA can be categorized into two main groups: adversarial learning and self-supervised learning. Adversarial learning methods employ adversarial networks to detect unknown samples and align the distributions of known samples between the source and target domains (Saito et al. 2018; Luo et al. 2020). On the other hand, self-supervised learning methods utilize techniques like data augmentation to distinguish between known and unknown instances in the target domain (Bucci, Loghmani, and Tommasi 2020; Li et al. 2021). Open-Set Semi-supervised Learning (OS-SSL). OS-SSL is a SSL scenario that addresses novel classes within unlabeled data during training. Unlike OSDA, OS-SSL requires only a small amount of labeled data. However, it assumes that both labeled and unlabeled data of known classes are drawn from the same distribution, and this setting does not account for novel classes during inference. Methods designed for OS-SSL can be broadly categorized into two types based on how they detect novel classes: criterion-based approaches and detector-based approaches. Criterion-based approaches use heuristic rules to identify novel classes (Chen et al. 2020; Huang, Yang, and Gong 2022; Du et al. 2023; He et al. 2022). In contrast, detectorbased approaches employ parameterized detectors to filter outliers (Yu et al. 2020; Huang et al. 2021; Wang et al. 2023; Saito, Kim, and Saenko 2021).\n\n# 3 Problem Formulation\n\n# 2 Related Works\n\nIn this section, we summarize existing research from related areas including heterogeneous domain adaptation, open-set domain adaptation, and open-set semi-supervised learning. Heterogeneous Domain Adaptation (HeDA). HeDA aims to transfer knowledge across domains with distinct feature spaces and data distributions. Depending on whether unlabeled target data are used in the adaptation process, HeDA approaches are categorized into three types: supervised, semi-supervised, and unsupervised methods. Supervised HeDA methods utilize ample labeled data from both source and target domains for adaptation (Hoffman et al.\n\nNotations. Let $\\mathcal { X } ^ { d }$ and ${ \\mathcal { V } } ^ { d }$ denote the feature and label spaces of a domain $d$ associated with a distribution $P _ { d } ( \\dot { X _ { d } } , Y _ { d } ) ~ : ~ \\mathcal { X } ^ { d } \\times \\mathcal { Y } ^ { d } ~  ~ [ 0 , 1 ]$ and labeling function $h _ { d } : \\mathcal { X } ^ { d }  \\Delta ( \\mathcal { Y } ^ { d } )$ where $X _ { d }$ and $Y _ { d }$ are random variables that take values in $\\mathcal { X } ^ { d }$ and $\\mathcal { V } ^ { d }$ , and $\\Delta \\left( \\mathcal { V } ^ { d } \\right)$ is a probability simplex over ${ \\mathcal { V } } ^ { d }$ . Consider a model $h : \\mathcal { X } ^ { d } \\to \\Delta \\left( \\mathcal { Y } ^ { d } \\right)$ , then the expected error of $h$ under domain $d$ for some loss function $\\dot { L } : \\Delta ( \\mathcal { V } ^ { d } ) \\times \\mathcal { V } ^ { d }  \\mathbb { R } _ { + }$ (e.g., 0-1, cross-entropy loss) can be defined as $\\operatorname { E } \\left( P _ { d } , h \\right) = \\mathbb { E } _ { P _ { d } } \\left[ L \\left( h \\left( X _ { d } \\right) , Y _ { d } \\right) \\right]$ .\n\nOpen-Set Heterogeneous Domain Adaptation (OSHeDA) Setup. In DA, we consider $d \\in \\{ s , t \\}$ where $s$ and $t$ denote the source and target domains, respectively. Different from\n\nconventional DA setup where feature and label spaces remain the same between source and target domains, in OSHeDA, we have $\\chi ^ { s } \\neq \\chi ^ { t }$ (heterogeneous) and $\\mathcal { V } ^ { s } \\subset \\mathcal { V } ^ { t }$ (open-set). Because $\\mathcal { V } ^ { s } \\subset \\mathcal { V } ^ { t }$ , we use $Y$ to denote the random variable of label in both source and target domains, and we have $P _ { s } \\left( Y \\in \\mathcal { V } ^ { t } \\backslash \\mathcal { V } ^ { s } \\right) = 0$ . Moreover, classes in the sets $\\mathcal { V } ^ { t } \\backslash \\mathcal { V } ^ { s }$ are referred to as unknown in our setting. Given sets of samples $D _ { s } = \\{ x _ { i } ^ { s } , y _ { i } ^ { s } \\} _ { i = 1 } ^ { n _ { s } } \\stackrel { i . i . d } { \\sim } P _ { s } \\left( X _ { s } , Y \\right)$ (source dataset), Dtl = {xit, yit}in=tl1 i.i∼.d P $D _ { t _ { l } } \\ = \\ \\{ x _ { i } ^ { t } , y _ { i } ^ { t } \\} _ { i = 1 } ^ { n _ { t _ { l } } } \\stackrel { i . i . d } { \\sim } P _ { t } ( X _ { t } , Y | Y \\in \\mathcal { Y } ^ { s } )$ (labeled target dataset), and Dtu = {xit}in=tu1 i.i∼.d Pt (Xt, Y ) (unlabeled target dataset), where $n _ { s } , n _ { t _ { l } } , n _ { t _ { u } }$ are size of datasets and $n _ { t _ { l } } \\ll n _ { s } , n _ { t _ { u } }$ , the goal of OSHeDA is to learn a model $h : \\mathcal { X } ^ { t } \\to \\Delta \\left( \\mathcal { Y } ^ { t } \\right)$ from $D _ { s } , D _ { t _ { l } } , D _ { t _ { u } }$ such that the expected error on the target domain $\\operatorname { E } \\left( P _ { t } , h \\right)$ is small.\n\nRepresentation learning. Representation learning is a common approach for transferring knowledge from a source to a target domain in DA (Zhao et al. 2019; Ganin et al. 2016; Albuquerque et al. 2019; Pham, Zhang, and Zhang 2023), and we will leverage this method in OSHeDA. Specifically, it maps the input spaces $\\mathcal { X } ^ { s }$ and ${  { \\mathcal X } } ^ { t }$ of the source and target domains to a shared representation space $\\mathcal { Z }$ using two representation mappings: $f _ { s } : \\mathcal { X } ^ { s } \\to \\mathcal { Z }$ and $f _ { t } : \\mathcal { X } ^ { \\bar { t } } \\to \\mathcal { Z }$ . A shared classifier $h : \\mathcal { Z } \\to \\Delta ( \\mathcal { V } ^ { t } )$ can then be employed to make predictions from this representation space. Notably, $h$ can be utilized for both domains because $\\mathcal { V } ^ { s } \\subset \\mathcal { V } ^ { t }$ .\n\n# 4 Theoretical Analysis\n\nIn our analysis, we consider Jensen–Shannon (JS) divergence $( \\mathcal { D } _ { J S } )$ as the statistical distance between two domains. While different distances (Ben-David et al. 2010) were used in domain adaptation literature, we adopt JS divergence because it is aligned with the training objective of adversarial learning (Goodfellow et al. 2014), a technique used in many representation learning-based domain adaptation works (Zhao et al. 2019; Ganin et al. 2016; Pham, Zhang, and Zhang 2023). Next, we present the main theorems, with detailed proofs provided in Appendix A.\n\n# 4.1 Learning bounds for OSHeDA (infinite case)\n\nTo simplify notations used in our following analysis, we denote $P _ { t , k } ( \\cdot ) = P _ { t } ( \\cdot | Y \\in \\mathcal { V } ^ { s } )$ and $P _ { t , u } ( \\cdot ) = P _ { t } ( \\cdot | Y \\notin \\mathcal { V } ^ { s } )$ as the distributions of target domain conditioned on known and unknown classes, respectively. We also introduce two distributions $P _ { s } ^ { u }$ and $P _ { t } ^ { u }$ induced from $P _ { s }$ and $P _ { t }$ by the two mappings $f _ { s } ^ { u }$ and $f _ { t } ^ { u }$ such that $f _ { s } ^ { u } ( X ^ { s } , Y ) \\ = \\ ( X ^ { s } , u n k )$ and $f _ { t } ^ { u } ( X ^ { t } , Y ) = ( X ^ { t } , u n k )$ where unk denotes unknown class. In addition, we adopt an assumption commonly used in DA literature (Nguyen et al. 2021; Mansour, Mohri, and Rostamizadeh 2009; Cortes and Mohri 2014) as follows.\n\nAssumption 1 (Bounded loss) Assume loss function $L$ defined on input space $\\chi$ and output space $y$ is upper bounded by a constant $C$ , i.e., $\\forall x \\in \\mathcal { X } , y \\in \\mathcal { X }$ , $h \\in { \\mathcal { H } }$ , we have $\\dot { L } ( h ( x ) , y ) \\leq C$ .\n\nWe note that this assumption is indeed reasonable rather than stringent. For example, while Assumption 1 does not hold for the cross-entropy loss typically utilized in classification, we can adjust this loss to ensure that it satisfies Assumption 1 (Pham, Zhang, and Zhang 2024). Based on this assumption, we then provide an upper bound for prediction error on the target domain in OSHeDA as follows.\n\nTheorem 1 Given a loss function $L$ satisfying Assumption $\\boldsymbol { { I } }$ , then for any $h \\in { \\mathcal { H } }$ , $f _ { s } \\in \\mathcal { F } _ { s } , f _ { t } \\in \\mathcal { F } _ { t }$ , we have:\n\n$$\n\\begin{array} { r l } & { \\mathrm { E } \\left( P _ { t } , h \\circ f _ { t } \\right) \\leq \\underbrace { \\lambda \\mathrm { E } \\left( P _ { s } , h \\circ f _ { s } \\right) } _ { s o u r e e r o r r } } \\\\ & { \\qquad + \\underbrace { \\mathrm { E } \\left( P _ { t } ^ { u } , h \\circ f _ { t } \\right) } _ { o p e n - s e t i f i f e r n e c e } \\lambda \\mathrm { E } \\left( P _ { s } ^ { u } , h \\circ f _ { s } \\right) } \\\\ & { \\qquad + \\sqrt { 2 } \\lambda C \\left( ( \\mathscr { D } _ { J S } \\left( P _ { s } ( Z ) \\parallel P _ { t , k } ( Z ) \\right) ) ^ { \\frac { 1 } { 2 } } \\right. } \\\\ & { \\qquad \\left. + ( \\mathscr { D } _ { J S } \\left( P _ { s } ( Z , Y ) \\parallel P _ { t , k } ( Z , Y ) \\right) ) ^ { \\frac { 1 } { 2 } } \\right) } \\\\ & { \\qquad \\underbrace { d \\circ m a n d i f i e n c e } _ { d o m a n d i f i e n e c e } } \\end{array}\n$$\n\nwhere $\\lambda = P _ { t } ( Y \\in \\mathcal { V } ^ { s } )$ , $\\mathcal { H }$ , $\\mathcal { F } _ { s }$ , $\\mathcal { F } _ { t }$ are hypothesis classes for $h , f _ { s } , f _ { t }$ , and $P _ { s } ( Z )$ and $P _ { t , k } ( Z )$ are the distributions induced from $P _ { s } ( X _ { s } )$ and $P _ { t , k } ( X _ { t } )$ by $f _ { s }$ and $f _ { t }$ , respectively.\n\nRemark 1 The upper bound in Theorem $\\boldsymbol { { l } }$ shed a light on achieving good accuracy on target domain. Specifically, to minimize $\\operatorname { E } \\left( P _ { t } , h \\circ f _ { t } \\right)$ , the model need to optimize three terms: (i) the source error $\\mathrm { E } \\left( P _ { s } , h \\circ f _ { s } \\right)$ , (ii) the open-set difference $\\mathrm { ~ E ~ } ( P _ { t } ^ { u } , h \\circ f _ { t } ) \\ : - \\ : \\lambda \\mathrm { E } \\left( P _ { s } ^ { u } , h \\circ f _ { s } \\right)$ , and (iii) the distances of marginal and joint distributions between source domain and target domain conditioned on known labels $\\mathcal { D } _ { J S } \\left( P _ { s } ( Z ) \\parallel P _ { t , k } ( Z ) \\right)$ and ${ \\mathcal D } _ { J S } \\left( P _ { s } ( Z , Y ) \\parallel P _ { t , k } ( Z , Y ) \\right)$ .\n\nWe want to emphasize that minimizing the distance of the joint distribution between the source and target domains, $\\mathsf { \\tilde { D } } _ { J S } \\left( P _ { s } ( Z , Y ) \\parallel P _ { t , k } ( Z , Y ) \\right)$ , requires knowledge of the label distribution in the target domain $P _ { t , k } ( Y )$ . Therefore, access to labeled target data during training is essential to avoid negative transfer. Note that the concept of open-set difference is not exclusive to OSHeDA. This term also appears in existing works for OSDA (Fang et al. 2020) and positive-unlabeled learning (Kiryo et al. 2017) which are special cases of our setting. Thus, this demonstrates the consistency between our work and the existing literature. Next, we present a lower bound for OSHeDA.\n\nProposition 1 Given a loss function $L$ satisfying Assumption $\\jmath$ , then for any $h \\in { \\mathcal { H } }$ , $f _ { s } \\in \\mathcal { F } _ { s } , f _ { t } \\in \\mathcal { F } _ { t }$ , we have:\n\n$$\n\\begin{array} { r } { \\mathrm { E } \\left( P _ { t } , h \\circ f _ { t } \\right) \\geq \\lambda \\mathrm { E } \\left( P _ { t , k } , h \\circ f _ { t } \\right) + ( 1 - \\lambda ) \\mathrm { E } \\left( P _ { s } ^ { u } , h \\circ f _ { s } \\right) } \\\\ { - \\sqrt { 2 } ( 1 - \\lambda ) C \\left( \\mathscr { D } _ { J S } \\left( P _ { s } ( Z ) \\parallel P _ { t , u } ( Z ) \\right) \\right) ^ { \\frac { 1 } { 2 } } } \\end{array}\n$$\n\nwhere $P _ { t , u } ( Z )$ is distribution induced from $P _ { t , u } ( X _ { t } )$ by $f _ { t }$ .\n\nRemark 2 Theorem $\\boldsymbol { { \\mathit { 1 } } }$ shows the necessity of reducing $\\mathrm { E } \\left( P _ { s } , h \\circ f _ { s } \\right)$ to achieve high accuracy on target domain. However, it may unavoidably increase $\\operatorname { E } \\left( P _ { s } ^ { u } , h \\circ f _ { s } \\right)$ . This observation, combined with Proposition $^ { l }$ , suggests that to avoid the large lower bound for the target error $\\operatorname { E } \\left( P _ { t } , h \\circ f _ { t } \\right)$ , we should increase the distance of the marginal distribution between the source domain and the unknown data in target domain, $\\mathcal { D } _ { J S } \\left( P _ { s } ( Z ) \\parallel P _ { t , u } ( Z ) \\right)$ . In other words, we should segregate the representations of known classes from those of unknown class.\n\n# 4.2 Learning bound for OSHeDA (finite case)\n\nThe learning bounds discussed in Section 4.1 are only applicable for the setting when we have access to unlimited data from source and target domains. In such cases, minimizing JS divergence of data distribution between these domains is equivalent to achieving invariant representations through adversarial learning (Goodfellow et al. 2014). However, we only work with finite data in practice. Thus, we present the following result, which provides a guarantee for using adversarial learning to optimize JS divergence from finite data.\n\nProposition 2 (Adapted from Biau et al. (2020)) The error in minimizing $J S$ divergence of data distributions between source and target domains in representation space, using finite data, is up to $\\mathcal { O } \\left( \\left( 1 / \\sqrt { n _ { s } } + \\mathrm { \\bar { 1 } } / \\sqrt { n _ { t } } \\right) \\right)$ .\n\nwhere $n _ { s }$ and $n _ { t }$ are the size of source and target datasets.\n\nRemark 3 Proposition 2 states that the performance of minimizing JS divergence from finite data is proportional to the dataset size. Note that in OSHeDA, we only have access to limited label data from target domain which then results in significant error in estimating $J S$ divergence only from labeled source and target data. In essence, this result underscores the need for the development of an effective approach to utilize unlabeled target data for estimating the JS divergence, which involves techniques like pseudo-labeling.\n\nTherefore, we apply pseudo-labeling on unlabeled data to enrich labeled target data. Let $g$ be pseudo-label model and denote $\\mathrm { N } ( P _ { t , k } , g ) = \\mathbb { E } \\left[ \\mathcal { D } _ { J S } \\left( P _ { t , k } ( g ( Z ) ) \\parallel P _ { t , k } ( Y | Z ) \\right) \\right]$ as the noise of $g$ with respect to the target domain conditioned on known labels. Then, the impact of pseudo-labeled data can be illustrated in a new bound for OSHeDA as follows.\n\nTheorem 2 Given a loss function $L$ satisfying Assumption $^ { \\small 1 }$ , for any $0 < \\delta < 1$ , with probability at least $1 - \\delta$ , the following holds for all $h \\in \\mathcal { H } , f _ { s } \\in \\mathcal { F } _ { s } , f _ { t } \\in \\mathcal { F } _ { t }$ :\n\n$$\n\\begin{array} { r l } & { \\mathbf { E } ( P _ { t } , h \\circ f _ { t } ) \\leq \\lambda \\hat { \\mathbf { E } } ( P _ { s } , h \\circ f _ { s } ) + \\hat { \\mathbf { E } } ( P _ { t } ^ { a } , h \\circ f _ { t } ) } \\\\ & { - \\lambda \\hat { \\mathbf { E } } \\left( P _ { s } ^ { n } , h \\circ f _ { s } \\right) + \\sqrt { 2 } \\lambda C \\left( ( \\mathcal { D } _ { J S } \\left( P _ { s } ( Z ) \\parallel P _ { t , k } ( Z ) \\right) ) ^ { \\frac { 1 } { 2 } } \\right. } \\\\ & { \\left. + ( \\mathcal { D } _ { J S } \\left( P _ { s } ( Z , Y ) \\parallel P _ { t , k } ( Z , g ( Z ) ) \\right) ) ^ { \\frac { 1 } { 2 } } + ( \\mathrm { N } ( P _ { t , k } , g ) ) ^ { \\frac { 1 } { 2 } } \\right) } \\\\ & { + \\mathcal { O } \\left( \\lambda C \\sqrt { \\frac { d _ { s } \\log n _ { s } + d _ { s } \\log | y | + \\log \\frac { 1 } { \\delta } } { n _ { s } } } \\right. } \\\\ & { \\left. + C \\sqrt { \\frac { d _ { t } \\log n _ { t } + d _ { t } \\log | y | + \\log \\frac { 1 } { \\delta } } { n _ { t } } } \\right) } \\end{array}\n$$\n\nwhere $\\widehat { \\mathrm { E } } { ( P _ { s } , h \\circ f _ { s } ) } , \\widehat { \\mathrm { E } } { ( P _ { t } ^ { u } , h \\circ f _ { t } ) } , \\widehat { \\mathrm { E } } { ( P _ { s } ^ { u } , h \\circ f _ { s } ) }$ are empirica berrors calculatbed on samples bfrom distributions $P _ { s }$ , $P _ { t } ^ { u }$ , $P _ { s } ^ { u }$ , $n _ { t } = n _ { t _ { l } } + n _ { t _ { u } }$ , and $d _ { s }$ , $d _ { t }$ are Natarajan dimension (Natarajan 1989) of hypothesis classes $\\mathcal { H } \\circ \\mathcal { F } _ { s } , \\mathcal { H } \\circ \\mathcal { F } _ { t }$ .\n\nTheorem 2 shows that the error in the target domain depends on the quality of the pseudo-label model $g$ , with higherquality $g$ being more effective at reducing noise. Additionally, the bound emphasizes the importance of aligning the joint distributions between the source and target domains in OSHeDA. This makes OSHeDA more challenging compared to homogeneous DA (HoDA), where source and target data lie on the same space. In contrast, HoDA methods can attain good performance under certain conditions by solely aligning the marginal distributions of representations between source and target domains. We will illustrate this contrast through the bound for HoDA in Section 4.3.\n\n# 4.3 Learning bound for HoDA\n\nBefore constructing the learning bound for HoDA, we introduce an assumption about the representation $Z$ as follows.\n\nAssumption 2 (Sufficient representation) Let $I _ { s } ( \\cdot , \\cdot )$ be the mutual information between two random variables in the source domain. We assume $I _ { s } ( Z , Y ) = I _ { s } ( X _ { s } , Y )$ . In particular, $I _ { s } ( Z , Y ) = \\mathcal { D } _ { K L } \\left( P _ { s } ( Z , Y ) \\parallel P _ { s } ( Z ) \\otimes P _ { s } ( Y ) \\right)$ and $\\begin{array} { r l r } { I _ { s } ( X _ { s } , Y ) } & { { } = } & { { \\mathcal D } _ { K L } \\left( P _ { s } ( X _ { s } , Y ) \\parallel P _ { s } ( X _ { s } ) \\otimes P _ { s } ( Y ) \\right) } \\end{array}$ where $D _ { K L }$ is $K L$ divergence between two distributions.\n\nNote that Assumption 2 is reasonable because we have access to labeled data of source domain and the dimension of $y$ is often smaller than that of $\\mathcal { Z }$ . Based on this, we establish the learning bound in HoDA under the covariate shift below.\n\nProposition 3 Suppose Assumptions $^ { l }$ and 2 hold and the distribution shift between source and target domains is covariate shift (i.e., $P _ { s } ( X ) \\neq P _ { t } ( X ) , P _ { s } ( Y | X ) = P _ { t } ( Y | X ) )$ , then for any $h \\in { \\mathcal { H } }$ and $f \\in { \\mathcal { F } }$ , we have:\n\n$$\n\\mathrm { E } \\left( P _ { t } , h \\circ f \\right) \\leq \\mathrm { E } \\left( P _ { s } , h \\circ f \\right) + \\sqrt { 2 } C \\left( \\mathcal { D } _ { J S } \\left( P _ { s } ( Z ) \\parallel P _ { t } ( Z ) \\right) \\right) ^ { \\frac { 1 } { 2 } }\n$$\n\nIn HoDA, due to the homogeneity of the input space, we can utilize a single representation mapping $f$ for both the source and target domains. Note that the bound in Proposition 3 depends solely on the distance of the marginal distributions between the source and target domains, $\\bar { \\mathcal { D } } _ { J S } \\left( P _ { s } ( Z ) \\parallel P _ { t } ( Z ) \\right)$ , which can be effectively minimized even without access to labeled data in the target domain. Clearly, covariate shift assumption is only reasonable in HoDA, where the source and target data share the same feature and label spaces.\n\n# 5 Methodology\n\nMotivated by theoretical results presented in Section 4, we introduce RL-OSHeDA, a representation learning method specifically designed for OSHeDA. Our method aims to simultaneously optimize both the upper bound in Theorem 2 and the lower bound in Proposition 1. RL-OSHeDA features two distinct representation mappings, $f _ { s }$ and $f _ { t }$ , which map heterogeneous source and target feature spaces to a shared representation space, along with a classifier $h$ that makes predictions based on these representations. Figure 2 presents the overall architecture of RL-OSHeDA, while pseudo code describing training process can be found in Appendix B.2.\n\n# 5.1 Objective function\n\nTo improve predictive performance in OSHeDA, our method targets the following: (i) minimizing prediction errors on both source and labeled target data, (ii) minimizing the distances of marginal and label-conditioned representation distributions for known classes between source and target\n\nμ μ Lunk . □ Representations of NORM Linv Eq. (3) i △ ○口 known classes   \nH STTC fs ☆△○□ Losd △  Per-n centrods f Eq. (5) Representations and centroid ！ > X CD of unknown class Representation Space $h$ Lcls ★☆ Centroids of known classes Eq. (2) Ground-truth label :NORM □ △ Lsgg Eq. (4) Pseudo-label   \nft k 始 A会 S iunk Unknown label ☆ g /STTCT: O! ！◇ 公 μu ☆ $\\boxed { h }$ Represention mapings Lunk/: μt,k μk [g] Pseudo-label model\n\ndata, (iii) maximizing the distances of marginal representation distributions between known and unknown classes, and (iv) minimizing the open-set difference. Specifically, RLOSHeDA optimizes the following objective function:\n\n$$\nL = L _ { c l s } + L _ { i n v } - L _ { s e g } + L _ { o s d }\n$$\n\nwhere $L _ { c l s }$ is the classification error computed from source and labeled target datasets $D _ { s }$ and $D _ { t _ { l } }$ , defined as follows:\n\n$$\nL _ { c l s } = \\frac { \\lambda } { n _ { s } } \\sum _ { i = 1 } ^ { n _ { s } } \\mathrm { C E } \\left( h \\left( f _ { s } \\left( x _ { i } ^ { s } \\right) \\right) , y _ { i } ^ { s } \\right) + \\frac { 1 } { n _ { t _ { l } } } \\sum _ { i = 1 } ^ { n _ { t _ { l } } } \\mathrm { C E } \\left( h \\left( f _ { t } \\left( x _ { i } ^ { t } \\right) \\right) , y _ { i } ^ { t } \\right)\n$$\n\nHere CE is the cross-entropy loss.\n\n${ { L } _ { i n v } }$ denotes the distances of marginal and labelconditioned representation distributions for known classes between source and target datasets. Note that, we minimize the distance of the label-conditioned representation distribution $P ( Z | Y )$ , rather than the joint distribution $P ( Z , Y )$ , as noted by Pham, Zhang, and Zhang (2023). As shown in Proposition 2, $L _ { i n v }$ can be defined based on JS divergence and minimized through adversarial learning. However, the number of discriminators required for this approach scales linearly with the number of classes, leading to instability in training when the dataset has a large number of classes. To address this issue, we implement $L _ { i n v }$ using maximum mean discrepancy (MMD) defined as follows:\n\n$$\nL _ { i n v } = \\left\\| \\mu _ { s } - \\mu _ { t , k } \\right\\| _ { 2 } ^ { 2 } + \\sum _ { m = 1 } ^ { | \\mathcal { V } ^ { s } | } \\left\\| \\mu _ { s } ^ { m } - \\mu _ { t , k } ^ { m } \\right\\| _ { 2 } ^ { 2 }\n$$\n\nwhere $\\mu _ { s }$ (resp. $\\mu _ { t , k }$ ) is centroid of representations from source data (resp. target data belonging to known classes), and $\\mu _ { s } ^ { m }$ (resp. $\\mu _ { t , k } ^ { m } )$ is centroid of representations from source data (resp. target data) belonging to known class $m$ . Note that $\\mu _ { t , k }$ and $\\mu _ { t , k } ^ { m }$ are computed using both instances with ground-truth labels from labeled target data and those with high-quality pseudo-labels (see Section 5.2) from unlabeled target data to provide a more accurate estimation.\n\n$L _ { s e g }$ is the distances between marginal representation distributions of known and unknown classes. Similarly, we implement $L _ { s e g }$ with MMD as follows:\n\n$$\nL _ { s e g } = \\| \\mu _ { k } - \\mu _ { u } \\| _ { 2 } ^ { 2 }\n$$\n\nwhere $\\mu _ { k }$ (resp. $\\mu _ { u . }$ ) are centroids of representations from both source and target datasets belonging to ground-truth and pseudo known (resp. unknown) classes.\n\n$L _ { o s d }$ represents the open-set difference, as detailed in Theorem 2. The optimal value for the open-set difference is 0. However, due to the flexibility of deep neural networks, this term can become excessively negative during training and adversely affect model performance. To address this issue, we implement $L _ { o s d }$ as a non-negative risk estimator:\n\n$$\nL _ { o s d } = \\operatorname* { m a x } \\left( 0 , \\frac { 1 } { n _ { t } } \\sum _ { i = 1 } ^ { n _ { t } } \\mathrm { C E } \\left( h \\left( f _ { t } \\left( x _ { i } ^ { t } \\right) \\right) , u n k \\right) - \\frac { \\lambda } { n _ { s } } \\sum _ { i = 1 } ^ { n _ { s } } \\mathrm { C E } \\left( h \\left( f _ { s } \\left( x _ { i } ^ { s } \\right) \\right) , u n k \\right) \\right)\n$$\n\nwhere $n _ { t } = n _ { t _ { l } } + n _ { t _ { u } }$ is the size of the target dataset.\n\n# 5.2 Pseudo-labeling using 2-stage learning\n\nThe accuracy of ${ \\cal L } _ { i n v }$ and $L _ { s e g }$ highly depends on the quality of pseudo-labels. Traditionally, the pseudo-label model $g$ is derived by modifying the classifier $h$ (e.g., using hard labels calculated from $h$ ’s outputs as pseudo-labels), which creates a coupling between $g$ and $h$ . Specifically, $g$ is defined as $a \\circ h$ , where $a$ is an operator applied to the output of $h$ (e.g., $a : =$ arg max). When the distributions of the source and target domains are well-aligned, this coupling is harmless, as the optimal solution for $g$ also aligns with that for $h$ . However, at the beginning of the training process, when the distributions of the source and target domains are not aligned, $g$ and $h$ have completely different objective functions, resulting in a trade-off between them. To address this issue, we propose a 2-stage learning approach as follows:\n\n• Stage 1 (epoch $< T$ ): Update $f _ { s } , f _ { t } , h$ using $L _ { c l s }$ .   \n• Stage 2 (epoch $\\geq T$ ): Update $f _ { s } , f _ { t } , h$ using $L$ .\n\n<html><body><table><tr><td rowspan=\"2\"></td><td colspan=\"3\">CIFAR10&ILSVRC2012</td><td colspan=\"3\">ImageCLEF-DA</td><td colspan=\"3\">Multilingual Reuters Collection</td><td colspan=\"3\">NUSWIDE&ImageNet</td></tr><tr><td>HOS</td><td>OS*</td><td>UNK</td><td>HOS</td><td>OS*</td><td>UNK</td><td>HOS</td><td>OS*</td><td>UNK</td><td>HOS</td><td>OS*</td><td>UNK</td></tr><tr><td>DS3L</td><td>61.49±0.74</td><td>59.04±1.00</td><td>64.40±1.06</td><td>58.62±2.04</td><td>52.87±2.70</td><td>66.74±2.77</td><td>59.35±0.94</td><td>52.92±1.27</td><td>67.57±1.24</td><td>67.61±1.65</td><td>66.17±2.22</td><td>69.20±2.30</td></tr><tr><td>KPG</td><td>57.27±0.50</td><td>54.73±0.00</td><td>60.30±1.11</td><td>40.68±0.94</td><td>34.60±0.00</td><td>50.79±2.91</td><td>11.27±0.07</td><td>8.59±0.00</td><td>17.04±0.96</td><td>55.18±1.17</td><td>52.60±0.00</td><td>58.10±2.45</td></tr><tr><td>OPDA</td><td>53.30±0.77</td><td>48.22±1.00</td><td>60.26±1.11</td><td>53.17±1.83</td><td>45.28±2.13</td><td>65.76±2.76</td><td>55.85±0.96</td><td>48.47±1.23</td><td>65.94±1.23</td><td>71.06±1.44</td><td>66.60±1.98</td><td>76.38±2.09</td></tr><tr><td>PL</td><td>42.75±0.52</td><td>37.12±0.49</td><td>52.31±1.10</td><td>39.20±1.62</td><td>31.93±1.66</td><td>54.34±2.91</td><td>42.85±0.81</td><td>34.56±1.00</td><td>57.86±1.29</td><td>42.43±0.26</td><td>34.05±0.00</td><td>61.15±2.10</td></tr><tr><td>SCT</td><td>59.61±0.75</td><td>57.35±1.00</td><td>62.33±1.08</td><td>58.76±2.05</td><td>53.09±2.71</td><td>66.71±2.76</td><td>61.17±0.94</td><td>54.96±1.30</td><td>69.00±1.21</td><td>70.42±1.49</td><td>68.00±2.20</td><td>73.10±1.99</td></tr><tr><td>SSAN</td><td>60.38±0.73</td><td>59.01±1.00</td><td>62.01±1.08</td><td>58.61±2.05</td><td>53.18±2.74</td><td>66.14±2.74</td><td>58.25±0.93</td><td>51.99±1.25</td><td>66.26±1.24</td><td>67.98±1.49</td><td>66.25±2.04</td><td>69.85±2.21</td></tr><tr><td>STN</td><td>61.59±0.72</td><td>58.80±0.98</td><td>64.87±1.05</td><td>56.25±2.06</td><td>49.80±2.69</td><td>65.84±2.76</td><td>59.21±0.96</td><td>52.91±1.31</td><td>67.24±1.23</td><td>67.75±1.23</td><td>64.80±1.42</td><td>71.08±2.16</td></tr><tr><td>SL</td><td>60.74±0.74</td><td>58.29±1.00</td><td>63.67±1.08</td><td>58.59±2.05</td><td>52.84±2.70</td><td>66.71±2.76</td><td>58.53±0.96</td><td>52.14±1.32</td><td>66.74±1.21</td><td>69.41±1.64</td><td>66.63±2.26</td><td>72.57±2.23</td></tr><tr><td>RL-OSHeDA</td><td>72.33±0.70</td><td>67.88±0.98</td><td>77.81±0.97</td><td>63.98±2.04</td><td>56.63±2.72</td><td>74.80±2.51</td><td>65.39±0.91</td><td>54.47±1.21</td><td>81.97±0.96</td><td>80.01±1.30</td><td>74.65±2.01</td><td>86.35±0.81</td></tr><tr><td></td><td colspan=\"3\">Office&Caltech256</td><td colspan=\"3\">Wikipedia</td><td colspan=\"3\">PTB-XL</td><td colspan=\"3\">Average over datasets</td></tr><tr><td></td><td>HOS</td><td>OS*</td><td>UNK</td><td>HOS</td><td>Os*</td><td>UNK</td><td>HOS</td><td>OS*</td><td>UNK</td><td>HOS</td><td>OS*</td><td>UNK</td></tr><tr><td>DS3L</td><td>72.06±2.48</td><td>67.41±3.68</td><td>78.15±2.89</td><td>56.00±2.01</td><td>50.72±2.36</td><td>66.24±2.80</td><td>30.30±1.19</td><td>34.95±0.58</td><td>26.74±1.82</td><td>57.92±1.58</td><td>54.87±1.97</td><td>62.72±2.12</td></tr><tr><td>KPG</td><td>34.46±0.99</td><td>29.18±0.00</td><td>45.34±3.58</td><td>24.82±0.42</td><td>16.40±0.00</td><td>52.52±3.18</td><td>N/A</td><td>N/A</td><td>N/A</td><td>37.28±0.68</td><td>32.68±0.00</td><td>47.35±2.36</td></tr><tr><td></td><td>65.23±2.58</td><td>57.70±3.43</td><td>76.23±3.03</td><td>52.66±1.92</td><td>45.94±1.81</td><td>65.42±3.12</td><td>31.47±1.22</td><td>36.35±0.63</td><td>27.74±1.86</td><td>54.67±1.53</td><td>49.79±1.74</td><td>62.53±2.17</td></tr><tr><td>OPDA</td><td>48.92±1.36</td><td>40.38±1.13</td><td>68.41±3.40</td><td>41.87±1.65</td><td>35.14±1.48</td><td>58.40±3.10</td><td>26.18±1.37</td><td>36.43±0.55</td><td>20.43±1.66</td><td>40.60±1.08</td><td>35.66±0.90</td><td>53.27±2.22</td></tr><tr><td>PL</td><td>75.72±2.14</td><td>71.05±3.20</td><td>81.79±2.54</td><td>58.41±2.01</td><td>52.86±2.39</td><td>68.42±2.74</td><td>26.23±1.65</td><td>46.48±1.71</td><td>18.27±1.60</td><td>59.89±1.58</td><td>57.10±1.93</td><td>64.49±1.99</td></tr><tr><td>SCT</td><td>72.95±2.36</td><td>67.99±3.37</td><td>79.67±2.88</td><td>58.37±1.76</td><td>52.76±1.95</td><td>68.36±2.80</td><td>25.16±1.47</td><td>40.40±0.65</td><td>18.27±1.54</td><td>57.39±1.54</td><td>55.94±1.86</td><td>61.51±2.07</td></tr><tr><td>SSAN STN</td><td>72.26±2.28</td><td>66.46±3.30</td><td>79.84±2.75</td><td>57.75±1.91</td><td>51.40±2.13</td><td>69.00±2.97</td><td>27.08±0.96</td><td>22.63±0.26</td><td>33.72±1.65</td><td>57.41±1.45</td><td>52.40±1.73</td><td>64.51±2.08</td></tr><tr><td>SL</td><td>72.14±2.54</td><td>67.72±3.75</td><td>77.89±2.96</td><td>57.10±1.97</td><td>51.60±2.19</td><td>67.04±2.76</td><td>25.74±1.55</td><td>44.50±0.76</td><td>18.11±1.52</td><td>57.46±1.64</td><td>56.24±2.00</td><td>61.82±2.08</td></tr><tr><td>RL-OSHeDA</td><td>78.18±2.05</td><td>73.04±2.91</td><td>85.25±2.50</td><td>63.10±1.89</td><td>57.26±2.45</td><td>73.04±2.37</td><td>47.48±1.25</td><td>44.30±1.39</td><td>51.16±1.86</td><td>67.21±1.45</td><td>61.18±1.95</td><td>75.77±1.71</td></tr></table></body></html>\n\nTable 1: Prediction performances (HOS, $O S ^ { * }$ , $U N K )$ of RL-OSHeDA and baselines for OSHeDA scenario on 7 datasets. We report average results over 10 random seeds for each dataset.\n\nwhere $T$ is a threshold indicating when to switch from stage 1 to stage 2. In stage 1, optimizing $L _ { c l s }$ partially aligns the source and target domains, thereby reducing the trade-off between $g$ and $h$ during the optimization of $L$ in stage 2. Additionally, rather than simply using the hard labels with the largest logits from $h$ as the output of $g$ , we propose generating pseudo-labels as follows:\n\n• First, select pseudo-labels as $g ( x ^ { t } ) ~ = ~ a ^ { \\prime } ( h ( f _ { t } ( x ^ { t } ) ) )$ where $a ^ { \\prime }$ is arg max operator applied to the logits of the known classes only. • Then, select $1 - \\lambda$ fraction of instances with the smallest maximum logits and assign pseudo-labels unk to them.\n\nThe motivation behind this design of the pseudo-label model $g$ is that, at the beginning of stage 2, there is no supervision signal for training the parameters of $h$ related to unknown class. Therefore, relying solely on logits to determine the unknown class is unreliable. Note that this strategy is only used to generate pseudo-labels during the training of stage 2. Once training is complete and $h$ ’s parameters for unknown class are well-trained by optimizing $L _ { o s d }$ , we can simply use arg max across all classes to generate predictions.\n\n# 6 Experiments\n\nNext, we empirically evaluate the performance of our methods across clinical, computer vision, and natural language processing applications. We focus on the OsHeDA scenario, characterized by heterogeneity in the feature space between the source and target domains, with the label space of the target domain encompassing both known and unknown classes.\n\n# 6.1 Experimental setup\n\nDatasets. We conduct our experiments on 7 datasets including CIFAR10 (Krizhevsky 2009) & ILSVRC2012 (Russakovsky et al. 2015); Wikipedia (Rasiwasia et al. 2010); Multilingual Reuters Collection (Amini, Usunier, and Goutte 2009); NUSWIDE (Chua et al. 2009) & ImageNet (Deng et al. 2009); Office (Saenko et al. 2010) & Caltech256 (Griffin et al. 2007); ImageCLEF-DA (Griffin et al.\n\n2007); PTB-XL (Wagner et al. 2020). These datasets results in 56 DA tasks. Detailed descriptions and statistics of these datasets are provided in Appendix C.1.\n\nBaselines. We compare our method with several representative methods from HeDA (SSAN (Li et al. 2020), STN (Yao et al. 2019), SCT (Zhao et al. 2022), KPG (Gu et al. 2022)), OSDA (OPDA (Saito et al. 2018)), and OS-SSL (DS3L (Guo et al. 2020)) literature. For the HeDA methods, they are trained on both source and target data. In contrast, OSDA and OS-SSL methods are trained only on target data as they cannot handle heterogeneous feature spaces. During inference, HeDA and OS-SSL methods classify instances as unk using the same method as our pseudo-label model $g$ (see Section 5.2). Additionally, we explore supervised learning (SL) and pseudo-labeling (PL) methods trained on target data. Among all baselines, only KPG is designed to handle OSHeDA by combining Gromov-Wasserstein distance and partial optimal transport $\\mathrm { \\Delta X u }$ et al. 2020). Since $\\lambda$ is a required input for most methods in our experiments, we utilize techniques from positive-unlabeled learning (Zeiberg, Jain, and Radivojac 2020) to estimate $\\lambda$ . Detailed architectures of our model and the baselines are in Appendix B.1.\n\nEvaluation method. We utilize $H O S$ , the harmonic mean of $O S ^ { * }$ and $U N K$ (Bucci, Loghmani, and Tommasi 2020). $O S ^ { * }$ is the class-wise averaged accuracy of known classes, while $U N K$ measures the accuracy for the unknown class. $H O S$ is particularly suitable for OSHeDA because it emphasizes the ability to both correctly classify known classes and detect out-of-distribution instances simultaneously. In particular, this metric increases when the performance in both known and unknown classifications is high.\n\n# 6.2 Experimental results\n\nOSHeDA benchmark. The prediction performance $( H O S )$ of RL-OSHeDA and the baselines is summarized in Table 1. RL-OSHeDA consistently outperforms all baselines across all datasets, demonstrating its effectiveness in simultaneously addressing heterogeneity in the feature space and open-set in the label space during training. Among the baselines, KPG is specifically designed for OSHeDA by using optimal transport. Then, SVM trained on transported source and labeled target data is used to make prediction. However, this method underperforms in our evaluation due to its difficulty in correctly transporting from source to target data. Moreover, this method is not applicable for complex data structures, such as those found in PTB-XL dataset. Other baselines achieve better prediction performances, but their $H O S$ remains suboptimal due to their inability to handle novel classes or heterogeneous source data during training.\n\n![](images/1393c706656de9e5c8a5beab83e3a3c389d440a1145bdaad020e07ac1164130e.jpg)  \nFigure 3: Performances w.r.t. different number of labeled target instances per class on CIFAR10 & ILSVRC2012 dataset.\n\n![](images/efa1fddd0ff2b83240df7ed46968f7b035312f486f3e6bc9b649de80442ac3d7.jpg)  \nFigure 4: Visualization of representation spaces learned by RL-OSHeDA and STN for NUSWIDE & ImageNet dataset. Different colors represent different classes, with the unknown class denoted in grey.\n\nTo further validate the superiority of RL-OSHeDA across all datasets, we conduct significance testing, including Friedman test followed by Nemenyi test (Demsˇar 2006). The results (see Appendix C.4) show that our method significantly outperforms the baselines, with P-values $< 0 . 0 5$ . Among all the baselines, SCT, SSAN, STN, SL, and DS3L exhibit better prediction performances than KPG, OPDA, and PL. Note that all methods, except OPDA and KPG, utilize our approach to detect the unknown class based on logits of known classes. This result suggests that while this approach can partially address the open-set issue, it cannot fully resolve it. For OPDA, although it is designed to handle open-set issue, its inability to leverage heterogeneous source data limits its performance to adapting with only a small labeled target dataset, resulting in suboptimal performance.\n\nTable 2: Ablation study for RL-OSHeDA on Multilingual Reuters Collection dataset. Align refers to using $L _ { i n v }$ ; Segregate refers to using $L _ { s e g }$ ; OSD refers to using $L _ { o s d }$ ; 2- stage refers to using 2-stage learning approach.   \n\n<html><body><table><tr><td>Align</td><td>Segregate</td><td>OSD</td><td>2-stage</td><td>HOS</td><td>OS*</td><td>UNK</td></tr><tr><td>√</td><td>√</td><td>√</td><td>√</td><td>65.39</td><td>54.47</td><td>81.97</td></tr><tr><td>√</td><td>√</td><td>√</td><td>X</td><td>59.40</td><td>49.47</td><td>74.42</td></tr><tr><td>√</td><td>X</td><td>√</td><td>√</td><td>61.92</td><td>52.63</td><td>75.37</td></tr><tr><td>X</td><td>√</td><td>√</td><td>√</td><td>58.23</td><td>51.13</td><td>68.01</td></tr><tr><td>√</td><td>√</td><td>×</td><td>√</td><td>59.96</td><td>53.10</td><td>68.97</td></tr><tr><td>X</td><td>X</td><td>X</td><td>X</td><td>58.33</td><td>51.86</td><td>66.68</td></tr></table></body></html>\n\nAblation study. We conduct an ablation study to better understand the contribution of each component in the objective function of our method. As shown in Table 2, removing any component deteriorates model performance. This finding highlights the importance of achieving a good pseudolabel model using 2-stage learning approach as well as aligning the data distribution of known classes between source and target domains while simultaneously detecting and segregating unknown class from known ones for OSHeDA.\n\nImpact of labeled target data. We vary the number of instances per class in the labeled target data to investigate their impact on the DA process. Specifically, we conduct experiments on CIFAR10 & ILSVRC2012 dataset with 1, 3, and 5 instances per class in the labeled target data and visualize the result in Figure 3. Generally, we observe that increasing the number of labeled target instances facilitates better alignment and enhances the performance of all methods. This result demonstrates the importance of labeled target data for DA methods in OSHeDA.\n\nVisualization of representation space. We perform a qualitative analysis to examine the learned representations of RL-OSHeDA and STN for NUSWIDE & ImageNet dataset. Specifically, we use t-SNE (Van der Maaten and Hinton 2008) to project these representations into a 2-dimensional space. As shown in Figure 4, our method effectively aligns representations of the known classes between source and target domains while simultaneously segregating the representations of the unknown class (grey color). This results in improved $H O S$ scores compared to STN.\n\n# 7 Conclusion\n\nThis paper studied a novel domain adaptation scenario called open-set heterogeneous domain adaptation (OSHeDA). We first conducted a theoretical analysis to establish learning bounds in OSHeDA. Based on these theorems, we proposed a representation learning method that aligns the data distribution of known classes between source and target domains while simultaneously detecting and segregating unknown class from known ones. The resulting models trained with the proposed method generalize well to target domains. Experiments on real datasets across diverse domains, including healthcare, natural language processing, and computer vision, demonstrate the effectiveness of our proposed method.",
    "summary": "```json\n{\n  \"core_summary\": \"### 🎯 核心概要\\n\\n> **问题定义 (Problem Definition)**\\n> *   论文解决的核心问题是开放集异构域适应（Open-Set Heterogeneous Domain Adaptation, OSHeDA），即在源域和目标域特征空间异构的情况下，同时处理目标域中出现的新类别。\\n> *   该问题的重要性在于现有异构域适应（HeDA）方法仅能处理特征空间的异构性，无法应对标签空间的不匹配（即新类别），限制了在实际场景中的应用。例如，在医疗领域，ECG数据的异构性和新出现的罕见异常类别需要同时处理。\\n\\n> **方法概述 (Method Overview)**\\n> *   论文提出了一种基于表示学习的方法RL-OSHeDA，通过理论分析构建目标域预测误差的学习边界，并设计了一种同时对齐已知类别表示和分离未知类别的算法。\\n\\n> **主要贡献与效果 (Contributions & Results)**\\n> *   **理论贡献：** 建立了OSHeDA场景下的学习边界，强调了最小化已知类别的域间距离和最大化未知类别的分离的重要性。\\n> *   **算法贡献：** 提出RL-OSHeDA方法，通过两阶段学习和伪标签技术优化表示对齐和未知类别检测。\\n> *   **实验效果：** 在7个数据集上的实验表明，RL-OSHeDA在HOS指标上平均提升约10%，显著优于基线方法。\",\n  \"algorithm_details\": \"### ⚙️ 算法/方案详解\\n\\n> **核心思想 (Core Idea)**\\n> *   RL-OSHeDA的核心思想是通过表示学习将异构的源域和目标域映射到共享表示空间，同时优化三个目标：(1) 最小化源域和目标域已知类别的表示距离；(2) 最大化已知类别和未知类别的表示分离；(3) 最小化开放集差异。\\n> *   该方法通过理论指导的设计，确保在有限数据下仍能有效对齐分布和检测新类别。\\n\\n> **创新点 (Innovations)**\\n> *   **与先前工作的对比：** 现有HeDA方法无法处理标签空间不匹配，而OSDA方法假设特征空间同构。\\n> *   **本文的改进：** RL-OSHeDA首次在异构特征空间和开放标签空间的联合设定下提出解决方案，通过非负风险估计器和伪标签技术提升未知类别检测的鲁棒性。\\n\\n> **具体实现步骤 (Implementation Steps)**\\n> 1.  **表示映射：** 使用两个映射函数 $f_s$ 和 $f_t$ 将源域和目标域数据映射到共享表示空间。\\n> 2.  **两阶段训练：** \\n>     - 阶段1：仅使用分类损失 $L_{cls}$ 初步对齐表示。\\n>     - 阶段2：联合优化总损失 $L = L_{cls} + L_{inv} - L_{seg} + L_{osd}$。\\n> 3.  **伪标签生成：** 在阶段2中，对未标记目标数据生成伪标签，优先选择已知类别中置信度高的样本，剩余样本标记为未知。\\n> 4.  **损失函数：** \\n>     - $L_{inv}$：通过MMD对齐已知类别的表示分布。\\n>     - $L_{seg}$：通过MMD分离已知和未知类别的表示。\\n>     - $L_{osd}$：非负风险估计器，最小化开放集差异。\\n\\n> **案例解析 (Case Study)**\\n> *   论文未明确提供此部分信息。\",\n  \"comparative_analysis\": \"### 📊 对比实验分析\\n\\n> **基线模型 (Baselines)**\\n> *   对比方法包括HeDA领域的SSAN、STN、SCT、KPG，OSDA领域的OPDA，以及OS-SSL领域的DS3L等。\\n\\n> **性能对比 (Performance Comparison)**\\n> *   **在HOS指标上：** RL-OSHeDA在CIFAR10 & ILSVRC2012数据集上达到72.33，显著优于最佳基线STN（61.59）和SCT（59.61），提升约10个百分点。\\n> *   **在未知类别检测（UNK）上：** RL-OSHeDA在Multilingual Reuters Collection数据集上达到81.97，远超基线DS3L（67.57）和OPDA（65.94），提升约15个百分点。\\n> *   **在已知类别分类（OS*）上：** RL-OSHeDA在PTB-XL数据集上达到44.30，与基线STN（22.63）相比显著提升，同时保持未知类别检测的高性能（51.16 vs. 33.72）。\",\n  \"keywords\": \"### 🔑 关键词\\n\\n*   开放集异构域适应 (Open-Set Heterogeneous Domain Adaptation, OSHeDA)\\n*   表示学习 (Representation Learning, N/A)\\n*   域适应 (Domain Adaptation, DA)\\n*   异构特征空间 (Heterogeneous Feature Space, N/A)\\n*   开放集识别 (Open-Set Recognition, OSR)\\n*   最大均值差异 (Maximum Mean Discrepancy, MMD)\\n*   伪标签 (Pseudo-Labeling, N/A)\\n*   医疗影像分析 (Medical Image Analysis, N/A)\"\n}\n```"
}