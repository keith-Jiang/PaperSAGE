{
    "source": "ArXiv (Semantic ScholarÊú™Êî∂ÂΩï)",
    "arxiv_id": "2507.14011",
    "link": "https://arxiv.org/abs/2507.14011",
    "pdf_link": "https://arxiv.org/pdf/2507.14011.pdf",
    "title": "Conceptual and Design Principles for a Self-Referential Algorithm Mimicking Neuronal Assembly Functions",
    "authors": [
        "Paolo Totaro",
        "Alberto Mangiante"
    ],
    "categories": [
        "cs.NE",
        "cs.RO"
    ],
    "publication_date": "Êú™ÊâæÂà∞Êèê‰∫§Êó•Êúü",
    "venue": "ÊöÇÊú™ÂΩïÂÖ•Semantic Scholar",
    "fields_of_study": "ÊöÇÊú™ÂΩïÂÖ•Semantic Scholar",
    "citation_count": "ÊöÇÊú™ÂΩïÂÖ•Semantic Scholar",
    "influential_citation_count": "ÊöÇÊú™ÂΩïÂÖ•Semantic Scholar",
    "institutions": [
        "Federal University of Alagoas",
        "FBC - Utility Management"
    ],
    "paper_content": "# Conceptual and Design Principles for a Self-Referential Algorithm Mimicking Neuronal Assembly Functions\n\nPaolo Totaro Federal University of Alagoas - Brazil paolototaro1 $@$ gmail.com\n\nAlberto Mangiante FBC - Utility Management - Italy mangiante.alberto $@$ gmail.com\n\n# Short Abstract\n\nThis article proposes a method to formalise models of cognitive processes grounded in experience, considering experience from the perspective of a living system and not from that of an observer of the living system. The perspective of a living system is defined by the need of the system to preserve the vital equilibria. The method is based on an algorithmic schema that we call Environment Generative Operator (EGO) and uses a self-referential language developed for this purpose which we call E-language. EGO simulates cognitive processes as operations on neuron assemblies as understood by Hebb. In this article we present an EGO prototype (EGO-P) which has already been implemented and tested.\n\n# Long Abstract\n\nThis article proposes a method to formalise models of cognitive processes grounded in experience, considering experience from the perspective of a living system and not from that of an observer of the living system. The perspective of a living system is defined by the need of the system to preserve the vital equilibria. The method is based on an algorithmic schema that we call Environment Generative Operator (EGO) and uses an object language developed for this purpose, that we call E-language. E-language consists of strings that can be interpreted as neuron assemblies as understood by Hebb. It embeds various mathematical properties, the most significant being self-reference. Given any two strings belonging to the language, it is always possible to build a third string ‚Äòevaluating‚Äô whether a relation between the first two exists. Hence the third string represents an assembly of neurons capable of evaluating whether or not a certain relationship exists between two other assemblies. The E-language self-reference is demonstrated in a Supplementary Material. The aim of the EGO algorithm is to preserve vital equilibria facing environmental perturbations affecting the structure of the system. Among the many possible developments of the EGO, in this article we present one called EGO-P, which has already been implemented and tested. It represents a specific theory that has the same goals as Perceptual Symbol Systems (PSS) in showing how to overcome the problems that, in our opinion, PSS have left unresolved.\n\nKeywords: cognitive processes; artificial cognitive system; self-reference; perceptual symbol systems; neuron assemblies; two-valued logic.\n\n# 1.‚Äã Introduction\n\nThis article proposes a method to formalise models of cognitive processes ‚Äúgrounded‚Äù in experience. However, the epistemological approach differs from that of so-called ‚Äúgrounded cognition‚Äù. We can summarise this difference as follows: while grounded cognition analyses the experience of a living system from the point of view of an observer, we adopt the point of view of the system itself, defined by the need to preserve the biological properties essential for its survival. Therefore, our proposal implies the idea that the system is self-referential, since it operates with the aim of being able to continue operating. The method is based on an algorithmic schema that we called Environment Generative Operator (EGO) and uses an object language developed for this purpose, that we called E-language. EGO simulates cognitive processes by manipulating E-language strings. Among all the feasible ones, an EGO model called ‚ÄúEGO-P‚Äù (Supplementary Material 2) was implemented and tested, achieving the expected objectives. Repositories 2 and 3, as all the others mentioned in the article, can be accessed via the corresponding link in the bibliography.\n\nE-language has various mathematical properties. Those useful for this work have been demonstrated and are available in Supplementary Material 1. As usual, in formal languages (e.g. Mendelson, 2015, p. 27), E-language strings that meet a certain syntax are called well-formed formulas (WFFs). The WFFs of E-language have the property of being at the same time finite sets and statements of a two-valued logic. This dual approach allows them to be self-referential. In Supplementary Material 1, it is demonstrated that given any two WFFs, it is always possible to construct a third WFF which is either a tautology if the first two WFFs represent equal sets, or a contradiction if they represent unequal sets. All set relations and operations on WFFs can be expressed from other WFFs via the equality relation. WFFs are interpreted as assemblies as understood by Donald Olding Hebb (1949). This interpretation is possible due to the fact that (1) the assemblies can be considered neuronal signals collected into sets (and WFFs represent sets) and that (2) the neurons in the assemblies can be considered a firing or non-firing unit. That is, they can assume only two values, as for logical statements (and WFFs represent logical statements in addition to representing sets). Thus, the self-referentiality property of the WFFs can be transferred to assemblies of neuronal signals, enabling them to formally represent neuronal signals ‚Äòsaying‚Äô things on other neuronal signals.\n\nThe EGO algorithm aims to show that E-language can formalise a grounded cognition theory once a theoretical premise is accepted. EGO assumes the central principle of Perceptual Symbolic Systems (PSS) by Lawrence Barsalou (1999) that symbol formation is inherently perceptual but differs from PSS as it shares a principle present in the works of Humberto Maturana (Maturana and Varela, 1980; 1987) and Antonio Damasio (1994, 1999): cognition arises through the continuous attempt of a living system to preserve its vital equilibria when facing environmental pressures. This constant link with the vital relations of the organism is absent in PSS, although Barsalou often refers to Damasio's ideas. More precisely, according to Maturana and Damasio, cognition arises from neurobiological processes that aim to maintain invariant vital relationships between components of such processes in the face of material changes induced by the environment (Totaro, 2021, Totaro &\n\nNinno, 2020). In Maturana's theory, the relationships that the system must keep invariant constitute its \"organisation\", while the material status of processes represents its \"structure\" (Maturana & Varela, 1980, p. xix‚Äìxx, 26-27, 88-95). The structure is continuously subject to changes that are triggered by the external and internal environment and that can threaten the organisation. In response, the system changes the structure to restore the organisation. In a similar way, Damasio (1994, p. 135, 1999, pp. 133‚Äì145) identifies an invariant part in the organism represented by relationships that preserve its homeostatic equilibrium. Environmental stimuli create changes in the body that trigger reactions of the nervous system associated with responses in the visceral and musculoskeletal systems, with the aim of preserving the ‚Äúinternal milieu‚Äù.\n\nIn the following sections, we will present the EGO and E-language in detail, often using Barsalou's theory as a counterpoint. The second section consists of a brief presentation of the philosophy of EGO, emphasising that it also allows the grounding of psychological faculties which in Barsalou's theory seem assigned a priori. The third section presents E-language and its property of representing both sets and logical statements, as well as showing how its WFFs can be interpreted as assemblies of neuronal signals. The fourth is dedicated to the self-reference of E-language and the possibility of transferring this property to assemblies of neuronal signals. The fifth presents the fundamental principles of EGO and its ability to develop processes that can be interpreted as cognitive processes such as the emergence of perceptual symbols, \"objects\", memories and imagination.\n\n# 2.‚Äã EGO and PSS\n\nPSS theory claims that cognition is based on perceptual symbols (Barsalou, 1999). Such symbols should not be conceived as mental images, but as recordings of neural states. These premises are also shared by EGO. But Barsalou's theory ultimately contradicts his underlying premise that cognition is grounded. Barsalou argues that selective attention isolates a \"coherent\" subset from the complex of neurons that are active during a perception. This subset - which selective attention itself induces to record in long-term memory - would constitute the \"schema\" on which the symbol is based:\n\nPerceptual symbols are not like physical pictures; nor are they mental images or any other form of conscious subjective experience. As natural and traditional as it is to think of perceptual symbols in these ways, this is not the form they take here. Instead, they are records of the neural states that underlie perception [‚Ä¶] A perceptual symbol is not the record of the entire brain state that underlies a perception. Instead, it is only a very small subset that represents a coherent aspect of the state [‚Ä¶] Rather than containing an entire holistic representation of a perceptual brain state, a perceptual symbol contains only a schematic aspect [‚Ä¶] The schematic nature of perceptual symbols falls out naturally from two attentional assumptions that are nearly axiomatic in cognitive psychology: Selective attention (1) isolates information in perception, and (2) stores the isolated information in long-term memory (Barsalou, 1999, p. 582-583).\n\nThis conception of the cognitive process has elements of philosophical \"realism\" and ‚Äúsensism\", to which Barsalou (1999, p. 578) refers, also citing Aristotle and Locke among the historical precursors of his theory. The philosophies inspired by realism and sensism (i.e. by the idea that the entities of the world have an objective form that must somehow pass through our senses in order to be known) presents the limitations shown by Ernst Cassirer (1971, 1953a, 1953b).\n\nCassirer distinguishes two possible principles to further study the phenomenon of knowledge. One assigns primacy to 'objects', considered as 'real' entities, that is, independent of the activity of the knowing subject. In this conception, the relationships between objects are a consequence of the properties ascribed to them. The other principle instead claims the primacy of the relationship with respect to the properties of the objects it connects. It is the relationship that defines the properties of objects. The first principle always proved to be self-contradicting when it was used to explain the phenomenon of cognition (Cassirer, 1953a, 1971). It always had to introduce some faculties of the soul without being able to explain the origin of such faculties starting from experience (for example, the \"active reason\" in Aristotle and in Scholasticism and the \"reflection\" in Locke). Indeed, how can an entire object penetrate us through the senses? Aristotle (Shields, 2016, p. 65 - 432a) states that ‚Äú[...] the stone is not in the soul, but rather its form‚Äù. Even so, it is still not understood how an entire form can remain 'intact' on its path through the senses to finally reach the intellect. This difficulty is resolved by dissolving the form into the raw perceptions obtained through the senses. But at this point, the recomposition of the form in the soul starting from the raw perceptions must necessarily be the work of some psychological faculty. In this way, cognition has been split into two halves that are irreducible to each other: perception on one side, judgement on the other (Cassirer, 1953a, p. 312-321). This also occurs with Barsalou: things in the ‚Äòreal‚Äô world have objective shapes that are reproduced in our psyche as symbols thanks to the perceptions that pass through the senses as neural states. Selective attention coordinates such states to produce results that are isomorphic to the shapes of 'real things'. Here, selective attention is defined as a psychological faculty capable of judging the coherence or incoherence of a subset of such neural states. But what is the origin of selective attention? Neural states must be coherent with reference to what?\n\nIn order to answer these questions, we must accept the idea that cognition always refers to a model, since the concepts of coherence or incoherence concern whether or not something is respected. It would therefore be necessary to establish what model of relationships the living system is obliged to respect. This model, we believe, can only be made up of essential relationships between the components of biological processes, but this reference to vital relationships is absent in Barsalou, while it is central in EGO. Here, perceptions are understood as \"perturbations \" of vital relationships that trigger the perennial activity of the system to preserve homeostatic equilibrium (Damasio, 1999; Maturana & Varela, 1980, 1987) and not as a neural recomposition of the objective forms of things in the 'real world'. In other words, the processes developed by living systems in the face of environmental 'stimuli' are self-referential, since their aim is the maintenance of these same processes. In order to develop a cognitive algorithm consistent with this philosophy, it was necessary to define an object language capable of representing the self-reference of neurobiological processes.\n\n# 3.‚Äã The EGO object language\n\nAs clarified in section 2, EGO shares with PSS the idea that perceptual symbols are made up of sets of neural states with certain properties. But in EGO, these properties do not consist in an indefinite coherence or incoherence of the active states, as we saw in the Barsalou passage cited above, but in coherence with specific set relations that constitute vital properties for the entire system. EGO must therefore be able to represent these relationships and evaluate whether or not they are respected at each step of the algorithm. It therefore requires a language capable of (1) representing neural states as sets and of (2) expressing the relations between other neural states in terms of neural states - therefore as sets. In other words, EGO requires a self-referential set-theoretic representation, which allows us to generate sets that represent relations between other sets. We called the language developed on these properties E-language. The theory of E-language as a mathematical object is presented in Supplementary Material 1, which can be accessed through the link in the bibliographical references. In the present work, we only show the elements of E-language necessary to understand how it is used in EGO.\n\nThe self-referentiality of E-language is due to the fact that each of its \"well-formed formulas\" (WFF) constitutes both a finite set represented through the listing method and a truth function of the propositional calculus, i.e. a logical statement. It is precisely the ability of WFFs to represent both sets and statements that allows the identification of a rule according to which, given two sets, a third set can be generated to represent a statement on the relations existing between the first two. In order to apply E-language to neural states, the first step to take is to interpret these states as sets.\n\nTo this end, we adopt Donald Olding Hebb's (1949) concept of ‚Äúassembly‚Äù, which is also consistent with the PSS hypotheses (Barsalou, 1999, p.584). Hebb proposes that in the nervous system the cells that repeatedly ‚Äòfire‚Äô together tend to be assembled into a single functional unit that persists even when the nervous stimulation has ceased:\n\n[‚Ä¶] a repeated stimulation of specific receptors will lead slowly to the formation of an \"assembly\" of association-area cells which can act briefly as a dosed system after stimulation has ceased; this prolongs the time during which the structural changes of learning can occur and constitutes the simplest instance of a representative process (image or idea) [‚Ä¶] When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A's efficiency, as one of the cells firing B, is increased. (Hebb, 1949, pp. 60, 62)\n\nIn order to interpret Hebb assemblies as sets, three postulates must be accepted. The first is a consequence of the process of abstraction necessary to consider, according to EGO's philosophy, neural states from the point of view of the nervous system and not from that of an observer of the nervous system. As we have seen, it is an epistemological change that was conceived by Maturana and Varela (1987, 1980), yet recently revived and updated by Gy√∂rgy Buzs√°ki (2019). Neurons, as morphologically and spatially distinguishable objects, only exist for an observer external to the nervous system. The nervous system, instead, should only distinguish whether it experiences the processes or not, in the specific case whether it experiences the \"action potential\" (which for the external observer is constituted by the phenomena of the neuron that ‚Äúfires‚Äù or ‚Äúdoes not fire‚Äù). If we take to the extreme the feature of action potentials of being momentary, of discharging in all their power or of not discharging at all (Pinel, 2022, p. 101), we consider it is plausible to postulate (1) that the nervous system experiences \"repeated stimulations of specific receptors\" - corresponding to repeated action potentials reached by presynaptic neurons - as repetitions of the same 'signal'.\n\nThe second postulate is based on Hebb's concept of assembly mentioned above and on that of \"structural coupling\" formulated by Maturana and Varela (1987, 1980). Let us briefly summarise the concept of structural coupling. As already pointed out, according to Maturana the behaviour of a living system is always a response to a perturbation of its structure with the intention of preserving its organisation. From the perspective of an external observer, there is an environment consisting of objects, phenomena etc. which acts on the system and to which the system reacts through behaviours. From the system's point of view, however, there is no environment 'populated' by objects and phenomena that act on it, but only perturbations of its structure that threaten its organisation. The behaviour of the system, from its point of view, is only a direct reaction meant to re-establish a structure that is compliant with the organisation. However, if living system A reacts to a perturbation originating from living system B, causing a counter-reaction in B which generates a perturbation of the same type as the first in A, then A and B enter a circuit in which they trigger perturbations and reactions of the same type in each other, each preserving its organisation in a combined way. That is, A and B enter into structural coupling.\n\nDespite being exclusively oriented towards preserving the organisation of the single system, their respective behaviours have the ‚Äòinvoluntary‚Äô consequence of preserving the organisation - and therefore the survival - of the new functional unit resulting from structural coupling. According to Maturana and Varela (1987, 1980) this is the mechanism by which cellular organisms give rise to multicellular ones and, specifically, to the nervous system. The cells, each preserving its own organisation, 'unconsciously' preserve that of the multicellular organism. In turn, the multicellular organism 'unconsciously' preserves the organisation of all cells that compose it. In this way, the multicellular organism \"emerges\" - in the sense that Popper (1985) gives to this term - from cellular organisms. On the basis of these considerations, it should be acceptable to postulate that (2) when two neurons enter into structural coupling, the behaviour of one must be experienced by the other as a cyclical repetition, that is, as repetitions of the same signal collected in a set, or rather, in an assembly. In symbols: if we represent the signal with $\\varnothing$ , the repetitions of the signal are received by the neuron as the assembly $\\{ \\emptyset , . . . , \\emptyset \\}$ if, and only if, the repetitions in question result from the structural coupling with other neurons. The fundamental step occurs when the set $\\{ \\emptyset , . . . , \\emptyset \\}$ containing the signal $\\varnothing$ emerges from signal $\\varnothing$ , that is, a new functional unit emerges having $\\varnothing$ as its founding element. Hence, it is legitimate - in consonance with set theory (e.g.\n\nMendelson, 2015, p. 235) - to abbreviate $\\{ \\emptyset , . . . , \\emptyset \\}$ with $\\{ \\emptyset \\}$ : the emergence resides in the formation of something containing $\\varnothing$ and not in the number of times $\\varnothing$ is repeated, just as the emergence of a complex functional unit is represented by the structural coupling of certain behaviours of the elementary units and not by the number of times such behaviours occur.\n\nThe third postulate is also a consequence of Hebb's theory and the concept of structural coupling. If the assembly of signals is the result of the formation of a multicellular functional unit, it can be assumed that this unit can in turn enter into structural coupling both with other neurons and with other assemblies of neurons. Therefore, we believe it is legitimate to postulate that (3) a signal assembly can couple both with signals and signal assemblies. In symbols, there can be, for example: $\\{ \\emptyset , \\{ \\emptyset \\} \\}$ or $\\{ \\emptyset , \\{ \\emptyset , \\{ \\emptyset \\} \\} \\}$ or even $\\{ \\{ \\emptyset \\} , \\{ \\emptyset , \\{ \\emptyset \\} \\} \\}$ and so on, for an infinite number of possibilities.\n\nTo refer both to signal $\\varnothing$ and to the assemblies that can be formed from it, we introduce the concept of ‚Äúneural state‚Äù, which we formally define as follows:\n\n# Definition 1. [Neural state]\n\na)‚Äã If $\\varnothing$ is a neural state, then $\\{ \\emptyset , . . . , \\emptyset \\}$ is a neural state.   \nb)‚Äã I $\\operatorname { f } X _ { _ { 1 } } , \\ . . . , X _ { _ { n } }$ are neural states, with $n { \\geq } 1$ , then $\\{ X _ { 1 } , . . . , X _ { n } \\}$ is a neural state.   \nc)‚Äã An object is a neural state if, and only if, it satisfies (a) - (b).\n\nWe call ‚Äúassembly‚Äù a neural state other than $\\varnothing$ . Comparing definition 1 above with definition 1 in Supplementary Material 1, it appears that the neural states are identical to the WFFs of E-language. Both neural states and WFFs constitute finite sets constructed starting from $\\varnothing$ (interpreted as an empty set) and represented by the listing method.\n\nIn Supplementary Material 1b, we present an example of rules that can allow a frequency distribution of neural signals to be ‚Äòtranslated' into an assembly. In the example, the rules are a way of representing the \"attractor\" concept (Hopfield, 1982). The attractor hypothesis provides an interpretation of the grid-cell phenomenon that represents one of the most significant discoveries on the association between mammalian spatial orientation and neuronal signals (Moser, Kropff, & Moser, 2008).\n\nOnce the neural states (and the assemblies) have been defined, we now move on to defining the relations of equality between them. This definition is identical to that of the equality between WFFs of E-language (definition 2 of Supplementary Material 1):\n\nDefinition 2. [Equality between neural states] Any two neural states $X$ and $Y$ are equal, and we write $X = Y$ , if and only if:\n\na)‚Äã $X$ and $Y$ represent $\\varnothing$ . b)‚Äã $X$ is $\\{ X _ { 1 } , . . . , X _ { n } \\}$ and $Y$ is $\\{ Y _ { _ { 1 } } , . . . , Y _ { _ { m } } \\}$ and for each $X _ { _ i }$ there is at least one $Y _ { _ j }$ such that $X _ { _ { i } } = Y _ { _ { j } }$ and for each $Y _ { _ j }$ there is at least one $X _ { _ i }$ such that $X _ { _ i } = Y _ { _ j }$ .\n\nIt is specifically point (b) of definition 2 that establishes the equality between assemblies. As for the WFFs of E-language (Supplementary Material 1), thanks to definitions 1 and 2, it is possible to interpret assemblies as objects of classical set theory and the relations between assemblies as set-theoretic relations. In order to transfer the self-referentiality of WFFs to the assemblies, we only need to show that it is possible to interpret assemblies as logical statements.\n\nHebb's theory (1949) maintains that assemblies persist even after the activity of the neurons that led to their generation ceases. In the formalisation we are proposing, this means that when a repetition of signal $\\varnothing$ is no longer active, the assemblies that it formed when it was active persist. For example, if the repetitions of the signal produced the assembly $\\{ \\{ \\emptyset \\} , \\{ \\emptyset , \\{ \\emptyset \\} \\} \\}$ , this assembly persists when signal $\\varnothing$ ends. We must therefore distinguish assembly $\\{ \\{ \\emptyset \\} , \\{ \\emptyset , \\{ \\emptyset \\} \\} \\}$ when the signal $\\varnothing$ is active and the same assembly when the signal is inactive. If we indicate with the symbols T (true) and F (false) respectively the \"active\" and \"inactive\" states of the signal - i.e. the action potential generated or not generated - the symbol $\\varnothing$ can be interpreted as a variable of the two-valued propositional calculus. Therefore, by definition 3 below, neural states can be interpreted as truth functions built on the variable $\\varnothing$ alone.\n\nDefinition 3. [Interpretation of neural states as logical statements]\n\n1.‚Äã $\\varnothing$ is a variable that can assume the values ${ \\bf T }$ or $\\mathbf { F }$ .   \n2.‚Äã Let $X _ { _ { 1 } } , . . . , X _ { _ { n } }$ be $n$ neural states, with $n \\geq 1$ ; if each of the $X _ { _ { 1 } } , . . . , X _ { _ { \\eta } }$ has the value ${ \\bf T }$ , then the neural state $\\{ X _ { _ { 1 } } , . . . , X _ { _ { n } } \\}$ has the value F. Otherwise, the neural state $\\{ X _ { 1 } , . . . , X _ { n } \\}$ has the value ${ \\bf T }$ .\n\nAlthough neural states that are assemblies also have truth values of ${ \\bf T }$ or F, such values should not be interpreted as representing active or inactive signals. In fact, assemblies are not signals but sets of signals. As truth functions, they refer to this activity of composing sets of signals and not to the active or inactive state of the signals.\n\nBy definition 3, a neural state can be interpreted as the NAND of propositional calculus. In fact, NAND returns the \"false\" value if, and only if, all its arguments have the \"true\" value. NAND allows one to express any other logical operator. Therefore, the traditional operators of propositional calculus can be understood as a means of shortening the representation of assemblies. Definition 4 indicates such abbreviations.\n\nDefinition 4. [Assemblies as logical statements]\n\na)‚Äã For every neural instance $X$ : $\\begin{array} { l l } { \\boxed { \\begin{array} { r l } \\end{array} } } & { \\sim X } \\end{array}$ stands for the assembly $\\{ X \\}$ .   \nb)‚Äã For every $n$ -tuple of neural states $X _ { _ 1 } , . . . , X _ { _ n }$ , with $n \\geq 1$ : \u0000‚Äã $\\{ X _ { _ { 1 } } \\land \\dotsc \\land X _ { _ { n } } \\}$ stands for $\\sim \\{ X _ { _ { 1 } } , . . . , X _ { _ { n } } \\}$ and thus, for the assembly $\\{ \\{ X _ { 1 } , . . . , X _ { n } \\} \\}$ . \u0000 $\\begin{array} { c l c c } { { \\displaystyle \\vphantom { \\displaystyle \\sum _ { i } ^ { n } \\sum _ { 1 } ^ { n } \\ldots \\sum _ { n } ^ { n } \\sum _ { n } ^ { i } } \\mathrm { s t a n d s } } } & { { \\mathrm { f o r } } } & { { \\stackrel { \\scriptscriptstyle , } { \\displaystyle } \\{ } \\sim X _ { 1 } , \\ldots \\sim X _ { n } \\} }  \\\\ { { \\{ \\{ X _ { 1 } \\} , \\ \\ldots , \\ \\{ X _ { n } \\} \\} . } } \\end{array}$ and thus, for the assembly\n\nc)‚Äã For every pair of neural states $X _ { _ 1 }$ and $X _ { _ 2 }$ :\n\n$\\{ X _ { _ 1 } \\supset X _ { _ 2 } \\}$ stands for $\\{ X _ { _ 1 } \\vee \\sim X _ { _ 2 } \\} \\}$ and thus, for the assembly $\\{ X _ { _ 1 } , \\{ X _ { _ 2 } \\} \\}$ . $\\{ X _ { _ 1 } \\equiv X _ { _ 2 } \\}$ stands for $\\{ \\{ X _ { _ { 1 } } , \\{ X _ { _ { 2 } } \\} \\} \\wedge \\{ X _ { _ { 2 } } , \\{ X _ { _ { 1 } } \\} \\} $ and thus, for the assembly {{{ùëã1, {ùëã2}},  {ùëã2, {ùëã1}}}.\n\nTo facilitate the understanding of definition 4, in the following two examples we explain the cases of $\\sim X$ nd $\\{ X _ { _ { 1 } } \\lor \\dots \\lor X _ { n } \\}$ .\n\n# Example 1.\n\nIf $X$ is a neural state, the assembly represented by $\\{ X \\}$ is its negation. In fact, by definition 3, if $X$ has value $\\mathbf { F }$ , then $\\{ X \\}$ has value $\\mathbf { T }$ , and if $X$ has value ${ \\bf T }$ , then $\\{ X \\}$ has value F. We can therefore write $\\sim X$ (the negation symbol in propositional calculus) as an abbreviation of $\\{ X \\}$ .\n\n# Example 2.\n\nIf $X _ { _ 1 } , . . . , X _ { _ n }$ are neural states, with $n { \\geq } 2$ , then the assembly $\\{ \\{ X _ { 1 } \\} , . . . , \\{ X _ { n } \\} \\}$ is their logical disjunction. Let us recall that the logical disjunction is an operator that returns the ‚Äútrue‚Äù value if, and only if, at least one of its arguments is true. Now, if at least one of $X _ { _ 1 } , . . . , X _ { _ n }$ neural states has the value ${ \\bf T }$ , then by definition 3 at least one of the assemblies $\\{ X _ { 1 } \\} , . . . , \\{ X _ { n } \\}$ has the value $\\mathbf { F }$ , and  the value of $\\{ \\{ X _ { 1 } \\} , . . . , \\{ X _ { n } \\} \\}$ is ${ \\bf T }$ . If instead all $X _ { _ { 1 } } , . . . , X _ { _ { n } }$ neural states have $\\mathbf { F }$ values, then by definition 3 all the assemblies $\\{ X _ { 1 } \\} , . . . , \\{ X _ { n } \\}$ have the value ${ \\bf T }$ , and the value of $\\{ \\{ X _ { 1 } \\} , . . . , \\{ X _ { n } \\} \\}$ is $\\mathbf { F }$ . We can therefore use the $^ { 6 6 } V ^ { 3 }$ disjunction operator and write $\\{ X _ { _ { 1 } } \\lor \\dots \\lor X _ { n } \\}$ in the place of $\\{ \\{ X _ { 1 } \\} , . . . , \\{ X _ { n } \\} \\}$ .\n\n# 4.‚Äã The self-reference of assemblies\n\nIn E-language, the WFFs $\\{ X , . . . , X \\}$ and $\\{ X , . . . X , Y _ { 1 } , . . . , Y _ { n } \\}$ are abbreviated as $\\{ X \\}$ and $\\{ X , Y _ { 1 } , . . . , Y _ { n } \\}$ respectively. These abbreviations of WFFs are called ‚ÄúE-formulas‚Äù and correspond to the abbreviated representations of the assemblies introduced with the second postulate at the beginning of section 3. At the end of section 2.2 of Supplementary Material 1, there is an explanation as to why all proofs that are valid for E-formulas are also valid for non-abbreviated WFFs and vice versa. Therefore, from now on, we will always refer to the abbreviated forms of both WFFs (that is, to E-formulas) and assemblies.\n\nThe theory of E-language presents a formally defined rule (Supplementary Material 1, section 3) according to which, starting from any two $X$ and ùëå E-formulas, it is always possible to generate a third E-formula having the property of being a tautology if $X = Y$ (i.e. if $X$ and $Y$ are equal sets) and a contradiction if $X \\neq Y$ (i.e. if $X$ and $Y$ are not equal sets). This E-formula is called the ‚Äúequality evaluator‚Äù and is expressed by the notation $\\{ X = Y \\}$ . The rule that generates $\\{ X = Y \\}$ is defined recursively and is therefore difficult to express correctly without resorting to mathematical tools. For its full and correct understanding, we refer the reader to sections 3 and 3.1 of Supplementary Material 1. It roughly consists in transforming into logical equivalence the equality between $X$ and $Y$ and recursively performing the same operation for the equalities between each member of $X$ with all members of ùëå. Since every E-formula of the E-language can be interpreted as a neural state, the construction rule $\\{ X = Y \\}$ also applies to them. Therefore, for two neural states $X$ and $Y$ , the assembly $\\{ X = Y \\}$ is the equality evaluator of those neural states. To better understand the construction rule of $\\{ X = Y \\}$ intuitively, we present example 3.\n\n# Example 3.\n\nIf $X = \\{ \\varnothing \\}$ and $Y = \\{ \\emptyset , \\{ \\emptyset \\} \\}$ , the assembly $\\{ X \\ = \\ Y \\}$ is given by:   \n$\\{ \\{ \\emptyset \\} \\ = \\ \\{ \\emptyset , \\ \\{ \\emptyset \\} \\} \\}$ ‚Äã that stands for $\\{ \\{ \\{ \\emptyset \\} \\equiv \\{ \\emptyset , \\ \\{ \\emptyset \\} \\} \\} \\wedge \\{ \\{ \\emptyset \\ = \\ \\emptyset \\} \\wedge \\{ \\emptyset \\ = \\ \\{ \\emptyset \\} \\} \\} \\}$ that stands for $\\{ \\{ \\emptyset \\} \\equiv \\{ \\emptyset , \\ \\{ \\emptyset \\} \\} \\} \\wedge \\{ \\{ \\emptyset \\equiv \\emptyset \\} \\wedge \\{ \\emptyset \\equiv \\{ \\emptyset \\} \\} \\}$ }   \nHence $\\{ X \\ = \\ Y \\}$ represents $\\{ \\{ \\emptyset \\} \\equiv \\{ \\emptyset , \\ \\{ \\emptyset \\} \\} \\wedge \\{ \\{ \\emptyset \\equiv \\emptyset \\} \\wedge \\{ \\emptyset \\equiv \\{ \\emptyset \\} \\} \\} \\}$ which is an   \nassembly by definition 4.\n\nStarting from $X$ and $Y$ , the assembly $\\{ X \\ = \\ Y \\}$ is composed. The 'self-reference theorem' demonstrated in Supplementary Material 1 ensures that $\\{ X \\ = \\ Y \\}$ is a tautology if $X = Y$ and is a contradiction if $X \\neq Y$ . That is, the following theorem holds:\n\nSelf-reference theorem. [Self-reference of neural states] Given any two neural states $X$ and $Y , X \\ = \\ Y$ if, and only if, the assembly $\\{ X \\ = \\ Y \\}$ is a tautology, and $X \\neq Y$ if, and only if, the assembly $\\{ X \\ = \\ Y \\}$ is a contradiction.\n\nWe present the following example to clarify the meaning of the theorem.\n\n# Example 4.\n\nAs we saw in example 3, the equality evaluator $\\{ X \\ = \\ Y \\}$ referring to the assemblies $X = \\{ \\varnothing \\}$ and $Y = \\{ \\emptyset , \\{ \\emptyset \\} \\}$ is given by the following assembly:\n\n$$\n\\{ \\{ \\{ \\emptyset \\} \\equiv \\{ \\emptyset , \\ \\{ \\emptyset \\} \\} \\} \\wedge \\{ \\{ \\emptyset \\equiv \\emptyset \\} \\wedge \\{ \\emptyset \\equiv \\{ \\emptyset \\} \\} \\} \\}\n$$\n\nApplying definitions 3 and 4, [1] results in a contradiction. [1] states that $X$ and $Y$ are not equal assemblies due to the self-reference theorem. In fact, set $X = \\{ \\varnothing \\} \\neq Y = \\{ \\varnothing , \\{ \\varnothing \\} \\}$ . EGO cannot observe assemblies from the outside to establish whether or not they represent equal sets. It can only compose assemblies and calculate their truth values. It is assembly [1] ‚Äòstating‚Äô that $\\{ \\emptyset \\}$ is different from $\\{ \\{ \\emptyset , \\{ \\emptyset \\} \\}$ , i.e. that $\\{ \\emptyset \\} \\neq \\{ \\emptyset , \\{ \\emptyset \\} \\}$ .\n\nAs shown in section 4 of Supplementary Material 1, starting from the equality evaluator, it is possible to define any relationships and operations between two sets. Obviously, the same applies to assemblies. Below, we report as an example the evaluator of the membership relationship between the assemblies shown in example 4.\n\n# Example 5.\n\nIf $X = \\{ \\varnothing \\}$ and $Y = \\{ \\emptyset , \\{ \\emptyset \\} \\}$ , the membership evaluator of $X$ to $Y$ must say whether $X$ is equal to $\\varnothing$ or $\\{ \\emptyset \\}$ . Thus, by definition 4, this evaluator is given by $\\{ \\{ \\{ \\emptyset \\} = \\emptyset \\} \\lor \\{ \\{ \\emptyset \\} = \\{ \\emptyset \\} \\} \\}$ . The assembly $\\{ \\{ \\emptyset \\} = \\{ \\emptyset \\} \\}$ is a tautology and therefore, by definition 4, so is the entire assembly $\\{ \\{ \\{ \\emptyset \\} = \\emptyset \\} \\lor \\{ \\{ \\emptyset \\} = \\{ \\emptyset \\} \\} \\}$ . By self-reference theorem, it ‚Äòsays‚Äô that $X$ is a member of $Y$ . This evaluator can be abbreviated by writing $\\{ \\{ \\emptyset \\} \\in \\{ \\emptyset , \\ \\{ \\emptyset \\} \\} \\}$ .\n\nWe call \"relational evaluators\" (REs) all the assemblies that represent the existence or otherwise of a specific set relationship between other assemblies. It is now possible to highlight the following consequences of the self-reference theorem for the method we are presenting.\n\nI.‚Äã The method supports the phenomenon of self-reference of brain functions, that is, to use the words of Maturana and Varela (1980, pp. 25-26), ‚Äúthe ability of the nervous system to interact with its own internal states, as if these were independent entities‚Äù. In fact, given two neural states $X$ and ùëå, EGO can always compose an assembly which represents an RE of $X$ and $Y$ , that is an assembly that says that there is a specific relationship between $X$ and ùëå.\n\nII.‚Äã The method allows comparison between memory contents and perceptual symbols. We call Active States Assembly (ASA) an assembly in which all occurrences of $\\varnothing$ have the value ${ \\bf T }$ and ‚ÄúInactive States Assembly‚Äù (ISA), an assembly in which all occurrences of $\\varnothing$ , have the value F. Therefore an ASA corresponds to an assembly of active neurons while an ISA is an assembly of neurons whose signal has decayed. If we accept Hebb's (1949) hypothesis that the assemblies built on active signals arise from a current experience and those of decayed signals are the foundation of memory, we can believe that ASAs refer to the first case and ISAs to the second. Now, EGO calculates the truth value of a Relationship Evaluator (RE) only after composing it. In examples 3 and 4, we can observe that the application of the self-reference theorem is possible only after the equality evaluator $\\{ X \\ = \\ Y \\}$ has been composed. In other words, the ${ \\bf T }$ value or $\\mathbf { F }$ value is assigned to the logical variable $\\varnothing$ present in $\\{ X ~ = ~ Y \\}$ only after $\\{ X ~ = ~ Y \\}$ has been generated. The same thing happens for any REs, since they are composed of equality evaluators. Therefore, an RE allows you to establish the relationship between any assemblies regardless of whether they are ISAs or ASAs. If the comparison occurs between ISAs, the RE compares stored experiences; if instead it occurs between ISAs and ASAs, the RE compares a memorised experience with one currently lived, giving rise to the comparison between memory and ‚Äòreality‚Äô.\n\nIII.‚Äã Memory arises at the same time as the system's ability to relate experiences. In fact, in order for an RE to be able to determine whether a given relationship exists or not, EGO must assign both the value T to all the occurrences of $\\varnothing$ present in the RE and the value F to those same occurrences. This means that a current experience, in order to be related to another, must be considered both an ASA and an ISA. The transition from the domain of the ASAs to that of the ISAs is interpreted as the memorization of the experience, while the one from the domain of the ISAs to that of the ASAs as its recall from memory. Therefore, it is not possible to establish any relationship between experiences without memorising them and it is not possible to memorise experiences without relating them to each other.\n\nWe now introduce EGO through one of the possible ways it can be developed. Any algorithm that adopts the perspective of the system - instead of that of the observer system - and uses E-language to simulate cognitive processes is understood by us as a version of EGO. We call the version we present \"EGO Prototype\" (EGO-P).\n\n# 5.‚Äã The EGO-P algorithm\n\nAs we have repeatedly highlighted, EGO emulates a living system that experiences \"perception\" as a perturbation of its organisation, that is, as a perturbation of the relationships necessary for its survival and which constitute its biological identity. The main difference between EGO and PSS lies precisely in the fact that in EGO, cognition is ‚Äòmotivated‚Äô by the preservation of the organisation, while in PSS, cognition is not driven by a general purpose.\n\nMany existing works present algorithms that try to emulate the phenomena of motivation and emotion (Moerland, Broekens, & Jonker, 2018). Emotion is introduced on the basis of the algorithm's \"extrinsic motivations\" to operate (i.e. motivations consisting of the need to preserve homeostasis in the face of pressure from the external environment) and \"intrinsic motivations\" (i.e. those consisting in the evaluation (appraisal) of the effectiveness and efficiency of the possible responses to these pressures). All these proposals are based on the Reinforcement Learning (RL) technique, precisely on the concept of value of the actions and states of the system in terms of probability of obtaining a \"reward\", as well as on the concept of developing a strategy (‚Äúpolicy‚Äù) aimed at defining probabilistic rules that maximise the set of current and future rewards (Sutton & Barto, 2018). Due to this probabilistic approach, RL seems to pursue different objectives from those in which the theory of cognition is concerned. A central problem for the theory of cognition is the mechanism of symbol formation, but RL does not provide answers in this sense; indeed, it is considered an alternative approach to the symbolic one in the field of AI (Moerland, Broekens, & Jonker, 2018, p. 447). The development of soft-robotics is also starting to be seen as an opportunity to relate cognition to the preservation of the system's homeostasis, but even in this case the reference technique remains the RL (Man & Damasio, 2019).\n\nThere are also approaches that try to reproduce the cognitive functions performed by symbols using techniques originating from neural networks and Reinforcement Learning, thus trying to exploit the advantages offered by both the connectionist and symbolist approaches (Kleyko, Rachkovskij, Osipov, & Rahimi, 2022, 2023). First of all, the attempt consists in expressing through vectors both the symbols and the \"bindings\" existing between them in the so-called \"structured representations\" of experience. These techniques are known as Hyperdimensional Computing (HDC) and Vector Symbolic Architectures (VSA). Once the symbols and bindings have been represented with vectors and matrices, the idea is to search for isomorphisms between the inputs and outputs of the vector representations and the inputs and outputs of the neurosensory systems. If the outputs generated by the mathematical model starting from certain inputs are isomorphic to the frequencies of the ‚Äúspikes‚Äù generated by the neurons of certain brain areas stimulated by similar inputs, then it can be concluded that the cognition of those stimuli occurs in a manner equivalent to the mathematical model proposed. This is an idea that may appear methodologically convincing. However, we believe that it presents two epistemological flaws:\n\n1)‚Äã The relationships between the symbols and their semantic contents (which, in the mathematical model, are represented respectively by the \"compression\" and \"decompression\" of those \"hypervectors\" called \"semantic pointers\") are those of the researcher and not those of the observed living system. This is the basic criticism levelled by Maturana (1988a, 1988b, 1990a), Maturana and Varela (1980, 1987), and Gy√∂rgy Buzs√°ki (2019) at the objectivist approach of experimental research in the neurobiology of cognition. It can also be extended to Barsalou's (2020, p. 3) vision of grounded cognition: the system's motivations, i.e. its 'point of view' on its experience, come into play only after the perception data and perceptual symbols have been generated. On the one hand, there is perception (and perceptual symbols) and on the other, the emotional and moral evaluations of the living system from which it selects the data of perception. Here too, the separation of cognition into two independent origins - experience and judgement - highlighted by Cassirer as a typical consequence of the realist approaches we have already mentioned in section 2, appears clearly.\n\n2)‚Äã Considering the structured representation as a set of predefined data to which ‚Äúbindings‚Äù are subsequently applied introduces a separation between the data and the relationships as if they had a different origin and could not both originate from the experience of the system. For example, in his main work, Eliasmith (2013, pp. 133-139) searches for algorithmic models that emulate the functioning of the nervous system by generating results isomorphic to the ‚Äúchases‚Äù answer to the question: ‚ÄúWhat was the action‚Äù in the sentence ‚Äúthe dog chases the boy‚Äù? We believe that cognition does not proceed by developing the categories \"dog\" and \"boy\" on the one hand and then connecting them with the \"action\" made up of \"chases\". In EGO-P, it simply happens that both the ‚Äúdog‚Äù category and the ‚Äúdog chasing something‚Äù category can be developed and that the former includes the latter. So, while a given dog chasing something is an instance of both the ‚Äúdog chasing something‚Äù category and the ‚Äúdog‚Äù category, a sleeping dog is an instance of the ‚Äúdog‚Äù category but not of the ‚Äúdog chasing something‚Äù category.\n\nThe isomorphism that EGO-P presents with the ‚Äòreal‚Äô cognitive processes is mainly given by the fact that both EGO-P and living systems are self-organised, self-determined and self-referential. As we will see, once a starting \"structure\" - that is, the structure at step 0 of the algorithm - has been assigned to EGO-P, its organisation is implicitly defined by the system itself (section 5.2). Since the moment of the structure assignment and the consequent definition of the organisation, the pressure of the environment triggers in EGO-P autonomously developed processes that are interpretable such as perception (section 5.3), homeostasis (section 5.4), selective attention, the emergence of symbols, of objects, images and memory (section 5.5). The primitive operation in the cognitive processes of EGO-P is categorization. It is categorization that also allows the formal definition of the concept of system organisation.\n\n# 5.1. The categorization\n\nIn EGO-P, the categorization of assemblies is fundamental in all phases of cognition, starting from perception, in consonance with the centrality that abstraction and categorization have in the PSS (Barsalou, 2005) and with empirical evidence (Barsalou, 2008a). To indicate what is meant by the category of $n$ assemblies, it is first necessary to define the concepts of \"subassembly\" and \"common aspect\" of $n$ assemblies.\n\nDefinition 5. [Subassembly]\n\nFor every assembly $X .$ we say that an assembly $Y$ is a subassembly of $X$ if, and only if, one of the following conditions are respected:\n\na) $Y = X$   \n$\\operatorname { \\harpoonup } X = \\{ U _ { 1 } , . . . , U _ { n } \\}$ , and $Y = U _ { _ { 1 } }$ or ‚Ä¶ or $Y = U _ { n } ;$   \nc) $W ~ = ~ \\{ V _ { _ { 1 } } , . . . , V _ { _ { m } } \\}$ is a subassembly of $X$ and $Y = { V } _ { _ { 1 } }$ or ‚Ä¶ or $\\boldsymbol { Y } = \\boldsymbol { V } _ { \\boldsymbol { m } }$\n\nIn other words, $X$ is a subassembly of itself, every member of $X$ is a subassembly of $X$ , and every subassembly of a subassembly of $X$ is still a subassembly of $X$ .\n\nWe can now give the definitions of \"common aspect\" and \"category\". Such definitions are difficult to understand intuitively. Immediately after providing them, we will present examples that facilitate understanding.\n\n# Definition 6. [Common aspect]\n\nGiven $n$ assemblies $X _ { 1 } , . . . , X _ { n } ,$ we say that $Y$ is a ‚Äúcommon aspect‚Äù of $X _ { 1 } , . . . , X _ { n }$ if, and only if, for each $X _ { i }$ , $Y$ is a subassembly of $X _ { i }$ and is not a subassembly of a subassembly that  is already a common aspect of $X _ { 1 } , . . . , X _ { n }$ .\n\n# Definition 7. [Category]\n\nWe say that an assembly is the category of $n$ assemblies $X _ { _ { 1 } , \\dots , X _ { n } }$ and denote it by $C ( X _ { 1 } , . . . , X _ { n } )$ if, and only if, the elements of $C ( X _ { 1 } , . . . , X _ { n } )$ are all and only all the common aspects of $X _ { 1 } , . . . ,$ $X _ { n }$ .\n\nTo understand the meaning of definitions 6 and 7, it is useful to imagine an assembly as a rooted tree graph and use a way to uniquely identify each node of the tree. Both operations are carried out in example 6 where, after coding the nodes, we show how EGO categorises two assemblies.\n\n# Example 6.\n\nAn $f$ function has been defined in Supplementary Material 3 to univocally indicate the nodes of a tree. Thanks to $f ,$ we can uniquely indicate any subassembly $Y$ of an assembly $X$ by writing $X _ { f ( Y ) }$ , where $f ( Y )$ is the decimal number uniquely associated with subassembly Y. Fig. 1 shows how every node of assembly $X = \\{ \\emptyset , \\{ \\emptyset , \\{ \\emptyset \\} \\} \\}$ is indicated using $X _ { f ( Y ) }$ .\n\n![](images/688e3530ea51f41418001f1c89b3b5a29114e947557ae3c0856ec7689b246ad9.jpg)\n\nFigure 1. Example of rooted tree representation of an assembly with nodes coded according to the function defined in Supplementary Material 3.\n\nNow let us consider the two assemblies in Fig. 2, where $U = \\{ \\emptyset , \\{ \\{ \\emptyset \\} \\} , \\{ \\emptyset , \\{ \\{ \\emptyset \\} \\} \\} \\}$ and $V = \\{ \\{ \\emptyset \\} , \\{ \\{ \\emptyset \\} \\} \\}$ . In trees $U$ and $V ,$ we have $U _ { _ { 0 . 2 } } = V _ { _ { 0 . 2 } } = \\{ \\{ \\emptyset \\} \\}$ . Therefore, $U _ { _ { 0 . 2 } }$ and $V _ { 0 . 2 }$ can represent a common aspect of $U$ and $V$ , as long as they meet the condition that they are not subassemblies of another common aspect. We see in Figure 2 that $U _ { 0 . 2 }$ and $V _ { 0 . 2 }$ are only subassemblies of $U$ and $V$ . Therefore, $U _ { _ { 0 . 2 } } = V _ { _ { 0 . 2 } } = \\{ \\{ \\emptyset \\} \\}$ is a common aspect of $U$ and $V$ . All subassemblies of $U _ { 0 . 2 }$ and $V _ { 0 . 2 }$ cannot be a common aspect as they are already subassemblies of the common aspect $U _ { _ { 0 . 2 } } = V _ { _ { 0 . 2 } } = \\{ \\{ \\emptyset \\} \\}$ . Again, let us consider the subassemblies $U _ { 0 . 1 } = V _ { 0 . 0 1 } = \\emptyset$ . As neither $U _ { 0 . 1 }$ nor $V _ { _ { 0 . 0 1 } }$ are subassemblies of common aspects of $U$ and $V , \\emptyset$ is another common aspect of $U$ and $V$ . To complete the illustrative capacity of the example, we note that despite $U _ { _ { 0 . 0 2 } } = V _ { _ { 0 . 1 } } = \\{ \\varnothing \\}$ , assembly $\\{ \\emptyset \\}$ is not a common aspect of $U$ and $V$ , as $U _ { _ { 0 . 0 2 } }$ is a subassembly of $U _ { _ { 0 . 2 } }$ that is already a common aspect. As in $U$ and $V$ there are no other subassemblies matching the definition of common aspect, the category of $U$ and $V$ is given by $C ( U , V ) = \\{ \\{ \\{ \\emptyset \\} \\} , \\emptyset \\}$ .\n\n![](images/3806153caf4a9bdf2efcbc68aae78906368c1c715569dc8b33ea65a109571657.jpg)  \nFigure 2. Example of comparison between two assemblies to identify common aspects. By definition 6, the common aspects of $U$ and $V$ are $U _ { _ { 0 . 2 } } = V _ { _ { 0 . 2 } } = \\{ \\{ \\emptyset \\} \\}$ and $U _ { 0 . 1 } = V _ { 0 . 0 1 } = \\emptyset$\n\nFrom definitions 5 and 6, it follows that category $C ( X _ { 1 } , . . . , X _ { n } )$ can be built starting from $X _ { _ { 1 } , \\dots , X _ { n } }$ in a unique way. Thus, $C ( X _ { 1 } , . . . , X _ { n } )$ is the output of a process that has as input assemblies $X _ { _ { 1 } , \\dots , X _ { n } }$ . We call this process ‚Äúcategorization‚Äù. We say that assemblies $X _ { _ { 1 } , \\dots , X _ { n } }$ are \"instances\" of category $C ( X _ { 1 } , . . . , X _ { n } )$ and that the members of $C ( X _ { 1 } , . . . , X _ { n } )$ are the \"properties\" of that category.\n\nIt is important not to confuse assemblies that are properties with those that are instances of a category. This difference is commonly understood as intuitive. For example, if we talk about trees as a category of objects, their properties are those of having roots, a trunk, branches and leaves, while the instances of the category 'trees' are this fir tree or oak in the window. Let us consider example 6, where:\n\n$$\n\\begin{array} { c } { { U = \\{ \\emptyset , \\{ \\{ \\emptyset \\} \\} , \\{ \\emptyset , \\{ \\{ \\emptyset \\} \\} \\} \\} , } } \\\\ { { { } } } \\\\ { { V = \\{ \\{ \\emptyset \\} , \\{ \\{ \\emptyset \\} \\} \\} , } } \\\\ { { { } } } \\\\ { { C ( U , V ) = \\{ \\{ \\{ \\emptyset \\} \\} , \\emptyset \\} . } } \\end{array}\n$$\n\nIn $C ( U , V )$ $U$ and $V$ are the input of the categorization process and therefore the instances of $C ( U , V )$ , while the properties of $C ( U , V )$ are $\\{ \\{ \\emptyset \\} \\}$ and $\\varnothing$ , i. e. the members of assembly $\\{ \\{ \\{ \\emptyset \\} \\} , \\emptyset \\}$ .\n\nCategorization in EGO-P possesses the properties that PSS requires of an algorithmic abstraction process (Barsalou, 2005). At each clock of the digital device on which EGO-P is implemented, each category has a precise set of instances. However, the categorical representation of assemblies is not rigid. Firstly, at each clock EGO-P is able to evaluate whether newly emerged assemblies can represent instances of pre-existing categories. Secondly, new assemblies can give rise to new categories that not only represent properties of the new assemblies but can also represent properties of pre-existing assemblies that were previously unrepresented in any category. Therefore, the categorization process easily achieves the objectives of semantic coding and decoding that the HDC/VSA addresses by compressing and decompressing the experience data into the hypervectors made up of semantic pointers. The categorization process does not have the limit indicated in point (1) of the epistemological discussion on HDC/VSA because, as we shall see, categories become symbols and then 'objects' only by associating them with the reactions of the system.\n\nHDC/VSA also uses hypervectors to pursue the goal of representing the links between data in structured experiences. As we highlighted in point (2) of the above discussion, for epistemological reasons, HDC/VSA presents the problem in an unsolvable way when it considers the objects and the relationships between the objects separately. In EGO-P, any object is an assembly, and any assembly generated at a level higher than simple perturbation is the result of a Relationship Evaluator (RE). In fact, categorization - including that of the perturbations - is based on the identification of the common aspects of the assemblies to be categorised. This identification can only occur by searching for relations of equality between the subassemblies of the assemblies to be categorised. Therefore, categories are ultimately relationships. In turn, the categories themselves enter into relations that may still be subject to categorization. In other words, EGO-P's initial cognitive processes are always relationships. Starting from them, a hierarchy develops inductively where at each step, the categories represent underlying relationships that in turn enter into relationships that are categorised at the higher level. The combinatorial explosion of assemblies that would form in EGO-P at each step of the hierarchy is avoided through a pointer system always expressed in E-language and therefore, in the form of assemblies. Such pointers are called ‚Äúarchetypes‚Äù. For more details on how they work, see section 3.1 of Supplementary Material 2.\n\nAs we will see shortly, in addition to representing the multiplicity of relationships between perturbations and their effects, categorization also allows the definition of the system organisation. In fact, the organisation is given by the categories of assemblies present in the system at the start conditions. Therefore, through the categories and the relationships that they represent, on the one hand the organisation of the system is defined, and on the other, the continuous modification of the properties of its structure is represented.\n\n# 5.2. EGO-P organisation and structure\n\nEGO-P is initialised with a predefined set of assemblies which are called \"internal states\". The set of internal states is presented to the system already divided into \"parts\" of a set-theoretic partition, that is, into subsets that do not overlap and which exhaust all the internal states. We call these parts \"modalities\", taking the term from Grounded Cognition Theory (Barsalou, 2020), without limiting this concept to external and internal perception (Barsalou, 2020, p. 2), but extending it to the effector and connecting components of the nervous system. Therefore, each modality can be interpreted as a sensory, somatosensory, sensorimotor, motor, proprioceptive, interoceptive, etc. system or as a system connecting them all. In short, whatever cognitive functions a theory wants to consider, in EGO-P these functions can be considered as sets of assemblies. Modalities are such sets, and internal states are their members.\n\nAt starting conditions, the categorization process produces a category of internal states for each modality (Figure 3). If $Y _ { _ { 1 } , \\dots , Y _ { _ m } }$ are the internal states of modality $M$ at starting conditions, then we denote by $C ( M )$ the category $C ( Y _ { _ { 1 } , \\dots , Y _ { m } } )$ . If $M _ { 1 } , . . . , M _ { n }$ are all the modalities of EGO-P, the categories $C ( M _ { _ 1 } ) { , } . . . , C ( M _ { _ n } )$ constitute the \"organisation\" of EGO. Since the set of these categories is itself an assembly, the organisation is defined by the following assembly:\n\n$O r g a n i s a t i o n = \\{ C ( M _ { ‚òâ } ) , . . . , C ( M _ { n } ) \\}$ where $M _ { ‚òâ } , . . . , M _ { n }$ are all the modalities of EGO-P. L\n\n![](images/b194e71a3036ca415660f53e5fe34f3f73a70f1cf1398b434c91d0cca1f5e3b5.jpg)  \nFigure 3. An example of an EGO-P structure at starting conditions with the consequent definition of its organisation. The strings of assemblies are figurative, because the ones actually generated by the algorithm are much more complex. For each modality, from the internal states (in green), categorization derives the category (in black) that establishes the properties that the modality must possess. The set of modality categories constitutes the organisation of EGO-P.\n\nPreserving the organisation therefore means preserving categories $C ( M _ { _ 1 } ) { , } _ { \\dots } , C ( M _ { _ n } )$ in the actions that the system undertakes to respond to the perturbations of the internal states triggered by the environment. For example, if assemblies $U$ and $V$ shown in figure 2 were the only internal states of an EGO-P modality at starting conditions, the category $C ( U , V ) ~ = ~ \\{ \\{ \\{ \\emptyset \\} \\} , \\emptyset \\}$ would represent the organisation of the system regarding that modality. If $U$ and $V$ were subsequently perturbed by the environment and transformed into the assemblies $U _ { _ 1 }$ and $V _ { _ 1 }$ , categorised by $C ( U _ { 1 } , V _ { 1 } ) { \\neq } C ( U , V )$ , then the organisation of EGO would not be preserved. The system would react in such a way as to modify $U _ { _ 1 }$ and $V _ { _ { 1 } }$ to obtain assemblies $U _ { _ 2 }$ and $V _ { _ 2 }$ such that $C ( U _ { 2 } , V _ { 2 } ) = C ( U , V ) = \\{ \\{ \\{ \\emptyset \\} \\} , \\emptyset \\}$ , thus preserving the organisation.\n\nLet us now move on to the definition of the \"structure\" of EGO-P. It can vary at each clock of the digital medium that executes the algorithm and is made up of all internal states that are present in EGO-P at that clock. If we denote by ${ \\cal S } _ { i } ( M )$ the assembly of internal states that constitute a modality $M$ at clock $i$ , then ${ \\cal S } _ { i } ( M )$ is part of the structure of EGO-P at that clock. We can therefore define the assembly that constitutes the structure of EGO-P at clock $i$ in the following way.\n\n$$\nS t r u c t u r e _ { _ i } = \\{ S _ { _ i } ( M _ { 1 } ) , . . . . , S _ { _ i } ( M _ { _ n } ) \\}\n$$\n\nwhere $M _ { _ { 1 } } , . . . , M _ { _ { r } }$ are all the modalities of EGO-P. 2\n\nFor example, if the assemblies $U$ and $V$ shown in figure 2 were the only internal states of an $M$ modality of EGO-P at clock $i$ , then ${ \\cal S } _ { i } ( M ) = \\{ U , V \\}$ would be part of ùëÜùë°ùëüùë¢ùëêùë°ùë¢ùëüùëíùëñ.\n\nA structural change is a phenomenon where at clock ùëñ, $S _ { \\scriptscriptstyle i } ( M ) { \\neq } S _ { \\scriptscriptstyle i - 1 } ( M )$ for at least one ùëÄ modality. Following Maturana and Varela (1987), there can be two possible structural changes: those that threaten the organisation and those that cause the loss of the organisation. The first type belongs to the domain of structural changes, while the second belongs to the domain of destructive changes. The interactions that trigger the first type of change are called 'perturbations'. In the EGO-P algorithm, we have represented these principles in the following way. Let $\\{ Y _ { 0 . 1 } , . . . , Y _ { 0 . m } \\}$ be the assembly of the internal states of modality $M$ at starting conditions - i.e. $S _ { _ { 0 } } ( M ) = \\{ Y _ { _ { 0 . 1 } } , . . . . , Y _ { _ { 0 . m } } \\}$ - and let $C ( Y _ { 0 . 1 } , . . . , Y _ { 0 . m } )$ be the category of such internal states - that is, $C ( M ) = C ( Y _ { _ { 0 . 1 } } , . . . , Y _ { _ { 0 . m } } )$ . Then we can have:\n\n1)‚Äã $S _ { i } ( M ) = \\{ Y _ { i . 1 } , . . . , Y _ { i . p } , Z _ { i . 1 } , . . . , Z _ { i . l } \\}$ is the result of a structural change such that $p < m$ , $Y _ { _ { i . 1 } } , . . . , Y _ { _ { i . p } }$ are instances of $C ( M )$ , and $C ( Y _ { _ { i . 1 } } , . . . , Y _ { _ { i . p } } , Z _ { _ { i . 1 } } , . . . , Z _ { _ { i . l } } ) { \\neq } C ( M )$ . In this case, there is no destructive change, but only a change in the configuration of the structure. In fact, $Y _ { _ { i . 1 } } , . . . , Y _ { _ { i . p } }$ still comply with the properties envisaged by the organisation and indicated by $C ( M )$ . However, the number of internal states that comply with these properties has changed (i.e. $p < m$ ) and new internal states $Z _ { _ { i , 1 } } , . . . , Z _ { _ { i , l } }$ have emerged which 'threaten' the organisation, given that $C ( Y _ { _ { i . 1 } } , . . . , Y _ { _ { i . p } } , Z _ { _ { i . 1 } } , . . . , Z _ { _ { i . l } } ) \\not = C ( M )$ . In other words, as long as $M$ presents internal states that have the properties expected by the organisation, the structure undergoes a configuration change that threatens the organisation but does not destroy it. Thus, a structural change is not destructive. The interactions that triggered it are called ‚Äúperturbations‚Äù.\n\n2)‚Äã $S _ { i } ( M ) = \\{ Y _ { i . 1 } , . . . , Y _ { _ { 1 . p } } , Z _ { i . 1 } , . . . , Z _ { _ { i . l } } \\}$ is the result of a structural change such that $Y _ { _ { i . 1 } } , . . . , Y _ { _ { i . p } }$ are not instances of $C ( M )$ and $C ( Y _ { _ { i . 1 } } , . . . , Y _ { _ { i . p } } , Z _ { _ { i . 1 } } , . . . , Z _ { _ { i . l } } ) \\not = C ( M )$ . In this case, the change is destructive. That is, if in $\\mathbf { M }$ there are no subsets of internal states that satisfy the organisation, then the change is destructive.\n\nInteractions that trigger changes in the structure can originate from both the external environment and from changes to the structure itself. In the first case, we say that the interactions are 'exogenous', and in the second, 'endogenous'. Consequently, we also call the structural changes that they respectively trigger 'exogenous' and 'endogenous'. Endogenous interactions consist of changes in a certain modality that trigger changes in that same modality or in other modalities. In other words, endogenous perturbations arise from neural structural couplings (and therefore, by postulate (II), from assemblies) involving the so-called 'interneurons'. It is the endogenous interactions that develop the correlations between the sensory and effector areas of the nervous system and therefore, between sensation and movement (Maturana, 1995, pp. 156-161). They also produce the continuous correlations that define the \"core dynamic‚Äù of the brain (Edelman & Tononi, 2000) which is considered as the basis of the phenomenon of consciousness (Edelman & Tononi, 2000, Damasio, 1999). Let us now analyse the structural changes triggered by perturbations in general and in particular by exogenous interactions. It is from the latter that the phenomenon of perception originates.\n\n# 5.3. Perception\n\nIn the previous section, we represented with ${ \\cal S } _ { i } ( M )$ only the results of structural changes, but not the changes themselves. If we use $X _ { _ { i . 1 } } , . . . , X _ { _ { i . n } }$ to indicate the neural states that at clock $i$ trigger the structural change of a modality $M$ , we say that the following assembly $E _ { _ i }$ is an ‚Äúevent‚Äù:\n\n$$\nE _ { _ i } = \\{ \\{ X _ { _ { i . 1 } } , . . . , X _ { _ { i . n } } \\} , \\{ Y _ { _ { i - 1 . 1 } } , . . . , Y _ { _ { i - 1 . q } } \\} \\} , \\{ Z _ { _ { i . 1 } } , . . . , Z _ { _ { i . l } } \\} \\}\n$$\n\nwhere $Y _ { i - 1 . 1 } , . . . , Y _ { \\substack { i - 1 . q } }$ are the internal states of $M$ that complied with the organisation at clock $i - 1$ and that at clock $i$ , they were replaced by $Z _ { i . 1 } , . . . , Z _ { i . l } .$\n\nLet us now analyse the particular case in which $X _ { _ { i . 1 } } , . . . , X _ { _ { i . n } }$ are the result of exogenous interactions. The tests to which EGO was subjected took strings of bits, i.e. signals 1 and 0 as the external environment, which stimulated the system. As mentioned above, classical set theory shows how classes built on $\\varnothing$ have the property of representing numbers and arithmetic calculation (e.g. Mendelson, 2015, pp. 273-274). There are therefore various possibilities for encoding strings of bits in sets constructed from $\\varnothing$ , i.e. for representing such strings as assemblies. The choice of coding system is absolutely arbitrary, and does not change the result of EGO-P's performance.\n\nIn the case of exogenous events (that we also call ‚Äúsensory events‚Äù), the neural states $X _ { _ { i . 1 } } , . . . , X _ { _ { i . n } }$ of [2] represent encodings of strings of bits that impact the 'surface' of the system. EGO does not connect - as the observer external to the system can do - neural states $X _ { _ { i . 1 } } , . . . , X _ { _ { i . n } }$ with the strings of 1s and 0s coming from the environment. From EGO's point of view, $X _ { _ { i . 1 } } , . . . , X _ { _ { i . n } }$ simply appear ex novo, they emerge from the clock.\n\nAn event is a ‚Äúperception‚Äù if, and only if, it is exogenous (sensory). Both in the case of perceptions and endogenous events, EGO-P reacts with a process that we call ‚Äúhomeostatic recursion‚Äù. The process leading to symbol formation begins with perception, but also involves endogenous changes. Homeostatic recursion describes the reaction to any type of structural change and therefore represents the formalisation of any phase of the symbol formation process.\n\n# 5.4. Homeostatic recursion\n\nIn any event, a living system reacts to respond to threats to the organisation (Maturana, 1980, 1987). In EGO-P, this reaction is represented by homeostatic recursion. It manages to preserve the organisation in the face of disruptions to the structure. The generated process is split into three phases. The first is given by the emergency of perturbations, as described above. In the second phase, working only with the properties of the categories, the system tries to find a rule to replace the internal states that no longer respect the organisation, and in the third, it actually replaces the internal states. The process that represents the second phase is called ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ, and the third is called ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü.\n\nThe distinction between a phase of production of behavioural rules (ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ) and one of execution of processes (ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü) according to those rules seems consistent with the experimental data of Diba and Buzs√°ki (2007) who recorded the activity of ‚Äúplace cells‚Äù (Moser,  Kropff, & Moser, 2008, pp. 70-71) of rats while they ran back and forth on a linear track for a water reward at each end:\n\nDuring the run, each neuron's firing was tuned to a particular location along the track, which was stable from lap to lap. These locations define a temporal sequence of place-cell firing on the timescale of seconds. During immobility following the run the same neurons fired again [Reverse replay], on the timescale of hundreds of milliseconds, but in the reverse temporal order, confirming previous findings. In addition, the neurons fired in the forward temporal order during immobility prior to the run [Forward preplay] [...] Observations suggest that forward preplay may be more directly linked to the cellular representation of the run sequence than is reverse replay. (Diba and Buzs√°ki, 2007, p. 1241,1242)\n\nThe forward preplay seems to correspond to the ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ activity, while ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü to the activity of place cells during the actual movement. For Diba and Buzs√°ki (2007), furthermore, memory has more to do with the contents of the forward preplay and reverse replay rather than with the activity presented by the play cells during the actual action. This is consistent with the idea followed in EGO-P that memory retains categories - which are the assemblies on which ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ operates - rather than the assemblies generated by ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü. (The temporally reversed order of place cell activity in the reward replay compared to that of the forward preplay can be represented in the way explained in section 2 of Supplementary Material 1b. However, we did not take this reversal into account in EGO-P). Let us now describe the steps of homeostatic recursion.\n\nAt clock 0 of the digital medium on which EGO-P is implemented, the system is in its starting conditions, made up of the internal states $Y _ { _ { 0 . 1 } } , . . . , Y _ { _ { 0 . m } }$ of each modality and the corresponding category $C ( Y _ { 0 . 1 } , . . . , Y _ { 0 . m } )$ (see Figure 3). At the clock $j$ , with $j > 0$ (Figure 4), perturbations $X _ { _ { j . 1 } , \\dotsc , X _ { _ { j . n } } }$ emerge ex novo, and so do internal states $Z _ { _ { j . 1 } } , . . . , Z _ { _ { j . l } }$ not complying with the organisation, while some who complied with it ‚Äòdisappears‚Äô. The first operation that ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ undertakes at each step is to check whether $X _ { _ { j . 1 } , \\dotsc , X _ { _ { j . n } } }$ are all instances of the same category that were already generated. If not, it produces a category. ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ also performs the same operations on $Z _ { _ { j . . 1 } } , . . . , Z _ { _ { j . l } }$ (Figure 4).\n\n![](images/e628307fcde24cd8ab5467e6adc5d1a4b4ffdee444c113dc46147f7d2c30014a.jpg)  \nFigure 4. A fictitious example of three possible perturbations triggered by the external environment in the structure from Figure 3 at a step $j > 0$ . The strings in red represent the $X$ and $Z$ assemblies, that is, perturbations and their effects on modalities (in this case Modality 2). In Modality 2, the internal states that complied with the organisation (in green) decreased from 3 to 2. The 'disappeared' internal state was replaced by 2 assemblies (in red) that do not comply with it. Graphically, the perturbations were represented by a recess in the system boundary. ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ immediately categorises both perturbations and their consequences on Modality 2.\n\nAfter categorising $X _ { _ { j . 1 } , \\dotsc , X _ { _ { j . n } } }$ and $Z _ { _ { j . 1 } } , . . . , Z _ { _ { j . l } }$ by producing $C ( X _ { j . 1 } , . . . , X _ { j . n } )$ and $C ( Z _ { _ { j . . 1 } } , . . . , Z _ { _ { j . l } } )$ , ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ attempts to generate an assembly whose members match those of $C ( M )$ , i.e. the properties that the internal states of $M$ must have to comply with the organisation. At clock ùëñ, ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ may not yet have recomposed the properties of a certain modality perturbed at an earlier clock. Let $M _ { j ^ { \\mathstrut } }$ with $i > j$ , stand for the most perturbed among all the modalities in this condition, i.e. the one that records a greater decrease in instances of $C ( M _ { j } )$ . The process that attempts to recompose the properties of $C ( M _ { j } )$ is ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ ${ } _ { i } ( M _ { j } )$ . To generate an assembly whose members match the properties of $C ( M _ { j } )$ ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ ${ } _ { i } ( M _ { j } )$ can use all members of the various $C ( Z )$ categories created up to clock $i$ and not used by ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ in the previous step (Figure 5).\n\n![](images/aed0ae725cf1055dd1cbf1adc7800a621a99994cd72831a6e296d59607d5e20c.jpg)\n\nFigure 5. A fictitious example of ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ ${ } _ { i } ( M _ { j } )$ that produces an output. The perturbations of step $i < j$ do not appear in the diagram because they no longer act on the structure at current step $i > j$ . Only the product of their categorization is retained in memory and is represented in violet. However, the alterations that they caused in Modality 2 are still active. Perturbations at the current step $i$ have generated the replacement of an internal state of Modality $n$ that complied with the organisation with two assemblies (in red) that do not comply with it. The string in black represents the assembly generated by ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ $( M _ { j } )$ , that is equal to the one defining the organisation of Modality 2. It was produced using subassemblies of $\\{ \\{ \\{ \\emptyset \\} \\} \\}$ (the one in violet) and $\\{ \\{ \\emptyset \\} , \\emptyset \\} , \\{ \\emptyset \\} \\}$ (the one in red) which are respectively the categories of consequences in Modality 2 and Modality $n$ generated at steps $j$ and $i$ .\n\nùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ is organisation-focused while ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü is structure-focused. Once ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ has found a way to use the $C ( Z )$ categories to compose $C ( M _ { j } )$ , the system is induced to use the members of $C ( Z )$ to concretely generate new internal states categorizable with $C ( M _ { j } )$ to replace those altered by the perturbations. This operation, which actually modifies the structure and does not only operate with the properties, is represented by ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü.\n\nThe task of ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü is to produce internal states that comply with the organisation to compensate for the decrease in the number $d$ of such internal states, a decrease that results from the emergence of perturbations. For this purpose, ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü must use the material offered by the $Z s$ assemblies that emerge from the perturbations of internal states. Precisely, it must produce the greatest number $q$ , with $q \\leq d _ { j }$ , of assemblies that include the property of $C ( M _ { j } )$ . In fact, if an assembly includes $C ( M _ { j } )$ , it is necessarily an instance of $C ( M _ { j } )$ , and thus complying with the organisation. Such $q$ assemblies must be unequal to each other, since the objective of ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü is to produce distinct assemblies to replace the internal states altered by perturbations. Therefore, aside from including $C ( M _ { j } )$ , they must contain some members that distinguish them from each other. Thus ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü must add an accidental member (ùê¥ùëêùëê ) to the output of ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ to produce $d _ { j }$ distinct instances of $C ( M _ { j } )$ , that is, $d _ { j }$ distinct internal states of $M _ { j }$ which comply with the organisation (Figures 6a and 6b). In Supplementary Material 4, we present a very simple case exemplifying how ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ and ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü work.\n\n![](images/58721bda44158679289fcd7efedf00673051e30388bc62d34fc83cdc41753967.jpg)  \nFigure 6a. A fictitious example of the ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ \\bf \\Xi } _ { \\mathrm { { \\ell } } } ( M _ { j } )$ process once ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ ${ \\bf \\Xi } _ { ; } ( M _ { j } )$ has produced an output. The goal of ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü is to produce internal states that comply with the organisation using subassemblies of the internal states that do not comply with the organisation. In the example in figure 6a, ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ \\bf \\Xi } ( M _ { j } )$ uses subassemblies of the internal states highlighted in yellow to which it adds an accidental element (in this case $\\varnothing$ ) to produce a new internal state (in blue) that complies with the organisation. In this way, in Modality 2, the system returned to equilibrium.\n\n![](images/57cac29c290667fb44b6dfd281403b10d5582566e1add3e580b98396fac6d466.jpg)  \nFigure 6b. The structure at the end of step ùëñ. Internal states (highlighted in yellow in Figure 6a) used by ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ } _ { i } ( M _ { j } )$ have been removed. In Modality 2, there are once again three internal states that comply with the organisation. To represent this graphically, a recess in the boundary of the system was eliminated. However, Modality 2 still has an anomaly represented by the only remaining internal state in red. It will return to equilibrium when and if this internal state is eliminated. Modality $n$ , instead, still presents an insufficient number of internal states that comply with the organisation as well, as it still presents one internal state that does not comply with it.\n\n# 5.5. Perceptual and objective symbols, memory, imagination, and selective attention\n\nLet us now describe the emergence of a symbol in EGO-P. In Maturana (1995, pp. 154‚Äì156, 1990a pp. 15‚Äì16, 2001 pp. 6‚Äì12, 1978 pp. 47‚Äì55; Maturana & Varela, 1987, pp. 231‚Äì235), a symbol emerges from a phenomenon similar to that of structural coupling. Although citing Piaget instead of Maturana, Von Foerster (2003), and then Kauffman (2003), provided a mathematical interpretation of this phenomenon, coining the terms ‚Äúeigen-value‚Äù, ‚Äúeigen-form‚Äù and ‚Äúeigen-function‚Äù to designate a recursive process that converges towards a limit value. This value is never reached by the process and therefore only constitutes a symbol of the continuous execution of that process which develops an increasingly tighter and more stable circularity: ‚ÄúThe leap of imagination to the infinite eigenform is akin to the human ability to create signs and symbols‚Äù (Kauffman, 2003, p.76). EGO-P generates symbols in a similar way. But unlike Von Foerster and Kauffman, it shows how this mechanism can be grounded in perception, which is impossible with the purely mathematical representations offered by these authors. The price that EGO-P pays for this progress compared to Von Foerster's intuition is that it operates in a ‚Äúdiscrete‚Äù dimension (that of neural states) and therefore does not have the possibility of using the mathematical concept of limit.\n\nThe process of the formation of perceptual symbols starts from the reaction of ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ to exogenous perturbations, i.e. the perturbations that trigger perceptions (see section 5.3). When a kind of perturbation represented by a category $C ( X _ { i . 1 } , . . . , X _ { i . n } )$ causes a ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ ${ \\bf \\Xi } _ { : } ( M _ { j } )$ that converges towards a stable ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ ( M } _ { j } )$ , the category $C ( X _ { i . 1 } , . . . , X _ { i . n } )$ emerges as the signal of an automatic behaviour. Our model allows us to support the idea that $C ( X _ { i . 1 } , . . . , X _ { i . n } )$ progressively becomes the \"perceptual symbol\" of this automatic reaction through the following steps:\n\n1)‚Äã Let $p$ be a clock with $j \\le i < p$ . If ùëãùëù.1,..., ùëãùëù.ùëõ are instances of ùê∂(ùëãùëñ.1,..., ùëãùëñ.ùëõ), and a ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ ${ \\bf \\Xi } ( M _ { j } )$ that has triggered ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ } _ { \\cdot } ( M _ { \\cdot } )$ already exists, then ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ \\bf \\Xi } ( M _ { j } )$ is directly executed (Figures 7a, 7b, 7c). Therefore, in this case, assembly $C ( X _ { i . 1 } , . . . , X _ { i . n } )$ becomes the signal associated with a specific behaviour. Since $C ( X _ { i . 1 } , . . . , X _ { i . n } )$ has been recalled from memory and is associated with a behaviour, it can be interpreted as a perceptual symbol.\n\n2)‚Äã At the $p$ -th clock, if perceptual symbol $C ( X _ { i . 1 } , . . . , X _ { i . n } )$ already exists, it can become ‚Äúobjective‚Äù. Let ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ \\bf \\Xi } ( M _ { j } )$ be the one associated to the perceptual symbol $C ( X _ { i . 1 } , . . . , X _ { i . n } )$ . If the ‚Äònew‚Äô internal states produced by ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ } _ { ; } ( M _ { } )$ represent changes in the system's disposition towards the environment, and if the environment reacts to these changes, causing the emergence of $X _ { _ { p . 1 } , \\ldots , X _ { p . r } }$ perturbations in EGO-P in a way that they remain instances of $C ( X _ { i . 1 } , . . . , X _ { i . n } )$ , then structural coupling with the environment could be established. In fact, in this case, $C ( X _ { i . 1 } , . . . , X _ { i . n } )$ would once again activate ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ \\bf \\Xi } _ { i } ( M _ { j } )$ which would in turn produce new internal states in $M _ { j }$ of the same category as those that have been generated as a counter-reaction to the environment (Figure 8).\n\n![](images/8b0e7ff2a96e3fe3f8c18922e0cf0750e4a96b8a73617e8cd8a0e3cbcf0d5972.jpg)\n\nFigure 7a. ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ ${ \\bf \\Xi } _ { ; } ( M _ { j } )$ output recall. In this example, at the current step $p > i > j$ , we have a Modality 2 disequilibrium with two internal states that comply with the organisation and two that do not comply with it. Modality $n$ is the one perturbed at the current step $p$ and is also in a condition of disequilibrium. Such perturbations are all instances of category $\\{ \\{ \\{ \\emptyset \\} \\} , \\{ \\emptyset \\} , \\emptyset \\}$ (in violet)  that had been produced at the previous step $i$ . Under these conditions, EGO-P does not give rise to a manipulation process, but recalls the output of ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ ${ } _ { \\cdot } ( M _ { \\mathfrak { j } } )$ , generated at step $i$ , to immediately execute ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ \\bf \\Xi } _ { i } ( M _ { j } )$ .\n\n![](images/07c33597ce0c9cfa4ad3612f72fd89b20c622a7dca9afcd11210e316076b612f.jpg)  \nFigure 7b. Immediate activation of ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ } _ { i } ( M _ { j } )$ . In the conditions present in Figure 7a, EGO-P executes ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ \\bf \\Xi } _ { i } ( M _ { j } )$ without building a ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ process. Once the result $\\{ \\{ \\emptyset , \\{ \\emptyset \\} \\} , \\{ \\{ \\emptyset \\} \\} \\}$ of ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ ${ \\bf \\Xi } _ { \\mathrm { { \\ell } } } ( M _ { j } )$ has been recalled, ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ \\bf \\nabla } _ { i } ( M _ { \\it _ { j } } )$ produces a new internal state (in blue) that complies with the organisation using the instances of categories $\\cdot$ and $\\cdot$ , since such categories were the inputs of ùëÄùëéùëõùëñùëùùë¢ùëôùëéùë°ùëñùëúùëõ ${ } _ { \\cdot } ( M _ { \\mathfrak { j } } )$ . The category of perturbations $\\cdot$ (in violet) that was created in step $i$ has become a perceptual symbol.\n\n![](images/4c73480bd83bd66514f88c3309b995dcd8b61a46d0318f3866a8e550c24fa5b0.jpg)\n\nFigure 7c. End of step $p > i > j$ . At the end of step $p$ , the internal states of Modality 2 that did not satisfy the organisation and which were used by ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ \\bf \\Xi } _ { ; } ( M _ { \\it _ { j } } )$ to produce new internal states that do satisfy it have been removed. One recess in the system boundary has also been removed, as Modality 2 now has three internal states that comply with the organisation, the way it was at the starting conditions. The category $\\{ \\{ \\{ \\emptyset \\} \\} , \\{ \\emptyset \\} , \\emptyset \\}$ (in violet) that was generated by the categorization of perturbations at step $i$ is now a perceptual symbol.\n\n![](images/a45bc062902e068766cbfe7a08a5a2e75ac4ab5851bc472a3af91cb65cb4239c.jpg)  \nFigure 8. Structural coupling. At step $p > i > j$ , perturbations are instances of perceptual symbol {{{√ò}}, {√ò}, √ò} ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ } _ { i } ( M _ { j } )$ is immediately executed producing a new internal state of Modality 2 complying with the organisation. If the removal of this recess produces a reaction from the environment that produces new perturbations that are still instances of the perpetual symbol {{{√ò}}, {√ò}, √ò} ùêµùëí‚Ñéùëéùë£ùëñùëúùë¢ùëü ${ } _ { i } ( M _ { j } )$ is again executed, making it possible to initiate a structural coupling between EGO-P and the environment. In this case, the perceptual symbol $\\cdot$ becomes an ‚Äòobject‚Äô.\n\nIn summary: the transition from category to perceptual symbol occurs when exogenous perturbations recall from memory a category already associated with certain behaviours. A perceptual symbol becomes an objective symbol if it represents not only the association between the categorised perturbations and certain behaviours of the system, but also a structural coupling of these behaviours with such types of perturbations: the behaviours of the system and perturbations enter in a recursive cycle where both are stabilised and where their connection is represented by the perceptual symbol. In other words, the phenomenon of 'objects' of 'reality' arises from perceptual symbols that represent stable circular links between behaviours and exogenous perturbations. This hypothesis is quite consistent with Maturana's theory (1995 pp. 154‚Äì156, 1990a pp. 15‚Äì16). In the next section, we shall see that the transition from perceptual symbol to 'image' occurs when an entire objective symbol is memorised.\n\n# 5.6. Mental images, simulation and selective attention\n\nAs described above, the memory of categories allows the formation of perceptual symbols, that is, stable associations between exogenous perturbations and behaviours. The memory of perceptual symbols allows the formation of objective symbols, that is, the formation of stable associations between behavioural reactions and counter-reactions from the environment. Through objective symbols, the reaction is no longer immediately linked to the defence of the organisation, but occurs by considering the counter-reactions from the environment: the preservation of the organisation is not an immediate goal, but is pursued through the manipulation of the object. However, at this level, EGO-P does not yet have the ability to choose through possible alternatives. We consider objective symbols as the result of automatic reactions. In fact, the recognition of categories of exogenous perturbations, their association with effective behaviours and the structural coupling with the counter-reactions from the environment are automatic cognitive processes. They would allow us to address the problems of Psychology focused on ‚Äúsituated‚Äù cognition in operational contexts (Roth & Jornet, 2013, Bereiter 2021) but would not be able to represent mental phenomena ‚Äúoff line‚Äù, i.e. decoupled from the operational context, such as abstract thinking or ‚Äúdaydreaming‚Äù (Wilson, 2002). In order for EGO-P to have this potential, it is necessary to introduce processes similar to the phenomenon of \"mental images\".\n\nIn EGO-P, a mental image is a memory of an objective symbol triggered by endogenous perturbations. The memory from which the mental image is born therefore differs from the memory from which the perceptive and objective symbols are born, because the first is triggered by endogenous perturbations and not by exogenous ones, and because it recalls objective symbols instead of categories or perceptual symbols. In other words, unlike objective symbols, images are not immediately associated with perceptions. Expressing themselves with the vocabulary of the external observer, objective symbols that are not images are used to recognize 'objects' and immediately react to them, while images are used to recall 'objects' from memory. This interpretation is consistent with Damasio's (1999) concept of image and his somatic marker hypothesis (Damasio, 1994), given that an image is associated with possible behaviours and not actual behaviours.\n\nIn EGO-P, the phenomenon of endogenous perturbations is linked to a type of processes that are called \"emotional chains\", which are described in Supplementary Material 2. The emotional chains begin with the endogenous perturbations of the internal states of a given modality. These perturbations are self-induced by the system to dispose of redundancies in internal states ùëçs - i.e. those that do not respect the organisation. For this purpose, the system simulates a perturbation of internal states that comply with the organisation to verify whether this generates conditions that allow the use of excess $Z \\mathrm { s }$ to restore those internal states altered in a self-induced way. The simulations consist of set-theoretic operations on assemblies. If the simulation is successful, endogenous perturbations actually take place and behaviours are started. An emotional chain generates an image when some $Z _ { \\scriptscriptstyle i . 1 } , \\ldots , Z _ { \\scriptscriptstyle i . l }$ involved in the simulation are instances of a $C ( Z _ { i . 1 } , . . . , Z _ { i . l } )$ emerging with $X _ { _ { i . 1 } , \\dots , X _ { _ { i . 1 } } }$ instances of a category $C ( X _ { i . 1 } , . . . , X _ { i . n } )$ that became an objective symbol. In the simulation, this objective symbol $C ( X _ { i . 1 } , . . . , X _ { i . n } )$ is recalled by memory and becomes a mental image.\n\nThe introduction of the phenomenon of simulation into the PSS is susceptible to the criticism advanced by Barbara Landau (1999), since PSS does not explain how simulation is grounded in experience. The perceptual origin of the simulation remains unclear and this is a limit for the PSS, as it assumes that cognition originates in perception. Instead, we have seen how simple it is to trace the origin of simulation and imagination back to perception in\n\nEGO-P, thanks to the epistemological presuppositions of EGO and to the E-language. The epistemological presuppositions make it possible to trace imagination and simulation back to the homeostatic reaction to perception. The self-reference theorem of the E-language allows us to present a hypothesis for the phenomenon of memory, which is indispensable for imagination.\n\nFinally, selective attention ends up being a false problem in EGO-P. In section 5.4, we saw that the process of categorising perturbations already involves selective attention, since the system must select subassemblies that are common aspects of the assemblies to be categorised. This not only happens during the categorization process, but every time the system searches for some set relationship between assemblies. All EGO-P activity is based on the search for set relationships and therefore, on selective attention.\n\n# 5.6. Final considerations\n\nEGO represents first and foremost a tool for formalising cognitive models and allowing their implementation on digital media. To illustrate its operating philosophy, we presented the EGO-P algorithm to show how EGO can be used to formalise hypotheses about phenomena such as categorization, symbol formation, 'object' representation, memory, imagination and selective attention. The EGO framework is nevertheless very flexible and can support different theories. All they need is to use E-language, and share the Hebbian concept of assembly along with that of cognition as a reaction to perturbations of relationships that are vital for the system proposed by Maturana and Damasio.\n\nEven though it was created to formalise theories of cognition, we believe that EGO also has the potential to be used in the field of AI. In light of the epistemological premises of EGO, current AI techniques cannot represent a way to formalise cognitive processes, because they adopt the perspective of the observer external to the system and not that of the system, which is the one arising from its need to preserve the conditions required for its survival. The very definition of \"intelligent machine\" given by Turing (2007) adopts the point of view of the external observer. In a nutshell, according to Turing, if a human being is unaware that they are interacting with a machine and thinks they are interacting with another human being, then the machine can be defined as intelligent. This position has led research to focus on the performances of the system and not on the origin of cognitive phenomena. With EGO, we hope to contribute to filling the void that has been created in this way.",
    "summary": "```json\n{\n  \"core_summary\": \"### üéØ Ê†∏ÂøÉÊ¶ÇË¶Å\\n\\n> **ÈóÆÈ¢òÂÆö‰πâ (Problem Definition)**\\n> *   ËÆ∫ÊñáÊó®Âú®ÂΩ¢ÂºèÂåñÂü∫‰∫éÁªèÈ™åÁöÑËÆ§Áü•ËøáÁ®ãÊ®°ÂûãÔºå‰ªéÁîüÁâ©Á≥ªÁªüËá™Ë∫´ÔºàËÄåÈùûÂ§ñÈÉ®ËßÇÂØüËÄÖÔºâÁöÑËßÜËßíÂá∫ÂèëÔºåËß£ÂÜ≥Â¶Ç‰ΩïÊ®°ÊãüÁ•ûÁªèÂÖÉÈõÜÂêàÂäüËÉΩÁöÑËá™ÊåáÊÄßÈóÆÈ¢ò„ÄÇ\\n> *   ËØ•ÈóÆÈ¢òÂØπÁêÜËß£ÁîüÁâ©ËÆ§Áü•ÁöÑÊú¨Ë¥®Êú∫Âà∂Ëá≥ÂÖ≥ÈáçË¶ÅÔºåÁ™ÅÁ†¥‰∫Ü‰º†ÁªüËÆ§Áü•Ê®°ÂûãÔºàÂ¶ÇPerceptual Symbol Systems, PSSÔºâÁöÑÂ±ÄÈôêÊÄßÔºåÂ∞§ÂÖ∂Âú®Ëß£ÈáäÁ¨¶Âè∑ÂΩ¢Êàê„ÄÅËÆ∞ÂøÜÂíåÈÄâÊã©ÊÄßÊ≥®ÊÑèÁ≠âËÆ§Áü•Áé∞Ë±°Êó∂ÂÖ∑ÊúâÁêÜËÆ∫‰ª∑ÂÄº„ÄÇ\\n\\n> **ÊñπÊ≥ïÊ¶ÇËø∞ (Method Overview)**\\n> *   ÊèêÂá∫‰∏ÄÁßçÁß∞‰∏∫ÁéØÂ¢ÉÁîüÊàêÁÆóÂ≠êÔºàEnvironment Generative Operator, EGOÔºâÁöÑÁÆóÊ≥ïÊ°ÜÊû∂Ôºå‰ΩøÁî®Ëá™ÊåáÊÄßËØ≠Ë®ÄE-languageÊ®°ÊãüÁ•ûÁªèÂÖÉÈõÜÂêàÁöÑÊìç‰ΩúÔºåÈÄöËøáÁª¥Êä§ÁîüÂëΩÂπ≥Ë°°Ôºàvital equilibriaÔºâÈ©±Âä®ËÆ§Áü•ËøáÁ®ã„ÄÇ\\n\\n> **‰∏ªË¶ÅË¥°ÁåÆ‰∏éÊïàÊûú (Contributions & Results)**\\n> *   **Ëá™ÊåáÊÄßËØ≠Ë®ÄËÆæËÆ°**ÔºöE-languageËÉΩÂêåÊó∂Ë°®Á§∫ÈõÜÂêàÂíåÈÄªËæëÂëΩÈ¢òÔºåÊîØÊåÅÁ•ûÁªèÂÖÉÈõÜÂêàÈó¥ÂÖ≥Á≥ªÁöÑËá™ÊàëËØÑ‰º∞ÔºàÂ¶Ç`{X=Y}`ÔºâÔºåÂπ∂ÈÄöËøáÊï∞Â≠¶ËØÅÊòéÂÖ∂ÂÆåÂ§áÊÄßÔºàSupplementary Material 1Ôºâ„ÄÇ\\n> *   **EGO-PÂéüÂûãÂÆûÁé∞**ÔºöÈÄöËøáÂàÜÁ±ªÔºàcategorizationÔºâÂíåÁ®≥ÊÄÅÈÄíÂΩíÔºàhomeostatic recursionÔºâÊú∫Âà∂ÔºåÊàêÂäüÊ®°Êãü‰∫ÜÊÑüÁü•Á¨¶Âè∑„ÄÅÂØπË±°„ÄÅËÆ∞ÂøÜÁ≠âËÆ§Áü•Áé∞Ë±°Ôºå‰∏éÁîüÁâ©ËÆ§Áü•ËøáÁ®ãÁêÜËÆ∫‰∏ÄËá¥„ÄÇ\\n> *   **ÁêÜËÆ∫Êï¥Âêà**ÔºöÁªü‰∏Ä‰∫ÜMaturanaÁöÑËá™ÁªÑÁªáÁêÜËÆ∫„ÄÅHebbÁöÑÁ•ûÁªèÂÖÉÈõÜÂêàÁêÜËÆ∫ÂíåDamasioÁöÑÁ®≥ÊÄÅÁêÜËÆ∫ÔºåËß£ÂÜ≥‰∫ÜPSS‰∏≠Á¨¶Âè∑ÂΩ¢Êàê‰∏éÂä®Êú∫ËÑ±ËäÇÁöÑÈóÆÈ¢ò„ÄÇ\",\n  \"algorithm_details\": \"### ‚öôÔ∏è ÁÆóÊ≥ï/ÊñπÊ°àËØ¶Ëß£\\n\\n> **Ê†∏ÂøÉÊÄùÊÉ≥ (Core Idea)**\\n> *   ËÆ§Áü•ËøáÁ®ãË¢´Âª∫Ê®°‰∏∫Á≥ªÁªü‰∏∫Áª¥ÊåÅÁîüÂëΩÂπ≥Ë°°ËÄåÂØπÁéØÂ¢ÉÊâ∞Âä®ÔºàperturbationsÔºâÁöÑÂèçÂ∫î„ÄÇE-languageÁöÑÂ≠óÁ¨¶‰∏≤ÂØπÂ∫îÁ•ûÁªèÂÖÉÈõÜÂêàÔºàassembliesÔºâÔºåÂÖ∂Ëá™ÊåáÊÄßÂÖÅËÆ∏ÈõÜÂêàÈó¥ÂÖ≥Á≥ªÈÄöËøáÈÄªËæëËøêÁÆóÔºàÂ¶ÇNANDÔºâÂä®ÊÄÅÁîüÊàê„ÄÇ\\n\\n> **ÂàõÊñ∞ÁÇπ (Innovations)**\\n> *   **‰∏éPSSÁöÑÂØπÊØî**ÔºöPSS‰æùËµñÂ§ñÈÉ®ËßÇÂØüËÄÖÁöÑ‚ÄúÈÄâÊã©ÊÄßÊ≥®ÊÑè‚ÄùÁîüÊàêÁ¨¶Âè∑ÔºåËÄåEGOÈÄöËøáÂÜÖÈÉ®Á®≥ÊÄÅÈ©±Âä®Ëá™ÁªÑÁªáËøáÁ®ã„ÄÇ\\n> *   **Ëá™ÊåáÊÄßÂÆûÁé∞**ÔºöÂÆö‰πâÁ•ûÁªèÁä∂ÊÄÅÔºàneural statesÔºâ‰∏∫Âü∫‰∫éÁ©∫ÈõÜ`‚àÖ`ÁöÑÊúâÈôêÈõÜÂêàÔºåÈÄöËøáÈÄíÂΩíÊûÑÈÄ†Á≠âÂºèËØÑ‰º∞Âô®ÔºàÂ¶Ç`{X=Y}`ÔºâÂÆûÁé∞ÂÖ≥Á≥ªÂà§Êñ≠ÔºàËá™ÊåáÂÆöÁêÜÔºâ„ÄÇ\\n\\n> **ÂÖ∑‰ΩìÂÆûÁé∞Ê≠•È™§ (Implementation Steps)**\\n> 1.  **Á•ûÁªèÁä∂ÊÄÅÂÆö‰πâ**ÔºöÂü∫‰∫éHebbÁöÑÈõÜÂêàÁêÜËÆ∫ÔºåÁ•ûÁªèÁä∂ÊÄÅ`X`ÂèØÈÄíÂΩíÊûÑÈÄ†‰∏∫`{‚àÖ,...,‚àÖ}`Êàñ`{X‚ÇÅ,...,X‚Çô}`ÔºàÂÆö‰πâ1Ôºâ„ÄÇ\\n> 2.  **ÂÖ≥Á≥ªËØÑ‰º∞**ÔºöÂØπ‰ªªÊÑèÁ•ûÁªèÁä∂ÊÄÅ`X,Y`ÔºåÁîüÊàê`{X=Y}`Âπ∂È™åËØÅÂÖ∂ÊòØÂê¶‰∏∫ÈáçË®ÄÂºè/ÁüõÁõæÂºèÔºàÁ§∫‰æã3-4Ôºâ„ÄÇ\\n> 3.  **Á®≥ÊÄÅÈÄíÂΩí**Ôºö\\n>     - **ManipulationÈò∂ÊÆµ**ÔºöÁî®Êâ∞Âä®ÂêéÁöÑÂÜÖÈÉ®Áä∂ÊÄÅÔºàZÔºâÈáçÊûÑÁ¨¶ÂêàÁªÑÁªáÁöÑÁ±ªÂà´`C(M)`ÔºàÂõæ5Ôºâ„ÄÇ\\n>     - **BehaviourÈò∂ÊÆµ**ÔºöÈÄöËøáÊ∑ªÂä†ÂÅ∂ÁÑ∂ÊàêÂëòÔºàAccÔºâÁîüÊàêÂÖ∑‰ΩìÂÆû‰æã‰ª•ÊÅ¢Â§çÂπ≥Ë°°ÔºàÂõæ6a-6bÔºâ„ÄÇ\\n\\n> **Ê°à‰æãËß£Êûê (Case Study)**\\n> *   Ëã•`X={‚àÖ}`Ôºå`Y={‚àÖ,{‚àÖ}}`ÔºåÂàô`{X=Y}`Â±ïÂºÄ‰∏∫`{{{‚àÖ}}‚â°{‚àÖ,{‚àÖ}}}‚àß{{‚àÖ‚â°‚àÖ}‚àß{‚àÖ‚â°{‚àÖ}}}`ÔºåÊúÄÁªà‰∏∫ÁüõÁõæÂºèÔºåË°®Êòé`X‚â†Y`ÔºàÁ§∫‰æã4Ôºâ„ÄÇ\\n> *   ÂàÜÁ±ªËøáÁ®ãÁ§∫‰æãÔºöÈõÜÂêà`U={‚àÖ,{{‚àÖ}},{‚àÖ,{{‚àÖ}}}}`Âíå`V={{‚àÖ},{{‚àÖ}}}`ÁöÑÂÖ±ÂêåÂ±ûÊÄßÊòØ`{{‚àÖ}}`Âíå`‚àÖ`ÔºåÂÖ∂Á±ªÂà´‰∏∫`{{{‚àÖ}},‚àÖ}`ÔºàÂõæ2Ôºâ„ÄÇ\",\n  \"comparative_analysis\": \"### üìä ÂØπÊØîÂÆûÈ™åÂàÜÊûê\\n\\n> **Âü∫Á∫øÊ®°Âûã (Baselines)**\\n> *   Perceptual Symbol Systems (PSS)\\n> *   Reinforcement Learning (RL) ÊñπÊ≥ï\\n> *   Hyperdimensional Computing (HDC)/Vector Symbolic Architectures (VSA)\\n\\n> **ÊÄßËÉΩÂØπÊØî (Performance Comparison)**\\n> *   **Âú®Á¨¶Âè∑Ëá™ÊåáÊÄß‰∏ä**ÔºöEGO-PÈÄöËøáE-languageÁöÑ`{X=Y}`ÁªìÊûÑÁõ¥Êé•ÂÆûÁé∞ÂÖ≥Á≥ªËØÑ‰º∞ÔºåËÄåPSSÈúÄ‰æùËµñÂ§ñÈÉ®ÂÆö‰πâÁöÑ‚ÄúÈÄâÊã©ÊÄßÊ≥®ÊÑè‚ÄùÊú∫Âà∂ÔºåÂêéËÄÖÊó†Ê≥ïËß£ÈáäÁ¨¶Âè∑ÁöÑËá™ÊàëÂÖ≥ËÅîÊÄß„ÄÇ\\n> *   **Âú®Âä®Êú∫Êï¥Âêà‰∏ä**ÔºöEGO-PÂ∞ÜËÆ§Áü•ËøáÁ®ã‰∏éÁîüÂëΩÂπ≥Ë°°ÔºàÂ¶ÇDamasioÁöÑÁ®≥ÊÄÅÁêÜËÆ∫ÔºâÁªëÂÆöÔºåËÄåRLÊñπÊ≥ï‰ªÖÈÄöËøáÂ•ñÂä±ÂáΩÊï∞Èó¥Êé•Ê®°ÊãüÂä®Êú∫ÔºåÂØºËá¥Á¨¶Âè∑ÂΩ¢Êàê‰∏éÁõÆÊ†áËÑ±ËäÇ„ÄÇ\\n> *   **Âú®ÁªìÊûÑÂåñË°®Á§∫‰∏ä**ÔºöHDC/VSAÈúÄÈ¢ÑËÆæÊï∞ÊçÆ‰∏éÁªëÂÆöÁöÑÂàÜÁ¶ªÔºåËÄåEGO-PÈÄöËøáÂàÜÁ±ªËøáÁ®ãËá™ÁÑ∂ÁîüÊàêÂ±ÇÁ∫ßÂÖ≥Á≥ªÔºàÂ¶Ç`C(U,V)={{{‚àÖ}},‚àÖ}`ÔºâÔºåÈÅøÂÖç‰∫ÜÁªÑÂêàÁàÜÁÇ∏ÔºàSupplementary Material 1bÔºâ„ÄÇ\",\n  \"keywords\": \"### üîë ÂÖ≥ÈîÆËØç\\n\\n*   Ëá™ÊåáÁÆóÊ≥ï (Self-Referential Algorithm, N/A)\\n*   Á•ûÁªèÂÖÉÈõÜÂêà (Neuronal Assemblies, N/A)\\n*   ÁéØÂ¢ÉÁîüÊàêÁÆóÂ≠ê (Environment Generative Operator, EGO)\\n*   EËØ≠Ë®Ä (E-language, N/A)\\n*   Á®≥ÊÄÅÈÄíÂΩí (Homeostatic Recursion, N/A)\\n*   ÊÑüÁü•Á¨¶Âè∑Á≥ªÁªü (Perceptual Symbol Systems, PSS)\\n*   ËÆ§Áü•Âª∫Ê®° (Cognitive Modeling, N/A)\\n*   ‰∏§ÂÄºÈÄªËæë (Two-Valued Logic, N/A)\"\n}\n```"
}