{
    "source": "ArXiv (Semantic Scholar未收录)",
    "arxiv_id": "2507.14109",
    "link": "https://arxiv.org/abs/2507.14109",
    "pdf_link": "https://arxiv.org/pdf/2507.14109.pdf",
    "title": "An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting",
    "authors": [
        "Xinyu Cao",
        "Bimal Adhikari",
        "Shangqing Zhao",
        "Jingxian Wu",
        "Yanjun Pan"
    ],
    "categories": [
        "cs.CR",
        "cs.LG"
    ],
    "publication_date": "未找到提交日期",
    "venue": "暂未录入Semantic Scholar",
    "fields_of_study": "暂未录入Semantic Scholar",
    "citation_count": "暂未录入Semantic Scholar",
    "influential_citation_count": "暂未录入Semantic Scholar",
    "institutions": [
        "University of Oklahoma",
        "University of Arkansas"
    ],
    "paper_content": "# An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting\n\nXinyu Cao∗1 Bimal Adhikari∗2 Shangqing Zhao1 Jingxian $\\mathrm { \\Delta W u ^ { 2 } }$ Yanjun Pan2 $^ * \\mathrm { C o }$ -First Authors 1University of Oklahoma, Norman, OK 2University of Arkansas, Fayetteville, AR 1{xinyu.cao-1, shangqing}@ou.edu 2{bimala, wuj, yanjunp}@uark.edu\n\nAbstract—Radio frequency (RF) fingerprinting, which extracts unique hardware imperfections of radio devices, has emerged as a promising physical-layer device identification mechanism in zero trust architectures and beyond 5G networks. In particular, deep learning (DL) methods have demonstrated state-of-the-art performance in this domain. However, existing approaches have primarily focused on enhancing system robustness against temporal and spatial variations in wireless environments, while the security vulnerabilities of these DL-based approaches have often been overlooked. In this work, we systematically investigate the security risks of DL-based RF fingerprinting systems through an adversarial-driven experimental analysis. We observe a consistent misclassification behavior for DL models under domain shifts, where a device is frequently misclassified as another specific one. Our analysis based on extensive real-world experiments demonstrates that this behavior can be exploited as an effective backdoor to enable external attackers to intrude into the system. Furthermore, we show that training DL models on raw received signals causes the models to entangle RF fingerprints with environmental and signal-pattern features, creating additional attack vectors that cannot be mitigated solely through postprocessing security methods such as confidence thresholds.\n\nIndex Terms—Security, RF fingerprinting, Impersonation attacks, Deep learning\n\n# I. INTRODUCTION\n\nThe proliferation of wireless devices and the expansion of beyond 5G networks have significantly increased the demand for reliable and secure device authentication methods. Radio frequency (RF) fingerprinting, which extracts the intrinsic hardware characteristics of radio devices, offers a promising physical-layer approach for device identification and authentication. RF fingerprinting is inherently difficult to forge or spoof, making it a valuable complement to traditional cryptographic-based security mechanisms. Due to its unique ability to distinguish devices based on their hardware signatures and its resistance to forgery, RF fingerprinting is envisioned as a key enabler for zero trust architectures and continuous device authentication and access control in 5G and beyond wireless networks [1], [2].\n\nRecently, deep learning (DL)-based approaches have emerged as state-of-the-art techniques for RF fingerprint-based device identification, thanks to their superior performance and ease of deployment [3]–[10]. Most existing research in this area focuses on improving system robustness against temporal and spatial variations in wireless environments. For example, multi-day training [9], data augmentation [6], artificial amplification of hardware features [4], [7], novel neural network architectures [5], [8], and domain adaptation techniques such as transfer learning [10] have been introduced to improve robustness. Although these advances have strengthened the resilience of DL models for RF fingerprinting, the security aspects of these DL-based approaches have often been overlooked. Despite the fact that the RF fingerprint observed by a receiver is uniquely shaped by the pairwise characteristics of the transceiver pair, which makes it difficult to reproduce or replay, integrating DL models introduces a new attack surface that can potentially become the system’s weakest link.\n\nIn particular, we have observed a consistent misclassification behavior in such DL-based RF fingerprinting systems, where a given device is frequently identified as another specific one under domain shifts [3]–[10]. Figure 1 illustrates the typical performance of convolutional neural network (CNN)-based device identification systems using RF fingerprinting [4]–[8]. These systems commonly take raw received signals as input to a CNN trained to maximize classification accuracy. As shown in Fig. 1(a), the model performs effectively when evaluated on data collected at time $( t _ { 1 } )$ and location $( l _ { 1 } )$ as the training set. However, when tested on data gathered at a different time $( t _ { 2 } )$ or location $( l _ { 2 } )$ , performance often degrades significantly. The confusion matrix in Fig. 1(b) reflects this degradation and the consistent misclassification behavior: while some devices may still be correctly identified with high confidence, others are consistently misclassified, often into specific incorrect classes. For instance, device 2 is consistently misclassified as device 4 with a high probability (often exceeding $90 \\%$ ) in Fig. 1(b). This misclassification behavior occurs because CNNs tend to learn features that are highly specific to the training domain, making it difficult to generalize across variations in the data distribution caused by changes in time, location, or environmental conditions. From a security perspective, however, this misclassification pattern can be exploited as an unintended backdoor, potentially enabling impersonation attacks for external adversaries and thereby undermining the system’s security.\n\nIn this work, we fill a fundamental gap between the promises of RF fingerprinting and the practical realities of deploying DL models in dynamic, adversarial wireless environments through a comprehensive, adversarial-driven experimental analysis. We consider practical replay and naive impersonation attacks executed by external adversaries with no additional knowledge or technological advantage beyond standard equipment. The main contributions of this work are threefold and summarized as three key remarks, illustrated in Fig. 2.\n\n![](images/f1233a4cc55e3cfc25d40deb7ee3b1820105041d75d3d2c834077ed23ec6860c.jpg)  \nFig. 1: Illustration of typical performance of CNN-based device identification systems for four devices: (a) trained at time $t _ { 1 }$ and location $l _ { 1 }$ ; (b) tested at a different time $( t _ { 2 } )$ or location $( l _ { 2 } )$ .\n\n• To the best of our knowledge, we are the first to systematically evaluate DL-based RF fingerprinting systems from a security perspective. Unlike prior works that primarily focus on classification accuracy and domain robustness, we reveal a critical and underexplored vulnerability: the consistent misclassification behavior of CNN models under domain shifts can be exploited an effective backdoor to enable external attackers to launch impersonation attacks and intrude into the system. • Our extensive in-lab experimental results show that CNNs trained on raw received signals inadvertently entangle hardware-specific, hard-to-forge RF fingerprints with easy-to-reproduce environmental and signal-pattern features. This entanglement further renders the system highly vulnerable to impersonation attacks, even when the attacker lacks prior knowledge or channel control. Our evaluation of a commonly used security patch based on softmax confidence thresholding for CNNs demonstrates that it provides insufficient protection against impersonation attacks. Our findings highlight that the vulnerability stemming from the CNN’s inability to disentangle hardware-specific features from spatiotemporal artifacts in wireless signals cannot be mitigated by post-processing techniques alone. Instead, carefully designed signal preprocessing methods are required to fully leverage the security potential of RF fingerprints.\n\nThe reminder of this paper is organized as follows: In Sec. II, we provide background and motivation for this work, followed by the system and threat models defined in Sec. III. Section IV describes the experimental setup, and Sec. V presents the security evaluation of the CNN-based RF fingerprinting system. We discuss potential future directions in Sec. VI and conclude the paper in Sec. VII.\n\n![](images/cbb05308be11f81d45bb5c1055dd79bb24750a27afcfea0dc572a1277aaafed9.jpg)  \nFig. 2: The investigated CNN-based RF fingerprinting architecture.\n\n# II. BACKGROUND AND MOTIVATION\n\n# A. Input/Output Modeling with RF Fingerprints\n\nThe transmitted data, denoted as $x [ n ]$ , adheres to protocol standards and includes various components such as headers, preambles, and payloads. Due to unavoidable manufacturing imperfections in the transmitter’s hardware, such as filters, oscillators, and clocks, the emitted signal subtly deviates from the ideal. These deviations result in unique, device-specific signal characteristics, known as RF fingerprints. Common RF fingerprints include carrier frequency offset (CFO), inphase/quadrature (I/Q) imbalance, DC offset, phase noise, turnon transients, and error vector magnitude (EVM) [4]. These features are typically consistent over time for a given device and can be exploited for reliable identification.\n\nConsidering the effects of CFO, phase offset, and IQ imbalance at both the transmitter and receiver, as well as the wireless channel, and assuming that the $L$ -length channel is quasistatic over the duration of an OFDM symbol (i.e., allowing the channel to be modeled as time-invariant within the symbol duration) we can represent the time-domain baseband signal of an OFDM symbol at the receiver as [11]\n\n$$\n\\begin{array} { r l } & { y [ n ] = \\eta e ^ { - j \\left( n \\Delta \\omega _ { R T } T _ { s } + \\psi _ { R T } \\right) } r [ n ] } \\\\ & { ~ + \\kappa e ^ { j \\left( n \\Delta \\omega _ { R T } T _ { s } + \\psi _ { R T } \\right) } r ^ { * } [ n ] + w [ n ] } \\end{array}\n$$\n\nwhere $n = 0 , 1 , \\ldots , N - 1 , T _ { s }$ is the sampling period of the OFDM system, and $w [ n ]$ is additive white Gaussian noise. $r [ n ] = \\sum _ { l = 0 } ^ { L - 1 } h [ l ] x [ n - l ]$ , the composite time-varying $\\mathrm { C S I } \\ h [ l ] =$ $p _ { T } ( n T \\dot { s } ) \\stackrel { \\textstyle > } { \\otimes } g ( n T s , l T _ { s } ) \\otimes p _ { R } ( n T s )$ includes the transmit filter $p _ { T } ( t )$ , the receive filter $p _ { R } ( t )$ , and the time-varying impulse response of the physical fading channel $g ( t , \\tau )$ . The composite CFO is $\\Delta \\omega _ { R T } = \\Delta \\omega _ { R } - \\Delta \\omega _ { T }$ , and the composite phase offset is $\\psi _ { R T } = \\psi _ { R } - \\psi _ { T }$ . The parameters $\\eta = \\left( \\alpha _ { R } \\alpha _ { T } + \\beta _ { R } \\beta _ { T } ^ { * } \\right)$ , $\\kappa =$ $( \\alpha _ { R } \\beta _ { T } + \\beta _ { R } \\alpha _ { T } ^ { * } )$ , where $\\alpha _ { ( \\cdot ) }$ and $\\beta _ { ( \\cdot ) }$ represent the effects of IQ imbalance of either the transmitter or the receiver. W.l.o.g, for the transmitter $\\alpha _ { T } = \\cos ( \\Delta \\phi _ { T } ) + j \\epsilon _ { T } \\sin ( \\Delta \\phi _ { T } )$ and $\\beta _ { T } =$ $\\epsilon _ { T } \\cos ( \\Delta \\phi _ { T } ) - j \\sin ( \\Delta \\phi _ { T } )$ , where $\\epsilon _ { T }$ and $\\Delta \\phi _ { T }$ represent the amplitude and phase differences between the transmitter’s IQ branches.\n\nEquation (1) shows that the RF fingerprint observed by a receiver such as an access point (AP) is uniquely shaped by the pairwise characteristics of the transceiver pair. As a result, it is generally considered difficult to reproduce or replay RF fingerprints. This is because any replaying device introduces its own hardware impairments, which distort the composite RF fingerprint perceived by the AP. Hence, the replay attack is widely believed to have limited effectiveness.\n\n# B. Vulnerability Analysis\n\nState-of-the-art DL-based RF fingerprinting and device identification approaches have primarily focused on enhancing system robustness against temporal and spatial variations in wireless environments [4]–[10]. However, these works often neglect thorough security evaluations of the systems themselves. Although the inherent uniqueness of RF fingerprints makes forging another device’s signal challenging, the DL model can become the system’s weakest link. Specifically, we observed a consistent misclassification behavior in DL models, where a device is frequently misclassified as another specific device under domain shifts, as illustrated in Fig. 1(b). This behavior can unintentionally introduce exploitable vulnerabilities. Despite the physical uniqueness of RF fingerprints making forgery difficult, this recurrent misclassification, shown in several prior works [4]–[8], creates a new attack surface that adversaries may exploit for impersonation attacks. This vulnerability exposes a critical gap in current DL-based RF fingerprinting research, i.e., the security implications of the learned feature representations remain insufficiently explored. To address this gap, in this work, we conduct a comprehensive, adversarial-driven experimental analysis by considering two straightforward and practical yet later proven effective attacks.\n\n# III. SYSTEM AND THREAT MODELS\n\nThis section defines the system and threat models, including the two practical attacks that we use to evaluate the security of DL-based RF fingerprinting and device identification systems.\n\n# A. RF Fingerprint-based Device Identification Systems\n\nRF fingerprint-based device identification and management systems typically involve a receiver, usually a radio AP, that aims to identify and authenticate any transmitter attempting to establish a communication link. For instance, in 5G and beyond wireless networks, the base station (BS), which acts as a fixed receiver and serves as the AP to the network, must authenticate any user equipment (UE) attempting to connect. This process involves two main phases: fingerprinting and identification.\n\nDuring the fingerprinting phase, the AP requires each transmitter to send signals in accordance with the communication protocol for a certain period during its first access attempt to the network. The AP can either process the received signal to explicitly extract RF fingerprints for input into a classification model, or directly input the received IQ samples into a model for classification. In this work, we adopt the second approach as in state-of-the-art systems, the AP directly feeds the raw IQ signals into a DL model such as a CNN for fingerprinting [4], [5], [8], [10]. An illustration of the investigated CNN-based RF fingerprinting architecture is shown in Fig. 2.\n\nDuring the identification phase, when a transmitter seeks to connect to the AP, the AP collects its transmitted radio signals and performs identification with the pretrained DL model for RF fingerprinting. Based on the classification outcome, the AP either authenticates the device and permits connection establishment, or denies access.\n\n# B. Threat Model\n\nWe consider an external attacker attempting to compromise an RF fingerprint-based device identification system. The attacker’s goal is to impersonate an authorized device in order to gain unauthorized access to the network. We assume a practical attacker with no additional knowledge or technological advantage beyond standard equipment. The attacker is located away from the AP and legitimate transmitters.\n\nThe attacker’s capabilities are limited to passively collecting signals emitted by the legitimate transmitters over the air during both the fingerprinting and identification phases. The attacker then either replays these captured signals or transmits synthesized signals from its own transmitter to bypass the DLbased device identification system. The attacker cannot control the communication channel between the AP and any legitimate transmitter, nor inject false data to disrupt the AP’s model training. We consider the following two attack scenarios:\n\nReplay attack: The attacker records signals emitted by legitimate transmitters during the fingerprinting phase and replays them during the identification phase to fool the DLbased authentication system.\n\nNaive impersonation attack: During the identification phase, the attacker simply transmits signals that mimic the format used by legitimate devices during CNN model training (e.g., preambles or random payloads) using its own transmitter.\n\n# IV. IN-LAB EXPERIMENTAL SETUP\n\nWe conduct an adversarial-driven experimental study on a CNN-based device identification system using IQ samples collected from an in-lab testbed. The testbed consists of 6 USRP X300 SDRs, each equipped with a UBX-160 daughterboard operating at a center frequency of $5 . 7 8 \\ \\mathrm { G H z }$ and a sampling rate of $1 9 2 ~ \\mathrm { K H z }$ . In each experiment, four of these USRPs act as legitimate transmitters (TXs), one as the attacker (Eve), and one as the AP. All devices are connected to the same host computer equipped with an AMD Ryzen 9 9950X CPU, 96 GB RAM, 6 TB storage, and an NVIDIA RTX 4090 GPU.\n\nAll transmitters emit IEEE 802.11a-compliant OFDM frames using QPSK modulation, generated via GNU Radio. Each transmitted frame has a fixed length and contains three OFDM symbols, including a header with CRC, a cyclic prefix, and payload data. Two types of frames are used: those with fixed payloads (referred to as repeated signals) and those with random payloads (referred to as random signals). The AP is a fixed-endpoint USRP that collects raw IQ samples from all transmitters. Eve is another fixed-endpoint USRP positioned approximately $2 \\mathrm { m }$ away from the AP. During the fingerprinting phase, when the AP collects signals from each transmitter, Eve simultaneously records the raw IQ samples she receives.\n\nAll experiments are conducted in an indoor lab environment under non-line-of-sight (NLoS) conditions only, i.e., there is no direct path between any transmitter–receiver pair. The distances between transmitter–receiver pairs vary and can extend up to $1 8 \\mathrm m$ . This NLoS setting introduces significant multipath fading and spatiotemporal channel fluctuations, providing sufficient data diversity for CNN training.\n\nIn each experiment, we collect three sets of 8 million IQ samples per transmitter at both the AP and Eve. This entire collection process is repeated two hours later. The initial dataset is used for training, while the second dataset is reserved for testing. The datasets used for system performance evaluation are categorized as the training set (TrS), the testing set (TeS), and the attacking set (AS), as detailed below.\n\n• TrS 1: Collected on Day 1 at time $t _ { 1 }$ , with TXs sending   \nrandom signals at location $l _ { 1 }$ . • TeS 1: Collected on Day 1 at time $t _ { 2 }$ , with TXs sending   \nrandom signals at location $l _ { 2 }$ . TrS 2: Collected on Day 2 at time $t _ { 3 }$ , with TXs sending   \nrepeated signals at location $l _ { 4 }$ . TeS 2: Collected on Day 2 at time $t _ { 4 }$ , with TXs sending   \nrepeated signals at location $l _ { 4 }$ . AS 1: Collected by Eve alongside $\\mathrm { T r S ~ 1 }$ . AS 2: Collected by Eve alongside $\\mathrm { T r } \\mathrm { \\bf S \\mathrm { \\Theta } } 2$ .\n\nThe training and testing sets are collected by the AP, while the attacking sets are collected by Eve. Each training dataset is split into $70 \\%$ for training and $30 \\%$ for validation, while each testing dataset is used entirely for testing.\n\n# V. PERFORMANCE EVALUATION\n\nIn this section, we evaluate the security of the CNNbased RF fingerprinting system for device identification against replay and naive impersonation attacks.\n\n# A. Classifier Architecture\n\nIn this work, we adopt the CNN architecture presented in [5], which is a typical design consisting of eight layers including four convolutional layers followed by three fully connected (dense) layers. All input data are normalized using per-device standardization, where for each deice, we flatten its $\\mathrm { I } / \\mathrm { Q }$ data and fit using only that device’s data before being fed into the CNN model. For the input, a sliding window of frame size 4 is implemented that makes the input as $2 \\times 2 5 6$ where the I and Q components of the signal are stored in two rows of matrix. Each of the convolutional layers uses 40 filters, where the first two have kernel sizes of $1 \\times 7$ and $1 \\times 5$ , respectively, each followed by a max-pooling layer that reduces the dimensionality to $2 \\times 1 2 8 \\times 4 0$ and $2 \\times 6 4 \\times 4 0$ , respectively. These are followed by a convolution layer of size $2 \\times 7$ and max-pooling layer that further reduces the dimension to $2 \\times 3 2 \\times 4 0$ . Finally, a convolution layer of size $2 \\times 5$ is implemented followed by a flattening layer, and the final feature maps are passed through three dense layers with 1024, 256 and 4 neurons, respectively. Dropout is applied after the flattening and first dense to help prevent overfitting. The final classification layer uses softmax activation to output probabilities over 4 classes. We use Adam optimizer with a learning rate of $1 \\times 1 0 ^ { - 3 }$ to train the model.\n\n![](images/28ce4e15de05d1b29309a57e107654470dcb25e6a7737e6fccbb1f27a70fa3f7.jpg)  \nFig. 3: Confusion matrix showing the classification accuracy of the CNN model trained on $\\mathrm { T r } \\mathsf { S \\ 1 } \\mathrm { : \\Omega }$ (a) tested on TeS 1; (b) tested on AS 1.\n\n# B. Experiment Results\n\nAs Eq. (1) shows, the received signal is a complex and nonlinear combination of multiple factors, including RF fingerprints, the time- and space-varying wireless channel, the transmitted signal, and AWGN. Although the CNN is intended to learn hardware-specific RF fingerprints only, when trained directly on raw IQ data, standard neural networks, which are typically designed to learn approximately linear or piecewise linear mappings, are not well suited to extract these features directly, especially in the absence of carefully designed, domainspecific signal preprocessing techniques. Hence, the model may fail to capture the correct latent representations associated with hardware impairments. To facilitate the analysis of system performance and security, we consider two types of transmitted frames, as described in Section IV. In the following, we evaluate the system using IQ samples collected under each of these two frame types, respectively.\n\n1) Consistent misclassification behavior during domain shifts: We begin with the CNN trained using TrS 1 and test it on TeS 1 and AS 1, respectively, as existing works typically assume transmitters send random payloads [3]–[10]. Figure 3(a) shows that the device authentication accuracy of the trained model experiences a significant drop when tested on TeS 1 due to the domain shift, compared to the overall training accuracy of $9 9 . 9 5 \\%$ . In other words, when there is a domain shift between the training and testing sets, we observe a misclassification behavior of the CNN similar to that reported in the literature. For example, device 4 is frequently identified as device 3 with a probability as high as $9 8 . 7 1 \\%$ .\n\nTo verify whether this misclassification behavior of the model during domain shifts is consistent and allows Eve to easily penetrate the system by impersonating a legitimate transmitter, we show the success rate of the replay attack launched by Eve. In this untargeted attack, Eve attempts to impersonate any legitimate device by replaying AS 1. As illustrated in Fig. 3(b), we observe that Eve can successfully impersonate Devices 2, 3, and 4 with relatively high probabilities $( \\geq 9 5 \\% )$ )\n\nand an overall untargeted impersonation attack success rate of $9 5 . 9 6 \\%$ .\n\nPrior works attribute the consistent misclassification behavior of the CNN to the similarity in wireless channels experienced by certain transmitter pairs. However, since the correlation coefficients of the channel state information (CSI) for each communication pair across TrS 1, TeS 1, and AS 1 are low (significantly below 0.5, as shown in Fig. 4), yet the misclassification behavior remains consistent, we conclude that this behavior is an inherent limitation of the CNN, caused by its lack of generalization during domain shifts.\n\nRemark 1. The consistent misclassification behavior of the CNN-based device identification system is caused by the lack of generalization of the model during domain shifts, leaving the system vulnerable to untargeted impersonation attacks.\n\n2) Entangled feature maps: We then consider the case when the CNN is trained with some publicly known, fixed, or lowentropy signals such as preambles, pilots, and headers and train the CNN with TrS 2. Surprisingly, when all the transmitters repeatedly transmit the same frame, the CNN model demonstrates robust and high classification accuracy despite domain shifts, as shown in Fig. 5(a), even when the signals are collected at significantly different times and locations, and the CSI in the training and testing data is temporally and spatially distinct, similar to that in Fig. 4.\n\nDoes this mean we can simply train the CNN to learn RF fingerprints from raw IQ samples by having transmitters send a fixed signal? Unfortunately, the results in Fig. 3(b) suggest that the CNN is not learning pure RF fingerprints. Instead, some environmental and location-dependent information associated with the receiver, patterns of the transmitted signals, and the RF fingerprints are jointly preserved in the neurons. Regardless of the transmitter’s location, the signal received by the AP, which is fixed in a limited space such as a lab, is likely to pass through a limited number of scatterers, resulting in some common signal paths, especially considering that channels in typical multipath environments are dominated by 3–5 path components [12], [13]. Hence, for a transmitter whose RF fingerprint the CNN has learned, the corresponding neurons are activated, enabling the CNN to correctly identify the transmitter with high confidence even if the channel conditions change dramatically, as shown in Fig. 5(a).\n\nOn the other hand, for a transmitter with an RF fingerprint unknown to the CNN, the received signal still tends to contain common environmental characteristics associated with the AP used during training. As a result, the neurons preserving the environmental and location-dependent information of the AP are activated, causing the AP to misclassify the signal as originating from an authorized transmitter with high confidence, as shown in Fig. 5(b).\n\nTo further verify this insight, we evaluate the system’s performance against a naive impersonation attack. We consider two scenarios in which Eve transmits either random or repeated signals, mimicking those of legitimate devices using her own transmitter. The success rates of these attacks are shown in\n\n![](images/868ff74b5414d335d8caa999e0efd2d7c13b317a71b340a7a5ecdc6f44c5547f.jpg)  \nFig. 4: Correlation coefficient matrix for each communication pair: (a) between TrS 1 & TeS 1; (b) between TrS 1 & AS 1.\n\n![](images/b2a8f4aa43fea39c029d5bfc9c1c64ed15322f57c792343942e0a7438f08f733.jpg)  \nFig. 5: Confusion matrix showing the classification accuracy of the CNN model trained on $\\mathrm { T r } \\mathbf { S } \\ 2$ : (a) tested on TeS 2; (b) tested on AS 2.\n\nTable I. We observe that when Eve transmits repeated signals identical to those of $\\mathrm { T r } \\mathrm { \\bf S } \\mathrm { \\bf \\Delta } 2$ , which the CNN model is trained on, the model continues to exhibit the consistent misclassification behavior. In other words, despite Eve’s RF fingerprints being distinct from those of the authorized transmitters, the model frequently misclassifies her signals as originating from a certain legitimate device. This misclassification is likely due to the model having learned not only RF fingerprints but also environmental and signal-pattern characteristics associated with the AP and transmitted frames, which dominate the model’s performance. In contrast, when Eve performs the naive impersonation attack using random signals, the highest misclassification rate significantly drops from $9 8 . 0 6 \\%$ to $4 8 . 0 3 \\%$ , further confirming that the transmitted signal pattern plays a key role in the model’s robustness and security.\n\nTABLE I: Success rates of naive impersonation attacks   \n\n<html><body><table><tr><td rowspan=\"2\">Actual: Eve</td><td colspan=\"4\">Predicted</td></tr><tr><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>repeated signals</td><td>1.86%</td><td>0</td><td>0.09%</td><td>98.06%</td></tr><tr><td>random signals</td><td>13.8%</td><td>0.49%</td><td>48.03%</td><td>37.68%</td></tr></table></body></html>\n\nRemark 2. When the transmitted frame is deterministic, the CNN model trained with raw $I Q$ samples can partially learn RF fingerprints associated with transceivers. However, it also jointly learns environmental and location-dependent information associated with the receiver, as well as patterns in the transmitted signals. These entangled features within the trained CNN model provide significant attack opportunities for both untargeted and naive impersonation attacks.\n\n3) Thresholding CNN with softmax confidence is insufficient: A straightforward approach to enhance the security of the CNN-based device identification system is to apply a threshold on the model’s softmax confidence scores, allowing it to reject signals from Eve as unknown. However, our study shows that this method does not improve the system’s resilience to replay or naive impersonation attacks, nor does it increase robustness against domain shifts.\n\nTABLE II: Success and rejection rates of naive impersonation attacks against the CNN with softmax confidence   \n\n<html><body><table><tr><td rowspan=\"2\">Actual: Eve</td><td rowspan=\"2\">Rejection</td><td colspan=\"4\">Predicted</td></tr><tr><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>repeated signals</td><td>21.19%</td><td>0.44%</td><td>0</td><td>0.04%</td><td>99.52%</td></tr><tr><td>random signals</td><td>5.13%</td><td>11.77%</td><td>0.27%</td><td>52.4%</td><td>35.56%</td></tr></table></body></html>\n\nTable II presents the success and rejection rates of naive impersonation attacks when a confidence threshold of 0.95 is applied to the CNN’s output class probabilities via softmax. When the highest softmax score falls below this threshold, the CNN rejects the input as unknown. Comparing the results from Tables I and II, we observe that although the CNN correctly rejects some attacks, the overall rejection rate remains low $( 2 1 . 1 9 \\%$ when the transmitted signal pattern does not match, and $5 . 1 3 \\%$ when Eve transmits repeated signals). The CNN’s performance on TeS 2 and AS 2 with softmax confidence is similar to that shown in Fig. 5, with a low rejection rate in both cases. We omit the detailed results here due to page limitations. Consequently, the model’s performance remains nearly unchanged, as the jointly learned environmental and location-dependent information, along with transmitted signal patterns, still provide significant attack opportunities for Eve.\n\nRemark 3. The vulnerability caused by the lack of carefully designed signal preprocessing techniques for RF fingerprinting, combined with the limited capacity of neural networks to learn from complex and nonlinear wireless signals, means that applying post-processing security techniques such as a softmax confidence threshold to the CNN alone is insufficient to secure the system.\n\n# VI. DISCUSSION\n\nOur experimental findings necessitate the design of RF fingerprint estimation methods that can effectively disentangle device-specific hardware signatures from spatiotemporal channel and environmental artifacts. Special structures can be leveraged for estimating certain RF fingerprints, such as IQ imbalance, in a manner similar to how the CFO is estimated in WiFi standards using repeated symbols in synchronization words. Exploring hybrid models that integrate signal processing-based RF fingerprinting techniques with powerful DL architectures, such as embedding hardware impairment models or using generative models to simulate and enhance RF fingerprints, is also promising for providing robust and secure RF fingerprinting techniques. In our future work, we will design new signal processing techniques for RF fingerprinting and carefully integrate them with DL models to ensure system robustness and security.\n\n# VII. CONCLUSION\n\nWe revisited CNN-based RF fingerprinting for device identification from a security perspective through an adversarialdriven experimental study. We demonstrated that although CNN models exhibit superior classification performance, they consistently show misclassification behaviors due to limitations in generalizing across temporal and spatial domain shifts in wireless signals. Attackers can exploit these behaviors to compromise the system through simple replay and naive impersonation attacks. Moreover, training CNNs with raw IQ samples causes the models to entangle RF fingerprints with environmental and signal-pattern features, creating additional attack vectors that cannot be mitigated by applying postprocessing security techniques to the CNN alone.",
    "summary": "```json\n{\n  \"core_summary\": \"### 🎯 核心概要\\n\\n> **问题定义 (Problem Definition)**\\n> *   论文系统研究了基于深度学习（DL）的射频指纹识别（RF fingerprinting）系统在动态对抗性无线环境中的安全漏洞。\\n> *   该问题的重要性在于，尽管RF指纹识别因其硬件特征的唯一性被视为5G及未来网络中的关键设备认证机制，但现有研究主要关注系统在时间和空间变化下的鲁棒性，而忽略了深度学习模型本身引入的安全风险。\\n\\n> **方法概述 (Method Overview)**\\n> *   通过对抗性驱动的实验分析，系统评估了CNN-based RF指纹识别系统在域偏移（domain shifts）下的误分类行为及其安全影响。\\n\\n> **主要贡献与效果 (Contributions & Results)**\\n> *   **首次系统性安全评估：** 揭示了CNN模型在域偏移下的一致误分类行为可被外部攻击者利用为后门，实现高达 `95.96%` 的冒充攻击成功率。\\n> *   **特征纠缠现象：** 发现CNN在原始IQ信号训练中会混淆硬件指纹与环境/信号模式特征，导致即使攻击者无先验知识也能发起有效攻击（如重复信号攻击成功率 `98.06%`）。\\n> *   **后处理防御局限性：** 证明基于softmax置信度阈值的常见安全补丁对冒充攻击的防御效果有限（仅 `21.19%` 拒绝率）。\\n> *   **实验验证：** 在6台USRP X300 SDR构建的测试床上，采集4个合法发射器在不同时空条件下的IQ样本（共8M样本/设备）进行验证。\",\n  \"algorithm_details\": \"### ⚙️ 算法/方案详解\\n\\n> **核心思想 (Core Idea)**\\n> *   通过实验证明：当CNN直接学习原始IQ信号时，其线性/分段线性特性难以解耦硬件指纹与时空信道伪影，导致模型在域偏移下学习到可被攻击者利用的脆弱特征表示。\\n\\n> **创新点 (Innovations)**\\n> *   **与先前工作的对比：** 现有研究聚焦分类准确率提升（如通过数据增强、域适应），但未分析模型学到的特征安全性。\\n> *   **本文的改进：** 首次通过对抗性实验揭示：1) 误分类行为的一致性（如Device 4→3概率 `98.71%`）；2) 特征纠缠使攻击者仅需标准设备即可发起攻击。\\n\\n> **具体实现步骤 (Implementation Steps)**\\n> 1.  **实验设置：** 使用6台USRP X300 SDR构建测试床，采集4个合法发射器（TXs）在不同时空条件下的IQ样本（共8M样本/设备）。\\n> 2.  **CNN架构：** 采用4卷积层+3全连接层结构，输入为2×256的I/Q矩阵，使用Adam优化器（lr=1e-3）训练。\\n> 3.  **攻击模拟：** 设计重放攻击（replay）和朴素冒充攻击（naive impersonation），评估模型在攻击集（AS）上的漏洞。\\n> 4.  **信号类型：** 使用固定信号（repeated signals）和随机信号（random signals）进行对比实验。\\n\\n> **案例解析 (Case Study)**\\n> *   当CNN在随机信号训练集（TrS1）训练后测试域偏移数据（TeS1）时，Device 4被误分类为Device 3的概率达 `98.71%`；攻击者Eve重放攻击集（AS1）时可冒充任意合法设备（成功率 `95.96%`）。\\n> *   当TX发送固定信号时，模型保持高准确率但仍有特征纠缠问题，导致攻击者Eve发送重复信号时冒充Device 4的成功率高达 `98.06%`。\",\n  \"comparative_analysis\": \"### 📊 对比实验分析\\n\\n> **基线模型 (Baselines)**\\n> *   论文隐含对比了：1) 原始CNN在时空域偏移下的表现；2) 增加softmax阈值后的防御效果。\\n\\n> **性能对比 (Performance Comparison)**\\n> *   **在冒充攻击成功率上：** 原始CNN在重放攻击下达到 `95.96%` 成功率，而增加0.95置信度阈值后仅能拒绝 `21.19%` 的攻击样本。\\n> *   **在误分类率上：** 当TX发送随机信号时，域偏移导致Device 4→3误分类率高达 `98.71%`；发送固定信号时模型保持高准确率但仍有特征纠缠问题。\\n> *   **在防御效果上：** Softmax阈值对重复信号攻击的拒绝率仅 `21.19%`，对随机信号攻击的拒绝率更低（`5.13%`）。\\n> *   **在特征纠缠上：** 当TX发送固定信号时，模型能部分学习RF指纹，但仍与环境/信号模式特征纠缠，导致攻击成功率 `98.06%`。\",\n  \"keywords\": \"### 🔑 关键词\\n\\n*   射频指纹识别 (Radio Frequency Fingerprinting, RFF)\\n*   深度学习安全 (Deep Learning Security, N/A)\\n*   冒充攻击 (Impersonation Attacks, N/A)\\n*   卷积神经网络 (Convolutional Neural Network, CNN)\\n*   域偏移 (Domain Shift, N/A)\\n*   无线设备认证 (Wireless Device Authentication, N/A)\\n*   信号预处理 (Signal Preprocessing, N/A)\\n*   零信任架构 (Zero Trust Architectures, N/A)\\n*   对抗性实验 (Adversarial Experimentation, N/A)\"\n}\n```"
}